{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bd79bb-1862-4f19-b3e8-a8d827be6faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882904ff-0340-4a30-9315-5fb187698370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/DARM/darm_mujoco'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
    "os.getenv('DARM_MUJOCO_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea4d0f1-e0e8-41d0-9c7c-006cb9a9926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running generate_darm_xml.sh\n",
      "Single Finger: true\n",
      "No Wrist: true\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../mujoco_env\n",
    "bash generate_darm_xml.sh true true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6733be-66a7-4aa7-81b5-b1b28b0a0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if GCC is installed\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9d52a-a921-4b43-ab04-dd0701fb5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GCC if absent\n",
    "!sudo apt update\n",
    "!sudo apt install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c027ec5-151e-4986-a444-2107e98fb741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing darm_gym_env.egg-info/PKG-INFO\n",
      "writing dependency_links to darm_gym_env.egg-info/dependency_links.txt\n",
      "writing requirements to darm_gym_env.egg-info/requires.txt\n",
      "writing top-level names to darm_gym_env.egg-info/top_level.txt\n",
      "reading manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "writing manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_sf_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/__init__.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/multi_darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/env_test.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_sf_gym.py to darm_sf_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/multi_darm_gym.py to multi_darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_gym.py to darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/env_test.py to env_test.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "creating 'dist/darm_gym_env-0.0.1-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "darm_gym_env.__pycache__.multi_darm_gym.cpython-38: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing darm_gym_env-0.0.1-py3.8.egg\n",
      "removing '/home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg' (and everything under it)\n",
      "creating /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Extracting darm_gym_env-0.0.1-py3.8.egg to /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "darm-gym-env 0.0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Processing dependencies for darm-gym-env==0.0.1\n",
      "Searching for gym==0.21.0\n",
      "Best match: gym 0.21.0\n",
      "Adding gym 0.21.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for mujoco==2.2.2\n",
      "Best match: mujoco 2.2.2\n",
      "Processing mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "mujoco 2.2.2 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages/mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "Searching for cloudpickle==2.2.0\n",
      "Best match: cloudpickle 2.2.0\n",
      "Adding cloudpickle 2.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for numpy==1.23.4\n",
      "Best match: numpy 1.23.4\n",
      "Adding numpy 1.23.4 to easy-install.pth file\n",
      "Installing f2py script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3 script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3.8 script to /home/daniel/miniconda3/bin\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for PyOpenGL==3.1.6\n",
      "Best match: PyOpenGL 3.1.6\n",
      "Adding PyOpenGL 3.1.6 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for glfw==2.5.5\n",
      "Best match: glfw 2.5.5\n",
      "Adding glfw 2.5.5 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for absl-py==1.2.0\n",
      "Best match: absl-py 1.2.0\n",
      "Adding absl-py 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Finished processing dependencies for darm-gym-env==0.0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8b1cb4-49d2-416d-b23b-004c54cefbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mujoco import is successful\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a51788-02c3-4cac-a869-8f62b25d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If mujoco import fails, update pandas and restart runtime\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047544b-c26e-4ef2-8b41-4b7fe8ae79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GLFW is missing\n",
    "%%bash\n",
    "sudo apt-get install libglfw3 -y\n",
    "sudo apt-get install libglfw3-dev -y\n",
    "pip install --user glfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a012c8-fe11-44e5-ada6-5c7b50405c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea66991b-3d7c-4e2e-8133-c5f358fa797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from darm_gym_env import DARMEnv\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "from stable_baselines3.common.vec_env.vec_normalize import VecNormalize\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.callbacks import CallbackList, EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7b4bbe-9994-4dc5-b212-c0f5d6ca25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"SF_SB3_SAC_4\"\n",
    "\n",
    "config = {\n",
    "    \"env_id\": \"darm/DarmHand-v0\", # changed from SF\n",
    "    \"single_finger_env\": True,\n",
    "    \"algo\": \"SAC\",\n",
    "    \"rl_lib\": \"SB3\",\n",
    "    \n",
    "    \"seed\": 0,\n",
    "    \"mean_reward_thresh\": 1_300,\n",
    "    \"total_timesteps\": 10_000_000,\n",
    "    \"pi_net_arch\": [32, 256, 256, 64],\n",
    "    \"qf_net_arch\": [32, 256, 256, 64],\n",
    "    \"learning_starts\": 40_000,\n",
    "    \"num_cpu\": 6,\n",
    "    \n",
    "    \"eval_freq\": 2_000, # 5_000\n",
    "    \"max_no_improvement_evals\": 10,\n",
    "    \"no_improvement_min_evals\": 20,\n",
    "    \n",
    "    \"log_interval\": 20, # episodes\n",
    "    \"wandb_model_save_freq\": 2_000, #5_000 timesteps?\n",
    "    \n",
    "    \"run_local_dir\": f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/darm_sf_hand/{run_name}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bdd726-0edc-4e6b-8c4b-b679c56ce71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/wandb/run-20230302_145847-jfvnsuje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">test1_SF_SB3_SAC_4</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = \"\"\"\n",
    "- The environment was updated such that the target is within a range from the start point\n",
    "- Velocity penalty was removed and only effort penalty was used\n",
    "- The reward function was updated according to the reach task reward used in facebookresearch/myosuite [https://github.com/facebookresearch/myosuite/blob/main/myosuite/envs/myo/reach_v0.py]\n",
    "- The done signal is trigerred only when the fingertip goes beyond a threshold. The episode continues to the maximum timestep otherwise.\n",
    "- The friction and damping coefficient of the environment is updated. Values are inspired from Deepmind's Mujoco Menagerie [https://github.com/deepmind/mujoco_menagerie/blob/main/shadow_hand/right_hand.xml]\n",
    "- The range of action from the model was changed to [-1, 1]. This action is mapped to the actual action sent to mujoco e.g [0, 2]]. This change is inspired from values used in OpenAI's Gym Mujoco environments.\n",
    "- max_episode_steps was updated to 200.\n",
    "- Velocity vector (size [3,]) was added to observation. Observation size is now (9,)\n",
    "- Action range was increased to [0, 5]\n",
    "<Changes: ID 3>\n",
    "- Observation warpper to scale observation from m and m/s to cm and cm/s was applied\n",
    "<Changes: ID 4>\n",
    "- Max Tension for Digitorum Extensor Communis was increased to 10\n",
    "- FIXED: Velocity Observation from (prev_pos - new_pos)/time to (new_pos - prev_pos)/time\n",
    "- FIXED: Removed weight of 1 from 'sparse', 'solved', and 'done' in reward weighting\n",
    "- Reduced max_target_th to 5*0.004, 20 mm\n",
    "\n",
    "- Single-Finger; No Wrist Environment\n",
    "- This run was trained on vast_ai using SB3's SAC algo.\n",
    "\"\"\"\n",
    "\n",
    "tags = [\"single_finger\", \"sac\", \"sb3\", \"vast_ai\"]\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"DARM\",\n",
    "    name=run_name,\n",
    "    tags=tags,\n",
    "    notes=notes,\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    # monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "376efc5a-273e-4074-ad31-329575675bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import TransformObservation\n",
    "# from gym.wrappers import RescaleAction\n",
    "\n",
    "create_env = lambda: TransformObservation(gym.make(config[\"env_id\"], single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87846de9-eca5-498d-a18d-c41b9363b5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "NUM_CPU = config[\"num_cpu\"]\n",
    "\n",
    "env = make_vec_env(create_env, n_envs=NUM_CPU, seed=config[\"seed\"])\n",
    "# env = VecNormalize(env)   #FIXME: Remember to save norm params if using VecNorm env\n",
    "# env = VecMonitor(env)\n",
    "\n",
    "policy_kwargs = dict(net_arch=dict(pi=config[\"pi_net_arch\"], qf=config[\"qf_net_arch\"]))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1,\n",
    "            learning_starts=config[\"learning_starts\"],\n",
    "            gradient_steps=NUM_CPU, # num of envs\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log=config['run_local_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665027f7-6606-4178-9ddb-614d3c1c4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.callbacks.CallbackList at 0x7fede6ed14f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "# Stop training when the model reaches the reward threshold\n",
    "# reward_thresh_callback = StopTrainingOnRewardThreshold(reward_threshold=config[\"mean_reward_thresh\"], verbose=1)\n",
    "\n",
    "# Stop training if there is no improvement after more than N evaluations\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(\n",
    "#     max_no_improvement_evals=config[\"max_no_improvement_evals\"], \n",
    "#     min_evals=config[\"no_improvement_min_evals\"], \n",
    "#     verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, \n",
    "                             best_model_save_path=f\"{config['run_local_dir']}/models/best\",\n",
    "                             log_path=f\"{config['run_local_dir']}/models/best/logs\", \n",
    "                             eval_freq=config[\"eval_freq\"],\n",
    "                             # callback_on_new_best=reward_thresh_callback,\n",
    "                             # callback_after_eval=stop_train_callback,\n",
    "                             deterministic=True, render=False, verbose=1)\n",
    "\n",
    "wandb_callback=WandbCallback(model_save_path=f\"{config['run_local_dir']}/models\",\n",
    "                             model_save_freq=config[\"wandb_model_save_freq\"],\n",
    "                             verbose=2)\n",
    "\n",
    "# Create the callback list\n",
    "callback = CallbackList([wandb_callback, eval_callback])\n",
    "callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2866ed92-c5e1-4179-a261-0378da2b421f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/test1_SF_SB3_SAC_4_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | -48      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 495      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 210      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -40      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 589      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1398     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -36.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1620     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.1     |\n",
      "|    ep_rew_mean     | -39.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 573      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1938     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.6     |\n",
      "|    ep_rew_mean     | -40.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.5     |\n",
      "|    ep_rew_mean     | -40.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 572      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2400     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.5     |\n",
      "|    ep_rew_mean     | -40.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2604     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.6     |\n",
      "|    ep_rew_mean     | -43.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.7     |\n",
      "|    ep_rew_mean     | -41.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 594      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 3948     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -35.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 596      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -26.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 598      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4470     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22       |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 587      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 4752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -28.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5484     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -29.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.8     |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6468     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | -37.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6894     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.8     |\n",
      "|    ep_rew_mean     | -36.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -37.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7380     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -38.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 7812     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -29.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 8664     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -27.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 9000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 9906     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.4     |\n",
      "|    ep_rew_mean     | -18.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 10206    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | -18.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10458    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -33.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10740    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | -35.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 581      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 11388    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-42.82 +/- 14.96\n",
      "Episode length: 43.00 +/- 78.51\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 43       |\n",
      "|    mean_reward     | -42.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 12000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 12042    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 12528    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.488   |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 13620    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 14520    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.5     |\n",
      "|    ep_rew_mean     | 9.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 14898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 2.21     |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 15150    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | 1.14     |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 15690    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.6     |\n",
      "|    ep_rew_mean     | -18.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 16386    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | -17.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 16854    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.1     |\n",
      "|    ep_rew_mean     | -26.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17130    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | -29.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17436    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -32.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 18114    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -43      |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 18666    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 19014    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.9     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 19926    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.7     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 20496    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -19.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21138    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | -13      |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21486    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -20.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 22434    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -20.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22650    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.7     |\n",
      "|    ep_rew_mean     | -32.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22908    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 23100    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.4     |\n",
      "|    ep_rew_mean     | -43.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 23658    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-47.14 +/- 3.87\n",
      "Episode length: 4.40 +/- 1.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 4.4      |\n",
      "|    mean_reward     | -47.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 24000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.4     |\n",
      "|    ep_rew_mean     | -25      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 24510    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | -25.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 24852    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.1     |\n",
      "|    ep_rew_mean     | -24.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25194    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -24      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25614    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -23.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 25974    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | -44.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 547      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 26424    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.4     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 27504    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.4     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 27768    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.4     |\n",
      "|    ep_rew_mean     | -6.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 29034    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.3     |\n",
      "|    ep_rew_mean     | -4.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 30264    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.8     |\n",
      "|    ep_rew_mean     | -5.32    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30516    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | -13.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30732    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -14.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 31026    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -39.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 31662    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | -34.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32226    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -30.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32538    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | -28.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 33336    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 34146    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.4     |\n",
      "|    ep_rew_mean     | -4.81    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 35088    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -12.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35262    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -15      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35694    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=235.63 +/- 501.15\n",
      "Episode length: 83.60 +/- 95.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 83.6     |\n",
      "|    mean_reward     | 236      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 36000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.3     |\n",
      "|    ep_rew_mean     | -4.42    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 36396    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.8     |\n",
      "|    ep_rew_mean     | -12.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 37242    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.6     |\n",
      "|    ep_rew_mean     | -28.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 37836    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -27.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 38922    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.4     |\n",
      "|    ep_rew_mean     | -15.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 517      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 40104    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.3     |\n",
      "|    critic_loss     | 77.1     |\n",
      "|    ent_coef        | 0.971    |\n",
      "|    ent_coef_loss   | -0.248   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 102      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40.8     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1520     |\n",
      "|    fps             | 456      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 40446    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.63    |\n",
      "|    critic_loss     | 52.7     |\n",
      "|    ent_coef        | 0.88     |\n",
      "|    ent_coef_loss   | -0.869   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 444      |\n",
      "---------------------------------\n",
      "Saving last checkpoint\n",
      "Last checkpoint saved in: /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/models/last_model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_interval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException caught:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:309\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m: SACSelf,\n\u001b[1;32m    297\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SACSelf:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:375\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 375\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:271\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Compute actor loss\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Alternative: actor_loss = th.mean(log_prob - qf1_pi)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Min over all critic networks\u001b[39;00m\n\u001b[1;32m    270\u001b[0m q_values_pi \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(replay_data\u001b[38;5;241m.\u001b[39mobservations, actions_pi), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m min_qf_pi, _ \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m (ent_coef \u001b[38;5;241m*\u001b[39m log_prob \u001b[38;5;241m-\u001b[39m min_qf_pi)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    273\u001b[0m actor_losses\u001b[38;5;241m.\u001b[39mappend(actor_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.learn(total_timesteps=config[\"total_timesteps\"], \n",
    "                log_interval=config[\"log_interval\"], \n",
    "                tb_log_name=run_name,\n",
    "                callback=callback)\n",
    "except Exception as e:\n",
    "    print(\"Exception caught:\")\n",
    "    print(e)\n",
    "finally:\n",
    "    # timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "    print(\"Saving last checkpoint\")\n",
    "    model_name = f\"{config['run_local_dir']}/models/last_model\"\n",
    "    model.save(model_name)\n",
    "    print(f\"Last checkpoint saved in: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139daf70-71ae-4b08-8798-a9e86b0a87a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td></td></tr><tr><td>eval/mean_reward</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>rollout/ep_len_mean</td><td></td></tr><tr><td>rollout/ep_rew_mean</td><td></td></tr><tr><td>time/fps</td><td></td></tr><tr><td>train/actor_loss</td><td></td></tr><tr><td>train/critic_loss</td><td></td></tr><tr><td>train/ent_coef</td><td></td></tr><tr><td>train/ent_coef_loss</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td>83.6</td></tr><tr><td>eval/mean_reward</td><td>235.63208</td></tr><tr><td>global_step</td><td>40446</td></tr><tr><td>rollout/ep_len_mean</td><td>40.81</td></tr><tr><td>rollout/ep_rew_mean</td><td>-15.53837</td></tr><tr><td>time/fps</td><td>456.0</td></tr><tr><td>train/actor_loss</td><td>-8.62987</td></tr><tr><td>train/critic_loss</td><td>52.72518</td></tr><tr><td>train/ent_coef</td><td>0.88031</td></tr><tr><td>train/ent_coef_loss</td><td>-0.86934</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test1_SF_SB3_SAC_4</strong> at: <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230302_145847-jfvnsuje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run test1_SF_SB3_SAC_4\n"
     ]
    }
   ],
   "source": [
    "# Finish the run if it's final\n",
    "run.finish()\n",
    "print(f\"Finished run {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6801db30-7721-45e3-af29-a2bc557d4fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d09bf-c365-498a-8534-c609b300a77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MORE TRAINING\n",
    "\n",
    "# LOAD TRAINED MODEL\n",
    "\n",
    "# ########### PATHS NEED TO BE UPDATED\n",
    "# try:\n",
    "#     model.learn(total_timesteps=10_000_000, log_interval=8, tb_log_name=\"PlainDarmEnv\",\n",
    "#                     callback=WandbCallback(model_save_path=f\"checkpoints/wandb/{run.id}\",\n",
    "#                                            model_save_freq=10, verbose=2)\n",
    "#                )\n",
    "#     # Add calbacks\n",
    "# except Exception as e:\n",
    "#     print(\"Exception caught:\")\n",
    "#     print(e)\n",
    "# finally:\n",
    "#     timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "#     print(f\"Saving checkpoint {timestamp}\")\n",
    "#     model_name = f\"./checkpoints/darm_sf_hand_{timestamp}\"\n",
    "#     env_norm_name = f\"./checkpoints/darm_sf_hand_env_norm_{timestamp}\"\n",
    "#     model.save(model_name)\n",
    "#     # env.save(env_norm_name) # FIXME: Remember to save norm params if using VecNorm env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f256d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923cae6-9497-4a2e-b9f8-db23ca6e1fae",
   "metadata": {},
   "source": [
    "### DONE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54a6abe-1b86-4682-9d7d-456dc1364ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e4596f3-355b-4200-9eb5-128405d6b914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7fc10d3873a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f\"{config['run_local_dir']}/models/model_3\"\n",
    "# env_norm_name = \"./checkpoints/darm_sf_hand_env_norm_2022-12-28__10:10:05.637581\"\n",
    "\n",
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "eval_model = SAC.load(model_name, env=eval_env)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759192eb-a5d0-43e5-825a-8f550c09ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103.7653834 500.0978336234947\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Evaluate the model with 10 evaluation episodes and deterministic=True\n",
    "mean_reward, std_reward = evaluate_policy(eval_model, env=eval_model.get_env(), \n",
    "                                          n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "# Print the results\n",
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89fa3c73-6a78-4b4f-93d3-f4cd855fdb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [01:56<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/100 Solved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "create_env_render = lambda: TransformObservation(gym.make(config[\"env_id\"], render_mode=\"human\", single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)\n",
    "env = make_vec_env(create_env_render, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "episode_length = 0\n",
    "N_EPISODES = 10\n",
    "solved = 0\n",
    "actions = []\n",
    "\n",
    "for i in tqdm(range(N_EPISODES)):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    # time.sleep(2)  # sleep for 2 seconds to see start state Update rendering order\n",
    "    \n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action, _states = eval_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        actions.append(info[0][\"action\"])\n",
    "        episode_return += reward[0]\n",
    "        episode_length += 1\n",
    "        done = done[0]\n",
    "        \n",
    "  #  print(f\"Episode Return: {episode_return} Episode Length: {episode_length}\")\n",
    "    info[0][\"model_action\"] = action\n",
    "    # pprint.pprint(info[0])\n",
    "  # print(f\"Solved: {info[0]['reward']['solved']}\")\n",
    "    solved += info[0]['reward']['solved'][0]\n",
    "    # info[\"model_action\"] = action\n",
    "    # pprint.pprint(info)\n",
    "    \n",
    "    done = False\n",
    "    episode_return = 0\n",
    "    episode_length = 0\n",
    "\n",
    "env.close()\n",
    "print(f\"{solved}/{N_EPISODES} Solved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2f714a1-e583-4c5a-a7bd-f9936df07ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 19022)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.asarray(actions)\n",
    "\n",
    "tendon_tensions = []\n",
    "tendon_names = [\"Dorsal Interossei\",\n",
    "                \"Palmar Interossei\",\n",
    "                \"Flexor Digitorum Profundus\",\n",
    "                \"Flexor Digitorum Superficialis\",\n",
    "                \"Extensor Digitorum Communis\"]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    tendon_tensions.append(actions[:, i])\n",
    "\n",
    "tendon_tensions = np.asarray(tendon_tensions)\n",
    "tendon_tensions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4af34a7e-25f2-4d1a-bcaa-19f2f5fa0d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dorsal Interossei</th>\n",
       "      <th>Palmar Interossei</th>\n",
       "      <th>Flexor Digitorum Profundus</th>\n",
       "      <th>Flexor Digitorum Superficialis</th>\n",
       "      <th>Extensor Digitorum Communis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19022.000000</td>\n",
       "      <td>19022.000000</td>\n",
       "      <td>19022.000000</td>\n",
       "      <td>19022.000000</td>\n",
       "      <td>19022.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.361365</td>\n",
       "      <td>0.860272</td>\n",
       "      <td>1.646712</td>\n",
       "      <td>0.610708</td>\n",
       "      <td>5.001712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.236096</td>\n",
       "      <td>1.065981</td>\n",
       "      <td>1.135751</td>\n",
       "      <td>0.837690</td>\n",
       "      <td>2.339854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.327077</td>\n",
       "      <td>0.115315</td>\n",
       "      <td>0.696996</td>\n",
       "      <td>0.195059</td>\n",
       "      <td>3.197265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960512</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>1.504847</td>\n",
       "      <td>0.385266</td>\n",
       "      <td>4.467413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.155793</td>\n",
       "      <td>1.206030</td>\n",
       "      <td>2.392552</td>\n",
       "      <td>0.557642</td>\n",
       "      <td>6.753891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.999942</td>\n",
       "      <td>4.999103</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.885460</td>\n",
       "      <td>9.998236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dorsal Interossei  Palmar Interossei  Flexor Digitorum Profundus  \\\n",
       "count       19022.000000       19022.000000                19022.000000   \n",
       "mean            1.361365           0.860272                    1.646712   \n",
       "std             1.236096           1.065981                    1.135751   \n",
       "min             0.000164           0.000272                    0.000499   \n",
       "25%             0.327077           0.115315                    0.696996   \n",
       "50%             0.960512           0.397200                    1.504847   \n",
       "75%             2.155793           1.206030                    2.392552   \n",
       "max             4.999942           4.999103                    5.000000   \n",
       "\n",
       "       Flexor Digitorum Superficialis  Extensor Digitorum Communis  \n",
       "count                    19022.000000                 19022.000000  \n",
       "mean                         0.610708                     5.001712  \n",
       "std                          0.837690                     2.339854  \n",
       "min                          0.001796                     0.000000  \n",
       "25%                          0.195059                     3.197265  \n",
       "50%                          0.385266                     4.467413  \n",
       "75%                          0.557642                     6.753891  \n",
       "max                          4.885460                     9.998236  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tendon_tensions_dict = {}\n",
    "\n",
    "for tendon_name, tensions in zip(tendon_names, tendon_tensions):\n",
    "    tendon_tensions_dict[tendon_name] = tensions\n",
    "\n",
    "tensions_df = pd.DataFrame(tendon_tensions_dict)\n",
    "tensions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b82ad6cc-b70e-45c0-8f5a-503381b6372a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19022.000000\n",
       "mean         5.001712\n",
       "std          2.339854\n",
       "min          0.000000\n",
       "25%          3.197265\n",
       "50%          4.467413\n",
       "75%          6.753891\n",
       "max          9.998236\n",
       "Name: Extensor Digitorum Communis, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tendon_idx = 4\n",
    "# tensions_df[tensions_df.columns[tendon_idx]].plot(kind='density', xlim=(-0.5,5.5))\n",
    "tensions_df[tensions_df.columns[tendon_idx]].plot(kind='hist', bins=50)\n",
    "plt.title(f\"{tensions_df.columns[tendon_idx]} Tension Histogram plot\")\n",
    "_ = plt.xlabel(\"Tendon Tension [N]\")\n",
    "# _ = plt.ylabel(\"Count\")\n",
    "\n",
    "tensions_df[tensions_df.columns[tendon_idx]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02519f-98c7-48d8-a9af-e266565e5758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02162-fb76-4e93-a1f9-373253dc4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03e71f-e842-45a8-9638-5477d0efd2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d81643-ff6f-441b-a92f-d6b48df9de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0254e0-8fa4-4b67-a708-0f9e9e56e5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b181d28b-35c8-4620-acde-49eaa01ea458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tensions_df[\"Flexor Digitorum Superficialis\"].hist()\n",
    "# tensions_df[\"Extensor Digitorum Communis\"].hist()\n",
    "# tensions_df[\"Dorsal Interossei\"].hist()\n",
    "# tensions_df[\"Palmar Interossei\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f67ea17-a30b-4b6c-a9ea-0bc5da32959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def norm_to_target(obs):\n",
    "    \"\"\"\n",
    "    Returns the norm of each fingertip to the target position\n",
    "    obs: an observation from the observation space [...fingertip_pos, ...target_pos]\n",
    "    \"\"\"\n",
    "    obs = obs.reshape((-1, 3))\n",
    "    n_fingertips = len(obs)//2\n",
    "\n",
    "    fingertip_poses = obs[0:n_fingertips]\n",
    "    target_poses = obs[n_fingertips:]\n",
    "\n",
    "    return np.linalg.norm(fingertip_poses-target_poses, ord=2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82aebaa-ee94-4d80-86b6-af957ff7ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Steps: 100\n",
      "Episode Return: [-206.27367]\n",
      "Episode Return Norm: [-6.1579084]\n",
      "\n",
      "\n",
      "Num Steps: 7\n",
      "Episode Return: [238.47386]\n",
      "Episode Return Norm: [7.1191816]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-112.209465]\n",
      "Episode Return Norm: [-3.3497994]\n",
      "\n",
      "\n",
      "Num Steps: 29\n",
      "Episode Return: [194.17151]\n",
      "Episode Return Norm: [5.7966194]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-154.97745]\n",
      "Episode Return Norm: [-4.6265574]\n",
      "\n",
      "\n",
      "Num Steps: 4\n",
      "Episode Return: [243.22809]\n",
      "Episode Return Norm: [7.2611094]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-204.50894]\n",
      "Episode Return Norm: [-6.1052227]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-108.443665]\n",
      "Episode Return Norm: [-3.2373753]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.46591]\n",
      "Episode Return Norm: [-6.163656]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.59006]\n",
      "Episode Return Norm: [-6.167353]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "N_EPISODES = 10\n",
    "\n",
    "for i in range(N_EPISODES):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  episode_steps = 0\n",
    "  episode_return = 0\n",
    "  episode_return_norm = 0\n",
    "\n",
    "  \n",
    "  while not done:\n",
    "    # print(\"Observation: \", env.unnormalize_obs(obs))\n",
    "    old_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # print(\"Action: \", action)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_steps += 1\n",
    "    new_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    # Get actual reward\n",
    "    unnormalized_reward = env.unnormalize_reward(reward)\n",
    "    episode_return += unnormalized_reward\n",
    "    episode_return_norm += reward\n",
    "    # print(f\"Reward: {unnormalized_reward}; Normalized: {reward}\")\n",
    "\n",
    "    # print(f\"Next Observation: {env.unnormalize_obs(obs)}\")\n",
    "    # print(f\"Change in Norm: {new_norm - old_norm}\")\n",
    "    # print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # render\n",
    "    env.render()\n",
    "  \n",
    "  print(f\"Num Steps: {episode_steps}\")\n",
    "  print(f\"Episode Return: {episode_return}\")\n",
    "  print(f\"Episode Return Norm: {episode_return_norm}\")\n",
    "  if episode_return > -70: \n",
    "    print(\"Goal Reached!\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f502c9f8cc810ebd22b57e7c79a9d06f7b7c060e6ecfb4908c78b2fe1d232067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
