{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bd79bb-1862-4f19-b3e8-a8d827be6faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882904ff-0340-4a30-9315-5fb187698370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/DARM/darm_mujoco'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
    "os.getenv('DARM_MUJOCO_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea4d0f1-e0e8-41d0-9c7c-006cb9a9926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running generate_darm_xml.sh\n",
      "Single Finger: true\n",
      "No Wrist: true\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../mujoco_env\n",
    "bash generate_darm_xml.sh true true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6733be-66a7-4aa7-81b5-b1b28b0a0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if GCC is installed\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9d52a-a921-4b43-ab04-dd0701fb5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GCC if absent\n",
    "!sudo apt update\n",
    "!sudo apt install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c027ec5-151e-4986-a444-2107e98fb741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing darm_gym_env.egg-info/PKG-INFO\n",
      "writing dependency_links to darm_gym_env.egg-info/dependency_links.txt\n",
      "writing requirements to darm_gym_env.egg-info/requires.txt\n",
      "writing top-level names to darm_gym_env.egg-info/top_level.txt\n",
      "reading manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "writing manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_sf_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/__init__.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/multi_darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/env_test.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_sf_gym.py to darm_sf_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/multi_darm_gym.py to multi_darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_gym.py to darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/env_test.py to env_test.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "creating 'dist/darm_gym_env-0.0.1-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "darm_gym_env.__pycache__.multi_darm_gym.cpython-38: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing darm_gym_env-0.0.1-py3.8.egg\n",
      "removing '/home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg' (and everything under it)\n",
      "creating /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Extracting darm_gym_env-0.0.1-py3.8.egg to /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "darm-gym-env 0.0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Processing dependencies for darm-gym-env==0.0.1\n",
      "Searching for gym==0.21.0\n",
      "Best match: gym 0.21.0\n",
      "Adding gym 0.21.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for mujoco==2.2.2\n",
      "Best match: mujoco 2.2.2\n",
      "Processing mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "mujoco 2.2.2 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages/mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "Searching for cloudpickle==2.2.0\n",
      "Best match: cloudpickle 2.2.0\n",
      "Adding cloudpickle 2.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for numpy==1.23.4\n",
      "Best match: numpy 1.23.4\n",
      "Adding numpy 1.23.4 to easy-install.pth file\n",
      "Installing f2py script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3 script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3.8 script to /home/daniel/miniconda3/bin\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for PyOpenGL==3.1.6\n",
      "Best match: PyOpenGL 3.1.6\n",
      "Adding PyOpenGL 3.1.6 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for glfw==2.5.5\n",
      "Best match: glfw 2.5.5\n",
      "Adding glfw 2.5.5 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for absl-py==1.2.0\n",
      "Best match: absl-py 1.2.0\n",
      "Adding absl-py 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Finished processing dependencies for darm-gym-env==0.0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8b1cb4-49d2-416d-b23b-004c54cefbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mujoco import is successful\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a51788-02c3-4cac-a869-8f62b25d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If mujoco import fails, update pandas and restart runtime\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047544b-c26e-4ef2-8b41-4b7fe8ae79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GLFW is missing\n",
    "%%bash\n",
    "sudo apt-get install libglfw3 -y\n",
    "sudo apt-get install libglfw3-dev -y\n",
    "pip install --user glfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a012c8-fe11-44e5-ada6-5c7b50405c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea66991b-3d7c-4e2e-8133-c5f358fa797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from darm_gym_env import DARMEnv\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "from stable_baselines3.common.vec_env.vec_normalize import VecNormalize\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.callbacks import CallbackList, EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7b4bbe-9994-4dc5-b212-c0f5d6ca25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"test1_SF_SB3_SAC_4\"\n",
    "\n",
    "config = {\n",
    "    \"env_id\": \"darm/DarmHand-v0\", # changed from SF\n",
    "    \"single_finger_env\": True,\n",
    "    \"algo\": \"SAC\",\n",
    "    \"rl_lib\": \"SB3\",\n",
    "    \n",
    "    \"seed\": 0,\n",
    "    \"mean_reward_thresh\": 1_300,\n",
    "    \"total_timesteps\": 10_000_000,\n",
    "    \"pi_net_arch\": [32, 256, 256, 64],\n",
    "    \"qf_net_arch\": [32, 256, 256, 64],\n",
    "    \"learning_starts\": 40_000,\n",
    "    \"num_cpu\": 6,\n",
    "    \n",
    "    \"eval_freq\": 2_000, # 5_000\n",
    "    \"max_no_improvement_evals\": 10,\n",
    "    \"no_improvement_min_evals\": 20,\n",
    "    \n",
    "    \"log_interval\": 20, # episodes\n",
    "    \"wandb_model_save_freq\": 2_000, #5_000 timesteps?\n",
    "    \n",
    "    \"run_local_dir\": f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/darm_sf_hand/{run_name}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bdd726-0edc-4e6b-8c4b-b679c56ce71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/wandb/run-20230302_145847-jfvnsuje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">test1_SF_SB3_SAC_4</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = \"\"\"\n",
    "- The environment was updated such that the target is within a range from the start point\n",
    "- Velocity penalty was removed and only effort penalty was used\n",
    "- The reward function was updated according to the reach task reward used in facebookresearch/myosuite [https://github.com/facebookresearch/myosuite/blob/main/myosuite/envs/myo/reach_v0.py]\n",
    "- The done signal is trigerred only when the fingertip goes beyond a threshold. The episode continues to the maximum timestep otherwise.\n",
    "- The friction and damping coefficient of the environment is updated. Values are inspired from Deepmind's Mujoco Menagerie [https://github.com/deepmind/mujoco_menagerie/blob/main/shadow_hand/right_hand.xml]\n",
    "- The range of action from the model was changed to [-1, 1]. This action is mapped to the actual action sent to mujoco e.g [0, 2]]. This change is inspired from values used in OpenAI's Gym Mujoco environments.\n",
    "- max_episode_steps was updated to 200.\n",
    "- Velocity vector (size [3,]) was added to observation. Observation size is now (9,)\n",
    "- Action range was increased to [0, 5]\n",
    "<Changes: ID 3>\n",
    "- Observation warpper to scale observation from m and m/s to cm and cm/s was applied\n",
    "<Changes: ID 4>\n",
    "- Max Tension for Digitorum Extensor Communis was increased to 10\n",
    "- FIXED: Velocity Observation from (prev_pos - new_pos)/time to (new_pos - prev_pos)/time\n",
    "- FIXED: Removed weight of 1 from 'sparse', 'solved', and 'done' in reward weighting\n",
    "- Reduced max_target_th to 5*0.004, 20 mm\n",
    "\n",
    "- Single-Finger; No Wrist Environment\n",
    "- This run was trained on vast_ai using SB3's SAC algo.\n",
    "\"\"\"\n",
    "\n",
    "tags = [\"single_finger\", \"sac\", \"sb3\", \"vast_ai\"]\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"DARM\",\n",
    "    name=run_name,\n",
    "    tags=tags,\n",
    "    notes=notes,\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    # monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376efc5a-273e-4074-ad31-329575675bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import TransformObservation\n",
    "# from gym.wrappers import RescaleAction\n",
    "\n",
    "create_env = lambda: TransformObservation(gym.make(config[\"env_id\"], single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87846de9-eca5-498d-a18d-c41b9363b5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "NUM_CPU = config[\"num_cpu\"]\n",
    "\n",
    "env = make_vec_env(create_env, n_envs=NUM_CPU, seed=config[\"seed\"])\n",
    "# env = VecNormalize(env)   #FIXME: Remember to save norm params if using VecNorm env\n",
    "# env = VecMonitor(env)\n",
    "\n",
    "policy_kwargs = dict(net_arch=dict(pi=config[\"pi_net_arch\"], qf=config[\"qf_net_arch\"]))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1,\n",
    "            learning_starts=config[\"learning_starts\"],\n",
    "            gradient_steps=NUM_CPU, # num of envs\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log=config['run_local_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665027f7-6606-4178-9ddb-614d3c1c4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.callbacks.CallbackList at 0x7fede6ed14f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "# Stop training when the model reaches the reward threshold\n",
    "# reward_thresh_callback = StopTrainingOnRewardThreshold(reward_threshold=config[\"mean_reward_thresh\"], verbose=1)\n",
    "\n",
    "# Stop training if there is no improvement after more than N evaluations\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(\n",
    "#     max_no_improvement_evals=config[\"max_no_improvement_evals\"], \n",
    "#     min_evals=config[\"no_improvement_min_evals\"], \n",
    "#     verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, \n",
    "                             best_model_save_path=f\"{config['run_local_dir']}/models/best\",\n",
    "                             log_path=f\"{config['run_local_dir']}/models/best/logs\", \n",
    "                             eval_freq=config[\"eval_freq\"],\n",
    "                             # callback_on_new_best=reward_thresh_callback,\n",
    "                             # callback_after_eval=stop_train_callback,\n",
    "                             deterministic=True, render=False, verbose=1)\n",
    "\n",
    "wandb_callback=WandbCallback(model_save_path=f\"{config['run_local_dir']}/models\",\n",
    "                             model_save_freq=config[\"wandb_model_save_freq\"],\n",
    "                             verbose=2)\n",
    "\n",
    "# Create the callback list\n",
    "callback = CallbackList([wandb_callback, eval_callback])\n",
    "callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2866ed92-c5e1-4179-a261-0378da2b421f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/test1_SF_SB3_SAC_4_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | -48      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 495      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 210      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -40      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 589      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1398     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -36.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1620     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.1     |\n",
      "|    ep_rew_mean     | -39.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 573      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1938     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.6     |\n",
      "|    ep_rew_mean     | -40.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.5     |\n",
      "|    ep_rew_mean     | -40.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 572      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2400     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.5     |\n",
      "|    ep_rew_mean     | -40.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2604     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.6     |\n",
      "|    ep_rew_mean     | -43.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.7     |\n",
      "|    ep_rew_mean     | -41.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 594      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 3948     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -35.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 596      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -26.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 598      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4470     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22       |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 587      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 4752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -28.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5484     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -29.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.8     |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6468     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | -37.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6894     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.8     |\n",
      "|    ep_rew_mean     | -36.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -37.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7380     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -38.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 7812     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -29.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 8664     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -27.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 9000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 9906     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.4     |\n",
      "|    ep_rew_mean     | -18.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 10206    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | -18.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10458    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -33.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10740    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | -35.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 581      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 11388    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-42.82 +/- 14.96\n",
      "Episode length: 43.00 +/- 78.51\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 43       |\n",
      "|    mean_reward     | -42.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 12000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 12042    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 12528    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.488   |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 13620    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 14520    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.5     |\n",
      "|    ep_rew_mean     | 9.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 14898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 2.21     |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 15150    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | 1.14     |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 15690    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.6     |\n",
      "|    ep_rew_mean     | -18.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 16386    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | -17.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 16854    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.1     |\n",
      "|    ep_rew_mean     | -26.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17130    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | -29.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17436    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -32.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 18114    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -43      |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 18666    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 19014    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.9     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 19926    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.7     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 20496    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -19.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21138    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | -13      |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21486    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -20.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 22434    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -20.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22650    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.7     |\n",
      "|    ep_rew_mean     | -32.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22908    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 23100    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.4     |\n",
      "|    ep_rew_mean     | -43.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 23658    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-47.14 +/- 3.87\n",
      "Episode length: 4.40 +/- 1.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 4.4      |\n",
      "|    mean_reward     | -47.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 24000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.4     |\n",
      "|    ep_rew_mean     | -25      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 24510    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | -25.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 24852    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.1     |\n",
      "|    ep_rew_mean     | -24.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25194    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -24      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25614    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -23.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 25974    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | -44.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 547      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 26424    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.4     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 27504    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.4     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 27768    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.4     |\n",
      "|    ep_rew_mean     | -6.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 29034    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.3     |\n",
      "|    ep_rew_mean     | -4.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 30264    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.8     |\n",
      "|    ep_rew_mean     | -5.32    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30516    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | -13.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30732    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -14.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 31026    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -39.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 31662    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | -34.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32226    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -30.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32538    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | -28.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 33336    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 34146    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.4     |\n",
      "|    ep_rew_mean     | -4.81    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 35088    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -12.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35262    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -15      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35694    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=235.63 +/- 501.15\n",
      "Episode length: 83.60 +/- 95.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 83.6     |\n",
      "|    mean_reward     | 236      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 36000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.3     |\n",
      "|    ep_rew_mean     | -4.42    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 36396    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.8     |\n",
      "|    ep_rew_mean     | -12.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 37242    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.6     |\n",
      "|    ep_rew_mean     | -28.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 37836    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -27.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 38922    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.4     |\n",
      "|    ep_rew_mean     | -15.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 517      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 40104    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.3     |\n",
      "|    critic_loss     | 77.1     |\n",
      "|    ent_coef        | 0.971    |\n",
      "|    ent_coef_loss   | -0.248   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 102      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40.8     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1520     |\n",
      "|    fps             | 456      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 40446    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.63    |\n",
      "|    critic_loss     | 52.7     |\n",
      "|    ent_coef        | 0.88     |\n",
      "|    ent_coef_loss   | -0.869   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 444      |\n",
      "---------------------------------\n",
      "Saving last checkpoint\n",
      "Last checkpoint saved in: /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/models/last_model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_interval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException caught:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:309\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m: SACSelf,\n\u001b[1;32m    297\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SACSelf:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:375\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 375\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:271\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Compute actor loss\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Alternative: actor_loss = th.mean(log_prob - qf1_pi)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Min over all critic networks\u001b[39;00m\n\u001b[1;32m    270\u001b[0m q_values_pi \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(replay_data\u001b[38;5;241m.\u001b[39mobservations, actions_pi), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m min_qf_pi, _ \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m (ent_coef \u001b[38;5;241m*\u001b[39m log_prob \u001b[38;5;241m-\u001b[39m min_qf_pi)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    273\u001b[0m actor_losses\u001b[38;5;241m.\u001b[39mappend(actor_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.learn(total_timesteps=config[\"total_timesteps\"], \n",
    "                log_interval=config[\"log_interval\"], \n",
    "                tb_log_name=run_name,\n",
    "                callback=callback)\n",
    "except Exception as e:\n",
    "    print(\"Exception caught:\")\n",
    "    print(e)\n",
    "finally:\n",
    "    # timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "    print(\"Saving last checkpoint\")\n",
    "    model_name = f\"{config['run_local_dir']}/models/last_model\"\n",
    "    model.save(model_name)\n",
    "    print(f\"Last checkpoint saved in: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139daf70-71ae-4b08-8798-a9e86b0a87a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td>▄▁█</td></tr><tr><td>eval/mean_reward</td><td>▁▁█</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▄▄▄▂▄▄▄▄▅▄▅▅▄▄▆▇▆▅▅▄▅▆▆▆▄▄▄▅▆▇█▆▄▄█▆▆▆█</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▂▂▂▂▃▃▃▂▂▃▄▅▃▄▇█▇▅▃▂▃▄▄▃▂▄▄▄▂▆▆▅▃▃▆▅▅▃▅</td></tr><tr><td>time/fps</td><td>▃█▇▇▇██▇▇▇▇▇▇▇▆▅▆▆▆▆▆▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▅▅▁</td></tr><tr><td>train/actor_loss</td><td>█▁</td></tr><tr><td>train/critic_loss</td><td>█▁</td></tr><tr><td>train/ent_coef</td><td>█▁</td></tr><tr><td>train/ent_coef_loss</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td>83.6</td></tr><tr><td>eval/mean_reward</td><td>235.63208</td></tr><tr><td>global_step</td><td>40446</td></tr><tr><td>rollout/ep_len_mean</td><td>40.81</td></tr><tr><td>rollout/ep_rew_mean</td><td>-15.53837</td></tr><tr><td>time/fps</td><td>456.0</td></tr><tr><td>train/actor_loss</td><td>-8.62987</td></tr><tr><td>train/critic_loss</td><td>52.72518</td></tr><tr><td>train/ent_coef</td><td>0.88031</td></tr><tr><td>train/ent_coef_loss</td><td>-0.86934</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test1_SF_SB3_SAC_4</strong> at: <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230302_145847-jfvnsuje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run test1_SF_SB3_SAC_4\n"
     ]
    }
   ],
   "source": [
    "# Finish the run if it's final\n",
    "run.finish()\n",
    "print(f\"Finished run {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6801db30-7721-45e3-af29-a2bc557d4fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d09bf-c365-498a-8534-c609b300a77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MORE TRAINING\n",
    "\n",
    "# LOAD TRAINED MODEL\n",
    "\n",
    "# ########### PATHS NEED TO BE UPDATED\n",
    "# try:\n",
    "#     model.learn(total_timesteps=10_000_000, log_interval=8, tb_log_name=\"PlainDarmEnv\",\n",
    "#                     callback=WandbCallback(model_save_path=f\"checkpoints/wandb/{run.id}\",\n",
    "#                                            model_save_freq=10, verbose=2)\n",
    "#                )\n",
    "#     # Add calbacks\n",
    "# except Exception as e:\n",
    "#     print(\"Exception caught:\")\n",
    "#     print(e)\n",
    "# finally:\n",
    "#     timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "#     print(f\"Saving checkpoint {timestamp}\")\n",
    "#     model_name = f\"./checkpoints/darm_sf_hand_{timestamp}\"\n",
    "#     env_norm_name = f\"./checkpoints/darm_sf_hand_env_norm_{timestamp}\"\n",
    "#     model.save(model_name)\n",
    "#     # env.save(env_norm_name) # FIXME: Remember to save norm params if using VecNorm env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f256d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923cae6-9497-4a2e-b9f8-db23ca6e1fae",
   "metadata": {},
   "source": [
    "### DONE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54a6abe-1b86-4682-9d7d-456dc1364ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e4596f3-355b-4200-9eb5-128405d6b914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7fede49427f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f\"{config['run_local_dir']}/models/best/best_model\"\n",
    "# env_norm_name = \"./checkpoints/darm_sf_hand_env_norm_2022-12-28__10:10:05.637581\"\n",
    "\n",
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "eval_model = SAC.load(model_name, env=eval_env)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759192eb-a5d0-43e5-825a-8f550c09ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.5527834 119.55361281297256\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Evaluate the model with 10 evaluation episodes and deterministic=True\n",
    "mean_reward, std_reward = evaluate_policy(eval_model, env=eval_model.get_env(), \n",
    "                                          n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "# Print the results\n",
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89fa3c73-6a78-4b4f-93d3-f4cd855fdb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 Solved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "create_env_render = lambda: TransformObservation(gym.make(config[\"env_id\"], render_mode=\"human\", single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)\n",
    "env = make_vec_env(create_env_render, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "episode_length = 0\n",
    "N_EPISODES = 10\n",
    "solved = 0\n",
    "actions = []\n",
    "\n",
    "for i in tqdm(range(N_EPISODES)):\n",
    "    done = False\n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action, _states = eval_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        actions.append(info[0][\"action\"])\n",
    "        episode_return += reward[0]\n",
    "        episode_length += 1\n",
    "        done = done[0]\n",
    "        \n",
    "  #  print(f\"Episode Return: {episode_return} Episode Length: {episode_length}\")\n",
    "    info[0][\"model_action\"] = action\n",
    "    # pprint.pprint(info[0])\n",
    "  # print(f\"Solved: {info[0]['reward']['solved']}\")\n",
    "    solved += info[0]['reward']['solved'][0]\n",
    "    # info[\"model_action\"] = action\n",
    "    # pprint.pprint(info)\n",
    "    \n",
    "    done = False\n",
    "    episode_return = 0\n",
    "    episode_length = 0\n",
    "\n",
    "env.close()\n",
    "print(f\"{solved}/{N_EPISODES} Solved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b2f714a1-e583-4c5a-a7bd-f9936df07ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 195072)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.asarray(actions)\n",
    "\n",
    "tendon_tensions = []\n",
    "tendon_names = [\"Dorsal Interossei\",\n",
    "                \"Palmar Interossei\",\n",
    "                \"Extensor Digitorum Communis\",\n",
    "                \"Flexor Digitorum Profundus\",\n",
    "                \"Flexor Digitorum Superficialis\"]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    tendon_tensions.append(actions[:, i])\n",
    "\n",
    "tendon_tensions = np.asarray(tendon_tensions)\n",
    "tendon_tensions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4af34a7e-25f2-4d1a-bcaa-19f2f5fa0d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dorsal Interossei</th>\n",
       "      <th>Palmar Interossei</th>\n",
       "      <th>Extensor Digitorum Communis</th>\n",
       "      <th>Flexor Digitorum Profundus</th>\n",
       "      <th>Flexor Digitorum Superficialis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195072.000000</td>\n",
       "      <td>195072.000000</td>\n",
       "      <td>195072.000000</td>\n",
       "      <td>195072.000000</td>\n",
       "      <td>195072.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.950422</td>\n",
       "      <td>0.767148</td>\n",
       "      <td>3.509327</td>\n",
       "      <td>1.329884</td>\n",
       "      <td>0.429009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.014455</td>\n",
       "      <td>0.936925</td>\n",
       "      <td>1.026986</td>\n",
       "      <td>0.747989</td>\n",
       "      <td>0.561555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.244022</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>2.881964</td>\n",
       "      <td>0.832723</td>\n",
       "      <td>0.155681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.590215</td>\n",
       "      <td>0.373623</td>\n",
       "      <td>3.788050</td>\n",
       "      <td>1.291511</td>\n",
       "      <td>0.288769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.207549</td>\n",
       "      <td>1.124003</td>\n",
       "      <td>4.289469</td>\n",
       "      <td>1.689200</td>\n",
       "      <td>0.432691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.999928</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.999597</td>\n",
       "      <td>4.999947</td>\n",
       "      <td>4.991437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dorsal Interossei  Palmar Interossei  Extensor Digitorum Communis  \\\n",
       "count      195072.000000      195072.000000                195072.000000   \n",
       "mean            0.950422           0.767148                     3.509327   \n",
       "std             1.014455           0.936925                     1.026986   \n",
       "min             0.001007           0.000811                     0.000827   \n",
       "25%             0.244022           0.115738                     2.881964   \n",
       "50%             0.590215           0.373623                     3.788050   \n",
       "75%             1.207549           1.124003                     4.289469   \n",
       "max             4.999928           5.000000                     4.999597   \n",
       "\n",
       "       Flexor Digitorum Profundus  Flexor Digitorum Superficialis  \n",
       "count               195072.000000                   195072.000000  \n",
       "mean                     1.329884                        0.429009  \n",
       "std                      0.747989                        0.561555  \n",
       "min                      0.000035                        0.000511  \n",
       "25%                      0.832723                        0.155681  \n",
       "50%                      1.291511                        0.288769  \n",
       "75%                      1.689200                        0.432691  \n",
       "max                      4.999947                        4.991437  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tendon_tensions_dict = {}\n",
    "\n",
    "for tendon_name, tensions in zip(tendon_names, tendon_tensions):\n",
    "    tendon_tensions_dict[tendon_name] = tensions\n",
    "\n",
    "tensions_df = pd.DataFrame(tendon_tensions_dict)\n",
    "tensions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b82ad6cc-b70e-45c0-8f5a-503381b6372a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    195072.000000\n",
       "mean          0.950422\n",
       "std           1.014455\n",
       "min           0.001007\n",
       "25%           0.244022\n",
       "50%           0.590215\n",
       "75%           1.207549\n",
       "max           4.999928\n",
       "Name: Dorsal Interossei, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tendon_idx = 0\n",
    "# tensions_df[tensions_df.columns[tendon_idx]].plot(kind='density', xlim=(-0.5,5.5))\n",
    "tensions_df[tensions_df.columns[tendon_idx]].plot(kind='hist', bins=50)\n",
    "plt.title(f\"{tensions_df.columns[tendon_idx]} Tension Histogram plot\")\n",
    "_ = plt.xlabel(\"Tendon Tension [N]\")\n",
    "# _ = plt.ylabel(\"Count\")\n",
    "\n",
    "tensions_df[tensions_df.columns[tendon_idx]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02519f-98c7-48d8-a9af-e266565e5758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02162-fb76-4e93-a1f9-373253dc4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03e71f-e842-45a8-9638-5477d0efd2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d81643-ff6f-441b-a92f-d6b48df9de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0254e0-8fa4-4b67-a708-0f9e9e56e5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b181d28b-35c8-4620-acde-49eaa01ea458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tensions_df[\"Flexor Digitorum Superficialis\"].hist()\n",
    "# tensions_df[\"Extensor Digitorum Communis\"].hist()\n",
    "# tensions_df[\"Dorsal Interossei\"].hist()\n",
    "# tensions_df[\"Palmar Interossei\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f67ea17-a30b-4b6c-a9ea-0bc5da32959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def norm_to_target(obs):\n",
    "    \"\"\"\n",
    "    Returns the norm of each fingertip to the target position\n",
    "    obs: an observation from the observation space [...fingertip_pos, ...target_pos]\n",
    "    \"\"\"\n",
    "    obs = obs.reshape((-1, 3))\n",
    "    n_fingertips = len(obs)//2\n",
    "\n",
    "    fingertip_poses = obs[0:n_fingertips]\n",
    "    target_poses = obs[n_fingertips:]\n",
    "\n",
    "    return np.linalg.norm(fingertip_poses-target_poses, ord=2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82aebaa-ee94-4d80-86b6-af957ff7ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Steps: 100\n",
      "Episode Return: [-206.27367]\n",
      "Episode Return Norm: [-6.1579084]\n",
      "\n",
      "\n",
      "Num Steps: 7\n",
      "Episode Return: [238.47386]\n",
      "Episode Return Norm: [7.1191816]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-112.209465]\n",
      "Episode Return Norm: [-3.3497994]\n",
      "\n",
      "\n",
      "Num Steps: 29\n",
      "Episode Return: [194.17151]\n",
      "Episode Return Norm: [5.7966194]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-154.97745]\n",
      "Episode Return Norm: [-4.6265574]\n",
      "\n",
      "\n",
      "Num Steps: 4\n",
      "Episode Return: [243.22809]\n",
      "Episode Return Norm: [7.2611094]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-204.50894]\n",
      "Episode Return Norm: [-6.1052227]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-108.443665]\n",
      "Episode Return Norm: [-3.2373753]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.46591]\n",
      "Episode Return Norm: [-6.163656]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.59006]\n",
      "Episode Return Norm: [-6.167353]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "N_EPISODES = 10\n",
    "\n",
    "for i in range(N_EPISODES):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  episode_steps = 0\n",
    "  episode_return = 0\n",
    "  episode_return_norm = 0\n",
    "\n",
    "  \n",
    "  while not done:\n",
    "    # print(\"Observation: \", env.unnormalize_obs(obs))\n",
    "    old_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # print(\"Action: \", action)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_steps += 1\n",
    "    new_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    # Get actual reward\n",
    "    unnormalized_reward = env.unnormalize_reward(reward)\n",
    "    episode_return += unnormalized_reward\n",
    "    episode_return_norm += reward\n",
    "    # print(f\"Reward: {unnormalized_reward}; Normalized: {reward}\")\n",
    "\n",
    "    # print(f\"Next Observation: {env.unnormalize_obs(obs)}\")\n",
    "    # print(f\"Change in Norm: {new_norm - old_norm}\")\n",
    "    # print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # render\n",
    "    env.render()\n",
    "  \n",
    "  print(f\"Num Steps: {episode_steps}\")\n",
    "  print(f\"Episode Return: {episode_return}\")\n",
    "  print(f\"Episode Return Norm: {episode_return_norm}\")\n",
    "  if episode_return > -70: \n",
    "    print(\"Goal Reached!\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f502c9f8cc810ebd22b57e7c79a9d06f7b7c060e6ecfb4908c78b2fe1d232067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
