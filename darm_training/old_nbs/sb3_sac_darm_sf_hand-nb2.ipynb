{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bd79bb-1862-4f19-b3e8-a8d827be6faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "882904ff-0340-4a30-9315-5fb187698370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/DARM/darm_mujoco'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
    "os.getenv('DARM_MUJOCO_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea4d0f1-e0e8-41d0-9c7c-006cb9a9926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running generate_darm_xml.sh\n",
      "Single Finger: true\n",
      "No Wrist: true\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ../mujoco_env\n",
    "bash generate_darm_xml.sh true true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a6733be-66a7-4aa7-81b5-b1b28b0a0efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if GCC is installed\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9d52a-a921-4b43-ab04-dd0701fb5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install GCC if absent\n",
    "!sudo apt update\n",
    "!sudo apt install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c027ec5-151e-4986-a444-2107e98fb741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing darm_gym_env.egg-info/PKG-INFO\n",
      "writing dependency_links to darm_gym_env.egg-info/dependency_links.txt\n",
      "writing requirements to darm_gym_env.egg-info/requires.txt\n",
      "writing top-level names to darm_gym_env.egg-info/top_level.txt\n",
      "reading manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "writing manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_sf_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/__init__.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/multi_darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/env_test.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_sf_gym.py to darm_sf_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/multi_darm_gym.py to multi_darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_gym.py to darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/env_test.py to env_test.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "creating 'dist/darm_gym_env-0.0.1-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "darm_gym_env.__pycache__.multi_darm_gym.cpython-38: module references __file__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing darm_gym_env-0.0.1-py3.8.egg\n",
      "removing '/home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg' (and everything under it)\n",
      "creating /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Extracting darm_gym_env-0.0.1-py3.8.egg to /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "darm-gym-env 0.0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Processing dependencies for darm-gym-env==0.0.1\n",
      "Searching for gym==0.21.0\n",
      "Best match: gym 0.21.0\n",
      "Adding gym 0.21.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for mujoco==2.2.2\n",
      "Best match: mujoco 2.2.2\n",
      "Processing mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "mujoco 2.2.2 is already the active version in easy-install.pth\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages/mujoco-2.2.2-py3.8-linux-x86_64.egg\n",
      "Searching for cloudpickle==2.2.0\n",
      "Best match: cloudpickle 2.2.0\n",
      "Adding cloudpickle 2.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for numpy==1.23.4\n",
      "Best match: numpy 1.23.4\n",
      "Adding numpy 1.23.4 to easy-install.pth file\n",
      "Installing f2py script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3 script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3.8 script to /home/daniel/miniconda3/bin\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for PyOpenGL==3.1.6\n",
      "Best match: PyOpenGL 3.1.6\n",
      "Adding PyOpenGL 3.1.6 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for glfw==2.5.5\n",
      "Best match: glfw 2.5.5\n",
      "Adding glfw 2.5.5 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for absl-py==1.2.0\n",
      "Best match: absl-py 1.2.0\n",
      "Adding absl-py 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Finished processing dependencies for darm-gym-env==0.0.1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8b1cb4-49d2-416d-b23b-004c54cefbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mujoco import is successful\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a51788-02c3-4cac-a869-8f62b25d5bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If mujoco import fails, update pandas and restart runtime\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047544b-c26e-4ef2-8b41-4b7fe8ae79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If GLFW is missing\n",
    "%%bash\n",
    "sudo apt-get install libglfw3 -y\n",
    "sudo apt-get install libglfw3-dev -y\n",
    "pip install --user glfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a012c8-fe11-44e5-ada6-5c7b50405c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea66991b-3d7c-4e2e-8133-c5f358fa797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from darm_gym_env import DARMEnv\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env.subproc_vec_env import SubprocVecEnv\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "from stable_baselines3.common.vec_env.vec_normalize import VecNormalize\n",
    "from stable_baselines3.common.vec_env.dummy_vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.callbacks import CallbackList, EvalCallback, StopTrainingOnRewardThreshold, StopTrainingOnNoModelImprovement\n",
    "\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d7b4bbe-9994-4dc5-b212-c0f5d6ca25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"SF_SB3_SAC_4\"\n",
    "\n",
    "config = {\n",
    "    \"env_id\": \"darm/DarmHand-v0\", # changed from SF\n",
    "    \"single_finger_env\": True,\n",
    "    \"algo\": \"SAC\",\n",
    "    \"rl_lib\": \"SB3\",\n",
    "    \n",
    "    \"seed\": 0,\n",
    "    \"mean_reward_thresh\": 1_300,\n",
    "    \"total_timesteps\": 10_000_000,\n",
    "    \"pi_net_arch\": [32, 256, 256, 64],\n",
    "    \"qf_net_arch\": [32, 256, 256, 64],\n",
    "    \"learning_starts\": 40_000,\n",
    "    \"num_cpu\": 6,\n",
    "    \n",
    "    \"eval_freq\": 2_000, # 5_000\n",
    "    \"max_no_improvement_evals\": 10,\n",
    "    \"no_improvement_min_evals\": 20,\n",
    "    \n",
    "    \"log_interval\": 20, # episodes\n",
    "    \"wandb_model_save_freq\": 2_000, #5_000 timesteps?\n",
    "    \n",
    "    \"run_local_dir\": f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/darm_sf_hand/{run_name}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6bdd726-0edc-4e6b-8c4b-b679c56ce71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/wandb/run-20230302_145847-jfvnsuje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">test1_SF_SB3_SAC_4</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notes = \"\"\"\n",
    "- The environment was updated such that the target is within a range from the start point\n",
    "- Velocity penalty was removed and only effort penalty was used\n",
    "- The reward function was updated according to the reach task reward used in facebookresearch/myosuite [https://github.com/facebookresearch/myosuite/blob/main/myosuite/envs/myo/reach_v0.py]\n",
    "- The done signal is trigerred only when the fingertip goes beyond a threshold. The episode continues to the maximum timestep otherwise.\n",
    "- The friction and damping coefficient of the environment is updated. Values are inspired from Deepmind's Mujoco Menagerie [https://github.com/deepmind/mujoco_menagerie/blob/main/shadow_hand/right_hand.xml]\n",
    "- The range of action from the model was changed to [-1, 1]. This action is mapped to the actual action sent to mujoco e.g [0, 2]]. This change is inspired from values used in OpenAI's Gym Mujoco environments.\n",
    "- max_episode_steps was updated to 200.\n",
    "- Velocity vector (size [3,]) was added to observation. Observation size is now (9,)\n",
    "- Action range was increased to [0, 5]\n",
    "<Changes: ID 3>\n",
    "- Observation warpper to scale observation from m and m/s to cm and cm/s was applied\n",
    "<Changes: ID 4>\n",
    "- Max Tension for Digitorum Extensor Communis was increased to 10\n",
    "- FIXED: Velocity Observation from (prev_pos - new_pos)/time to (new_pos - prev_pos)/time\n",
    "- FIXED: Removed weight of 1 from 'sparse', 'solved', and 'done' in reward weighting\n",
    "- Reduced max_target_th to 5*0.004, 20 mm\n",
    "\n",
    "- Single-Finger; No Wrist Environment\n",
    "- This run was trained on vast_ai using SB3's SAC algo.\n",
    "\"\"\"\n",
    "\n",
    "tags = [\"single_finger\", \"sac\", \"sb3\", \"vast_ai\"]\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"DARM\",\n",
    "    name=run_name,\n",
    "    tags=tags,\n",
    "    notes=notes,\n",
    "    config=config,\n",
    "    sync_tensorboard=True,  # auto-upload sb3's tensorboard metrics\n",
    "    # monitor_gym=True,  # auto-upload the videos of agents playing the game\n",
    "    save_code=True,  # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "376efc5a-273e-4074-ad31-329575675bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import TransformObservation\n",
    "# from gym.wrappers import RescaleAction\n",
    "\n",
    "create_env = lambda: TransformObservation(gym.make(config[\"env_id\"], single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87846de9-eca5-498d-a18d-c41b9363b5ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Loaded XML file successfully\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "NUM_CPU = config[\"num_cpu\"]\n",
    "\n",
    "env = make_vec_env(create_env, n_envs=NUM_CPU, seed=config[\"seed\"])\n",
    "# env = VecNormalize(env)   #FIXME: Remember to save norm params if using VecNorm env\n",
    "# env = VecMonitor(env)\n",
    "\n",
    "policy_kwargs = dict(net_arch=dict(pi=config[\"pi_net_arch\"], qf=config[\"qf_net_arch\"]))\n",
    "\n",
    "model = SAC(\"MlpPolicy\", env, verbose=1,\n",
    "            learning_starts=config[\"learning_starts\"],\n",
    "            gradient_steps=NUM_CPU, # num of envs\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            tensorboard_log=config['run_local_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "665027f7-6606-4178-9ddb-614d3c1c4706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.common.callbacks.CallbackList at 0x7fede6ed14f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "# Stop training when the model reaches the reward threshold\n",
    "# reward_thresh_callback = StopTrainingOnRewardThreshold(reward_threshold=config[\"mean_reward_thresh\"], verbose=1)\n",
    "\n",
    "# Stop training if there is no improvement after more than N evaluations\n",
    "# stop_train_callback = StopTrainingOnNoModelImprovement(\n",
    "#     max_no_improvement_evals=config[\"max_no_improvement_evals\"], \n",
    "#     min_evals=config[\"no_improvement_min_evals\"], \n",
    "#     verbose=1)\n",
    "\n",
    "eval_callback = EvalCallback(eval_env, \n",
    "                             best_model_save_path=f\"{config['run_local_dir']}/models/best\",\n",
    "                             log_path=f\"{config['run_local_dir']}/models/best/logs\", \n",
    "                             eval_freq=config[\"eval_freq\"],\n",
    "                             # callback_on_new_best=reward_thresh_callback,\n",
    "                             # callback_after_eval=stop_train_callback,\n",
    "                             deterministic=True, render=False, verbose=1)\n",
    "\n",
    "wandb_callback=WandbCallback(model_save_path=f\"{config['run_local_dir']}/models\",\n",
    "                             model_save_freq=config[\"wandb_model_save_freq\"],\n",
    "                             verbose=2)\n",
    "\n",
    "# Create the callback list\n",
    "callback = CallbackList([wandb_callback, eval_callback])\n",
    "callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2866ed92-c5e1-4179-a261-0378da2b421f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/test1_SF_SB3_SAC_4_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:86: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | -48      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 495      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 210      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -40      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 589      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1398     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -36.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 1620     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.1     |\n",
      "|    ep_rew_mean     | -39.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 573      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 1938     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.6     |\n",
      "|    ep_rew_mean     | -40.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2208     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 18.5     |\n",
      "|    ep_rew_mean     | -40.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 572      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2400     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 13.5     |\n",
      "|    ep_rew_mean     | -40.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 576      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2604     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 11.6     |\n",
      "|    ep_rew_mean     | -43.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 2760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 17.7     |\n",
      "|    ep_rew_mean     | -41.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 594      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 3948     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -35.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 596      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -26.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 598      |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 4470     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22       |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 587      |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 4752     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -28.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5484     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.7     |\n",
      "|    ep_rew_mean     | -29.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 9        |\n",
      "|    total_timesteps | 5760     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.8     |\n",
      "|    ep_rew_mean     | -29.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6468     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.3     |\n",
      "|    ep_rew_mean     | -37.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 320      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 11       |\n",
      "|    total_timesteps | 6894     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.8     |\n",
      "|    ep_rew_mean     | -36.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 340      |\n",
      "|    fps             | 579      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7194     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -37.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 360      |\n",
      "|    fps             | 578      |\n",
      "|    time_elapsed    | 12       |\n",
      "|    total_timesteps | 7380     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -38.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 380      |\n",
      "|    fps             | 577      |\n",
      "|    time_elapsed    | 13       |\n",
      "|    total_timesteps | 7812     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -29.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 400      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 8664     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -27.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 420      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 9000     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 440      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 9906     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.4     |\n",
      "|    ep_rew_mean     | -18.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 460      |\n",
      "|    fps             | 582      |\n",
      "|    time_elapsed    | 17       |\n",
      "|    total_timesteps | 10206    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 27.5     |\n",
      "|    ep_rew_mean     | -18.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 480      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10458    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -33.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 500      |\n",
      "|    fps             | 580      |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 10740    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.2     |\n",
      "|    ep_rew_mean     | -35.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 520      |\n",
      "|    fps             | 581      |\n",
      "|    time_elapsed    | 19       |\n",
      "|    total_timesteps | 11388    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=12000, episode_reward=-42.82 +/- 14.96\n",
      "Episode length: 43.00 +/- 78.51\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 43       |\n",
      "|    mean_reward     | -42.8    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 12000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -27.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 540      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 21       |\n",
      "|    total_timesteps | 12042    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 560      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 12528    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.2     |\n",
      "|    ep_rew_mean     | -0.488   |\n",
      "| time/              |          |\n",
      "|    episodes        | 580      |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 13620    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35       |\n",
      "|    ep_rew_mean     | 0.27     |\n",
      "| time/              |          |\n",
      "|    episodes        | 600      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 26       |\n",
      "|    total_timesteps | 14520    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.5     |\n",
      "|    ep_rew_mean     | 9.08     |\n",
      "| time/              |          |\n",
      "|    episodes        | 620      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 14898    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.3     |\n",
      "|    ep_rew_mean     | 2.21     |\n",
      "| time/              |          |\n",
      "|    episodes        | 640      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 15150    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.6     |\n",
      "|    ep_rew_mean     | 1.14     |\n",
      "| time/              |          |\n",
      "|    episodes        | 660      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 28       |\n",
      "|    total_timesteps | 15690    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.6     |\n",
      "|    ep_rew_mean     | -18.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 680      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 29       |\n",
      "|    total_timesteps | 16386    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23       |\n",
      "|    ep_rew_mean     | -17.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 700      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 30       |\n",
      "|    total_timesteps | 16854    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.1     |\n",
      "|    ep_rew_mean     | -26.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 720      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17130    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.2     |\n",
      "|    ep_rew_mean     | -29.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 740      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 17436    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.2     |\n",
      "|    ep_rew_mean     | -32.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 760      |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 18114    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.6     |\n",
      "|    ep_rew_mean     | -43      |\n",
      "| time/              |          |\n",
      "|    episodes        | 780      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 33       |\n",
      "|    total_timesteps | 18666    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24.4     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 800      |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 34       |\n",
      "|    total_timesteps | 19014    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.9     |\n",
      "|    ep_rew_mean     | -34.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 820      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 36       |\n",
      "|    total_timesteps | 19926    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.7     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 840      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 20496    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 32.7     |\n",
      "|    ep_rew_mean     | -19.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 860      |\n",
      "|    fps             | 553      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21138    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 29.6     |\n",
      "|    ep_rew_mean     | -13      |\n",
      "| time/              |          |\n",
      "|    episodes        | 880      |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 38       |\n",
      "|    total_timesteps | 21486    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.4     |\n",
      "|    ep_rew_mean     | -20.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 900      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 22434    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31       |\n",
      "|    ep_rew_mean     | -20.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 920      |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22650    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.7     |\n",
      "|    ep_rew_mean     | -32.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 940      |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 22908    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 960      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 23100    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.4     |\n",
      "|    ep_rew_mean     | -43.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 980      |\n",
      "|    fps             | 548      |\n",
      "|    time_elapsed    | 43       |\n",
      "|    total_timesteps | 23658    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=24000, episode_reward=-47.14 +/- 3.87\n",
      "Episode length: 4.40 +/- 1.36\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 4.4      |\n",
      "|    mean_reward     | -47.1    |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 24000    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.4     |\n",
      "|    ep_rew_mean     | -25      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1000     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 44       |\n",
      "|    total_timesteps | 24510    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.5     |\n",
      "|    ep_rew_mean     | -25.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1020     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 45       |\n",
      "|    total_timesteps | 24852    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.1     |\n",
      "|    ep_rew_mean     | -24.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1040     |\n",
      "|    fps             | 545      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25194    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.1     |\n",
      "|    ep_rew_mean     | -24      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1060     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 25614    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 24       |\n",
      "|    ep_rew_mean     | -23.6    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1080     |\n",
      "|    fps             | 546      |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 25974    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 20.6     |\n",
      "|    ep_rew_mean     | -44.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1100     |\n",
      "|    fps             | 547      |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 26424    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.4     |\n",
      "|    ep_rew_mean     | -36      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1120     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 49       |\n",
      "|    total_timesteps | 27504    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 26.4     |\n",
      "|    ep_rew_mean     | -31.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1140     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 27768    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.4     |\n",
      "|    ep_rew_mean     | -6.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 1160     |\n",
      "|    fps             | 554      |\n",
      "|    time_elapsed    | 52       |\n",
      "|    total_timesteps | 29034    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 43.3     |\n",
      "|    ep_rew_mean     | -4.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1180     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 54       |\n",
      "|    total_timesteps | 30264    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.8     |\n",
      "|    ep_rew_mean     | -5.32    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1200     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30516    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.2     |\n",
      "|    ep_rew_mean     | -13.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1220     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 30732    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 33.1     |\n",
      "|    ep_rew_mean     | -14.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1240     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 31026    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 23.3     |\n",
      "|    ep_rew_mean     | -39.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1260     |\n",
      "|    fps             | 551      |\n",
      "|    time_elapsed    | 57       |\n",
      "|    total_timesteps | 31662    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 19.8     |\n",
      "|    ep_rew_mean     | -34.1    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1280     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32226    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.9     |\n",
      "|    ep_rew_mean     | -30.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1300     |\n",
      "|    fps             | 552      |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 32538    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | -28.3    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1320     |\n",
      "|    fps             | 550      |\n",
      "|    time_elapsed    | 60       |\n",
      "|    total_timesteps | 33336    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.5     |\n",
      "|    ep_rew_mean     | -22.9    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1340     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 62       |\n",
      "|    total_timesteps | 34146    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.4     |\n",
      "|    ep_rew_mean     | -4.81    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1360     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 63       |\n",
      "|    total_timesteps | 35088    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.9     |\n",
      "|    ep_rew_mean     | -12.4    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1380     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35262    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | -15      |\n",
      "| time/              |          |\n",
      "|    episodes        | 1400     |\n",
      "|    fps             | 549      |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 35694    |\n",
      "---------------------------------\n",
      "Eval num_timesteps=36000, episode_reward=235.63 +/- 501.15\n",
      "Episode length: 83.60 +/- 95.04\n",
      "---------------------------------\n",
      "| eval/              |          |\n",
      "|    mean_ep_length  | 83.6     |\n",
      "|    mean_reward     | 236      |\n",
      "| time/              |          |\n",
      "|    total_timesteps | 36000    |\n",
      "---------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 34.3     |\n",
      "|    ep_rew_mean     | -4.42    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1420     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 67       |\n",
      "|    total_timesteps | 36396    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 28.8     |\n",
      "|    ep_rew_mean     | -12.8    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1440     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 69       |\n",
      "|    total_timesteps | 37242    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.6     |\n",
      "|    ep_rew_mean     | -28.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1460     |\n",
      "|    fps             | 539      |\n",
      "|    time_elapsed    | 70       |\n",
      "|    total_timesteps | 37836    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 31.5     |\n",
      "|    ep_rew_mean     | -27.7    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1480     |\n",
      "|    fps             | 538      |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 38922    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.4     |\n",
      "|    ep_rew_mean     | -15.2    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1500     |\n",
      "|    fps             | 517      |\n",
      "|    time_elapsed    | 77       |\n",
      "|    total_timesteps | 40104    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.3     |\n",
      "|    critic_loss     | 77.1     |\n",
      "|    ent_coef        | 0.971    |\n",
      "|    ent_coef_loss   | -0.248   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 102      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40.8     |\n",
      "|    ep_rew_mean     | -15.5    |\n",
      "| time/              |          |\n",
      "|    episodes        | 1520     |\n",
      "|    fps             | 456      |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 40446    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.63    |\n",
      "|    critic_loss     | 52.7     |\n",
      "|    ent_coef        | 0.88     |\n",
      "|    ent_coef_loss   | -0.869   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 444      |\n",
      "---------------------------------\n",
      "Saving last checkpoint\n",
      "Last checkpoint saved in: /home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_SB3_SAC_4/models/last_model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtotal_timesteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_interval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException caught:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:309\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m: SACSelf,\n\u001b[1;32m    297\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SACSelf:\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:375\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;66;03m# Special case when the user passes `gradient_steps=0`\u001b[39;00m\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m gradient_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 375\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:271\u001b[0m, in \u001b[0;36mSAC.train\u001b[0;34m(self, gradient_steps, batch_size)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# Compute actor loss\u001b[39;00m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# Alternative: actor_loss = th.mean(log_prob - qf1_pi)\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# Min over all critic networks\u001b[39;00m\n\u001b[1;32m    270\u001b[0m q_values_pi \u001b[38;5;241m=\u001b[39m th\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic(replay_data\u001b[38;5;241m.\u001b[39mobservations, actions_pi), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 271\u001b[0m min_qf_pi, _ \u001b[38;5;241m=\u001b[39m \u001b[43mth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq_values_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m (ent_coef \u001b[38;5;241m*\u001b[39m log_prob \u001b[38;5;241m-\u001b[39m min_qf_pi)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    273\u001b[0m actor_losses\u001b[38;5;241m.\u001b[39mappend(actor_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model.learn(total_timesteps=config[\"total_timesteps\"], \n",
    "                log_interval=config[\"log_interval\"], \n",
    "                tb_log_name=run_name,\n",
    "                callback=callback)\n",
    "except Exception as e:\n",
    "    print(\"Exception caught:\")\n",
    "    print(e)\n",
    "finally:\n",
    "    # timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "    print(\"Saving last checkpoint\")\n",
    "    model_name = f\"{config['run_local_dir']}/models/last_model\"\n",
    "    model.save(model_name)\n",
    "    print(f\"Last checkpoint saved in: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139daf70-71ae-4b08-8798-a9e86b0a87a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td>▄▁█</td></tr><tr><td>eval/mean_reward</td><td>▁▁█</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▄▄▄▂▄▄▄▄▅▄▅▅▄▄▆▇▆▅▅▄▅▆▆▆▄▄▄▅▆▇█▆▄▄█▆▆▆█</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▂▂▂▂▃▃▃▂▂▃▄▅▃▄▇█▇▅▃▂▃▄▄▃▂▄▄▄▂▆▆▅▃▃▆▅▅▃▅</td></tr><tr><td>time/fps</td><td>▃█▇▇▇██▇▇▇▇▇▇▇▆▅▆▆▆▆▆▆▆▆▆▆▅▅▅▆▆▆▆▆▆▆▆▅▅▁</td></tr><tr><td>train/actor_loss</td><td>█▁</td></tr><tr><td>train/critic_loss</td><td>█▁</td></tr><tr><td>train/ent_coef</td><td>█▁</td></tr><tr><td>train/ent_coef_loss</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/mean_ep_length</td><td>83.6</td></tr><tr><td>eval/mean_reward</td><td>235.63208</td></tr><tr><td>global_step</td><td>40446</td></tr><tr><td>rollout/ep_len_mean</td><td>40.81</td></tr><tr><td>rollout/ep_rew_mean</td><td>-15.53837</td></tr><tr><td>time/fps</td><td>456.0</td></tr><tr><td>train/actor_loss</td><td>-8.62987</td></tr><tr><td>train/critic_loss</td><td>52.72518</td></tr><tr><td>train/ent_coef</td><td>0.88031</td></tr><tr><td>train/ent_coef_loss</td><td>-0.86934</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">test1_SF_SB3_SAC_4</strong> at: <a href='https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/jfvnsuje</a><br/>Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230302_145847-jfvnsuje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished run test1_SF_SB3_SAC_4\n"
     ]
    }
   ],
   "source": [
    "# Finish the run if it's final\n",
    "run.finish()\n",
    "print(f\"Finished run {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6801db30-7721-45e3-af29-a2bc557d4fe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8d09bf-c365-498a-8534-c609b300a77e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MORE TRAINING\n",
    "\n",
    "# LOAD TRAINED MODEL\n",
    "\n",
    "# ########### PATHS NEED TO BE UPDATED\n",
    "# try:\n",
    "#     model.learn(total_timesteps=10_000_000, log_interval=8, tb_log_name=\"PlainDarmEnv\",\n",
    "#                     callback=WandbCallback(model_save_path=f\"checkpoints/wandb/{run.id}\",\n",
    "#                                            model_save_freq=10, verbose=2)\n",
    "#                )\n",
    "#     # Add calbacks\n",
    "# except Exception as e:\n",
    "#     print(\"Exception caught:\")\n",
    "#     print(e)\n",
    "# finally:\n",
    "#     timestamp = f\"{datetime.now().date()}__{datetime.now().time()}\"\n",
    "#     print(f\"Saving checkpoint {timestamp}\")\n",
    "#     model_name = f\"./checkpoints/darm_sf_hand_{timestamp}\"\n",
    "#     env_norm_name = f\"./checkpoints/darm_sf_hand_env_norm_{timestamp}\"\n",
    "#     model.save(model_name)\n",
    "#     # env.save(env_norm_name) # FIXME: Remember to save norm params if using VecNorm env\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f256d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.close()\n",
    "eval_env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6923cae6-9497-4a2e-b9f8-db23ca6e1fae",
   "metadata": {},
   "source": [
    "### DONE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c54a6abe-1b86-4682-9d7d-456dc1364ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e4596f3-355b-4200-9eb5-128405d6b914",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.sac.sac.SAC at 0x7f674531b0d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = f\"{config['run_local_dir']}/models/model_4\"\n",
    "# env_norm_name = \"./checkpoints/darm_sf_hand_env_norm_2022-12-28__10:10:05.637581\"\n",
    "\n",
    "eval_env = make_vec_env(create_env, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "eval_model = SAC.load(model_name, env=eval_env)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759192eb-a5d0-43e5-825a-8f550c09ad5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153.2036440999998 587.9564493972871\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "# Evaluate the model with 10 evaluation episodes and deterministic=True\n",
    "mean_reward, std_reward = evaluate_policy(eval_model, env=eval_model.get_env(), \n",
    "                                          n_eval_episodes=10, deterministic=True)\n",
    "\n",
    "# Print the results\n",
    "print(mean_reward, std_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89fa3c73-6a78-4b4f-93d3-f4cd855fdb2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:44<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/100 Solved\n",
      "86/100 Bonuses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "create_env_render = lambda: TransformObservation(gym.make(config[\"env_id\"], render_mode=None, single_finger_env=config[\"single_finger_env\"]), lambda obs: obs*100)\n",
    "env = make_vec_env(create_env_render, n_envs=1, seed=config[\"seed\"])\n",
    "\n",
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "episode_length = 0\n",
    "N_EPISODES = 100\n",
    "solved = 0\n",
    "bonuses = 0\n",
    "actions = []\n",
    "\n",
    "for i in tqdm(range(N_EPISODES)):\n",
    "    done = False\n",
    "    obs = env.reset()\n",
    "    # time.sleep(2)  # sleep for 2 seconds to see start state Update rendering order\n",
    "    \n",
    "    while not done:\n",
    "        # env.render()\n",
    "        action, _states = eval_model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        actions.append(info[0][\"action\"])\n",
    "        episode_return += reward[0]\n",
    "        episode_length += 1\n",
    "        done = done[0]\n",
    "        \n",
    "  #  print(f\"Episode Return: {episode_return} Episode Length: {episode_length}\")\n",
    "    info[0][\"model_action\"] = action\n",
    "    # pprint.pprint(info[0])\n",
    "  # print(f\"Solved: {info[0]['reward']['solved']}\")\n",
    "    solved += info[0]['reward']['solved'][0]\n",
    "    bonuses += info[0]['reward']['bonus'][0] > 0\n",
    "    # info[\"model_action\"] = action\n",
    "    # pprint.pprint(info)\n",
    "    \n",
    "    done = False\n",
    "    episode_return = 0\n",
    "    episode_length = 0\n",
    "\n",
    "env.close()\n",
    "print(f\"{solved}/{N_EPISODES} Solved\")\n",
    "print(f\"{bonuses}/{N_EPISODES} Bonuses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f714a1-e583-4c5a-a7bd-f9936df07ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 19802)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = np.asarray(actions)\n",
    "\n",
    "tendon_tensions = []\n",
    "tendon_names = [\"Dorsal Interossei\",\n",
    "                \"Palmar Interossei\",\n",
    "                \"Flexor Digitorum Profundus\",\n",
    "                \"Flexor Digitorum Superficialis\",\n",
    "                \"Extensor Digitorum Communis\"]\n",
    "\n",
    "\n",
    "for i in range(5):\n",
    "    tendon_tensions.append(actions[:, i])\n",
    "\n",
    "tendon_tensions = np.asarray(tendon_tensions)\n",
    "tendon_tensions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af34a7e-25f2-4d1a-bcaa-19f2f5fa0d59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dorsal Interossei</th>\n",
       "      <th>Palmar Interossei</th>\n",
       "      <th>Flexor Digitorum Profundus</th>\n",
       "      <th>Flexor Digitorum Superficialis</th>\n",
       "      <th>Extensor Digitorum Communis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19802.000000</td>\n",
       "      <td>19802.000000</td>\n",
       "      <td>19802.000000</td>\n",
       "      <td>19802.000000</td>\n",
       "      <td>19802.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.103419</td>\n",
       "      <td>0.910840</td>\n",
       "      <td>1.941189</td>\n",
       "      <td>0.609058</td>\n",
       "      <td>5.039713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.946743</td>\n",
       "      <td>1.057860</td>\n",
       "      <td>1.148230</td>\n",
       "      <td>0.857970</td>\n",
       "      <td>2.293364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.340933</td>\n",
       "      <td>0.109943</td>\n",
       "      <td>0.947354</td>\n",
       "      <td>0.164330</td>\n",
       "      <td>2.986025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.840970</td>\n",
       "      <td>0.482685</td>\n",
       "      <td>1.898292</td>\n",
       "      <td>0.373071</td>\n",
       "      <td>5.045188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.683563</td>\n",
       "      <td>1.379691</td>\n",
       "      <td>2.851413</td>\n",
       "      <td>0.589065</td>\n",
       "      <td>6.824331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.985662</td>\n",
       "      <td>4.999338</td>\n",
       "      <td>4.999955</td>\n",
       "      <td>4.868865</td>\n",
       "      <td>9.996423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Dorsal Interossei  Palmar Interossei  Flexor Digitorum Profundus  \\\n",
       "count       19802.000000       19802.000000                19802.000000   \n",
       "mean            1.103419           0.910840                    1.941189   \n",
       "std             0.946743           1.057860                    1.148230   \n",
       "min             0.002068           0.000825                    0.001235   \n",
       "25%             0.340933           0.109943                    0.947354   \n",
       "50%             0.840970           0.482685                    1.898292   \n",
       "75%             1.683563           1.379691                    2.851413   \n",
       "max             4.985662           4.999338                    4.999955   \n",
       "\n",
       "       Flexor Digitorum Superficialis  Extensor Digitorum Communis  \n",
       "count                    19802.000000                 19802.000000  \n",
       "mean                         0.609058                     5.039713  \n",
       "std                          0.857970                     2.293364  \n",
       "min                          0.002292                     0.000122  \n",
       "25%                          0.164330                     2.986025  \n",
       "50%                          0.373071                     5.045188  \n",
       "75%                          0.589065                     6.824331  \n",
       "max                          4.868865                     9.996423  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tendon_tensions_dict = {}\n",
    "\n",
    "for tendon_name, tensions in zip(tendon_names, tendon_tensions):\n",
    "    tendon_tensions_dict[tendon_name] = tensions\n",
    "\n",
    "tensions_df = pd.DataFrame(tendon_tensions_dict)\n",
    "tensions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b82ad6cc-b70e-45c0-8f5a-503381b6372a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    19802.000000\n",
       "mean         5.039713\n",
       "std          2.293364\n",
       "min          0.000122\n",
       "25%          2.986025\n",
       "50%          5.045188\n",
       "75%          6.824331\n",
       "max          9.996423\n",
       "Name: Extensor Digitorum Communis, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tendon_idx = 4\n",
    "tensions_df[tensions_df.columns[tendon_idx]].plot(kind='density')\n",
    "# tensions_df[tensions_df.columns[tendon_idx]].plot(kind='hist', bins=50)\n",
    "plt.title(f\"{tensions_df.columns[tendon_idx]} Tension Histogram plot\")\n",
    "_ = plt.xlabel(\"Tendon Tension [N]\")\n",
    "# _ = plt.ylabel(\"Count\")\n",
    "\n",
    "tensions_df[tensions_df.columns[tendon_idx]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d02519f-98c7-48d8-a9af-e266565e5758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac02162-fb76-4e93-a1f9-373253dc4ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd03e71f-e842-45a8-9638-5477d0efd2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d81643-ff6f-441b-a92f-d6b48df9de74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0254e0-8fa4-4b67-a708-0f9e9e56e5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b181d28b-35c8-4620-acde-49eaa01ea458",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tensions_df[\"Flexor Digitorum Superficialis\"].hist()\n",
    "# tensions_df[\"Extensor Digitorum Communis\"].hist()\n",
    "# tensions_df[\"Dorsal Interossei\"].hist()\n",
    "# tensions_df[\"Palmar Interossei\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f67ea17-a30b-4b6c-a9ea-0bc5da32959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def norm_to_target(obs):\n",
    "    \"\"\"\n",
    "    Returns the norm of each fingertip to the target position\n",
    "    obs: an observation from the observation space [...fingertip_pos, ...target_pos]\n",
    "    \"\"\"\n",
    "    obs = obs.reshape((-1, 3))\n",
    "    n_fingertips = len(obs)//2\n",
    "\n",
    "    fingertip_poses = obs[0:n_fingertips]\n",
    "    target_poses = obs[n_fingertips:]\n",
    "\n",
    "    return np.linalg.norm(fingertip_poses-target_poses, ord=2, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82aebaa-ee94-4d80-86b6-af957ff7ebb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Steps: 100\n",
      "Episode Return: [-206.27367]\n",
      "Episode Return Norm: [-6.1579084]\n",
      "\n",
      "\n",
      "Num Steps: 7\n",
      "Episode Return: [238.47386]\n",
      "Episode Return Norm: [7.1191816]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-112.209465]\n",
      "Episode Return Norm: [-3.3497994]\n",
      "\n",
      "\n",
      "Num Steps: 29\n",
      "Episode Return: [194.17151]\n",
      "Episode Return Norm: [5.7966194]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-154.97745]\n",
      "Episode Return Norm: [-4.6265574]\n",
      "\n",
      "\n",
      "Num Steps: 4\n",
      "Episode Return: [243.22809]\n",
      "Episode Return Norm: [7.2611094]\n",
      "Goal Reached!\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-204.50894]\n",
      "Episode Return Norm: [-6.1052227]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-108.443665]\n",
      "Episode Return Norm: [-3.2373753]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.46591]\n",
      "Episode Return Norm: [-6.163656]\n",
      "\n",
      "\n",
      "Num Steps: 100\n",
      "Episode Return: [-206.59006]\n",
      "Episode Return Norm: [-6.167353]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "episode_return = 0\n",
    "N_EPISODES = 10\n",
    "\n",
    "for i in range(N_EPISODES):\n",
    "  obs = env.reset()\n",
    "  done = False\n",
    "  episode_steps = 0\n",
    "  episode_return = 0\n",
    "  episode_return_norm = 0\n",
    "\n",
    "  \n",
    "  while not done:\n",
    "    # print(\"Observation: \", env.unnormalize_obs(obs))\n",
    "    old_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    # print(\"Action: \", action)\n",
    "\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_steps += 1\n",
    "    new_norm = norm_to_target(env.unnormalize_obs(obs))\n",
    "\n",
    "    # Get actual reward\n",
    "    unnormalized_reward = env.unnormalize_reward(reward)\n",
    "    episode_return += unnormalized_reward\n",
    "    episode_return_norm += reward\n",
    "    # print(f\"Reward: {unnormalized_reward}; Normalized: {reward}\")\n",
    "\n",
    "    # print(f\"Next Observation: {env.unnormalize_obs(obs)}\")\n",
    "    # print(f\"Change in Norm: {new_norm - old_norm}\")\n",
    "    # print(\"-----------------------------------------------------\")\n",
    "\n",
    "    # render\n",
    "    env.render()\n",
    "  \n",
    "  print(f\"Num Steps: {episode_steps}\")\n",
    "  print(f\"Episode Return: {episode_return}\")\n",
    "  print(f\"Episode Return Norm: {episode_return_norm}\")\n",
    "  if episode_return > -70: \n",
    "    print(\"Goal Reached!\")\n",
    "  print(\"\\n\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f502c9f8cc810ebd22b57e7c79a9d06f7b7c060e6ecfb4908c78b2fe1d232067"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
