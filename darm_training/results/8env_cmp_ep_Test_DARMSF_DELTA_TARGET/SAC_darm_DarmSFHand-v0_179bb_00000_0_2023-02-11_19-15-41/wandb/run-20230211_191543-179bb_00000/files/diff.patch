diff --git a/darm_training/.ipynb_checkpoints/darm_sf_hand_rllib_sac-checkpoint.ipynb b/darm_training/.ipynb_checkpoints/darm_sf_hand_rllib_sac-checkpoint.ipynb
index a39a7f1..b899852 100644
--- a/darm_training/.ipynb_checkpoints/darm_sf_hand_rllib_sac-checkpoint.ipynb
+++ b/darm_training/.ipynb_checkpoints/darm_sf_hand_rllib_sac-checkpoint.ipynb
@@ -31,21 +31,129 @@
    "execution_count": 2,
    "id": "f874e73d-f740-45bf-bed4-117e846ac0f2",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "'/home/daniel/DARM/darm_mujoco'"
+      ]
+     },
+     "execution_count": 2,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
    "source": [
     "# Configure env variables\n",
     "\n",
     "# TODO: change path\n",
     "import os\n",
-    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\""
+    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
+    "os.getenv('DARM_MUJOCO_PATH')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 3,
    "id": "b21d33a5-8591-4a1c-891e-a71073ff1c91",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "collapsed": true,
+    "jupyter": {
+     "outputs_hidden": true
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Requirement already satisfied: ray[rllib] in /home/daniel/miniconda3/lib/python3.8/site-packages (2.2.0)\n",
+      "Requirement already satisfied: torch in /home/daniel/miniconda3/lib/python3.8/site-packages (1.13.1)\n",
+      "Requirement already satisfied: pyyaml in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (6.0)\n",
+      "Requirement already satisfied: click>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (8.1.3)\n",
+      "Requirement already satisfied: numpy>=1.16 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.23.4)\n",
+      "Requirement already satisfied: grpcio>=1.32.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.51.1)\n",
+      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.0.4)\n",
+      "Requirement already satisfied: filelock in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.8.2)\n",
+      "Requirement already satisfied: aiosignal in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.1)\n",
+      "Requirement already satisfied: jsonschema in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.17.3)\n",
+      "Requirement already satisfied: virtualenv>=20.0.24 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (20.17.1)\n",
+      "Requirement already satisfied: attrs in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (22.2.0)\n",
+      "Requirement already satisfied: requests in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.27.1)\n",
+      "Requirement already satisfied: frozenlist in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.3)\n",
+      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.20.1)\n",
+      "Requirement already satisfied: scikit-image in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.19.3)\n",
+      "Requirement already satisfied: tensorboardX>=1.9 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.5.1)\n",
+      "Requirement already satisfied: matplotlib!=3.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.6.1)\n",
+      "Requirement already satisfied: scipy in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.9.2)\n",
+      "Requirement already satisfied: tabulate in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.9.0)\n",
+      "Requirement already satisfied: typer in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.7.0)\n",
+      "Requirement already satisfied: gym<0.24.0,>=0.21.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.21.0)\n",
+      "Requirement already satisfied: lz4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.0.2)\n",
+      "Requirement already satisfied: pandas in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.5.2)\n",
+      "Requirement already satisfied: rich in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (12.6.0)\n",
+      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.1.8)\n",
+      "Requirement already satisfied: typing_extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from torch) (4.4.0)\n",
+      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (2.2.0)\n",
+      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n",
+      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.0.5)\n",
+      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.9)\n",
+      "Requirement already satisfied: cycler>=0.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n",
+      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (4.37.4)\n",
+      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.4)\n",
+      "Requirement already satisfied: packaging>=20.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (21.3)\n",
+      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (9.3.0)\n",
+      "Requirement already satisfied: six>=1.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]) (1.12.0)\n",
+      "Requirement already satisfied: distlib<1,>=0.3.6 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (0.3.6)\n",
+      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (2.6.0)\n",
+      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (1.3.10)\n",
+      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (0.19.2)\n",
+      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (5.10.1)\n",
+      "Requirement already satisfied: zipp>=3.1.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->ray[rllib]) (3.11.0)\n",
+      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from pandas->ray[rllib]) (2022.7)\n",
+      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (1.26.14)\n",
+      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2022.12.7)\n",
+      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2.0.4)\n",
+      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (3.3)\n",
+      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (2.13.0)\n",
+      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (0.9.1)\n",
+      "Requirement already satisfied: networkx>=2.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.8.8)\n",
+      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (1.4.1)\n",
+      "Requirement already satisfied: tifffile>=2019.7.26 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2022.10.10)\n",
+      "Requirement already satisfied: imageio>=2.4.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.23.0)\n",
+      "Requirement already satisfied: wandb in /home/daniel/miniconda3/lib/python3.8/site-packages (0.13.10)\n",
+      "Requirement already satisfied: psutil>=5.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (5.9.4)\n",
+      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
+      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.20.1)\n",
+      "Requirement already satisfied: setproctitle in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
+      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
+      "Requirement already satisfied: PyYAML in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (6.0)\n",
+      "Requirement already satisfied: setuptools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (65.6.3)\n",
+      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
+      "Requirement already satisfied: appdirs>=1.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
+      "Requirement already satisfied: GitPython>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.1.30)\n",
+      "Requirement already satisfied: typing-extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (4.4.0)\n",
+      "Requirement already satisfied: requests<3,>=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
+      "Requirement already satisfied: pathtools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
+      "Requirement already satisfied: six>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.12.0)\n",
+      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
+      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
+      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
+      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
+      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
+      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
+      "Requirement already satisfied: tensorflow_probability in /home/daniel/miniconda3/lib/python3.8/site-packages (0.19.0)\n",
+      "Requirement already satisfied: cloudpickle>=1.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (2.2.0)\n",
+      "Requirement already satisfied: absl-py in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.2.0)\n",
+      "Requirement already satisfied: six>=1.10.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.12.0)\n",
+      "Requirement already satisfied: numpy>=1.13.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.23.4)\n",
+      "Requirement already satisfied: gast>=0.3.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.5.3)\n",
+      "Requirement already satisfied: decorator in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (5.1.1)\n",
+      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.1.8)\n"
+     ]
+    }
+   ],
    "source": [
     "!pip install ray[rllib] torch\n",
     "!pip install wandb\n",
@@ -216,7 +324,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 4,
    "id": "0ee4bf2a-d82c-4aaa-b278-f11a080e28af",
    "metadata": {},
    "outputs": [],
@@ -241,7 +349,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 5,
    "id": "4a0ed8ba-4f6b-47f9-b0e7-37d0eec71647",
    "metadata": {},
    "outputs": [],
@@ -281,10 +389,12 @@
     "    )\n",
     "    .rollouts(\n",
     "        num_rollout_workers=3,\n",
+    "        num_envs_per_worker=8,\n",
     "        rollout_fragment_length=1,\n",
     "        recreate_failed_workers=True,\n",
     "        num_consecutive_worker_failures_tolerance=10,\n",
-    "        restart_failed_sub_environments=True\n",
+    "        restart_failed_sub_environments=True,\n",
+    "        batch_mode=\"complete_episodes\"\n",
     "    )\n",
     "    .resources(num_gpus=0)\n",
     "    .evaluation(evaluation_interval=100) # For 1000 timesteps iter; 100 evals\n",
@@ -298,7 +408,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 6,
    "id": "46f0fa8e-5023-44c3-a9f7-8a6b041617a2",
    "metadata": {},
    "outputs": [],
@@ -311,6 +421,7 @@
     "\n",
     "wandb_init = dict(\n",
     "    save_code=True,\n",
+    "    resume=True,\n",
     "    config={\n",
     "        \"env\": \"DARMSFHand-v0\",\n",
     "        \n",
@@ -325,7 +436,7 @@
     "    },\n",
     "    tags=[\"single_finger\"],\n",
     "    notes=\"Fixed the env to use targets that are delta increaments from the starting state. Removed velocity penalty, and used only effort penalty\",\n",
-    "    name=\"Test_DARMSF_DELTA_TARGET\"\n",
+    "    name=\"8env_Test_DARMSF_DELTA_TARGET\"\n",
     "    # job_type=\n",
     "    # monitor_gym=\n",
     ")"
@@ -333,23 +444,28 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 7,
    "id": "6d7468b3-f377-4c7f-a0c3-6dec032fdc37",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[Errno 2] No such file or directory: '/home/daniel/DARM/darm-mujoco/darm_training/'\n",
+      "/home/daniel/DARM/darm_mujoco/darm_training\n"
+     ]
+    }
+   ],
    "source": [
     "%cd /home/daniel/DARM/darm-mujoco/darm_training/"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 8,
    "id": "727ee5b8-0cc3-4831-91ee-34514946c66a",
    "metadata": {
-    "collapsed": true,
-    "jupyter": {
-     "outputs_hidden": true
-    },
     "tags": []
    },
    "outputs": [
@@ -357,7 +473,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "2023-02-10 10:14:20,826\tINFO wandb.py:250 -- Already logged into W&B.\n"
+      "2023-02-11 18:21:54,285\tINFO worker.py:1538 -- Started a local Ray instance.\n"
      ]
     },
     {
@@ -369,16 +485,16 @@
        "      <h3>Tune Status</h3>\n",
        "      <table>\n",
        "<tbody>\n",
-       "<tr><td>Current time:</td><td>2023-02-10 10:20:23</td></tr>\n",
-       "<tr><td>Running for: </td><td>00:06:02.71        </td></tr>\n",
-       "<tr><td>Memory:      </td><td>5.8/7.5 GiB        </td></tr>\n",
+       "<tr><td>Current time:</td><td>2023-02-11 18:31:36</td></tr>\n",
+       "<tr><td>Running for: </td><td>00:09:40.99        </td></tr>\n",
+       "<tr><td>Memory:      </td><td>6.5/7.5 GiB        </td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "    </div>\n",
        "    <div class=\"vDivider\"></div>\n",
        "    <div class=\"systemInfo\">\n",
        "      <h3>System Info</h3>\n",
-       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.09 GiB objects\n",
+       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.25 GiB heap, 0.0/1.12 GiB objects\n",
        "    </div>\n",
        "    \n",
        "  </div>\n",
@@ -387,10 +503,10 @@
        "    <h3>Trial Status</h3>\n",
        "    <table>\n",
        "<thead>\n",
-       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
+       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
        "</thead>\n",
        "<tbody>\n",
-       "<tr><td>SAC_darm_DarmSFHand-v0_4d890_00000</td><td>RUNNING </td><td>192.168.152.36:5853</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         324.493</td><td style=\"text-align: right;\">15030</td><td style=\"text-align: right;\">-141.846</td><td style=\"text-align: right;\">             248.713</td><td style=\"text-align: right;\">            -192.044</td><td style=\"text-align: right;\">              90.1</td></tr>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_955d9_00000</td><td>RUNNING </td><td>192.168.152.36:25131</td><td style=\"text-align: right;\">    69</td><td style=\"text-align: right;\">         537.936</td><td style=\"text-align: right;\">69544</td><td style=\"text-align: right;\">-185.646</td><td style=\"text-align: right;\">            -171.193</td><td style=\"text-align: right;\">            -192.811</td><td style=\"text-align: right;\">               100</td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "  </div>\n",
@@ -437,63 +553,35 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:24,662 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1222045696; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:25,008\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:25,417\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m   logger.warn(\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m Loaded XML file successfully\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m Loaded XML file successfully\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m   logger.warn(\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m 2023-02-10 10:14:32,075\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:00,708\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:01,263\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:04,183 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 818434048; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m   logger.warn(\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m Loaded XML file successfully\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n"
      ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m   logger.warn(\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m 2023-02-11 18:22:10,650\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m Loaded XML file successfully\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   logger.warn(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,358\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,390\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,703\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:34,668 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221922816; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n"
      ]
     },
     {
@@ -511,7 +599,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_4d890_00000_0_2023-02-10_10-14-21/wandb/run-20230210_101425-4d890_00000</code>"
+       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/wandb/run-20230211_182159-955d9_00000</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -523,7 +611,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/4d890_00000' target=\"_blank\">Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/955d9_00000' target=\"_blank\">8env_Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -547,7 +635,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/4d890_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/4d890_00000</a>"
+       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/955d9_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/955d9_00000</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -556,6 +644,112 @@
      "metadata": {},
      "output_type": "display_data"
     },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m   logger.warn(\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:14,190 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 811732992; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25278)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25279)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=25277)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:21,576\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:24,195 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 815054848; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:28,164\tINFO trainable.py:172 -- Trainable.setup took 26.902 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:28,164\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:28,497\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
+     ]
+    },
     {
      "data": {
       "text/html": [
@@ -563,74 +757,74 @@
        "  <h3>Trial Progress</h3>\n",
        "  <table>\n",
        "<thead>\n",
-       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                              </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
+       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                         </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                             </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
        "</thead>\n",
        "<tbody>\n",
-       "<tr><td>SAC_darm_DarmSFHand-v0_4d890_00000</td><td style=\"text-align: right;\">                  15030</td><td>{&#x27;num_env_steps_sampled&#x27;: 15030, &#x27;num_env_steps_trained&#x27;: 429312, &#x27;num_agent_steps_sampled&#x27;: 15030, &#x27;num_agent_steps_trained&#x27;: 429312, &#x27;last_target_update_ts&#x27;: 15030, &#x27;num_target_updates&#x27;: 1677}</td><td>{}              </td><td>2023-02-10_10-19-58</td><td>False </td><td style=\"text-align: right;\">              90.1</td><td>{}             </td><td style=\"text-align: right;\">             248.713</td><td style=\"text-align: right;\">             -141.846</td><td style=\"text-align: right;\">            -192.044</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             154</td><td>8dd39779c7ef477aa164e54f946852e0</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.403343200683594, &#x27;actor_loss&#x27;: -6.434066295623779, &#x27;critic_loss&#x27;: 0.224114790558815, &#x27;alpha_loss&#x27;: -4.229072570800781, &#x27;alpha_value&#x27;: 0.60455614, &#x27;log_alpha_value&#x27;: -0.50326073, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.027431469410657883, &#x27;mean_q&#x27;: 4.410746097564697, &#x27;max_q&#x27;: 5.1180830001831055, &#x27;min_q&#x27;: 3.604030132293701}, &#x27;td_error&#x27;: array([3.76369953e-01, 2.18138933e-01, 8.90897512e-01, 5.00837326e-01,\n",
-       "       1.56644344e-01, 1.15910602e+00, 3.58983755e-01, 9.73417044e-01,\n",
-       "       4.54557180e-01, 3.18669558e-01, 2.47295618e-01, 3.98333549e-01,\n",
-       "       5.52456379e-02, 4.16686535e-01, 5.52578926e-01, 8.20993423e-01,\n",
-       "       4.80461121e-02, 5.51123619e-01, 3.48044634e-01, 4.45616722e-01,\n",
-       "       6.57121658e-01, 3.01966190e-01, 4.55074072e-01, 5.81701994e-01,\n",
-       "       4.43889856e-01, 3.61741066e-01, 6.02926254e-01, 6.10968113e-01,\n",
-       "       2.43805664e+02, 6.97162867e-01, 1.34469032e-01, 5.01981974e-01,\n",
-       "       5.75793648e+00, 3.33922148e-01, 2.84593582e-01, 8.42299938e-01,\n",
-       "       3.37388039e-01, 4.18749571e-01, 5.26380062e-01, 4.35695648e-01,\n",
-       "       4.50320482e-01, 6.56141853e+00, 9.19794083e-01, 4.95012522e-01,\n",
-       "       1.86808348e-01, 2.88064480e-01, 9.34903622e-02, 5.33180237e-01,\n",
-       "       7.46445179e-01, 3.29239368e-01, 4.63973522e-01, 5.52854300e-01,\n",
-       "       5.59043884e-01, 5.79916573e+00, 3.95936966e-01, 3.83873940e-01,\n",
-       "       7.85346985e-01, 3.67263794e-01, 5.48842669e-01, 6.90719604e-01,\n",
-       "       3.13124657e-02, 7.84007549e-01, 4.98735189e-01, 4.51488495e-01,\n",
-       "       2.78318405e-01, 8.23536158e-01, 5.27554512e-01, 1.09366131e+00,\n",
-       "       2.44073761e+02, 5.64733505e-01, 1.87523842e-01, 8.82987976e-01,\n",
-       "       4.84059095e-01, 6.78997517e-01, 8.01151276e-01, 6.06491089e-01,\n",
-       "       4.78818417e-01, 3.75759125e-01, 5.04173756e-01, 1.41024947e-01,\n",
-       "       2.97756195e-01, 6.70681572e+00, 6.38502359e-01, 1.84234142e-01,\n",
-       "       3.44598055e-01, 2.66064882e-01, 6.22176886e-01, 2.91838408e-01,\n",
-       "       6.30319595e-01, 3.90557766e-01, 7.24813938e-01, 6.66464329e-01,\n",
-       "       6.48372173e-01, 1.69317245e-01, 5.71012974e-01, 2.15357304e-01,\n",
-       "       4.80374098e-01, 4.54566240e-01, 6.62336826e-01, 5.37418842e-01,\n",
-       "       2.28084564e-01, 1.80234909e-01, 3.18274736e-01, 5.42303801e-01,\n",
-       "       2.43873016e+02, 3.50508213e-01, 6.72996044e-01, 3.73209953e-01,\n",
-       "       8.81858826e-01, 4.57011461e-01, 6.31304979e-01, 3.22345257e-01,\n",
-       "       4.37150240e-01, 8.15716267e-01, 6.95113182e-01, 5.28904438e-01,\n",
-       "       6.64132166e+00, 3.57316017e-01, 7.54707336e-01, 5.63272238e-01,\n",
-       "       8.61629725e-01, 1.76108837e-01, 8.31902027e-02, 1.03891134e-01,\n",
-       "       3.71709824e-01, 5.50470591e-01, 7.84245253e-01, 3.21080923e-01,\n",
-       "       3.92820835e-02, 5.49223900e-01, 6.91530704e-01, 3.57518673e-01,\n",
-       "       3.84907722e-01, 4.12734747e-01, 4.18194771e-01, 7.22610235e-01,\n",
-       "       3.24485064e-01, 5.38154554e+00, 7.06630945e-01, 1.67124152e-01,\n",
-       "       6.63487911e-01, 8.02201986e-01, 2.52504587e-01, 9.75709677e-01,\n",
-       "       4.89573479e-01, 6.64892435e-01, 1.03562427e+00, 3.95295620e-02,\n",
-       "       5.00542164e-01, 9.13107872e-01, 5.89080334e-01, 6.50176048e-01,\n",
-       "       6.37590694e+00, 8.55698586e-02, 3.50122690e-01, 6.35562181e-01,\n",
-       "       3.89072657e-01, 4.41820145e-01, 2.79556274e-01, 1.20183945e+00,\n",
-       "       5.35343766e-01, 5.90878248e-01, 6.06690645e-01, 7.29044676e-01,\n",
-       "       2.38976479e-01, 3.35858583e-01, 5.22370100e-01, 6.08634281e+00,\n",
-       "       6.85944557e-01, 4.10863638e-01, 3.76061916e-01, 3.61318350e-01,\n",
-       "       1.09372520e+00, 6.78944349e-01, 5.75511694e-01, 3.01788330e-01,\n",
-       "       2.70901680e-01, 3.42419863e-01, 3.19597006e-01, 1.56586289e-01,\n",
-       "       6.28098488e-01, 8.64251852e-01, 3.41733932e-01, 7.75881290e-01,\n",
-       "       2.96623230e-01, 3.41565371e-01, 2.20751286e-01, 3.47970247e-01,\n",
-       "       9.26482439e-01, 5.77410221e-01, 1.53335571e-01, 1.95543766e-02,\n",
-       "       7.58130074e-01, 4.61048365e-01, 4.55544472e-01, 4.03303385e-01,\n",
-       "       5.41186571e-01, 6.24453068e-01, 4.88040209e-01, 4.26761150e-01,\n",
-       "       1.01890087e-01, 8.34158182e-01, 6.50000811e-01, 5.72202206e-01,\n",
-       "       6.71605349e-01, 5.71026325e-01, 4.86349344e-01, 3.68950129e-01,\n",
-       "       3.34364176e-01, 7.52686977e-01, 3.25332880e-01, 3.64549398e-01,\n",
-       "       2.07561970e-01, 7.46529102e-01, 1.55097723e-01, 4.25298929e-01,\n",
-       "       8.42193842e-01, 2.43873016e+02, 2.43873016e+02, 2.82555580e-01,\n",
-       "       4.45864916e-01, 4.59903955e-01, 5.92770100e-01, 8.09845448e-01,\n",
-       "       8.23133469e-01, 5.77309561e+00, 5.96422911e-01, 7.31289148e-01,\n",
-       "       3.31299424e-01, 5.85563135e+00, 5.36827183e+00, 3.30348015e-01,\n",
-       "       5.50782681e-02, 8.04073811e-02, 6.67590857e-01, 6.92529202e-01,\n",
-       "       3.84135246e-01, 3.31759453e-01, 3.52068186e-01, 6.84356213e-01,\n",
-       "       6.38411427e+00, 2.44073761e+02, 9.02929783e-01, 6.10304737e+00,\n",
-       "       5.87041140e-01, 3.18532944e-01, 5.26460886e-01, 5.01149416e-01,\n",
-       "       3.49880457e-01, 4.51208830e-01, 1.33623719e-01, 1.37279153e-01,\n",
-       "       4.75117207e-01, 4.51113939e-01, 3.33072662e-01, 4.37882900e-01],\n",
-       "      dtype=float32), &#x27;mean_td_error&#x27;: 6.474668979644775, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 1677.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1676.0}}, &#x27;num_env_steps_sampled&#x27;: 15030, &#x27;num_env_steps_trained&#x27;: 429312, &#x27;num_agent_steps_sampled&#x27;: 15030, &#x27;num_agent_steps_trained&#x27;: 429312, &#x27;last_target_update_ts&#x27;: 15030, &#x27;num_target_updates&#x27;: 1677}       </td><td style=\"text-align: right;\">                        15</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    15030</td><td style=\"text-align: right;\">                   429312</td><td style=\"text-align: right;\">                  15030</td><td style=\"text-align: right;\">                             1002</td><td style=\"text-align: right;\">                 429312</td><td style=\"text-align: right;\">                            85504</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        85504</td><td>{&#x27;cpu_util_percent&#x27;: 46.60649350649351, &#x27;ram_util_percent&#x27;: 77.04415584415582}</td><td style=\"text-align: right;\"> 5853</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.2387199854807946, &#x27;mean_inference_ms&#x27;: 2.3233264583571662, &#x27;mean_action_processing_ms&#x27;: 0.2227478173887199, &#x27;mean_env_wait_ms&#x27;: 3.0315715951183035, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 248.7129012644291, &#x27;episode_reward_min&#x27;: -192.04356507956982, &#x27;episode_reward_mean&#x27;: -141.84599248990418, &#x27;episode_len_mean&#x27;: 90.1, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 10, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-188.50081959366798, -187.97007030248642, -189.0042775273323, -170.24335712194443, 248.7129012644291, -185.3823484480381, -187.89898101985455, -192.04356507956982, -176.78319323062897, -189.34621383994818], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 1, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.2387199854807946, &#x27;mean_inference_ms&#x27;: 2.3233264583571662, &#x27;mean_action_processing_ms&#x27;: 0.2227478173887199, &#x27;mean_env_wait_ms&#x27;: 3.0315715951183035, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             324.493</td><td style=\"text-align: right;\">            55.609</td><td style=\"text-align: right;\">       324.493</td><td>{&#x27;training_iteration_time_ms&#x27;: 144.554, &#x27;load_time_ms&#x27;: 0.263, &#x27;load_throughput&#x27;: 971712.058, &#x27;learn_time_ms&#x27;: 23.944, &#x27;learn_throughput&#x27;: 10691.626, &#x27;synch_weights_time_ms&#x27;: 5.41}</td><td style=\"text-align: right;\"> 1676020798</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            15030</td><td style=\"text-align: right;\">                  15</td><td>4d890_00000</td><td style=\"text-align: right;\">      7.98138</td></tr>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_955d9_00000</td><td style=\"text-align: right;\">                  69544</td><td>{&#x27;num_env_steps_sampled&#x27;: 69544, &#x27;num_env_steps_trained&#x27;: 638976, &#x27;num_agent_steps_sampled&#x27;: 69544, &#x27;num_agent_steps_trained&#x27;: 638976, &#x27;last_target_update_ts&#x27;: 69544, &#x27;num_target_updates&#x27;: 2496}</td><td>{}              </td><td>2023-02-11_18-31-31</td><td>False </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">            -171.193</td><td style=\"text-align: right;\">             -185.646</td><td style=\"text-align: right;\">            -192.811</td><td style=\"text-align: right;\">                  11</td><td style=\"text-align: right;\">             699</td><td>04874d707fbc4a058be02b4a4319fb7a</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.422243118286133, &#x27;actor_loss&#x27;: -5.14038610458374, &#x27;critic_loss&#x27;: 0.18727543950080872, &#x27;alpha_loss&#x27;: -6.30916690826416, &#x27;alpha_value&#x27;: 0.47278827, &#x27;log_alpha_value&#x27;: -0.7491076, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.004503707867115736, &#x27;mean_q&#x27;: 3.5478570461273193, &#x27;max_q&#x27;: 4.24842643737793, &#x27;min_q&#x27;: 2.603201389312744}, &#x27;td_error&#x27;: array([1.95934176e-01, 4.98089743e+00, 1.89424992e-01, 6.71895742e-01,\n",
+       "       7.33031631e-01, 8.49213481e-01, 7.51431346e-01, 4.33740973e-01,\n",
+       "       9.64703083e-01, 5.30384541e-01, 4.72339034e-01, 9.06269550e-02,\n",
+       "       3.49614263e-01, 8.87692809e-01, 8.08098316e-02, 2.08569646e-01,\n",
+       "       4.38382506e-01, 4.43389773e-01, 4.05444026e-01, 8.13477635e-01,\n",
+       "       3.25460434e-01, 5.69734335e-01, 5.90680242e-01, 5.73645592e-01,\n",
+       "       4.05951142e-01, 9.60426331e-01, 3.08855057e-01, 3.76948237e-01,\n",
+       "       3.55226278e-01, 1.72315955e-01, 6.02335215e-01, 6.45475149e-01,\n",
+       "       1.57423973e-01, 1.31635308e-01, 4.64949012e-01, 2.52607584e-01,\n",
+       "       1.83180690e-01, 3.66976142e-01, 4.62857842e-01, 6.61402106e-01,\n",
+       "       7.44413018e-01, 4.87931848e-01, 9.32562351e-02, 3.17810297e-01,\n",
+       "       6.33468151e-01, 5.13164997e-01, 4.77812648e-01, 1.09757423e-01,\n",
+       "       7.99443960e-01, 5.56855202e-01, 7.07716227e-01, 9.27923203e-01,\n",
+       "       6.69227958e-01, 2.54074097e-01, 3.10278058e-01, 1.64791703e-01,\n",
+       "       3.85820270e-01, 5.45998573e-01, 4.15854454e-02, 2.65067577e-01,\n",
+       "       5.09545445e-01, 5.46800375e-01, 3.70054841e-01, 1.56669021e-01,\n",
+       "       6.01548195e-01, 2.09501624e-01, 6.59341097e-01, 7.73742795e-01,\n",
+       "       6.03924751e-01, 3.36872220e-01, 2.06467628e-01, 7.80213714e-01,\n",
+       "       6.36670947e-01, 8.34103703e-01, 5.06087661e-01, 3.80478144e-01,\n",
+       "       2.69723535e-01, 6.75859809e-01, 5.45321226e-01, 3.19703460e-01,\n",
+       "       5.02280235e-01, 7.91096807e-01, 4.43688631e-01, 9.91499424e-03,\n",
+       "       7.47451425e-01, 2.36683965e-01, 2.60348678e-01, 4.67328787e-01,\n",
+       "       6.28292322e-01, 4.70365286e-01, 4.03882742e-01, 3.23166847e-01,\n",
+       "       6.03292513e+00, 4.29310799e-01, 6.10840917e-01, 3.73726845e-01,\n",
+       "       3.68518829e-02, 6.18789315e-01, 4.46662426e-01, 1.93954825e-01,\n",
+       "       4.20717359e-01, 6.37885690e-01, 4.72626567e-01, 4.44804430e-01,\n",
+       "       1.23008847e+00, 3.36173773e-01, 4.88475561e-01, 1.46518111e-01,\n",
+       "       6.58925414e-01, 2.10556030e-01, 5.41708231e-01, 6.53600693e-01,\n",
+       "       4.49524879e-01, 2.44677704e+02, 8.40904713e-01, 3.96098971e-01,\n",
+       "       2.85990000e-01, 2.98269629e-01, 2.79476166e-01, 2.45118744e+02,\n",
+       "       3.37035537e-01, 2.36833811e-01, 4.40242767e-01, 5.24304748e-01,\n",
+       "       1.83609843e-01, 3.88325453e-02, 4.69402194e-01, 4.96503592e-01,\n",
+       "       3.25291157e-01, 6.70904398e-01, 5.31253242e+00, 5.56430101e-01,\n",
+       "       2.86455989e-01, 2.21060157e-01, 4.41079140e-01, 5.26817036e+00,\n",
+       "       7.34386206e-01, 4.13230538e-01, 5.94475508e-01, 5.41901112e-01,\n",
+       "       4.30631518e-01, 2.32852340e-01, 2.46320963e-01, 2.59553075e-01,\n",
+       "       1.67002320e-01, 2.65804172e-01, 3.40333462e-01, 5.69654584e-01,\n",
+       "       2.44575684e+02, 6.30378723e-01, 4.61741209e-01, 6.60902858e-01,\n",
+       "       3.88297915e-01, 3.89522314e-01, 6.83917284e-01, 1.08264339e+00,\n",
+       "       2.89206982e-01, 5.26229024e-01, 5.29461622e-01, 5.37815213e-01,\n",
+       "       8.17095876e-01, 8.37937355e-01, 6.34663939e-01, 3.08352113e-01,\n",
+       "       7.25840926e-01, 6.19258046e-01, 5.19336939e+00, 4.91450310e-01,\n",
+       "       2.14041471e-01, 4.17014241e-01, 3.02111983e-01, 5.05619812e+00,\n",
+       "       6.65872097e-01, 3.76611948e-01, 7.40054250e-01, 3.73345017e-01,\n",
+       "       4.91391778e-01, 1.36850619e+00, 5.68441629e+00, 3.71704698e-01,\n",
+       "       3.10497284e-02, 4.98654246e-01, 4.75566268e-01, 6.99607015e-01,\n",
+       "       6.07254624e-01, 7.54065871e-01, 6.70101047e-01, 4.99469614e+00,\n",
+       "       4.19880152e-01, 4.69708562e-01, 9.46622133e-01, 2.60113597e-01,\n",
+       "       2.79498935e-01, 5.41265488e-01, 8.31641436e-01, 6.59172297e-01,\n",
+       "       2.14926958e-01, 7.11659551e-01, 3.87496114e-01, 8.89807940e-02,\n",
+       "       3.26396346e-01, 2.79494524e-01, 3.10897350e-01, 7.31913090e-01,\n",
+       "       1.89389825e-01, 2.28839993e-01, 3.23541164e-01, 1.11368537e-01,\n",
+       "       6.70159221e-01, 2.50860810e-01, 4.15617228e-01, 2.44613678e+02,\n",
+       "       5.66044688e-01, 3.92215252e-01, 1.89384222e-01, 7.22635865e-01,\n",
+       "       2.78705597e-01, 1.98728561e-01, 3.61492395e-01, 4.28767920e-01,\n",
+       "       8.03545594e-01, 5.33047557e-01, 3.75873446e-01, 2.15152383e-01,\n",
+       "       1.32757545e-01, 7.15655446e-01, 2.79827952e-01, 3.49776864e-01,\n",
+       "       2.45461226e-01, 4.23785806e-01, 1.69467688e-01, 3.69505763e-01,\n",
+       "       3.55105758e-01, 8.71978998e-02, 5.13431668e-01, 5.50498843e-01,\n",
+       "       7.05573201e-01, 4.56195712e-01, 3.82894397e-01, 8.50620508e-01,\n",
+       "       1.24529481e-01, 8.07293773e-01, 1.01107240e-01, 8.44668150e-01,\n",
+       "       2.34381199e-01, 1.26260042e-01, 1.12684441e+00, 5.72783589e-01,\n",
+       "       1.13141656e-01, 8.45807195e-01, 6.48936510e-01, 1.97365165e-01,\n",
+       "       5.37563658e+00, 2.44465351e-01, 6.03565931e-01, 5.81778407e-01],\n",
+       "      dtype=float32), &#x27;mean_td_error&#x27;: 4.448634147644043, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 2496.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 2495.0}}, &#x27;num_env_steps_sampled&#x27;: 69544, &#x27;num_env_steps_trained&#x27;: 638976, &#x27;num_agent_steps_sampled&#x27;: 69544, &#x27;num_agent_steps_trained&#x27;: 638976, &#x27;last_target_update_ts&#x27;: 69544, &#x27;num_target_updates&#x27;: 2496}       </td><td style=\"text-align: right;\">                        69</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    69544</td><td style=\"text-align: right;\">                   638976</td><td style=\"text-align: right;\">                  69544</td><td style=\"text-align: right;\">                             1000</td><td style=\"text-align: right;\">                 638976</td><td style=\"text-align: right;\">                            14336</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        14336</td><td>{&#x27;cpu_util_percent&#x27;: 67.03478260869565, &#x27;ram_util_percent&#x27;: 90.4913043478261}</td><td style=\"text-align: right;\">25131</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 9.044182009268827, &#x27;mean_inference_ms&#x27;: 2.674728818917897, &#x27;mean_action_processing_ms&#x27;: 0.9392519604046274, &#x27;mean_env_wait_ms&#x27;: 24.45927993064404, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -171.19273332506418, &#x27;episode_reward_min&#x27;: -192.81088799238205, &#x27;episode_reward_mean&#x27;: -185.64649303460664, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 11, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-190.76792462170124, -191.10273602604866, -184.69698552787304, -187.5072766020894, -178.02365075051785, -192.81088799238205, -190.08681654930115, -178.5881421416998, -189.39129136502743, -187.94297847896814, -171.19273332506418], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 9.044182009268827, &#x27;mean_inference_ms&#x27;: 2.674728818917897, &#x27;mean_action_processing_ms&#x27;: 0.9392519604046274, &#x27;mean_env_wait_ms&#x27;: 24.45927993064404, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             537.936</td><td style=\"text-align: right;\">           16.3271</td><td style=\"text-align: right;\">       537.936</td><td>{&#x27;training_iteration_time_ms&#x27;: 263.721, &#x27;load_time_ms&#x27;: 0.378, &#x27;load_throughput&#x27;: 676628.536, &#x27;learn_time_ms&#x27;: 36.426, &#x27;learn_throughput&#x27;: 7027.86, &#x27;synch_weights_time_ms&#x27;: 5.076}</td><td style=\"text-align: right;\"> 1676136691</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            69544</td><td style=\"text-align: right;\">                  69</td><td>955d9_00000</td><td style=\"text-align: right;\">      26.9068</td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</div>\n",
@@ -659,103 +853,227 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:44,673 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221365760; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:54,678 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221214208; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:04,684 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221103616; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:14,690 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1220038656; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:15:15,903\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:24,701 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219670016; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:34,712 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219510272; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:44,718 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219461120; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:54,724 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219444736; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:04,731 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219420160; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:14,737 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219231744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:24,743 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219137536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:34,750 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219129344; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:44,757 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219297280; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:54,766 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214754816; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:04,775 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214763008; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:14,781 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214701568; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:24,787 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214668800; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:34,792 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214619648; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:44,797 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214615552; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:54,803 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214607360; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:04,813 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214611456; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:14,818 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214554112; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:24,825 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214525440; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:34,831 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214480384; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:44,838 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214517248; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:54,843 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214537728; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:04,850 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214525440; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:14,856 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214529536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:24,862 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214271488; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:34,867 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214443520; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:44,874 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214414848; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:54,880 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214349312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:04,886 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214332928; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:14,891 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214316544; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "2023-02-10 10:20:20,585\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
-      "2023-02-10 10:20:21,533\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:20:23,571\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m Traceback (most recent call last):\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 364, in train\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     result = self.step()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 749, in step\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     results, train_iter_ctx = self._run_one_training_iteration()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 2623, in _run_one_training_iteration\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     results = self.training_step()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/dqn/dqn.py\", line 454, in training_step\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     update_priorities_in_replay_buffer(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/utils.py\", line 121, in update_priorities_in_replay_buffer\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     replay_buffer.update_priorities(prio_dict)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/multi_agent_prioritized_replay_buffer.py\", line 252, in update_priorities\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     self.replay_buffers[policy_id].update_priorities(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/prioritized_replay_buffer.py\", line 183, in update_priorities\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     assert priority > 0\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     sys.exit(1)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m SystemExit: 1\n",
-      "2023-02-10 10:20:23,760\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_4d890_00000]\n",
-      "2023-02-10 10:20:23,761\tINFO tune.py:762 -- Total run time: 362.95 seconds (362.71 seconds for the tuning loop).\n",
-      "2023-02-10 10:20:23,761\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:24,897 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214267392; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000001)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000002)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:34,200 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 811184128; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000003)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000004)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000005)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000006)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000007)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:44,210 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 804245504; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000008)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000009)... Done. 0.0s\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:22:50,898\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000010)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:22:54,222 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 799600640; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000011)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:04,227 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 798625792; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000012)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:14,237 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 797704192; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000013)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:24,243 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 796758016; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000014)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:34,248 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 794148864; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000015)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000016)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:44,255 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 788836352; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000017)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:23:54,265 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 786169856; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000018)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:04,270 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 783519744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000019)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:14,276 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 780857344; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000020)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:24,282 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 775610368; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000021)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:34,287 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 772968448; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000022)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:44,293 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 770310144; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000023)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000024)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:24:54,298 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 767496192; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000025)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:04,304 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 765784064; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000026)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:14,309 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 763187200; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000027)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:24,315 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 755310592; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000028)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:34,320 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 755204096; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000029)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:44,328 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 752521216; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000030)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:25:54,333 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 749830144; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000031)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:04,339 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 747139072; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000032)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000033)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:14,345 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 742752256; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000034)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:24,354 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 737456128; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000035)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:34,360 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 746070016; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000036)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:44,366 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 743362560; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000037)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:26:54,372 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 740585472; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000038)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:04,380 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 737955840; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000039)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:14,389 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 735154176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000040)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000041)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:24,394 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 729808896; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000042)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:34,400 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 727019520; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000043)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:44,408 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 724303872; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000044)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:27:54,414 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 719052800; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000045)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:04,420 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 718946304; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000046)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:14,427 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 713682944; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000047)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000048)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:24,432 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 710967296; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000049)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:34,438 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 708284416; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000050)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:44,443 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 705630208; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000051)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:28:54,449 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 702939136; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000052)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:04,454 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 700248064; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000053)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:14,460 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 697589760; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000054)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000055)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:24,465 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 692301824; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000056)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:34,472 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 689627136; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000057)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:44,477 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 686968832; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000058)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:29:54,485 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 684249088; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000059)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:04,491 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 681594880; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000060)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:14,497 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 678920192; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000061)... Done. 0.1s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000062)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:24,502 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 673615872; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000063)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:34,509 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 668360704; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000064)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:44,515 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 665812992; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000065)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:30:54,521 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 663056384; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000066)... Done. 0.1s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:31:04,526 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 662884352; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000067)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:31:14,532 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 660283392; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000068)... Done. 0.0s\n",
+      "\u001b[2m\u001b[36m(SAC pid=25131)\u001b[0m 2023-02-11 18:31:19,773\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. The actor died unexpectedly before finishing this task.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:31:24,537 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 654991360; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m 2023-02-11 18:31:26,837\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_955d9_00000_0_2023-02-11_18-21-56/checkpoint_000069)... Done. 0.1s\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 18:31:33,002\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
+      "2023-02-11 18:31:33,947\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:31:34,546 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 652316672; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=26947)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 18:31:37,190\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_955d9_00000]\n",
+      "2023-02-11 18:31:37,191\tINFO tune.py:762 -- Total run time: 581.49 seconds (580.98 seconds for the tuning loop).\n",
+      "2023-02-11 18:31:37,192\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:31:44,558 E 24872 24922] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-21-52_087643_24758 is over 95% full, available space: 654864384; capacity: 31845081088. Object creation will fail if spilling is required.\n"
      ]
     }
    ],
    "source": [
     "# TODO: \n",
     "# change: name\n",
+    "# change: checkpoint_freq\n",
+    "\n",
+    "sync_config = tune.SyncConfig()\n",
     "\n",
     "tuner = tune.Tuner(\n",
     "    \"SAC\",\n",
     "    run_config=air.RunConfig(\n",
-    "        name=\"Test_DARMSF_DELTA_TARGET\",\n",
+    "        name=\"8env_Test_DARMSF_DELTA_TARGET\",\n",
+    "        local_dir=f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results\",\n",
+    "        sync_config=sync_config,\n",
     "        stop={\"training_iteration\": 10_000, \"episode_reward_mean\": 200},\n",
-    "        checkpoint_config=air.CheckpointConfig(checkpoint_at_end=True),\n",
+    "        checkpoint_config=air.CheckpointConfig(\n",
+    "            checkpoint_at_end=True,\n",
+    "            checkpoint_score_attribute=\"episode_reward_mean\",  # or leave to save last chkpts\n",
+    "            checkpoint_score_order=\"max\",\n",
+    "            checkpoint_frequency=1,  #50,\n",
+    "            num_to_keep=3\n",
+    "        ),\n",
     "        callbacks=[\n",
     "                WandbLoggerCallback(project=\"DARM\", \n",
     "                                    api_key=\"392c8a47eb0658eb5c71190757a69110e2140f4a\",\n",
     "                                    save_checkpoints=True, \n",
     "                                    **wandb_init)\n",
     "            ],\n",
-    "        local_dir=\"./results\"\n",
     "        ),\n",
     "    param_space=config\n",
     ")\n",
@@ -765,10 +1083,674 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 16,
    "id": "1e3264d3-86a3-430c-bae2-940f2da854d2",
    "metadata": {},
    "outputs": [],
+   "source": [
+    "# Ensure wandb is sysncing to cloud\n",
+    "# cd to darm_training again if not"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "id": "ed17fb23-77b1-4e35-95b7-a44b6e342691",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 17:26:13,607\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.tuner.Tuner at 0x7fede99d9a90>"
+      ]
+     },
+     "execution_count": 10,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:16,601 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061720064; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    }
+   ],
+   "source": [
+    "# TODO:\n",
+    "# change: experiment name\n",
+    "\n",
+    "# Restore Interrupted run\n",
+    "tuner = tune.Tuner.restore(\n",
+    "    f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n",
+    "    resume_errored=True\n",
+    ")\n",
+    "tuner"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "id": "160c2790-f9ac-41cb-8198-d571d2c51332",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.result_grid.ResultGrid at 0x7fcd58384b80>"
+      ]
+     },
+     "execution_count": 15,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "results = tuner.get_results()\n",
+    "results"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 16,
+   "id": "ace959cb-3e05-4caa-8dd9-f00bbab33eb0",
+   "metadata": {
+    "collapsed": true,
+    "jupyter": {
+     "outputs_hidden": true
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Result(metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.343955039978027, 'actor_loss': -5.076763153076172, 'critic_loss': 0.4612053632736206, 'alpha_loss': -0.850807249546051, 'alpha_value': 0.9030595, 'log_alpha_value': -0.101966895, 'target_entropy': -5.0, 'policy_t': -0.01997794397175312, 'mean_q': 2.0334110260009766, 'max_q': 2.8355112075805664, 'min_q': 1.038293480873108}, 'td_error': array([9.46030378e-01, 4.29627061e-01, 2.65497327e-01, 8.43869328e-01,\n",
+       "       1.09686172e+00, 7.66791701e-01, 7.26696014e-01, 5.70532084e-02,\n",
+       "       1.14584994e+00, 4.43507016e-01, 1.04901314e-01, 1.52089047e+00,\n",
+       "       6.52013183e-01, 8.16148460e-01, 1.08409297e+00, 2.61833251e-01,\n",
+       "       3.79876256e-01, 9.56449747e-01, 5.75677335e-01, 1.02149987e+00,\n",
+       "       1.76170349e-01, 9.50863540e-01, 7.04805613e-01, 3.25276971e-01,\n",
+       "       6.36387825e-01, 8.46629441e-01, 5.59558868e-02, 8.83865356e-03,\n",
+       "       7.97627211e-01, 8.26396644e-01, 9.43091869e-01, 2.46674316e+02,\n",
+       "       5.55538654e-01, 7.27864265e-01, 1.29726791e+00, 4.26257730e-01,\n",
+       "       4.88600850e-01, 7.20911384e-01, 6.31772637e-01, 1.28249526e+00,\n",
+       "       7.96164632e-01, 3.33085537e+00, 3.80529928e+00, 9.50119078e-01,\n",
+       "       8.29495788e-01, 4.02090669e-01, 9.92336035e-01, 4.70980978e+00,\n",
+       "       7.12400794e-01, 5.61774313e-01, 8.87979388e-01, 6.99178576e-02,\n",
+       "       7.03785896e-01, 3.68088245e+00, 4.42697144e+00, 3.84785533e-02,\n",
+       "       4.06367898e-01, 9.53655124e-01, 1.01472402e+00, 6.36071920e-01,\n",
+       "       3.92946482e-01, 2.85786510e-01, 7.28411913e-01, 4.54745054e-01,\n",
+       "       5.25969863e-02, 6.62682295e-01, 2.46527893e+02, 3.33758354e-01,\n",
+       "       3.90868187e-01, 2.47024506e+02, 3.74032736e-01, 7.44001746e-01,\n",
+       "       1.19754124e+00, 1.98264122e-01, 5.89548111e-01, 7.19748855e-01,\n",
+       "       6.91104770e-01, 2.46527893e+02, 1.00903511e+00, 8.68608594e-01,\n",
+       "       1.46339655e-01, 8.63849521e-01, 6.97440386e-01, 6.95250630e-01,\n",
+       "       1.08643126e+00, 2.53858209e-01, 9.59976912e-01, 3.65842342e-01,\n",
+       "       5.75604081e-01, 1.01638889e+00, 5.54916143e-01, 2.61025906e-01,\n",
+       "       3.69157314e-01, 5.89906454e-01, 9.18144405e-01, 9.76853013e-01,\n",
+       "       7.45771408e-01, 7.41098404e-01, 3.15677047e-01, 1.40482628e+00,\n",
+       "       8.13360214e-02, 1.82469726e-01, 9.30288076e-01, 1.78921580e-01,\n",
+       "       2.64111042e-01, 7.66712904e-01, 2.51149416e-01, 3.72322750e+00,\n",
+       "       1.50621676e+00, 1.34934068e-01, 8.34389687e-01, 2.28880048e-01,\n",
+       "       2.46911713e+02, 8.71338129e-01, 1.41575491e+00, 1.15829027e+00,\n",
+       "       4.01661396e-01, 3.22172642e-02, 1.03146315e+00, 1.20233822e+00,\n",
+       "       3.63595724e-01, 3.59781146e-01, 3.90814304e-01, 7.14776337e-01,\n",
+       "       2.03609109e-01, 8.17107201e-01, 1.51301539e+00, 9.68729496e-01,\n",
+       "       8.05726111e-01, 6.48125052e-01, 4.55322862e-01, 2.52527475e-01,\n",
+       "       6.16939187e-01, 7.07782507e-01, 2.46674316e+02, 5.37988365e-01,\n",
+       "       8.88993800e-01, 6.42939091e-01, 5.66157341e-01, 7.45199919e-01,\n",
+       "       4.95904922e-01, 5.44749737e-01, 1.33524406e+00, 1.09470248e+00,\n",
+       "       4.20443952e-01, 2.31693149e-01, 1.49213076e-01, 4.79452491e-01,\n",
+       "       5.01387000e-01, 6.36883974e-01, 9.08940554e-01, 2.35339999e-02,\n",
+       "       1.09470153e+00, 6.25958681e-01, 4.33341503e-01, 8.15379143e-01,\n",
+       "       1.10253215e+00, 1.11163783e+00, 6.50242090e-01, 3.74678016e-01,\n",
+       "       5.57896376e-01, 6.90997720e-01, 1.67405367e-01, 5.14347076e-01,\n",
+       "       6.10636115e-01, 1.26651037e+00, 1.06177032e-01, 1.89136624e-01,\n",
+       "       7.38880932e-01, 1.18341660e+00, 2.61298299e-01, 1.94938481e-01,\n",
+       "       2.90627241e-01, 8.71249318e-01, 5.99144578e-01, 5.03087521e-01,\n",
+       "       1.23708069e+00, 3.05450976e-01, 3.46238852e-01, 5.79999447e-01,\n",
+       "       1.01897049e+00, 1.15455341e+00, 3.51977944e-01, 4.95337844e-01,\n",
+       "       1.29761028e+00, 2.77725697e-01, 9.85441983e-01, 6.46635413e-01,\n",
+       "       7.72787869e-01, 1.04821801e-01, 1.34492373e+00, 2.94095612e+00,\n",
+       "       1.16106701e+00, 1.31630957e-01, 9.86808658e-01, 4.82740879e-01,\n",
+       "       2.54980326e-01, 4.74518299e-01, 4.15986300e-01, 1.08055830e-01,\n",
+       "       6.39527440e-01, 1.52761579e-01, 4.26321507e-01, 8.16009641e-01,\n",
+       "       7.27825999e-01, 1.11527145e-01, 1.66661322e-01, 5.02551913e-01,\n",
+       "       1.97000146e-01, 4.07129705e-01, 7.51043320e-01, 2.46911713e+02,\n",
+       "       7.29810119e-01, 6.43945575e-01, 1.79764152e-01, 5.80982447e-01,\n",
+       "       2.05063581e-01, 1.04409027e+00, 4.56080079e-01, 4.46982563e-01,\n",
+       "       9.81729567e-01, 6.59761965e-01, 2.98615646e+00, 2.80451059e-01,\n",
+       "       4.59819794e-01, 9.62480664e-01, 1.36348128e-01, 9.03037906e-01,\n",
+       "       7.55133808e-01, 1.33910954e-01, 6.25847220e-01, 4.72928882e-01,\n",
+       "       1.15204036e-01, 1.34494066e+00, 3.28659534e-01, 7.61413455e-01,\n",
+       "       2.46207031e+02, 5.60174465e-01, 6.26057982e-01, 7.27932453e-01,\n",
+       "       5.94342828e-01, 1.06366754e-01, 8.86531234e-01, 7.32596040e-01,\n",
+       "       6.20095134e-01, 5.57798028e-01, 7.78808892e-01, 2.44230628e-01,\n",
+       "       4.23718333e-01, 1.13543332e-01, 5.97412705e-01, 7.66506553e-01,\n",
+       "       7.60311723e-01, 6.40589774e-01, 4.38361287e-01, 9.32641983e-01],\n",
+       "      dtype=float32), 'mean_td_error': 8.407605171203613, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 256.0, 'num_grad_updates_lifetime': 341.0, 'diff_num_grad_updates_vs_sampler_policy': 340.0}}, 'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'last_target_update_ts': 11022, 'num_target_updates': 341}, 'sampler_results': {'episode_reward_max': -175.28551595658064, 'episode_reward_min': -191.91201797127724, 'episode_reward_mean': -183.6617713689804, 'episode_len_mean': 100.0, 'episode_media': {}, 'episodes_this_iter': 10, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-177.71922475099564, -187.68662855029106, -175.28551595658064, -185.17646113038063, -188.07598569989204, -183.15926399081945, -187.51414139568806, -191.91201797127724, -180.03978146612644, -180.04869277775288], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.2209175070937799, 'mean_inference_ms': 2.2407887063058864, 'mean_action_processing_ms': 0.21747991990069954, 'mean_env_wait_ms': 3.0381576901390437, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': -175.28551595658064, 'episode_reward_min': -191.91201797127724, 'episode_reward_mean': -183.6617713689804, 'episode_len_mean': 100.0, 'episodes_this_iter': 10, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-177.71922475099564, -187.68662855029106, -175.28551595658064, -185.17646113038063, -188.07598569989204, -183.15926399081945, -187.51414139568806, -191.91201797127724, -180.03978146612644, -180.04869277775288], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.2209175070937799, 'mean_inference_ms': 2.2407887063058864, 'mean_action_processing_ms': 0.21747991990069954, 'mean_env_wait_ms': 3.0381576901390437, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 3, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_env_steps_sampled_this_iter': 1002, 'num_env_steps_trained_this_iter': 85504, 'num_steps_trained_this_iter': 85504, 'agent_timesteps_total': 11022, 'timers': {'training_iteration_time_ms': 147.211, 'load_time_ms': 0.259, 'load_throughput': 986985.774, 'learn_time_ms': 24.022, 'learn_throughput': 10657.075, 'synch_weights_time_ms': 5.359}, 'counters': {'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'last_target_update_ts': 11022, 'num_target_updates': 341}, 'done': False, 'trial_id': 'ad8de_00000', 'perf': {'cpu_util_percent': 38.9536231884058, 'ram_util_percent': 87.61304347826086}, 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_a1dbe_00000_0_2023-02-11_16-49-13/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_ad8de_00000_0_2023-02-11_16-56-43'))"
+      ]
+     },
+     "execution_count": 16,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# Get the best result based on a particular metric.\n",
+    "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
+    "best_result"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 17,
+   "id": "beca7170-c89a-402c-afb7-ce88cf5524b7",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Checkpoint(local_path=/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_a1dbe_00000_0_2023-02-11_16-49-13/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_ad8de_00000_0_2023-02-11_16-56-43/checkpoint_000011)"
+      ]
+     },
+     "execution_count": 17,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:32,579 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129005056; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:42,596 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129254912; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:52,615 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129238528; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    }
+   ],
+   "source": [
+    "# Get the best checkpoint corresponding to the best result.\n",
+    "best_checkpoint = best_result.checkpoint\n",
+    "best_checkpoint"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "id": "3b9e8a43-146c-4a5b-99b7-12384ff38b84",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 16:38:32,937\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "2023-02-11 16:38:32,949\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 16:38:35,741 E 6815 6860] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-34-33_438228_6699 is over 95% full, available space: 1174347776; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m 2023-02-11 16:38:38,536\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m   logger.warn(\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "  logger.warn(\n",
+      "2023-02-11 16:38:39,885\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
+      "2023-02-11 16:38:39,927\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "SAC"
+      ]
+     },
+     "execution_count": 11,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# Get Algorithm from saved checkpoint\n",
+    "from ray.rllib.algorithms.algorithm import Algorithm\n",
+    "algo = Algorithm.from_checkpoint(best_checkpoint._local_path)\n",
+    "algo"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "id": "a9cff7c5-f517-4287-9447-668320c35452",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 17:26:26,421\tINFO trial_runner.py:688 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
+      "2023-02-11 17:26:26,422\tINFO trial_runner.py:825 -- Using following checkpoint to resume: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-11_17-23-28.json\n",
+      "2023-02-11 17:26:26,426\tWARNING trial_runner.py:830 -- Attempting to resume experiment from /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET. This will ignore any new changes to the specification.\n",
+      "2023-02-11 17:26:26,440\tINFO tune.py:653 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "<div class=\"tuneStatus\">\n",
+       "  <div style=\"display: flex;flex-direction: row\">\n",
+       "    <div style=\"display: flex;flex-direction: column;\">\n",
+       "      <h3>Tune Status</h3>\n",
+       "      <table>\n",
+       "<tbody>\n",
+       "<tr><td>Current time:</td><td>2023-02-11 17:29:20</td></tr>\n",
+       "<tr><td>Running for: </td><td>00:02:54.01        </td></tr>\n",
+       "<tr><td>Memory:      </td><td>6.3/7.5 GiB        </td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "    </div>\n",
+       "    <div class=\"vDivider\"></div>\n",
+       "    <div class=\"systemInfo\">\n",
+       "      <h3>System Info</h3>\n",
+       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/1.72 GiB heap, 0.0/0.86 GiB objects\n",
+       "    </div>\n",
+       "    \n",
+       "  </div>\n",
+       "  <div class=\"hDivider\"></div>\n",
+       "  <div class=\"trialStatus\">\n",
+       "    <h3>Trial Status</h3>\n",
+       "    <table>\n",
+       "<thead>\n",
+       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
+       "</thead>\n",
+       "<tbody>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td>RUNNING </td><td>192.168.152.36:15703</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         227.817</td><td style=\"text-align: right;\">13026</td><td style=\"text-align: right;\">-179.588</td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">               100</td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "  </div>\n",
+       "</div>\n",
+       "<style>\n",
+       ".tuneStatus {\n",
+       "  color: var(--jp-ui-font-color1);\n",
+       "}\n",
+       ".tuneStatus .systemInfo {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "}\n",
+       ".tuneStatus td {\n",
+       "  white-space: nowrap;\n",
+       "}\n",
+       ".tuneStatus .trialStatus {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "}\n",
+       ".tuneStatus h3 {\n",
+       "  font-weight: bold;\n",
+       "}\n",
+       ".tuneStatus .hDivider {\n",
+       "  border-bottom-width: var(--jp-border-width);\n",
+       "  border-bottom-color: var(--jp-border-color0);\n",
+       "  border-bottom-style: solid;\n",
+       "}\n",
+       ".tuneStatus .vDivider {\n",
+       "  border-left-width: var(--jp-border-width);\n",
+       "  border-left-color: var(--jp-border-color0);\n",
+       "  border-left-style: solid;\n",
+       "  margin: 0.5em 1em 0.5em 1em;\n",
+       "}\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:26,618 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061683200; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:30,934\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:31,413\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/wandb/run-20230211_172629-6a944_00000</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Resuming run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/6a944_00000</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:36,627 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061359616; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m 2023-02-11 17:26:38,825\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,232\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,261\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:790 -- Restored on 192.168.152.36 from checkpoint: /tmp/checkpoint_tmp_7f50b6e15e2c473dba807bf1d398566d\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 11, '_timesteps_total': None, '_time_total': 113.04964661598206, '_episodes_total': 114}\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:46,634 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061335040; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:56,640 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:06,648 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061339136; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:16,654 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:26,659 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061314560; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "<div class=\"trialProgress\">\n",
+       "  <h3>Trial Progress</h3>\n",
+       "  <table>\n",
+       "<thead>\n",
+       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                               </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
+       "</thead>\n",
+       "<tbody>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td style=\"text-align: right;\">                  13026</td><td>{&#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}</td><td>{}              </td><td>2023-02-11_17-28-35</td><td>False </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">             -179.588</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             132</td><td>2674246d3b814ef583cb37ca785123d2</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.40356159210205, &#x27;actor_loss&#x27;: -4.885239601135254, &#x27;critic_loss&#x27;: 0.3069121241569519, &#x27;alpha_loss&#x27;: -2.5390048027038574, &#x27;alpha_value&#x27;: 0.7392387, &#x27;log_alpha_value&#x27;: -0.30213442, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.029988128691911697, &#x27;mean_q&#x27;: 2.379087448120117, &#x27;max_q&#x27;: 3.1470589637756348, &#x27;min_q&#x27;: 1.5433847904205322}, &#x27;td_error&#x27;: array([7.4213958e-01, 1.5848637e-01, 6.0251343e-01, 9.3348145e-01,\n",
+       "       7.2470105e-01, 6.5075898e-01, 7.4386942e-01, 4.2802992e+00,\n",
+       "       4.9475217e-01, 2.1274698e-01, 1.5443254e-01, 2.0181298e-01,\n",
+       "       4.8542452e-01, 4.9696553e-01, 3.7915547e+00, 8.3584547e-02,\n",
+       "       8.3843565e-01, 7.5096285e-01, 6.2452388e-01, 2.4125576e-01,\n",
+       "       7.7261329e-01, 2.6608777e-01, 3.3530772e-01, 2.6860654e-01,\n",
+       "       1.5399015e-01, 7.0978558e-01, 7.8079522e-01, 1.0731530e-01,\n",
+       "       8.8066232e-01, 1.1126903e+00, 3.6070585e-02, 6.7874563e-01,\n",
+       "       7.5406009e-01, 4.2981052e-01, 1.1391871e+00, 3.9740098e-01,\n",
+       "       1.0762990e+00, 8.4136343e-01, 5.8252001e-01, 4.0861154e-01,\n",
+       "       5.6281984e-01, 2.7024639e-01, 6.9000638e-01, 8.6244369e-01,\n",
+       "       5.7595563e-01, 7.2603118e-01, 5.9470689e-01, 2.7473211e-01,\n",
+       "       5.6826186e-01, 2.4650784e+02, 9.8598832e-01, 7.3479068e-01,\n",
+       "       6.1449623e-01, 1.2699622e+00, 7.5296319e-01, 2.8090358e-02,\n",
+       "       9.4109213e-01, 8.2771111e-01, 4.2838442e-01, 3.8090675e+00,\n",
+       "       4.7546709e-01, 2.4742079e-01, 4.1203547e-01, 7.3801911e-01,\n",
+       "       1.0025257e+00, 6.7763782e-01, 6.7099619e-01, 8.6762822e-01,\n",
+       "       5.6190348e-01, 8.8954902e-01, 8.1222010e-01, 8.6386180e-01,\n",
+       "       7.6953566e-01, 1.0633967e+00, 5.9996891e-01, 5.3750610e-01,\n",
+       "       7.0670819e-01, 4.9724150e-01, 3.3370614e-02, 6.8903613e-01,\n",
+       "       9.4764221e-01, 5.0915122e-02, 5.0027347e-01, 9.6055913e-01,\n",
+       "       5.5192137e-01, 7.9515433e-01, 7.2671640e-01, 3.9931262e-01,\n",
+       "       1.8239129e-01, 9.9649012e-01, 8.4206927e-01, 4.1600978e-01,\n",
+       "       4.0527940e-01, 7.6102638e-01, 2.3393106e-01, 4.7766042e-01,\n",
+       "       2.2459340e-01, 8.5827851e-01, 1.4306033e-01, 2.4650784e+02,\n",
+       "       7.1198571e-01, 3.9922416e+00, 1.2246186e+00, 7.4194229e-01,\n",
+       "       2.7496171e-01, 4.5212805e-02, 7.4664807e-01, 1.3847947e-02,\n",
+       "       8.7445688e-01, 6.6402781e-01, 1.0255686e+00, 4.5125723e-01,\n",
+       "       4.8755097e-01, 2.4650784e+02, 4.4124365e-01, 1.0487792e+00,\n",
+       "       5.8346188e-01, 2.6959336e-01, 3.5287654e-01, 5.9907603e-01,\n",
+       "       4.8603582e-01, 6.1551094e-01, 6.9831514e-01, 5.1433253e-01,\n",
+       "       1.8200487e-01, 9.6122825e-01, 7.8497732e-01, 2.2768998e-01,\n",
+       "       9.6964097e-01, 1.4972503e+00, 8.0229974e-01, 1.0484257e+00,\n",
+       "       5.5421102e-01, 8.3084774e-01, 4.7661805e-01, 3.9173824e-01,\n",
+       "       3.1396019e-01, 4.2802992e+00, 2.7052438e-01, 2.6957560e-01,\n",
+       "       7.5368738e-01, 4.4456518e-01, 3.1527257e-01, 8.5121763e-01,\n",
+       "       9.0664178e-01, 9.4629610e-01, 5.6297445e-01, 5.9285718e-01,\n",
+       "       6.3104606e-01, 5.2718985e-01, 6.5370166e-01, 7.0399725e-01,\n",
+       "       4.5417070e-02, 2.4650784e+02, 7.2803473e-01, 1.1245636e+00,\n",
+       "       3.7708211e-01, 3.7433398e-01, 4.3422055e-01, 3.2808065e-01,\n",
+       "       6.2305951e-01, 1.7103601e-01, 7.9449832e-01, 1.3040452e+00,\n",
+       "       7.1471536e-01, 4.5487504e+00, 4.1272748e-01, 6.5745860e-01,\n",
+       "       6.6768157e-01, 8.8028562e-01, 7.0535421e-01, 5.2402341e-01,\n",
+       "       5.6226981e-01, 5.4202604e-01, 2.7826047e-01, 2.6031137e-01,\n",
+       "       6.0549617e-02, 3.6561573e-01, 2.4650784e+02, 8.0606019e-01,\n",
+       "       8.4074116e-01, 4.9388194e-01, 7.1800745e-01, 2.9282093e-02,\n",
+       "       1.9090211e-01, 3.8544512e-01, 1.4638956e+00, 1.4547678e+00,\n",
+       "       1.0922147e+00, 2.6176953e-01, 1.3020796e-01, 5.6222248e-01,\n",
+       "       5.6339896e-01, 7.6045167e-01, 7.8438163e-01, 7.5755298e-01,\n",
+       "       8.2661462e-01, 3.5743856e-01, 1.3571662e-01, 5.3244066e-01,\n",
+       "       8.8719201e-01, 8.2828355e-01, 3.8229942e-01, 6.0678411e-01,\n",
+       "       4.7898412e-01, 8.2518208e-01, 5.2971601e-01, 6.7987609e-01,\n",
+       "       7.6182199e-01, 1.0264168e+00, 6.2066817e-01, 9.0486789e-01,\n",
+       "       4.7908902e-01, 1.1681950e-01, 7.6850456e-01, 3.1422675e-01,\n",
+       "       9.3148047e-01, 9.5507002e-01, 8.3421135e-01, 5.6414163e-01,\n",
+       "       4.1598296e-01, 5.0719857e-02, 9.6793044e-01, 1.4145180e+00,\n",
+       "       1.4200950e-01, 8.1434751e-01, 7.0387411e-01, 8.6176515e-01,\n",
+       "       6.2346458e-01, 1.4636874e-01, 3.2455921e-01, 1.5807381e+00,\n",
+       "       5.9650755e-01, 7.9351628e-01, 1.6089365e+00, 7.5115800e-01,\n",
+       "       5.8976293e-01, 4.7450304e-02, 6.6682827e-01, 7.1542680e-01,\n",
+       "       4.6520185e-01, 3.4638846e-01, 7.5957966e-01, 4.9341345e-01,\n",
+       "       4.8143768e-01, 1.2025452e-01, 6.0646594e-01, 1.1619196e+00,\n",
+       "       2.7393532e-01, 8.4904301e-01, 2.5427663e-01, 7.0259297e-01,\n",
+       "       5.2577734e-01, 2.9342413e-01, 6.1365223e-01, 9.0736806e-01],\n",
+       "      dtype=float32), &#x27;mean_td_error&#x27;: 5.492199897766113, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 668.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 667.0}}, &#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}       </td><td style=\"text-align: right;\">                         2</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    13026</td><td style=\"text-align: right;\">                   258304</td><td style=\"text-align: right;\">                  13026</td><td style=\"text-align: right;\">                             1002</td><td style=\"text-align: right;\">                 258304</td><td style=\"text-align: right;\">                            85504</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        85504</td><td>{&#x27;cpu_util_percent&#x27;: 54.76744186046512, &#x27;ram_util_percent&#x27;: 85.32209302325585}</td><td style=\"text-align: right;\">15703</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -166.09740307927132, &#x27;episode_reward_min&#x27;: -189.6840973868966, &#x27;episode_reward_mean&#x27;: -179.5880893824829, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 9, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-187.3498569726944, -166.09740307927132, -172.9712873697281, -187.82146245241165, -176.65354753285646, -183.53197374939919, -176.7706963941455, -189.6840973868966, -175.4124795049429], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             114.767</td><td style=\"text-align: right;\">            62.318</td><td style=\"text-align: right;\">       227.817</td><td>{&#x27;training_iteration_time_ms&#x27;: 151.985, &#x27;load_time_ms&#x27;: 0.246, &#x27;load_throughput&#x27;: 1042265.409, &#x27;learn_time_ms&#x27;: 25.824, &#x27;learn_throughput&#x27;: 9913.287, &#x27;synch_weights_time_ms&#x27;: 6.049}</td><td style=\"text-align: right;\"> 1676132915</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            13026</td><td style=\"text-align: right;\">                  13</td><td>6a944_00000</td><td style=\"text-align: right;\">      9.03385</td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "</div>\n",
+       "<style>\n",
+       ".trialProgress {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "  color: var(--jp-ui-font-color1);\n",
+       "}\n",
+       ".trialProgress h3 {\n",
+       "  font-weight: bold;\n",
+       "}\n",
+       ".trialProgress td {\n",
+       "  white-space: nowrap;\n",
+       "}\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000012)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:36,665 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055997952; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:46,672 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055973376; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:56,678 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055977472; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:06,689 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056280576; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:16,700 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056186368; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:26,706 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056030720; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000013)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:36,714 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053261824; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:46,719 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053159424; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:56,725 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053106176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:06,732 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053073408; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "2023-02-11 17:29:16,846\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:16,738 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053069312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "2023-02-11 17:29:17,441\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
+      "2023-02-11 17:29:20,661\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_6a944_00000]\n",
+      "2023-02-11 17:29:20,663\tINFO tune.py:762 -- Total run time: 174.25 seconds (174.00 seconds for the tuning loop).\n",
+      "2023-02-11 17:29:20,664\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.result_grid.ResultGrid at 0x7fedc40a1d90>"
+      ]
+     },
+     "execution_count": 11,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# resume the interrupted run\n",
+    "tuner.fit()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "1d25217d-5941-40bc-b103-d5ff3f6e9c72",
+   "metadata": {},
+   "outputs": [],
    "source": []
   }
  ],
diff --git a/darm_training/darm_sf_hand_rllib_sac.ipynb b/darm_training/darm_sf_hand_rllib_sac.ipynb
index a39a7f1..dc3b7c4 100644
--- a/darm_training/darm_sf_hand_rllib_sac.ipynb
+++ b/darm_training/darm_sf_hand_rllib_sac.ipynb
@@ -31,21 +31,129 @@
    "execution_count": 2,
    "id": "f874e73d-f740-45bf-bed4-117e846ac0f2",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "'/home/daniel/DARM/darm_mujoco'"
+      ]
+     },
+     "execution_count": 2,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
    "source": [
     "# Configure env variables\n",
     "\n",
     "# TODO: change path\n",
     "import os\n",
-    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\""
+    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
+    "os.getenv('DARM_MUJOCO_PATH')"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 3,
    "id": "b21d33a5-8591-4a1c-891e-a71073ff1c91",
-   "metadata": {},
-   "outputs": [],
+   "metadata": {
+    "collapsed": true,
+    "jupyter": {
+     "outputs_hidden": true
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Requirement already satisfied: ray[rllib] in /home/daniel/miniconda3/lib/python3.8/site-packages (2.2.0)\n",
+      "Requirement already satisfied: torch in /home/daniel/miniconda3/lib/python3.8/site-packages (1.13.1)\n",
+      "Requirement already satisfied: pyyaml in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (6.0)\n",
+      "Requirement already satisfied: click>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (8.1.3)\n",
+      "Requirement already satisfied: numpy>=1.16 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.23.4)\n",
+      "Requirement already satisfied: grpcio>=1.32.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.51.1)\n",
+      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.0.4)\n",
+      "Requirement already satisfied: filelock in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.8.2)\n",
+      "Requirement already satisfied: aiosignal in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.1)\n",
+      "Requirement already satisfied: jsonschema in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.17.3)\n",
+      "Requirement already satisfied: virtualenv>=20.0.24 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (20.17.1)\n",
+      "Requirement already satisfied: attrs in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (22.2.0)\n",
+      "Requirement already satisfied: requests in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.27.1)\n",
+      "Requirement already satisfied: frozenlist in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.3)\n",
+      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.20.1)\n",
+      "Requirement already satisfied: scikit-image in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.19.3)\n",
+      "Requirement already satisfied: tensorboardX>=1.9 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.5.1)\n",
+      "Requirement already satisfied: matplotlib!=3.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.6.1)\n",
+      "Requirement already satisfied: scipy in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.9.2)\n",
+      "Requirement already satisfied: tabulate in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.9.0)\n",
+      "Requirement already satisfied: typer in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.7.0)\n",
+      "Requirement already satisfied: gym<0.24.0,>=0.21.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.21.0)\n",
+      "Requirement already satisfied: lz4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.0.2)\n",
+      "Requirement already satisfied: pandas in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.5.2)\n",
+      "Requirement already satisfied: rich in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (12.6.0)\n",
+      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.1.8)\n",
+      "Requirement already satisfied: typing_extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from torch) (4.4.0)\n",
+      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (2.2.0)\n",
+      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n",
+      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.0.5)\n",
+      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.9)\n",
+      "Requirement already satisfied: cycler>=0.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n",
+      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (4.37.4)\n",
+      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.4)\n",
+      "Requirement already satisfied: packaging>=20.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (21.3)\n",
+      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (9.3.0)\n",
+      "Requirement already satisfied: six>=1.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]) (1.12.0)\n",
+      "Requirement already satisfied: distlib<1,>=0.3.6 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (0.3.6)\n",
+      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (2.6.0)\n",
+      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (1.3.10)\n",
+      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (0.19.2)\n",
+      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (5.10.1)\n",
+      "Requirement already satisfied: zipp>=3.1.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->ray[rllib]) (3.11.0)\n",
+      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from pandas->ray[rllib]) (2022.7)\n",
+      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (1.26.14)\n",
+      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2022.12.7)\n",
+      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2.0.4)\n",
+      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (3.3)\n",
+      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (2.13.0)\n",
+      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (0.9.1)\n",
+      "Requirement already satisfied: networkx>=2.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.8.8)\n",
+      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (1.4.1)\n",
+      "Requirement already satisfied: tifffile>=2019.7.26 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2022.10.10)\n",
+      "Requirement already satisfied: imageio>=2.4.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.23.0)\n",
+      "Requirement already satisfied: wandb in /home/daniel/miniconda3/lib/python3.8/site-packages (0.13.10)\n",
+      "Requirement already satisfied: psutil>=5.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (5.9.4)\n",
+      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
+      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.20.1)\n",
+      "Requirement already satisfied: setproctitle in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
+      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
+      "Requirement already satisfied: PyYAML in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (6.0)\n",
+      "Requirement already satisfied: setuptools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (65.6.3)\n",
+      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
+      "Requirement already satisfied: appdirs>=1.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
+      "Requirement already satisfied: GitPython>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.1.30)\n",
+      "Requirement already satisfied: typing-extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (4.4.0)\n",
+      "Requirement already satisfied: requests<3,>=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
+      "Requirement already satisfied: pathtools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
+      "Requirement already satisfied: six>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.12.0)\n",
+      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
+      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
+      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
+      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
+      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
+      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
+      "Requirement already satisfied: tensorflow_probability in /home/daniel/miniconda3/lib/python3.8/site-packages (0.19.0)\n",
+      "Requirement already satisfied: cloudpickle>=1.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (2.2.0)\n",
+      "Requirement already satisfied: absl-py in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.2.0)\n",
+      "Requirement already satisfied: six>=1.10.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.12.0)\n",
+      "Requirement already satisfied: numpy>=1.13.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.23.4)\n",
+      "Requirement already satisfied: gast>=0.3.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.5.3)\n",
+      "Requirement already satisfied: decorator in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (5.1.1)\n",
+      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.1.8)\n"
+     ]
+    }
+   ],
    "source": [
     "!pip install ray[rllib] torch\n",
     "!pip install wandb\n",
@@ -216,7 +324,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 9,
+   "execution_count": 4,
    "id": "0ee4bf2a-d82c-4aaa-b278-f11a080e28af",
    "metadata": {},
    "outputs": [],
@@ -241,7 +349,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
+   "execution_count": 5,
    "id": "4a0ed8ba-4f6b-47f9-b0e7-37d0eec71647",
    "metadata": {},
    "outputs": [],
@@ -281,10 +389,12 @@
     "    )\n",
     "    .rollouts(\n",
     "        num_rollout_workers=3,\n",
+    "        num_envs_per_worker=8,\n",
     "        rollout_fragment_length=1,\n",
     "        recreate_failed_workers=True,\n",
     "        num_consecutive_worker_failures_tolerance=10,\n",
-    "        restart_failed_sub_environments=True\n",
+    "        restart_failed_sub_environments=True,\n",
+    "        batch_mode=\"complete_episodes\"\n",
     "    )\n",
     "    .resources(num_gpus=0)\n",
     "    .evaluation(evaluation_interval=100) # For 1000 timesteps iter; 100 evals\n",
@@ -298,7 +408,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 6,
    "id": "46f0fa8e-5023-44c3-a9f7-8a6b041617a2",
    "metadata": {},
    "outputs": [],
@@ -311,6 +421,7 @@
     "\n",
     "wandb_init = dict(\n",
     "    save_code=True,\n",
+    "    resume=True,\n",
     "    config={\n",
     "        \"env\": \"DARMSFHand-v0\",\n",
     "        \n",
@@ -325,7 +436,7 @@
     "    },\n",
     "    tags=[\"single_finger\"],\n",
     "    notes=\"Fixed the env to use targets that are delta increaments from the starting state. Removed velocity penalty, and used only effort penalty\",\n",
-    "    name=\"Test_DARMSF_DELTA_TARGET\"\n",
+    "    name=\"8env_cp_ep_Test_DARMSF_DELTA_TARGET\"\n",
     "    # job_type=\n",
     "    # monitor_gym=\n",
     ")"
@@ -333,23 +444,28 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 7,
    "id": "6d7468b3-f377-4c7f-a0c3-6dec032fdc37",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "[Errno 2] No such file or directory: '/home/daniel/DARM/darm-mujoco/darm_training/'\n",
+      "/home/daniel/DARM/darm_mujoco/darm_training\n"
+     ]
+    }
+   ],
    "source": [
     "%cd /home/daniel/DARM/darm-mujoco/darm_training/"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": null,
    "id": "727ee5b8-0cc3-4831-91ee-34514946c66a",
    "metadata": {
-    "collapsed": true,
-    "jupyter": {
-     "outputs_hidden": true
-    },
     "tags": []
    },
    "outputs": [
@@ -357,7 +473,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "2023-02-10 10:14:20,826\tINFO wandb.py:250 -- Already logged into W&B.\n"
+      "2023-02-11 18:58:31,931\tINFO worker.py:1538 -- Started a local Ray instance.\n"
      ]
     },
     {
@@ -369,16 +485,16 @@
        "      <h3>Tune Status</h3>\n",
        "      <table>\n",
        "<tbody>\n",
-       "<tr><td>Current time:</td><td>2023-02-10 10:20:23</td></tr>\n",
-       "<tr><td>Running for: </td><td>00:06:02.71        </td></tr>\n",
-       "<tr><td>Memory:      </td><td>5.8/7.5 GiB        </td></tr>\n",
+       "<tr><td>Current time:</td><td>2023-02-11 18:59:19</td></tr>\n",
+       "<tr><td>Running for: </td><td>00:00:45.93        </td></tr>\n",
+       "<tr><td>Memory:      </td><td>5.9/7.5 GiB        </td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "    </div>\n",
        "    <div class=\"vDivider\"></div>\n",
        "    <div class=\"systemInfo\">\n",
        "      <h3>System Info</h3>\n",
-       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.17 GiB heap, 0.0/1.09 GiB objects\n",
+       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/2.42 GiB heap, 0.0/1.21 GiB objects\n",
        "    </div>\n",
        "    \n",
        "  </div>\n",
@@ -387,10 +503,10 @@
        "    <h3>Trial Status</h3>\n",
        "    <table>\n",
        "<thead>\n",
-       "<tr><th>Trial name                        </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
+       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
        "</thead>\n",
        "<tbody>\n",
-       "<tr><td>SAC_darm_DarmSFHand-v0_4d890_00000</td><td>RUNNING </td><td>192.168.152.36:5853</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         324.493</td><td style=\"text-align: right;\">15030</td><td style=\"text-align: right;\">-141.846</td><td style=\"text-align: right;\">             248.713</td><td style=\"text-align: right;\">            -192.044</td><td style=\"text-align: right;\">              90.1</td></tr>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_b35c7_00000</td><td>RUNNING </td><td>192.168.152.36:28751</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         16.1971</td><td style=\"text-align: right;\">7239</td><td style=\"text-align: right;\">-149.222</td><td style=\"text-align: right;\">             248.816</td><td style=\"text-align: right;\">            -193.321</td><td style=\"text-align: right;\">           92.3846</td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "  </div>\n",
@@ -437,63 +553,53 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:24,662 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1222045696; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:25,008\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
       "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:25,417\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m   logger.warn(\n"
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:58:38,049\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:58:38,509\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:58:41,845 E 28493 28543] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-58-29_803943_27113 is over 95% full, available space: 648900608; capacity: 31845081088. Object creation will fail if spilling is required.\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5990)\u001b[0m Loaded XML file successfully\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m Loaded XML file successfully\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n"
      ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m   logger.warn(\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5989)\u001b[0m 2023-02-10 10:14:32,075\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m 2023-02-11 18:58:46,271\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m   logger.warn(\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m Loaded XML file successfully\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n"
      ]
     },
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(RolloutWorker pid=5991)\u001b[0m   logger.warn(\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m   logger.warn(\n"
      ]
     },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m Loaded XML file successfully\n"
-     ]
-    },
-    {
-     "name": "stderr",
-     "output_type": "stream",
-     "text": [
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   logger.warn(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,358\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,390\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:14:33,703\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:34,668 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221922816; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n"
      ]
     },
     {
@@ -511,7 +617,7 @@
     {
      "data": {
       "text/html": [
-       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_4d890_00000_0_2023-02-10_10-14-21/wandb/run-20230210_101425-4d890_00000</code>"
+       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/wandb/run-20230211_185837-b35c7_00000</code>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -523,7 +629,7 @@
     {
      "data": {
       "text/html": [
-       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/4d890_00000' target=\"_blank\">Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/b35c7_00000' target=\"_blank\">8env_cp_ep_Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -547,7 +653,7 @@
     {
      "data": {
       "text/html": [
-       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/4d890_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/4d890_00000</a>"
+       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/b35c7_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/b35c7_00000</a>"
       ],
       "text/plain": [
        "<IPython.core.display.HTML object>"
@@ -556,6 +662,88 @@
      "metadata": {},
      "output_type": "display_data"
     },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:58:51,863 E 28493 28543] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-58-29_803943_27113 is over 95% full, available space: 642236416; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28889)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28888)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=28890)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:58:56,888\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:59:01,868 E 28493 28543] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-58-29_803943_27113 is over 95% full, available space: 645492736; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:59:03,235\tINFO trainable.py:172 -- Trainable.setup took 24.729 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:59:03,236\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
+      "\u001b[2m\u001b[36m(SAC pid=28751)\u001b[0m 2023-02-11 18:59:06,609\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
+     ]
+    },
     {
      "data": {
       "text/html": [
@@ -563,74 +751,10 @@
        "  <h3>Trial Progress</h3>\n",
        "  <table>\n",
        "<thead>\n",
-       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                              </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
+       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                  </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info                                                                                                                                     </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                             </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
        "</thead>\n",
        "<tbody>\n",
-       "<tr><td>SAC_darm_DarmSFHand-v0_4d890_00000</td><td style=\"text-align: right;\">                  15030</td><td>{&#x27;num_env_steps_sampled&#x27;: 15030, &#x27;num_env_steps_trained&#x27;: 429312, &#x27;num_agent_steps_sampled&#x27;: 15030, &#x27;num_agent_steps_trained&#x27;: 429312, &#x27;last_target_update_ts&#x27;: 15030, &#x27;num_target_updates&#x27;: 1677}</td><td>{}              </td><td>2023-02-10_10-19-58</td><td>False </td><td style=\"text-align: right;\">              90.1</td><td>{}             </td><td style=\"text-align: right;\">             248.713</td><td style=\"text-align: right;\">             -141.846</td><td style=\"text-align: right;\">            -192.044</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             154</td><td>8dd39779c7ef477aa164e54f946852e0</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.403343200683594, &#x27;actor_loss&#x27;: -6.434066295623779, &#x27;critic_loss&#x27;: 0.224114790558815, &#x27;alpha_loss&#x27;: -4.229072570800781, &#x27;alpha_value&#x27;: 0.60455614, &#x27;log_alpha_value&#x27;: -0.50326073, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.027431469410657883, &#x27;mean_q&#x27;: 4.410746097564697, &#x27;max_q&#x27;: 5.1180830001831055, &#x27;min_q&#x27;: 3.604030132293701}, &#x27;td_error&#x27;: array([3.76369953e-01, 2.18138933e-01, 8.90897512e-01, 5.00837326e-01,\n",
-       "       1.56644344e-01, 1.15910602e+00, 3.58983755e-01, 9.73417044e-01,\n",
-       "       4.54557180e-01, 3.18669558e-01, 2.47295618e-01, 3.98333549e-01,\n",
-       "       5.52456379e-02, 4.16686535e-01, 5.52578926e-01, 8.20993423e-01,\n",
-       "       4.80461121e-02, 5.51123619e-01, 3.48044634e-01, 4.45616722e-01,\n",
-       "       6.57121658e-01, 3.01966190e-01, 4.55074072e-01, 5.81701994e-01,\n",
-       "       4.43889856e-01, 3.61741066e-01, 6.02926254e-01, 6.10968113e-01,\n",
-       "       2.43805664e+02, 6.97162867e-01, 1.34469032e-01, 5.01981974e-01,\n",
-       "       5.75793648e+00, 3.33922148e-01, 2.84593582e-01, 8.42299938e-01,\n",
-       "       3.37388039e-01, 4.18749571e-01, 5.26380062e-01, 4.35695648e-01,\n",
-       "       4.50320482e-01, 6.56141853e+00, 9.19794083e-01, 4.95012522e-01,\n",
-       "       1.86808348e-01, 2.88064480e-01, 9.34903622e-02, 5.33180237e-01,\n",
-       "       7.46445179e-01, 3.29239368e-01, 4.63973522e-01, 5.52854300e-01,\n",
-       "       5.59043884e-01, 5.79916573e+00, 3.95936966e-01, 3.83873940e-01,\n",
-       "       7.85346985e-01, 3.67263794e-01, 5.48842669e-01, 6.90719604e-01,\n",
-       "       3.13124657e-02, 7.84007549e-01, 4.98735189e-01, 4.51488495e-01,\n",
-       "       2.78318405e-01, 8.23536158e-01, 5.27554512e-01, 1.09366131e+00,\n",
-       "       2.44073761e+02, 5.64733505e-01, 1.87523842e-01, 8.82987976e-01,\n",
-       "       4.84059095e-01, 6.78997517e-01, 8.01151276e-01, 6.06491089e-01,\n",
-       "       4.78818417e-01, 3.75759125e-01, 5.04173756e-01, 1.41024947e-01,\n",
-       "       2.97756195e-01, 6.70681572e+00, 6.38502359e-01, 1.84234142e-01,\n",
-       "       3.44598055e-01, 2.66064882e-01, 6.22176886e-01, 2.91838408e-01,\n",
-       "       6.30319595e-01, 3.90557766e-01, 7.24813938e-01, 6.66464329e-01,\n",
-       "       6.48372173e-01, 1.69317245e-01, 5.71012974e-01, 2.15357304e-01,\n",
-       "       4.80374098e-01, 4.54566240e-01, 6.62336826e-01, 5.37418842e-01,\n",
-       "       2.28084564e-01, 1.80234909e-01, 3.18274736e-01, 5.42303801e-01,\n",
-       "       2.43873016e+02, 3.50508213e-01, 6.72996044e-01, 3.73209953e-01,\n",
-       "       8.81858826e-01, 4.57011461e-01, 6.31304979e-01, 3.22345257e-01,\n",
-       "       4.37150240e-01, 8.15716267e-01, 6.95113182e-01, 5.28904438e-01,\n",
-       "       6.64132166e+00, 3.57316017e-01, 7.54707336e-01, 5.63272238e-01,\n",
-       "       8.61629725e-01, 1.76108837e-01, 8.31902027e-02, 1.03891134e-01,\n",
-       "       3.71709824e-01, 5.50470591e-01, 7.84245253e-01, 3.21080923e-01,\n",
-       "       3.92820835e-02, 5.49223900e-01, 6.91530704e-01, 3.57518673e-01,\n",
-       "       3.84907722e-01, 4.12734747e-01, 4.18194771e-01, 7.22610235e-01,\n",
-       "       3.24485064e-01, 5.38154554e+00, 7.06630945e-01, 1.67124152e-01,\n",
-       "       6.63487911e-01, 8.02201986e-01, 2.52504587e-01, 9.75709677e-01,\n",
-       "       4.89573479e-01, 6.64892435e-01, 1.03562427e+00, 3.95295620e-02,\n",
-       "       5.00542164e-01, 9.13107872e-01, 5.89080334e-01, 6.50176048e-01,\n",
-       "       6.37590694e+00, 8.55698586e-02, 3.50122690e-01, 6.35562181e-01,\n",
-       "       3.89072657e-01, 4.41820145e-01, 2.79556274e-01, 1.20183945e+00,\n",
-       "       5.35343766e-01, 5.90878248e-01, 6.06690645e-01, 7.29044676e-01,\n",
-       "       2.38976479e-01, 3.35858583e-01, 5.22370100e-01, 6.08634281e+00,\n",
-       "       6.85944557e-01, 4.10863638e-01, 3.76061916e-01, 3.61318350e-01,\n",
-       "       1.09372520e+00, 6.78944349e-01, 5.75511694e-01, 3.01788330e-01,\n",
-       "       2.70901680e-01, 3.42419863e-01, 3.19597006e-01, 1.56586289e-01,\n",
-       "       6.28098488e-01, 8.64251852e-01, 3.41733932e-01, 7.75881290e-01,\n",
-       "       2.96623230e-01, 3.41565371e-01, 2.20751286e-01, 3.47970247e-01,\n",
-       "       9.26482439e-01, 5.77410221e-01, 1.53335571e-01, 1.95543766e-02,\n",
-       "       7.58130074e-01, 4.61048365e-01, 4.55544472e-01, 4.03303385e-01,\n",
-       "       5.41186571e-01, 6.24453068e-01, 4.88040209e-01, 4.26761150e-01,\n",
-       "       1.01890087e-01, 8.34158182e-01, 6.50000811e-01, 5.72202206e-01,\n",
-       "       6.71605349e-01, 5.71026325e-01, 4.86349344e-01, 3.68950129e-01,\n",
-       "       3.34364176e-01, 7.52686977e-01, 3.25332880e-01, 3.64549398e-01,\n",
-       "       2.07561970e-01, 7.46529102e-01, 1.55097723e-01, 4.25298929e-01,\n",
-       "       8.42193842e-01, 2.43873016e+02, 2.43873016e+02, 2.82555580e-01,\n",
-       "       4.45864916e-01, 4.59903955e-01, 5.92770100e-01, 8.09845448e-01,\n",
-       "       8.23133469e-01, 5.77309561e+00, 5.96422911e-01, 7.31289148e-01,\n",
-       "       3.31299424e-01, 5.85563135e+00, 5.36827183e+00, 3.30348015e-01,\n",
-       "       5.50782681e-02, 8.04073811e-02, 6.67590857e-01, 6.92529202e-01,\n",
-       "       3.84135246e-01, 3.31759453e-01, 3.52068186e-01, 6.84356213e-01,\n",
-       "       6.38411427e+00, 2.44073761e+02, 9.02929783e-01, 6.10304737e+00,\n",
-       "       5.87041140e-01, 3.18532944e-01, 5.26460886e-01, 5.01149416e-01,\n",
-       "       3.49880457e-01, 4.51208830e-01, 1.33623719e-01, 1.37279153e-01,\n",
-       "       4.75117207e-01, 4.51113939e-01, 3.33072662e-01, 4.37882900e-01],\n",
-       "      dtype=float32), &#x27;mean_td_error&#x27;: 6.474668979644775, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 1677.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 1676.0}}, &#x27;num_env_steps_sampled&#x27;: 15030, &#x27;num_env_steps_trained&#x27;: 429312, &#x27;num_agent_steps_sampled&#x27;: 15030, &#x27;num_agent_steps_trained&#x27;: 429312, &#x27;last_target_update_ts&#x27;: 15030, &#x27;num_target_updates&#x27;: 1677}       </td><td style=\"text-align: right;\">                        15</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    15030</td><td style=\"text-align: right;\">                   429312</td><td style=\"text-align: right;\">                  15030</td><td style=\"text-align: right;\">                             1002</td><td style=\"text-align: right;\">                 429312</td><td style=\"text-align: right;\">                            85504</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        85504</td><td>{&#x27;cpu_util_percent&#x27;: 46.60649350649351, &#x27;ram_util_percent&#x27;: 77.04415584415582}</td><td style=\"text-align: right;\"> 5853</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.2387199854807946, &#x27;mean_inference_ms&#x27;: 2.3233264583571662, &#x27;mean_action_processing_ms&#x27;: 0.2227478173887199, &#x27;mean_env_wait_ms&#x27;: 3.0315715951183035, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 248.7129012644291, &#x27;episode_reward_min&#x27;: -192.04356507956982, &#x27;episode_reward_mean&#x27;: -141.84599248990418, &#x27;episode_len_mean&#x27;: 90.1, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 10, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-188.50081959366798, -187.97007030248642, -189.0042775273323, -170.24335712194443, 248.7129012644291, -185.3823484480381, -187.89898101985455, -192.04356507956982, -176.78319323062897, -189.34621383994818], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 1, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.2387199854807946, &#x27;mean_inference_ms&#x27;: 2.3233264583571662, &#x27;mean_action_processing_ms&#x27;: 0.2227478173887199, &#x27;mean_env_wait_ms&#x27;: 3.0315715951183035, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             324.493</td><td style=\"text-align: right;\">            55.609</td><td style=\"text-align: right;\">       324.493</td><td>{&#x27;training_iteration_time_ms&#x27;: 144.554, &#x27;load_time_ms&#x27;: 0.263, &#x27;load_throughput&#x27;: 971712.058, &#x27;learn_time_ms&#x27;: 23.944, &#x27;learn_throughput&#x27;: 10691.626, &#x27;synch_weights_time_ms&#x27;: 5.41}</td><td style=\"text-align: right;\"> 1676020798</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            15030</td><td style=\"text-align: right;\">                  15</td><td>4d890_00000</td><td style=\"text-align: right;\">      7.98138</td></tr>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_b35c7_00000</td><td style=\"text-align: right;\">                   7239</td><td>{&#x27;num_env_steps_sampled&#x27;: 7239, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 7239, &#x27;num_agent_steps_trained&#x27;: 0}</td><td>{}              </td><td>2023-02-11_18-59-19</td><td>False </td><td style=\"text-align: right;\">           92.3846</td><td>{}             </td><td style=\"text-align: right;\">             248.816</td><td style=\"text-align: right;\">             -149.222</td><td style=\"text-align: right;\">            -193.321</td><td style=\"text-align: right;\">                  13</td><td style=\"text-align: right;\">              77</td><td>38023f3150734146854039bccf941b2f</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {}, &#x27;num_env_steps_sampled&#x27;: 7239, &#x27;num_env_steps_trained&#x27;: 0, &#x27;num_agent_steps_sampled&#x27;: 7239, &#x27;num_agent_steps_trained&#x27;: 0}</td><td style=\"text-align: right;\">                         6</td><td>192.168.152.36</td><td style=\"text-align: right;\">                     7239</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">                   7239</td><td style=\"text-align: right;\">                             1201</td><td style=\"text-align: right;\">                      0</td><td style=\"text-align: right;\">                                0</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                            0</td><td>{&#x27;cpu_util_percent&#x27;: 42.5, &#x27;ram_util_percent&#x27;: 79.22500000000001}</td><td style=\"text-align: right;\">28751</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 2.4457443721132743, &#x27;mean_inference_ms&#x27;: 1.9462785846073098, &#x27;mean_action_processing_ms&#x27;: 0.6950759428253741, &#x27;mean_env_wait_ms&#x27;: 20.053145411004564, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: 248.81608164310455, &#x27;episode_reward_min&#x27;: -193.32089838385582, &#x27;episode_reward_mean&#x27;: -149.22188074256366, &#x27;episode_len_mean&#x27;: 92.38461538461539, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 13, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-185.64374712109566, -188.3895846605301, -173.114131167531, 248.81608164310455, -193.32089838385582, -174.03739013522863, -187.18334355205297, -170.0323799699545, -188.4403995424509, -186.57754173874855, -180.7140250056982, -187.85832431912422, -173.38876570016146], &#x27;episode_lengths&#x27;: [100, 100, 100, 1, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 2.4457443721132743, &#x27;mean_inference_ms&#x27;: 1.9462785846073098, &#x27;mean_action_processing_ms&#x27;: 0.6950759428253741, &#x27;mean_env_wait_ms&#x27;: 20.053145411004564, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             16.1971</td><td style=\"text-align: right;\">           2.49207</td><td style=\"text-align: right;\">       16.1971</td><td>{&#x27;training_iteration_time_ms&#x27;: 721.78}</td><td style=\"text-align: right;\"> 1676138359</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">             7239</td><td style=\"text-align: right;\">                   6</td><td>b35c7_00000</td><td style=\"text-align: right;\">      24.7334</td></tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</div>\n",
@@ -659,103 +783,45 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:44,673 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221365760; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:14:54,678 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221214208; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:04,684 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1221103616; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:14,690 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1220038656; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:15:15,903\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:24,701 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219670016; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:34,712 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219510272; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:44,718 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219461120; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:15:54,724 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219444736; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:04,731 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219420160; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:14,737 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219231744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:24,743 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219137536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:34,750 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219129344; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:44,757 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1219297280; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:16:54,766 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214754816; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:04,775 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214763008; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:14,781 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214701568; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:24,787 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214668800; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:34,792 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214619648; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:44,797 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214615552; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:17:54,803 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214607360; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:04,813 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214611456; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:14,818 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214554112; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:24,825 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214525440; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:34,831 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214480384; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:44,838 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214517248; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:18:54,843 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214537728; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:04,850 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214525440; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:14,856 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214529536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:24,862 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214271488; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:34,867 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214443520; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:44,874 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214414848; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:19:54,880 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214349312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:04,886 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214332928; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:14,891 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214316544; capacity: 31845081088. Object creation will fail if spilling is required.\n",
-      "2023-02-10 10:20:20,585\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
-      "2023-02-10 10:20:21,533\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m 2023-02-10 10:20:23,571\tERROR worker.py:763 -- Worker exits with an exit code 1.\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m Traceback (most recent call last):\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1135, in ray._raylet.task_execution_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 1045, in ray._raylet.execute_task_with_cancellation_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 782, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 823, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 830, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 834, in ray._raylet.execute_task\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"python/ray/_raylet.pyx\", line 780, in ray._raylet.execute_task.function_executor\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 674, in actor_method_executor\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 364, in train\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     result = self.step()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 749, in step\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     results, train_iter_ctx = self._run_one_training_iteration()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 2623, in _run_one_training_iteration\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     results = self.training_step()\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/util/tracing/tracing_helper.py\", line 466, in _resume_span\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     return method(self, *_args, **_kwargs)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/dqn/dqn.py\", line 454, in training_step\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     update_priorities_in_replay_buffer(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/utils.py\", line 121, in update_priorities_in_replay_buffer\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     replay_buffer.update_priorities(prio_dict)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/multi_agent_prioritized_replay_buffer.py\", line 252, in update_priorities\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     self.replay_buffers[policy_id].update_priorities(\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/replay_buffers/prioritized_replay_buffer.py\", line 183, in update_priorities\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     assert priority > 0\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 760, in sigterm_handler\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m     sys.exit(1)\n",
-      "\u001b[2m\u001b[36m(SAC pid=5853)\u001b[0m SystemExit: 1\n",
-      "2023-02-10 10:20:23,760\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_4d890_00000]\n",
-      "2023-02-10 10:20:23,761\tINFO tune.py:762 -- Total run time: 362.95 seconds (362.71 seconds for the tuning loop).\n",
-      "2023-02-10 10:20:23,761\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n",
-      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-10 10:20:24,897 E 4970 5022] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-10_10-10-12_403153_4748 is over 95% full, available space: 1214267392; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000001)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000002)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:59:11,874 E 28493 28543] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-58-29_803943_27113 is over 95% full, available space: 641527808; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000003)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000004)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000005)... Done. 0.0s\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000006)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 18:59:21,882 E 28493 28543] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_18-58-29_803943_27113 is over 95% full, available space: 636469248; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/8env_cp_ep_Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_b35c7_00000_0_2023-02-11_18-58-33/checkpoint_000007)... Done. 0.0s\n"
      ]
     }
    ],
    "source": [
     "# TODO: \n",
     "# change: name\n",
+    "# change: checkpoint_freq\n",
+    "\n",
+    "sync_config = tune.SyncConfig()\n",
     "\n",
     "tuner = tune.Tuner(\n",
     "    \"SAC\",\n",
     "    run_config=air.RunConfig(\n",
-    "        name=\"Test_DARMSF_DELTA_TARGET\",\n",
+    "        name=\"8env_cp_ep_Test_DARMSF_DELTA_TARGET\",\n",
+    "        local_dir=f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results\",\n",
+    "        sync_config=sync_config,\n",
     "        stop={\"training_iteration\": 10_000, \"episode_reward_mean\": 200},\n",
-    "        checkpoint_config=air.CheckpointConfig(checkpoint_at_end=True),\n",
+    "        checkpoint_config=air.CheckpointConfig(\n",
+    "            checkpoint_at_end=True,\n",
+    "            checkpoint_score_attribute=\"episode_reward_mean\",  # or leave to save last chkpts\n",
+    "            checkpoint_score_order=\"max\",\n",
+    "            checkpoint_frequency=1,  #50,\n",
+    "            num_to_keep=3\n",
+    "        ),\n",
     "        callbacks=[\n",
     "                WandbLoggerCallback(project=\"DARM\", \n",
     "                                    api_key=\"392c8a47eb0658eb5c71190757a69110e2140f4a\",\n",
     "                                    save_checkpoints=True, \n",
     "                                    **wandb_init)\n",
     "            ],\n",
-    "        local_dir=\"./results\"\n",
     "        ),\n",
     "    param_space=config\n",
     ")\n",
@@ -765,10 +831,674 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 16,
    "id": "1e3264d3-86a3-430c-bae2-940f2da854d2",
    "metadata": {},
    "outputs": [],
+   "source": [
+    "# Ensure wandb is sysncing to cloud\n",
+    "# cd to darm_training again if not"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "id": "ed17fb23-77b1-4e35-95b7-a44b6e342691",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 17:26:13,607\tINFO experiment_analysis.py:795 -- No `self.trials`. Drawing logdirs from checkpoint file. This may result in some information that is out of sync, as checkpointing is periodic.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.tuner.Tuner at 0x7fede99d9a90>"
+      ]
+     },
+     "execution_count": 10,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:16,601 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061720064; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    }
+   ],
+   "source": [
+    "# TODO:\n",
+    "# change: experiment name\n",
+    "\n",
+    "# Restore Interrupted run\n",
+    "tuner = tune.Tuner.restore(\n",
+    "    f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n",
+    "    resume_errored=True\n",
+    ")\n",
+    "tuner"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 15,
+   "id": "160c2790-f9ac-41cb-8198-d571d2c51332",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.result_grid.ResultGrid at 0x7fcd58384b80>"
+      ]
+     },
+     "execution_count": 15,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "results = tuner.get_results()\n",
+    "results"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 16,
+   "id": "ace959cb-3e05-4caa-8dd9-f00bbab33eb0",
+   "metadata": {
+    "collapsed": true,
+    "jupyter": {
+     "outputs_hidden": true
+    },
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Result(metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 8.343955039978027, 'actor_loss': -5.076763153076172, 'critic_loss': 0.4612053632736206, 'alpha_loss': -0.850807249546051, 'alpha_value': 0.9030595, 'log_alpha_value': -0.101966895, 'target_entropy': -5.0, 'policy_t': -0.01997794397175312, 'mean_q': 2.0334110260009766, 'max_q': 2.8355112075805664, 'min_q': 1.038293480873108}, 'td_error': array([9.46030378e-01, 4.29627061e-01, 2.65497327e-01, 8.43869328e-01,\n",
+       "       1.09686172e+00, 7.66791701e-01, 7.26696014e-01, 5.70532084e-02,\n",
+       "       1.14584994e+00, 4.43507016e-01, 1.04901314e-01, 1.52089047e+00,\n",
+       "       6.52013183e-01, 8.16148460e-01, 1.08409297e+00, 2.61833251e-01,\n",
+       "       3.79876256e-01, 9.56449747e-01, 5.75677335e-01, 1.02149987e+00,\n",
+       "       1.76170349e-01, 9.50863540e-01, 7.04805613e-01, 3.25276971e-01,\n",
+       "       6.36387825e-01, 8.46629441e-01, 5.59558868e-02, 8.83865356e-03,\n",
+       "       7.97627211e-01, 8.26396644e-01, 9.43091869e-01, 2.46674316e+02,\n",
+       "       5.55538654e-01, 7.27864265e-01, 1.29726791e+00, 4.26257730e-01,\n",
+       "       4.88600850e-01, 7.20911384e-01, 6.31772637e-01, 1.28249526e+00,\n",
+       "       7.96164632e-01, 3.33085537e+00, 3.80529928e+00, 9.50119078e-01,\n",
+       "       8.29495788e-01, 4.02090669e-01, 9.92336035e-01, 4.70980978e+00,\n",
+       "       7.12400794e-01, 5.61774313e-01, 8.87979388e-01, 6.99178576e-02,\n",
+       "       7.03785896e-01, 3.68088245e+00, 4.42697144e+00, 3.84785533e-02,\n",
+       "       4.06367898e-01, 9.53655124e-01, 1.01472402e+00, 6.36071920e-01,\n",
+       "       3.92946482e-01, 2.85786510e-01, 7.28411913e-01, 4.54745054e-01,\n",
+       "       5.25969863e-02, 6.62682295e-01, 2.46527893e+02, 3.33758354e-01,\n",
+       "       3.90868187e-01, 2.47024506e+02, 3.74032736e-01, 7.44001746e-01,\n",
+       "       1.19754124e+00, 1.98264122e-01, 5.89548111e-01, 7.19748855e-01,\n",
+       "       6.91104770e-01, 2.46527893e+02, 1.00903511e+00, 8.68608594e-01,\n",
+       "       1.46339655e-01, 8.63849521e-01, 6.97440386e-01, 6.95250630e-01,\n",
+       "       1.08643126e+00, 2.53858209e-01, 9.59976912e-01, 3.65842342e-01,\n",
+       "       5.75604081e-01, 1.01638889e+00, 5.54916143e-01, 2.61025906e-01,\n",
+       "       3.69157314e-01, 5.89906454e-01, 9.18144405e-01, 9.76853013e-01,\n",
+       "       7.45771408e-01, 7.41098404e-01, 3.15677047e-01, 1.40482628e+00,\n",
+       "       8.13360214e-02, 1.82469726e-01, 9.30288076e-01, 1.78921580e-01,\n",
+       "       2.64111042e-01, 7.66712904e-01, 2.51149416e-01, 3.72322750e+00,\n",
+       "       1.50621676e+00, 1.34934068e-01, 8.34389687e-01, 2.28880048e-01,\n",
+       "       2.46911713e+02, 8.71338129e-01, 1.41575491e+00, 1.15829027e+00,\n",
+       "       4.01661396e-01, 3.22172642e-02, 1.03146315e+00, 1.20233822e+00,\n",
+       "       3.63595724e-01, 3.59781146e-01, 3.90814304e-01, 7.14776337e-01,\n",
+       "       2.03609109e-01, 8.17107201e-01, 1.51301539e+00, 9.68729496e-01,\n",
+       "       8.05726111e-01, 6.48125052e-01, 4.55322862e-01, 2.52527475e-01,\n",
+       "       6.16939187e-01, 7.07782507e-01, 2.46674316e+02, 5.37988365e-01,\n",
+       "       8.88993800e-01, 6.42939091e-01, 5.66157341e-01, 7.45199919e-01,\n",
+       "       4.95904922e-01, 5.44749737e-01, 1.33524406e+00, 1.09470248e+00,\n",
+       "       4.20443952e-01, 2.31693149e-01, 1.49213076e-01, 4.79452491e-01,\n",
+       "       5.01387000e-01, 6.36883974e-01, 9.08940554e-01, 2.35339999e-02,\n",
+       "       1.09470153e+00, 6.25958681e-01, 4.33341503e-01, 8.15379143e-01,\n",
+       "       1.10253215e+00, 1.11163783e+00, 6.50242090e-01, 3.74678016e-01,\n",
+       "       5.57896376e-01, 6.90997720e-01, 1.67405367e-01, 5.14347076e-01,\n",
+       "       6.10636115e-01, 1.26651037e+00, 1.06177032e-01, 1.89136624e-01,\n",
+       "       7.38880932e-01, 1.18341660e+00, 2.61298299e-01, 1.94938481e-01,\n",
+       "       2.90627241e-01, 8.71249318e-01, 5.99144578e-01, 5.03087521e-01,\n",
+       "       1.23708069e+00, 3.05450976e-01, 3.46238852e-01, 5.79999447e-01,\n",
+       "       1.01897049e+00, 1.15455341e+00, 3.51977944e-01, 4.95337844e-01,\n",
+       "       1.29761028e+00, 2.77725697e-01, 9.85441983e-01, 6.46635413e-01,\n",
+       "       7.72787869e-01, 1.04821801e-01, 1.34492373e+00, 2.94095612e+00,\n",
+       "       1.16106701e+00, 1.31630957e-01, 9.86808658e-01, 4.82740879e-01,\n",
+       "       2.54980326e-01, 4.74518299e-01, 4.15986300e-01, 1.08055830e-01,\n",
+       "       6.39527440e-01, 1.52761579e-01, 4.26321507e-01, 8.16009641e-01,\n",
+       "       7.27825999e-01, 1.11527145e-01, 1.66661322e-01, 5.02551913e-01,\n",
+       "       1.97000146e-01, 4.07129705e-01, 7.51043320e-01, 2.46911713e+02,\n",
+       "       7.29810119e-01, 6.43945575e-01, 1.79764152e-01, 5.80982447e-01,\n",
+       "       2.05063581e-01, 1.04409027e+00, 4.56080079e-01, 4.46982563e-01,\n",
+       "       9.81729567e-01, 6.59761965e-01, 2.98615646e+00, 2.80451059e-01,\n",
+       "       4.59819794e-01, 9.62480664e-01, 1.36348128e-01, 9.03037906e-01,\n",
+       "       7.55133808e-01, 1.33910954e-01, 6.25847220e-01, 4.72928882e-01,\n",
+       "       1.15204036e-01, 1.34494066e+00, 3.28659534e-01, 7.61413455e-01,\n",
+       "       2.46207031e+02, 5.60174465e-01, 6.26057982e-01, 7.27932453e-01,\n",
+       "       5.94342828e-01, 1.06366754e-01, 8.86531234e-01, 7.32596040e-01,\n",
+       "       6.20095134e-01, 5.57798028e-01, 7.78808892e-01, 2.44230628e-01,\n",
+       "       4.23718333e-01, 1.13543332e-01, 5.97412705e-01, 7.66506553e-01,\n",
+       "       7.60311723e-01, 6.40589774e-01, 4.38361287e-01, 9.32641983e-01],\n",
+       "      dtype=float32), 'mean_td_error': 8.407605171203613, 'model': {}, 'custom_metrics': {}, 'num_agent_steps_trained': 256.0, 'num_grad_updates_lifetime': 341.0, 'diff_num_grad_updates_vs_sampler_policy': 340.0}}, 'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'last_target_update_ts': 11022, 'num_target_updates': 341}, 'sampler_results': {'episode_reward_max': -175.28551595658064, 'episode_reward_min': -191.91201797127724, 'episode_reward_mean': -183.6617713689804, 'episode_len_mean': 100.0, 'episode_media': {}, 'episodes_this_iter': 10, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-177.71922475099564, -187.68662855029106, -175.28551595658064, -185.17646113038063, -188.07598569989204, -183.15926399081945, -187.51414139568806, -191.91201797127724, -180.03978146612644, -180.04869277775288], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.2209175070937799, 'mean_inference_ms': 2.2407887063058864, 'mean_action_processing_ms': 0.21747991990069954, 'mean_env_wait_ms': 3.0381576901390437, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0}, 'episode_reward_max': -175.28551595658064, 'episode_reward_min': -191.91201797127724, 'episode_reward_mean': -183.6617713689804, 'episode_len_mean': 100.0, 'episodes_this_iter': 10, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'hist_stats': {'episode_reward': [-177.71922475099564, -187.68662855029106, -175.28551595658064, -185.17646113038063, -188.07598569989204, -183.15926399081945, -187.51414139568806, -191.91201797127724, -180.03978146612644, -180.04869277775288], 'episode_lengths': [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 1.2209175070937799, 'mean_inference_ms': 2.2407887063058864, 'mean_action_processing_ms': 0.21747991990069954, 'mean_env_wait_ms': 3.0381576901390437, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'num_healthy_workers': 3, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_env_steps_sampled_this_iter': 1002, 'num_env_steps_trained_this_iter': 85504, 'num_steps_trained_this_iter': 85504, 'agent_timesteps_total': 11022, 'timers': {'training_iteration_time_ms': 147.211, 'load_time_ms': 0.259, 'load_throughput': 986985.774, 'learn_time_ms': 24.022, 'learn_throughput': 10657.075, 'synch_weights_time_ms': 5.359}, 'counters': {'num_env_steps_sampled': 11022, 'num_env_steps_trained': 87296, 'num_agent_steps_sampled': 11022, 'num_agent_steps_trained': 87296, 'last_target_update_ts': 11022, 'num_target_updates': 341}, 'done': False, 'trial_id': 'ad8de_00000', 'perf': {'cpu_util_percent': 38.9536231884058, 'ram_util_percent': 87.61304347826086}, 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_a1dbe_00000_0_2023-02-11_16-49-13/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_ad8de_00000_0_2023-02-11_16-56-43'))"
+      ]
+     },
+     "execution_count": 16,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# Get the best result based on a particular metric.\n",
+    "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
+    "best_result"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 17,
+   "id": "beca7170-c89a-402c-afb7-ce88cf5524b7",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Checkpoint(local_path=/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_a1dbe_00000_0_2023-02-11_16-49-13/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_ad8de_00000_0_2023-02-11_16-56-43/checkpoint_000011)"
+      ]
+     },
+     "execution_count": 17,
+     "metadata": {},
+     "output_type": "execute_result"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:32,579 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129005056; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:42,596 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129254912; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:00:52,615 E 9254 9299] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-49-09_974082_9002 is over 95% full, available space: 1129238528; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    }
+   ],
+   "source": [
+    "# Get the best checkpoint corresponding to the best result.\n",
+    "best_checkpoint = best_result.checkpoint\n",
+    "best_checkpoint"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "id": "3b9e8a43-146c-4a5b-99b7-12384ff38b84",
+   "metadata": {
+    "tags": []
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 16:38:32,937\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "2023-02-11 16:38:32,949\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 16:38:35,741 E 6815 6860] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_16-34-33_438228_6699 is over 95% full, available space: 1174347776; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7501)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m 2023-02-11 16:38:38,536\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7500)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m   logger.warn(\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=7502)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "  logger.warn(\n",
+      "2023-02-11 16:38:39,885\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
+      "2023-02-11 16:38:39,927\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "SAC"
+      ]
+     },
+     "execution_count": 11,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# Get Algorithm from saved checkpoint\n",
+    "from ray.rllib.algorithms.algorithm import Algorithm\n",
+    "algo = Algorithm.from_checkpoint(best_checkpoint._local_path)\n",
+    "algo"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 11,
+   "id": "a9cff7c5-f517-4287-9447-668320c35452",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "2023-02-11 17:26:26,421\tINFO trial_runner.py:688 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
+      "2023-02-11 17:26:26,422\tINFO trial_runner.py:825 -- Using following checkpoint to resume: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-11_17-23-28.json\n",
+      "2023-02-11 17:26:26,426\tWARNING trial_runner.py:830 -- Attempting to resume experiment from /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET. This will ignore any new changes to the specification.\n",
+      "2023-02-11 17:26:26,440\tINFO tune.py:653 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "<div class=\"tuneStatus\">\n",
+       "  <div style=\"display: flex;flex-direction: row\">\n",
+       "    <div style=\"display: flex;flex-direction: column;\">\n",
+       "      <h3>Tune Status</h3>\n",
+       "      <table>\n",
+       "<tbody>\n",
+       "<tr><td>Current time:</td><td>2023-02-11 17:29:20</td></tr>\n",
+       "<tr><td>Running for: </td><td>00:02:54.01        </td></tr>\n",
+       "<tr><td>Memory:      </td><td>6.3/7.5 GiB        </td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "    </div>\n",
+       "    <div class=\"vDivider\"></div>\n",
+       "    <div class=\"systemInfo\">\n",
+       "      <h3>System Info</h3>\n",
+       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/1.72 GiB heap, 0.0/0.86 GiB objects\n",
+       "    </div>\n",
+       "    \n",
+       "  </div>\n",
+       "  <div class=\"hDivider\"></div>\n",
+       "  <div class=\"trialStatus\">\n",
+       "    <h3>Trial Status</h3>\n",
+       "    <table>\n",
+       "<thead>\n",
+       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
+       "</thead>\n",
+       "<tbody>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td>RUNNING </td><td>192.168.152.36:15703</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         227.817</td><td style=\"text-align: right;\">13026</td><td style=\"text-align: right;\">-179.588</td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">               100</td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "  </div>\n",
+       "</div>\n",
+       "<style>\n",
+       ".tuneStatus {\n",
+       "  color: var(--jp-ui-font-color1);\n",
+       "}\n",
+       ".tuneStatus .systemInfo {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "}\n",
+       ".tuneStatus td {\n",
+       "  white-space: nowrap;\n",
+       "}\n",
+       ".tuneStatus .trialStatus {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "}\n",
+       ".tuneStatus h3 {\n",
+       "  font-weight: bold;\n",
+       "}\n",
+       ".tuneStatus .hDivider {\n",
+       "  border-bottom-width: var(--jp-border-width);\n",
+       "  border-bottom-color: var(--jp-border-color0);\n",
+       "  border-bottom-style: solid;\n",
+       "}\n",
+       ".tuneStatus .vDivider {\n",
+       "  border-left-width: var(--jp-border-width);\n",
+       "  border-left-color: var(--jp-border-color0);\n",
+       "  border-left-style: solid;\n",
+       "  margin: 0.5em 1em 0.5em 1em;\n",
+       "}\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:26,618 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061683200; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:30,934\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:31,413\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "Tracking run with wandb version 0.13.10"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/wandb/run-20230211_172629-6a944_00000</code>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       "Resuming run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "data": {
+      "text/html": [
+       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/6a944_00000</a>"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:36,627 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061359616; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m Loaded XML file successfully\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m 2023-02-11 17:26:38,825\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m   logger.warn(\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,232\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,261\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m Loaded XML file successfully\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:790 -- Restored on 192.168.152.36 from checkpoint: /tmp/checkpoint_tmp_7f50b6e15e2c473dba807bf1d398566d\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 11, '_timesteps_total': None, '_time_total': 113.04964661598206, '_episodes_total': 114}\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
+      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:46,634 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061335040; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:56,640 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:06,648 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061339136; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:16,654 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:26,659 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061314560; capacity: 31845081088. Object creation will fail if spilling is required.\n"
+     ]
+    },
+    {
+     "data": {
+      "text/html": [
+       "<div class=\"trialProgress\">\n",
+       "  <h3>Trial Progress</h3>\n",
+       "  <table>\n",
+       "<thead>\n",
+       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                               </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
+       "</thead>\n",
+       "<tbody>\n",
+       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td style=\"text-align: right;\">                  13026</td><td>{&#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}</td><td>{}              </td><td>2023-02-11_17-28-35</td><td>False </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">             -179.588</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             132</td><td>2674246d3b814ef583cb37ca785123d2</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.40356159210205, &#x27;actor_loss&#x27;: -4.885239601135254, &#x27;critic_loss&#x27;: 0.3069121241569519, &#x27;alpha_loss&#x27;: -2.5390048027038574, &#x27;alpha_value&#x27;: 0.7392387, &#x27;log_alpha_value&#x27;: -0.30213442, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.029988128691911697, &#x27;mean_q&#x27;: 2.379087448120117, &#x27;max_q&#x27;: 3.1470589637756348, &#x27;min_q&#x27;: 1.5433847904205322}, &#x27;td_error&#x27;: array([7.4213958e-01, 1.5848637e-01, 6.0251343e-01, 9.3348145e-01,\n",
+       "       7.2470105e-01, 6.5075898e-01, 7.4386942e-01, 4.2802992e+00,\n",
+       "       4.9475217e-01, 2.1274698e-01, 1.5443254e-01, 2.0181298e-01,\n",
+       "       4.8542452e-01, 4.9696553e-01, 3.7915547e+00, 8.3584547e-02,\n",
+       "       8.3843565e-01, 7.5096285e-01, 6.2452388e-01, 2.4125576e-01,\n",
+       "       7.7261329e-01, 2.6608777e-01, 3.3530772e-01, 2.6860654e-01,\n",
+       "       1.5399015e-01, 7.0978558e-01, 7.8079522e-01, 1.0731530e-01,\n",
+       "       8.8066232e-01, 1.1126903e+00, 3.6070585e-02, 6.7874563e-01,\n",
+       "       7.5406009e-01, 4.2981052e-01, 1.1391871e+00, 3.9740098e-01,\n",
+       "       1.0762990e+00, 8.4136343e-01, 5.8252001e-01, 4.0861154e-01,\n",
+       "       5.6281984e-01, 2.7024639e-01, 6.9000638e-01, 8.6244369e-01,\n",
+       "       5.7595563e-01, 7.2603118e-01, 5.9470689e-01, 2.7473211e-01,\n",
+       "       5.6826186e-01, 2.4650784e+02, 9.8598832e-01, 7.3479068e-01,\n",
+       "       6.1449623e-01, 1.2699622e+00, 7.5296319e-01, 2.8090358e-02,\n",
+       "       9.4109213e-01, 8.2771111e-01, 4.2838442e-01, 3.8090675e+00,\n",
+       "       4.7546709e-01, 2.4742079e-01, 4.1203547e-01, 7.3801911e-01,\n",
+       "       1.0025257e+00, 6.7763782e-01, 6.7099619e-01, 8.6762822e-01,\n",
+       "       5.6190348e-01, 8.8954902e-01, 8.1222010e-01, 8.6386180e-01,\n",
+       "       7.6953566e-01, 1.0633967e+00, 5.9996891e-01, 5.3750610e-01,\n",
+       "       7.0670819e-01, 4.9724150e-01, 3.3370614e-02, 6.8903613e-01,\n",
+       "       9.4764221e-01, 5.0915122e-02, 5.0027347e-01, 9.6055913e-01,\n",
+       "       5.5192137e-01, 7.9515433e-01, 7.2671640e-01, 3.9931262e-01,\n",
+       "       1.8239129e-01, 9.9649012e-01, 8.4206927e-01, 4.1600978e-01,\n",
+       "       4.0527940e-01, 7.6102638e-01, 2.3393106e-01, 4.7766042e-01,\n",
+       "       2.2459340e-01, 8.5827851e-01, 1.4306033e-01, 2.4650784e+02,\n",
+       "       7.1198571e-01, 3.9922416e+00, 1.2246186e+00, 7.4194229e-01,\n",
+       "       2.7496171e-01, 4.5212805e-02, 7.4664807e-01, 1.3847947e-02,\n",
+       "       8.7445688e-01, 6.6402781e-01, 1.0255686e+00, 4.5125723e-01,\n",
+       "       4.8755097e-01, 2.4650784e+02, 4.4124365e-01, 1.0487792e+00,\n",
+       "       5.8346188e-01, 2.6959336e-01, 3.5287654e-01, 5.9907603e-01,\n",
+       "       4.8603582e-01, 6.1551094e-01, 6.9831514e-01, 5.1433253e-01,\n",
+       "       1.8200487e-01, 9.6122825e-01, 7.8497732e-01, 2.2768998e-01,\n",
+       "       9.6964097e-01, 1.4972503e+00, 8.0229974e-01, 1.0484257e+00,\n",
+       "       5.5421102e-01, 8.3084774e-01, 4.7661805e-01, 3.9173824e-01,\n",
+       "       3.1396019e-01, 4.2802992e+00, 2.7052438e-01, 2.6957560e-01,\n",
+       "       7.5368738e-01, 4.4456518e-01, 3.1527257e-01, 8.5121763e-01,\n",
+       "       9.0664178e-01, 9.4629610e-01, 5.6297445e-01, 5.9285718e-01,\n",
+       "       6.3104606e-01, 5.2718985e-01, 6.5370166e-01, 7.0399725e-01,\n",
+       "       4.5417070e-02, 2.4650784e+02, 7.2803473e-01, 1.1245636e+00,\n",
+       "       3.7708211e-01, 3.7433398e-01, 4.3422055e-01, 3.2808065e-01,\n",
+       "       6.2305951e-01, 1.7103601e-01, 7.9449832e-01, 1.3040452e+00,\n",
+       "       7.1471536e-01, 4.5487504e+00, 4.1272748e-01, 6.5745860e-01,\n",
+       "       6.6768157e-01, 8.8028562e-01, 7.0535421e-01, 5.2402341e-01,\n",
+       "       5.6226981e-01, 5.4202604e-01, 2.7826047e-01, 2.6031137e-01,\n",
+       "       6.0549617e-02, 3.6561573e-01, 2.4650784e+02, 8.0606019e-01,\n",
+       "       8.4074116e-01, 4.9388194e-01, 7.1800745e-01, 2.9282093e-02,\n",
+       "       1.9090211e-01, 3.8544512e-01, 1.4638956e+00, 1.4547678e+00,\n",
+       "       1.0922147e+00, 2.6176953e-01, 1.3020796e-01, 5.6222248e-01,\n",
+       "       5.6339896e-01, 7.6045167e-01, 7.8438163e-01, 7.5755298e-01,\n",
+       "       8.2661462e-01, 3.5743856e-01, 1.3571662e-01, 5.3244066e-01,\n",
+       "       8.8719201e-01, 8.2828355e-01, 3.8229942e-01, 6.0678411e-01,\n",
+       "       4.7898412e-01, 8.2518208e-01, 5.2971601e-01, 6.7987609e-01,\n",
+       "       7.6182199e-01, 1.0264168e+00, 6.2066817e-01, 9.0486789e-01,\n",
+       "       4.7908902e-01, 1.1681950e-01, 7.6850456e-01, 3.1422675e-01,\n",
+       "       9.3148047e-01, 9.5507002e-01, 8.3421135e-01, 5.6414163e-01,\n",
+       "       4.1598296e-01, 5.0719857e-02, 9.6793044e-01, 1.4145180e+00,\n",
+       "       1.4200950e-01, 8.1434751e-01, 7.0387411e-01, 8.6176515e-01,\n",
+       "       6.2346458e-01, 1.4636874e-01, 3.2455921e-01, 1.5807381e+00,\n",
+       "       5.9650755e-01, 7.9351628e-01, 1.6089365e+00, 7.5115800e-01,\n",
+       "       5.8976293e-01, 4.7450304e-02, 6.6682827e-01, 7.1542680e-01,\n",
+       "       4.6520185e-01, 3.4638846e-01, 7.5957966e-01, 4.9341345e-01,\n",
+       "       4.8143768e-01, 1.2025452e-01, 6.0646594e-01, 1.1619196e+00,\n",
+       "       2.7393532e-01, 8.4904301e-01, 2.5427663e-01, 7.0259297e-01,\n",
+       "       5.2577734e-01, 2.9342413e-01, 6.1365223e-01, 9.0736806e-01],\n",
+       "      dtype=float32), &#x27;mean_td_error&#x27;: 5.492199897766113, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 668.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 667.0}}, &#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}       </td><td style=\"text-align: right;\">                         2</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    13026</td><td style=\"text-align: right;\">                   258304</td><td style=\"text-align: right;\">                  13026</td><td style=\"text-align: right;\">                             1002</td><td style=\"text-align: right;\">                 258304</td><td style=\"text-align: right;\">                            85504</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        85504</td><td>{&#x27;cpu_util_percent&#x27;: 54.76744186046512, &#x27;ram_util_percent&#x27;: 85.32209302325585}</td><td style=\"text-align: right;\">15703</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -166.09740307927132, &#x27;episode_reward_min&#x27;: -189.6840973868966, &#x27;episode_reward_mean&#x27;: -179.5880893824829, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 9, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-187.3498569726944, -166.09740307927132, -172.9712873697281, -187.82146245241165, -176.65354753285646, -183.53197374939919, -176.7706963941455, -189.6840973868966, -175.4124795049429], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             114.767</td><td style=\"text-align: right;\">            62.318</td><td style=\"text-align: right;\">       227.817</td><td>{&#x27;training_iteration_time_ms&#x27;: 151.985, &#x27;load_time_ms&#x27;: 0.246, &#x27;load_throughput&#x27;: 1042265.409, &#x27;learn_time_ms&#x27;: 25.824, &#x27;learn_throughput&#x27;: 9913.287, &#x27;synch_weights_time_ms&#x27;: 6.049}</td><td style=\"text-align: right;\"> 1676132915</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            13026</td><td style=\"text-align: right;\">                  13</td><td>6a944_00000</td><td style=\"text-align: right;\">      9.03385</td></tr>\n",
+       "</tbody>\n",
+       "</table>\n",
+       "</div>\n",
+       "<style>\n",
+       ".trialProgress {\n",
+       "  display: flex;\n",
+       "  flex-direction: column;\n",
+       "  color: var(--jp-ui-font-color1);\n",
+       "}\n",
+       ".trialProgress h3 {\n",
+       "  font-weight: bold;\n",
+       "}\n",
+       ".trialProgress td {\n",
+       "  white-space: nowrap;\n",
+       "}\n",
+       "</style>\n"
+      ],
+      "text/plain": [
+       "<IPython.core.display.HTML object>"
+      ]
+     },
+     "metadata": {},
+     "output_type": "display_data"
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000012)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:36,665 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055997952; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:46,672 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055973376; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:56,678 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055977472; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:06,689 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056280576; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:16,700 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056186368; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:26,706 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056030720; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000013)... Done. 0.0s\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:36,714 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053261824; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:46,719 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053159424; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:56,725 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053106176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:06,732 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053073408; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "2023-02-11 17:29:16,846\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
+      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:16,738 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053069312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
+      "2023-02-11 17:29:17,441\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
+      "2023-02-11 17:29:20,661\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_6a944_00000]\n",
+      "2023-02-11 17:29:20,663\tINFO tune.py:762 -- Total run time: 174.25 seconds (174.00 seconds for the tuning loop).\n",
+      "2023-02-11 17:29:20,664\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
+     ]
+    },
+    {
+     "data": {
+      "text/plain": [
+       "<ray.tune.result_grid.ResultGrid at 0x7fedc40a1d90>"
+      ]
+     },
+     "execution_count": 11,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "# resume the interrupted run\n",
+    "tuner.fit()"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "1d25217d-5941-40bc-b103-d5ff3f6e9c72",
+   "metadata": {},
+   "outputs": [],
    "source": []
   }
  ],
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/events.out.tfevents.1675949679.Daniel b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/events.out.tfevents.1675949679.Daniel
deleted file mode 100644
index 11b4226..0000000
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/events.out.tfevents.1675949679.Daniel and /dev/null differ
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.json
deleted file mode 100644
index 268d009..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.json
+++ /dev/null
@@ -1,226 +0,0 @@
-{
-  "_deterministic_loss": false,
-  "_disable_action_flattening": false,
-  "_disable_execution_plan_api": true,
-  "_disable_preprocessor_api": false,
-  "_fake_gpus": false,
-  "_tf_policy_handles_more_than_one_loss": false,
-  "_use_beta_distribution": false,
-  "action_space": null,
-  "actions_in_input_normalized": false,
-  "always_attach_evaluation_results": false,
-  "batch_mode": "truncate_episodes",
-  "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>",
-  "clip_actions": false,
-  "clip_rewards": null,
-  "compress_observations": false,
-  "create_env_on_driver": false,
-  "custom_eval_function": null,
-  "custom_resources_per_worker": {},
-  "disable_env_checking": false,
-  "eager_max_retraces": 20,
-  "eager_tracing": false,
-  "enable_async_evaluation": false,
-  "enable_connectors": false,
-  "enable_tf1_exec_eagerly": false,
-  "env": "darm/DarmSFHand-v0",
-  "env_config": {},
-  "env_task_fn": null,
-  "evaluation_config": null,
-  "evaluation_duration": 10,
-  "evaluation_duration_unit": "episodes",
-  "evaluation_interval": 100,
-  "evaluation_num_workers": 0,
-  "evaluation_parallel_to_training": false,
-  "evaluation_sample_timeout_s": 180.0,
-  "exploration_config": {
-    "type": "StochasticSampling"
-  },
-  "explore": true,
-  "export_native_model_files": false,
-  "extra_python_environs_for_driver": {},
-  "extra_python_environs_for_worker": {},
-  "fake_sampler": false,
-  "framework": "torch",
-  "gamma": 0.99,
-  "grad_clip": null,
-  "horizon": null,
-  "ignore_worker_failures": false,
-  "in_evaluation": false,
-  "initial_alpha": 1.0,
-  "input": "sampler",
-  "input_config": {},
-  "keep_per_episode_custom_metrics": false,
-  "local_tf_session_args": {
-    "inter_op_parallelism_threads": 8,
-    "intra_op_parallelism_threads": 8
-  },
-  "log_level": "WARN",
-  "log_sys_usage": true,
-  "logger_config": null,
-  "logger_creator": null,
-  "lr": 0.001,
-  "max_requests_in_flight_per_sampler_worker": 2,
-  "metrics_episode_collection_timeout_s": 60.0,
-  "metrics_num_episodes_for_smoothing": 5,
-  "min_sample_timesteps_per_iteration": 1000,
-  "min_time_s_per_iteration": 1,
-  "min_train_timesteps_per_iteration": 0,
-  "model": {
-    "_disable_action_flattening": false,
-    "_disable_preprocessor_api": false,
-    "_time_major": false,
-    "_use_default_native_models": false,
-    "attention_dim": 64,
-    "attention_head_dim": 32,
-    "attention_init_gru_gate_bias": 2.0,
-    "attention_memory_inference": 50,
-    "attention_memory_training": 50,
-    "attention_num_heads": 1,
-    "attention_num_transformer_units": 1,
-    "attention_position_wise_mlp_dim": 32,
-    "attention_use_n_prev_actions": 0,
-    "attention_use_n_prev_rewards": 0,
-    "conv_activation": "relu",
-    "conv_filters": null,
-    "custom_action_dist": null,
-    "custom_model": null,
-    "custom_model_config": {},
-    "custom_preprocessor": null,
-    "dim": 84,
-    "fcnet_activation": "tanh",
-    "fcnet_hiddens": [
-      256,
-      256
-    ],
-    "framestack": true,
-    "free_log_std": false,
-    "grayscale": false,
-    "lstm_cell_size": 256,
-    "lstm_use_prev_action": false,
-    "lstm_use_prev_action_reward": -1,
-    "lstm_use_prev_reward": false,
-    "max_seq_len": 20,
-    "no_final_linear": false,
-    "post_fcnet_activation": "relu",
-    "post_fcnet_hiddens": [],
-    "use_attention": false,
-    "use_lstm": false,
-    "vf_share_layers": true,
-    "zero_mean": true
-  },
-  "multiagent": {
-    "count_steps_by": "env_steps",
-    "observation_fn": null,
-    "policies": {
-      "default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde38172880>"
-    },
-    "policies_to_train": null,
-    "policy_map_cache": null,
-    "policy_map_capacity": 100,
-    "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3be4d1f0>"
-  },
-  "n_step": 1,
-  "no_done_at_end": false,
-  "normalize_actions": true,
-  "num_consecutive_worker_failures_tolerance": 100,
-  "num_cpus_for_driver": 1,
-  "num_cpus_per_worker": 1,
-  "num_envs_per_worker": 1,
-  "num_gpus": 0,
-  "num_gpus_per_worker": 0,
-  "num_steps_sampled_before_learning_starts": 10000,
-  "num_workers": 3,
-  "observation_filter": "NoFilter",
-  "observation_space": null,
-  "off_policy_estimation_methods": {},
-  "offline_sampling": false,
-  "ope_split_batch_by_episode": true,
-  "optimization": {
-    "actor_learning_rate": 0.0003,
-    "critic_learning_rate": 0.0003,
-    "entropy_learning_rate": 0.0003
-  },
-  "optimizer": {},
-  "output": null,
-  "output_compress_columns": [
-    "obs",
-    "new_obs"
-  ],
-  "output_config": {},
-  "output_max_file_size": 67108864,
-  "placement_strategy": "PACK",
-  "policy_model_config": {
-    "custom_model": null,
-    "custom_model_config": {},
-    "fcnet_activation": "relu",
-    "fcnet_hiddens": [
-      256,
-      256
-    ],
-    "post_fcnet_activation": null,
-    "post_fcnet_hiddens": []
-  },
-  "postprocess_inputs": false,
-  "preprocessor_pref": "deepmind",
-  "q_model_config": {
-    "custom_model": null,
-    "custom_model_config": {},
-    "fcnet_activation": "relu",
-    "fcnet_hiddens": [
-      256,
-      256
-    ],
-    "post_fcnet_activation": null,
-    "post_fcnet_hiddens": []
-  },
-  "recreate_failed_workers": false,
-  "remote_env_batch_wait_ms": 0,
-  "remote_worker_envs": false,
-  "render_env": false,
-  "replay_buffer_config": {
-    "_enable_replay_buffer_api": true,
-    "capacity": 1000000,
-    "prioritized_replay": false,
-    "prioritized_replay_alpha": 0.6,
-    "prioritized_replay_beta": 0.4,
-    "prioritized_replay_eps": 1e-06,
-    "type": "MultiAgentPrioritizedReplayBuffer",
-    "worker_side_prioritization": false
-  },
-  "replay_sequence_length": null,
-  "restart_failed_sub_environments": false,
-  "rollout_fragment_length": 1,
-  "sample_async": false,
-  "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>",
-  "sampler_perf_stats_ema_coef": null,
-  "seed": null,
-  "shuffle_buffer_size": 0,
-  "simple_optimizer": -1,
-  "soft_horizon": false,
-  "store_buffer_in_checkpoints": false,
-  "sync_filters_on_rollout_workers_timeout_s": 60.0,
-  "synchronize_filters": true,
-  "target_entropy": "auto",
-  "target_network_update_freq": 1,
-  "tau": 0.005,
-  "tf_session_args": {
-    "allow_soft_placement": true,
-    "device_count": {
-      "CPU": 1
-    },
-    "gpu_options": {
-      "allow_growth": true
-    },
-    "inter_op_parallelism_threads": 2,
-    "intra_op_parallelism_threads": 2,
-    "log_device_placement": false
-  },
-  "train_batch_size": 256,
-  "training_intensity": null,
-  "twin_q": true,
-  "use_state_preprocessor": -1,
-  "validate_workers_after_construction": true,
-  "worker_cls": null,
-  "worker_side_prioritization": -1
-}
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.pkl b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.pkl
deleted file mode 100644
index 5e77f5b..0000000
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/params.pkl and /dev/null differ
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/progress.csv b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/progress.csv
deleted file mode 100644
index 1d8da5f..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/progress.csv
+++ /dev/null
@@ -1,98 +0,0 @@
-episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_faulty_episodes,num_healthy_workers,num_in_flight_async_reqs,num_remote_worker_restarts,num_agent_steps_sampled,num_agent_steps_trained,num_env_steps_sampled,num_env_steps_trained,num_env_steps_sampled_this_iter,num_env_steps_trained_this_iter,timesteps_total,num_steps_trained_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,warmup_time,info/num_env_steps_sampled,info/num_env_steps_trained,info/num_agent_steps_sampled,info/num_agent_steps_trained,sampler_results/episode_reward_max,sampler_results/episode_reward_min,sampler_results/episode_reward_mean,sampler_results/episode_len_mean,sampler_results/episodes_this_iter,sampler_results/num_faulty_episodes,hist_stats/episode_reward,hist_stats/episode_lengths,sampler_perf/mean_raw_obs_processing_ms,sampler_perf/mean_inference_ms,sampler_perf/mean_action_processing_ms,sampler_perf/mean_env_wait_ms,sampler_perf/mean_env_render_ms,timers/training_iteration_time_ms,counters/num_env_steps_sampled,counters/num_env_steps_trained,counters/num_agent_steps_sampled,counters/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,sampler_results/hist_stats/episode_reward,sampler_results/hist_stats/episode_lengths,sampler_results/sampler_perf/mean_raw_obs_processing_ms,sampler_results/sampler_perf/mean_inference_ms,sampler_results/sampler_perf/mean_action_processing_ms,sampler_results/sampler_perf/mean_env_wait_ms,sampler_results/sampler_perf/mean_env_render_ms
--172.03659576177597,-195.72291019558907,-188.20978297458754,100.0,9,0,3,0,0,1002,0,1002,0,1002,0,1002,0,1002,False,9,1,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-34-56,1675949696,5.359312057495117,5.359312057495117,27220,Daniel,192.168.152.36,5.359312057495117,0,1,8.03538990020752,1002,0,1002,0,-172.03659576177597,-195.72291019558907,-188.20978297458754,100.0,9,0,"[-195.72291019558907, -187.1162899285555, -190.60696797072887, -189.89828623831272, -190.89283438771963, -191.54977372288704, -189.29449943453074, -172.03659576177597, -186.7698891311884]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.427876296921156,2.599548937669441,0.2599483698754762,3.5897183774122556,0.0,11.747,1002,0,1002,0,77.2875,82.25,"[-195.72291019558907, -187.1162899285555, -190.60696797072887, -189.89828623831272, -190.89283438771963, -191.54977372288704, -189.29449943453074, -172.03659576177597, -186.7698891311884]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.427876296921156,2.599548937669441,0.2599483698754762,3.5897183774122556,0.0
-181.36450699716806,-188.52998483181,-116.5225211687386,91.6,10,0,3,0,0,2004,0,2004,0,1002,0,2004,0,2004,False,19,2,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-00,1675949700,4.41457462310791,9.773886680603027,27220,Daniel,192.168.152.36,9.773886680603027,0,2,8.03538990020752,2004,0,2004,0,181.36450699716806,-188.52998483181,-116.5225211687386,91.6,10,0,"[-186.0414990633726, -181.82346287369728, -187.07104221731424, 181.36450699716806, -188.52998483181, -186.8800953477621, -183.72251315414906, 119.88127318024635, -168.5321788340807, -183.87021554261446]","[100, 100, 100, 40, 100, 100, 100, 76, 100, 100]",1.3483278063558857,2.4592295534051227,0.24587505779636992,3.358560185795942,0.0,15.164,2004,0,2004,0,66.68333333333332,81.83333333333333,"[-186.0414990633726, -181.82346287369728, -187.07104221731424, 181.36450699716806, -188.52998483181, -186.8800953477621, -183.72251315414906, 119.88127318024635, -168.5321788340807, -183.87021554261446]","[100, 100, 100, 40, 100, 100, 100, 76, 100, 100]",1.3483278063558857,2.4592295534051227,0.24587505779636992,3.358560185795942,0.0
--166.59257543087006,-190.71805255115032,-183.2389093122699,100.0,11,0,3,0,0,3006,0,3006,0,1002,0,3006,0,3006,False,30,3,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-05,1675949705,4.316670894622803,14.09055757522583,27220,Daniel,192.168.152.36,14.09055757522583,0,3,8.03538990020752,3006,0,3006,0,-166.59257543087006,-190.71805255115032,-183.2389093122699,100.0,11,0,"[-186.16230046749115, -190.71805255115032, -186.63101022690535, -185.4745416790247, -189.33403262495995, -190.39464975893497, -187.7986584380269, -172.52650797367096, -182.9834259748459, -166.59257543087006, -177.0122473090887]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3246139718951833,2.436714203481088,0.23946076628844823,3.264693760930233,0.0,23.176,3006,0,3006,0,65.94285714285714,82.0,"[-186.16230046749115, -190.71805255115032, -186.63101022690535, -185.4745416790247, -189.33403262495995, -190.39464975893497, -187.7986584380269, -172.52650797367096, -182.9834259748459, -166.59257543087006, -177.0122473090887]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3246139718951833,2.436714203481088,0.23946076628844823,3.264693760930233,0.0
--178.81081108748913,-189.48420125246048,-184.38521087418,100.0,9,0,3,0,0,4008,0,4008,0,1002,0,4008,0,4008,False,39,4,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-10,1675949710,5.069538831710815,19.160096406936646,27220,Daniel,192.168.152.36,19.160096406936646,0,4,8.03538990020752,4008,0,4008,0,-178.81081108748913,-189.48420125246048,-184.38521087418,100.0,9,0,"[-189.48420125246048, -179.4162740111351, -178.81081108748913, -185.32138426601887, -185.3411936312914, -187.57649797201157, -181.8119632154703, -186.94552153348923, -184.75905089825392]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3515723967189595,2.523937655695951,0.25009217330031014,3.3161904086082306,0.0,18.62,4008,0,4008,0,73.22857142857141,82.17142857142856,"[-189.48420125246048, -179.4162740111351, -178.81081108748913, -185.32138426601887, -185.3411936312914, -187.57649797201157, -181.8119632154703, -186.94552153348923, -184.75905089825392]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3515723967189595,2.523937655695951,0.25009217330031014,3.3161904086082306,0.0
--160.33254747092724,-195.33662481606007,-183.9175837755203,100.0,10,0,3,0,0,5010,0,5010,0,1002,0,5010,0,5010,False,49,5,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-14,1675949714,4.382728338241577,23.542824745178223,27220,Daniel,192.168.152.36,23.542824745178223,0,5,8.03538990020752,5010,0,5010,0,-160.33254747092724,-195.33662481606007,-183.9175837755203,100.0,10,0,"[-195.33662481606007, -192.1119733080268, -160.33254747092724, -185.65166425704956, -182.5882617160678, -191.72356040775776, -171.65736323595047, -183.66383278369904, -191.31481182575226, -184.79519793391228]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3377852385661904,2.473846600485162,0.24650890195105762,3.2866380230385976,0.0,12.028,5010,0,5010,0,69.1,82.26666666666667,"[-195.33662481606007, -192.1119733080268, -160.33254747092724, -185.65166425704956, -182.5882617160678, -191.72356040775776, -171.65736323595047, -183.66383278369904, -191.31481182575226, -184.79519793391228]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.3377852385661904,2.473846600485162,0.24650890195105762,3.2866380230385976,0.0
-139.6858552545309,-196.0045984685421,-156.94192648244402,96.75,12,0,3,0,0,6012,0,6012,0,1002,0,6012,0,6012,False,61,6,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-19,1675949719,4.379156827926636,27.92198157310486,27220,Daniel,192.168.152.36,27.92198157310486,0,6,8.03538990020752,6012,0,6012,0,139.6858552545309,-196.0045984685421,-156.94192648244402,96.75,12,0,"[-189.58302499353886, -184.5064988285303, -187.74731319397688, -181.47071016579866, -183.56445981562138, -196.0045984685421, -190.47504161298275, 139.6858552545309, -188.03654915094376, -171.9393027573824, -181.4177524521947, -168.24372160434723]","[100, 100, 100, 100, 100, 100, 100, 61, 100, 100, 100, 100]",1.3299502834913044,2.4597411738369526,0.2425731665277521,3.2661979830671335,0.0,12.158,6012,0,6012,0,65.83333333333334,82.35000000000001,"[-189.58302499353886, -184.5064988285303, -187.74731319397688, -181.47071016579866, -183.56445981562138, -196.0045984685421, -190.47504161298275, 139.6858552545309, -188.03654915094376, -171.9393027573824, -181.4177524521947, -168.24372160434723]","[100, 100, 100, 100, 100, 100, 100, 61, 100, 100, 100, 100]",1.3299502834913044,2.4597411738369526,0.2425731665277521,3.2661979830671335,0.0
-196.41344634443521,-190.28570076823235,-143.89437042698265,93.4,10,0,3,0,0,7014,0,7014,0,1002,0,7014,0,7014,False,71,7,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-23,1675949723,3.9633991718292236,31.885380744934082,27220,Daniel,192.168.152.36,31.885380744934082,0,7,8.03538990020752,7014,0,7014,0,196.41344634443521,-190.28570076823235,-143.89437042698265,93.4,10,0,"[-190.12851731479168, -169.1818624585867, -190.28570076823235, -175.12801945209503, -181.12022495269775, -183.9177276864648, 196.41344634443521, -185.67551515996456, -183.3443570137024, -176.57522580772638]","[100, 100, 100, 100, 100, 100, 34, 100, 100, 100]",1.3077645283471118,2.4002063880878004,0.23739599885977242,3.2092160065493145,0.0,12.716,7014,0,7014,0,62.88333333333333,82.39999999999999,"[-190.12851731479168, -169.1818624585867, -190.28570076823235, -175.12801945209503, -181.12022495269775, -183.9177276864648, 196.41344634443521, -185.67551515996456, -183.3443570137024, -176.57522580772638]","[100, 100, 100, 100, 100, 100, 34, 100, 100, 100]",1.3077645283471118,2.4002063880878004,0.23739599885977242,3.2092160065493145,0.0
-210.6578472852707,-189.2391362041235,-143.9040757663548,92.3,10,0,3,0,0,8016,0,8016,0,1002,0,8016,0,8016,False,81,8,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-27,1675949727,3.8648064136505127,35.750187158584595,27220,Daniel,192.168.152.36,35.750187158584595,0,8,8.03538990020752,8016,0,8016,0,210.6578472852707,-189.2391362041235,-143.9040757663548,92.3,10,0,"[-188.13962118327618, -188.73138186335564, -184.52830079942942, -166.40105326473713, -185.9469074010849, -177.44468593597412, -184.1500248014927, 210.6578472852707, -189.2391362041235, -185.11749349534512]","[100, 100, 100, 100, 100, 100, 100, 23, 100, 100]",1.2881654859971698,2.3555338449617294,0.23198582641738566,3.1648960802111783,0.0,11.496,8016,0,8016,0,61.51666666666667,82.5,"[-188.13962118327618, -188.73138186335564, -184.52830079942942, -166.40105326473713, -185.9469074010849, -177.44468593597412, -184.1500248014927, 210.6578472852707, -189.2391362041235, -185.11749349534512]","[100, 100, 100, 100, 100, 100, 100, 23, 100, 100]",1.2881654859971698,2.3555338449617294,0.23198582641738566,3.1648960802111783,0.0
-77.90451084077358,-194.82577526569366,-163.0946609432047,99.9090909090909,11,0,3,0,0,9018,0,9018,0,1002,0,9018,0,9018,False,92,9,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-30,1675949730,3.912569999694824,39.66275715827942,27220,Daniel,192.168.152.36,39.66275715827942,0,9,8.03538990020752,9018,0,9018,0,77.90451084077358,-194.82577526569366,-163.0946609432047,99.9090909090909,11,0,"[-188.0968882739544, -188.9403100013733, -174.04480615258217, -194.82577526569366, -183.58984605967999, -190.4420650601387, 77.90451084077358, -186.39500673115253, -184.86948497593403, -190.73766081035137, -190.00393788516521]","[100, 100, 100, 100, 100, 100, 99, 100, 100, 100, 100]",1.2782163796158317,2.326747967981566,0.22898460741317284,3.134211638452612,0.0,11.428,9018,0,9018,0,61.86,82.5,"[-188.0968882739544, -188.9403100013733, -174.04480615258217, -194.82577526569366, -183.58984605967999, -190.4420650601387, 77.90451084077358, -186.39500673115253, -184.86948497593403, -190.73766081035137, -190.00393788516521]","[100, 100, 100, 100, 100, 100, 99, 100, 100, 100, 100]",1.2782163796158317,2.326747967981566,0.22898460741317284,3.134211638452612,0.0
-116.67252637445927,-192.85324969142675,-154.39962305948137,97.3,10,0,3,0,0,10020,1792,10020,1792,1002,1792,10020,1792,10020,False,102,10,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-35-36,1675949736,5.076626777648926,44.739383935928345,27220,Daniel,192.168.152.36,44.739383935928345,0,10,8.03538990020752,10020,1792,10020,1792,116.67252637445927,-192.85324969142675,-154.39962305948137,97.3,10,0,"[-174.45449054986238, -185.60987342894077, 116.67252637445927, -188.42734596133232, -182.72036488354206, -184.69620841741562, -192.85324969142675, -185.26639138907194, -177.13239042460918, -189.50844222307205]","[100, 100, 73, 100, 100, 100, 100, 100, 100, 100]",1.2687550729993073,2.304896534791573,0.22676882362765344,3.106975455513903,0.0,110.046,10020,1792,10020,1792,58.837500000000006,82.1375,"[-174.45449054986238, -185.60987342894077, 116.67252637445927, -188.42734596133232, -182.72036488354206, -184.69620841741562, -192.85324969142675, -185.26639138907194, -177.13239042460918, -189.50844222307205]","[100, 100, 73, 100, 100, 100, 100, 100, 100, 100]",1.2687550729993073,2.304896534791573,0.22676882362765344,3.106975455513903,0.0
-216.8899323642254,-192.72066298127174,-145.74130786880852,91.8,10,0,3,0,0,11022,87296,11022,87296,1002,85504,11022,85504,11022,False,112,11,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-36-28,1675949788,51.98261213302612,96.72199606895447,27220,Daniel,192.168.152.36,96.72199606895447,0,11,8.03538990020752,11022,87296,11022,87296,216.8899323642254,-192.72066298127174,-145.74130786880852,91.8,10,0,"[-186.25547470152378, 216.8899323642254, -192.72066298127174, -188.17130488157272, -189.20812480151653, -184.5493537336588, -176.92795492708683, -189.55872742831707, -184.22501057386398, -182.686397023499]","[100, 18, 100, 100, 100, 100, 100, 100, 100, 100]",1.2638436207154984,2.3208301699891387,0.22811111138791457,3.0926660485819086,0.0,150.498,11022,87296,11022,87296,41.026760563380286,82.74647887323943,"[-186.25547470152378, 216.8899323642254, -192.72066298127174, -188.17130488157272, -189.20812480151653, -184.5493537336588, -176.92795492708683, -189.55872742831707, -184.22501057386398, -182.686397023499]","[100, 18, 100, 100, 100, 100, 100, 100, 100, 100]",1.2638436207154984,2.3208301699891387,0.22811111138791457,3.0926660485819086,0.0
-163.30143769085407,-189.49322356283665,-154.7683419138193,95.75,12,0,3,0,0,12024,172800,12024,172800,1002,85504,12024,85504,12024,False,124,12,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-37-20,1675949840,52.209973096847534,148.931969165802,27220,Daniel,192.168.152.36,148.931969165802,0,12,8.03538990020752,12024,172800,12024,172800,163.30143769085407,-189.49322356283665,-154.7683419138193,95.75,12,0,"[-187.0355889648199, -184.92422227561474, -180.11302310228348, -189.49322356283665, -188.7259154766798, 163.30143769085407, -171.60176420211792, -185.7771929204464, -185.78353460133076, -186.6463469490409, -184.1562127098441, -176.26451589167118]","[100, 100, 100, 100, 100, 49, 100, 100, 100, 100, 100, 100]",1.251722379268787,2.321900696570889,0.2274580644909021,3.0715565853129996,0.0,147.041,12024,172800,12024,172800,41.1263888888889,82.9236111111111,"[-187.0355889648199, -184.92422227561474, -180.11302310228348, -189.49322356283665, -188.7259154766798, 163.30143769085407, -171.60176420211792, -185.7771929204464, -185.78353460133076, -186.6463469490409, -184.1562127098441, -176.26451589167118]","[100, 100, 100, 100, 100, 49, 100, 100, 100, 100, 100, 100]",1.251722379268787,2.321900696570889,0.2274580644909021,3.0715565853129996,0.0
--171.10303102433681,-193.52067467570305,-185.084595805241,100.0,9,0,3,0,0,13026,258304,13026,258304,1002,85504,13026,85504,13026,False,133,13,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-38-17,1675949897,56.6564667224884,205.5884358882904,27220,Daniel,192.168.152.36,205.5884358882904,0,13,8.03538990020752,13026,258304,13026,258304,-171.10303102433681,-193.52067467570305,-185.084595805241,100.0,9,0,"[-190.27473078668118, -193.52067467570305, -189.55877432227135, -173.10080946981907, -171.10303102433681, -192.36377274990082, -188.57738538086414, -190.57767274975777, -176.68451108783484]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2485003268254837,2.3459321896802416,0.22930553259729874,3.0790619092943188,0.0,150.548,13026,258304,13026,258304,47.40886075949367,84.63417721518991,"[-190.27473078668118, -193.52067467570305, -189.55877432227135, -173.10080946981907, -171.10303102433681, -192.36377274990082, -188.57738538086414, -190.57767274975777, -176.68451108783484]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2485003268254837,2.3459321896802416,0.22930553259729874,3.0790619092943188,0.0
--167.73383703827858,-193.160078458488,-181.85733484476805,100.0,9,0,3,0,0,14028,343808,14028,343808,1002,85504,14028,85504,14028,False,142,14,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-39-18,1675949958,61.66024971008301,267.2486855983734,27220,Daniel,192.168.152.36,267.2486855983734,0,14,8.03538990020752,14028,343808,14028,343808,-167.73383703827858,-193.160078458488,-181.85733484476805,100.0,9,0,"[-191.58597734570503, -190.74350184202194, -167.73383703827858, -184.81242395937443, -172.80720306932926, -193.160078458488, -171.496223077178, -177.10790572315454, -187.26886308938265]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2571061467183018,2.3783673479538177,0.23117343083424405,3.096820011455652,0.0,158.074,14028,343808,14028,343808,52.06941176470589,87.08588235294118,"[-191.58597734570503, -190.74350184202194, -167.73383703827858, -184.81242395937443, -172.80720306932926, -193.160078458488, -171.496223077178, -177.10790572315454, -187.26886308938265]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2571061467183018,2.3783673479538177,0.23117343083424405,3.096820011455652,0.0
--167.4954197704792,-191.98499378561974,-184.26235711947083,100.0,12,0,3,0,0,15030,429312,15030,429312,1002,85504,15030,85504,15030,False,154,15,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-40-13,1675950013,55.12917709350586,322.3778626918793,27220,Daniel,192.168.152.36,322.3778626918793,0,15,8.03538990020752,15030,429312,15030,429312,-167.4954197704792,-191.98499378561974,-184.26235711947083,100.0,12,0,"[-168.570613399148, -191.98499378561974, -187.01995192468166, -186.29515251517296, -187.99071127176285, -190.23062424361706, -185.3246492445469, -167.4954197704792, -185.65701182186604, -189.5101600587368, -181.4457355439663, -189.62326185405254]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2540615208410804,2.3901244801516417,0.23206122611594004,3.0908723684125796,0.0,153.463,15030,429312,15030,429312,44.62894736842105,86.69868421052634,"[-168.570613399148, -191.98499378561974, -187.01995192468166, -186.29515251517296, -187.99071127176285, -190.23062424361706, -185.3246492445469, -167.4954197704792, -185.65701182186604, -189.5101600587368, -181.4457355439663, -189.62326185405254]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2540615208410804,2.3901244801516417,0.23206122611594004,3.0908723684125796,0.0
-239.49217422306538,-193.72556272149086,-115.78511388227344,90.5,10,0,3,0,0,16032,514816,16032,514816,1002,85504,16032,85504,16032,False,164,16,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-41-04,1675950064,50.25693893432617,372.63480162620544,27220,Daniel,192.168.152.36,372.63480162620544,0,16,8.03538990020752,16032,514816,16032,514816,239.49217422306538,-193.72556272149086,-115.78511388227344,90.5,10,0,"[-190.27600866556168, -186.49399116635323, -185.00045055150986, -192.42266704142094, 239.49217422306538, -167.23813240230083, -181.1968899667263, -187.67299080640078, 86.68338027596474, -193.72556272149086]","[100, 100, 100, 100, 6, 100, 100, 100, 99, 100]",1.2443106368504693,2.3827020468502207,0.23075704601348507,3.0683417003549516,0.0,148.121,16032,514816,16032,514816,38.28529411764706,85.86470588235292,"[-190.27600866556168, -186.49399116635323, -185.00045055150986, -192.42266704142094, 239.49217422306538, -167.23813240230083, -181.1968899667263, -187.67299080640078, 86.68338027596474, -193.72556272149086]","[100, 100, 100, 100, 6, 100, 100, 100, 99, 100]",1.2443106368504693,2.3827020468502207,0.23075704601348507,3.0683417003549516,0.0
-222.05110174417496,-190.09670834243298,-143.9502118192613,91.4,10,0,3,0,0,17034,600320,17034,600320,1002,85504,17034,85504,17034,False,174,17,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-41-57,1675950117,53.24273991584778,425.8775415420532,27220,Daniel,192.168.152.36,425.8775415420532,0,17,8.03538990020752,17034,600320,17034,600320,222.05110174417496,-190.09670834243298,-143.9502118192613,91.4,10,0,"[-189.53125815093517, -183.7729166597128, -170.50420750677586, -187.2069180160761, -187.8617040514946, -178.82971841096878, -190.09670834243298, -184.87761634588242, 222.05110174417496, -188.8721724525094]","[100, 100, 100, 100, 100, 100, 100, 100, 14, 100]",1.2345175609598698,2.378194616344282,0.2297615622903159,3.0489242083171155,0.0,179.179,17034,600320,17034,600320,41.40405405405406,86.22567567567567,"[-189.53125815093517, -183.7729166597128, -170.50420750677586, -187.2069180160761, -187.8617040514946, -178.82971841096878, -190.09670834243298, -184.87761634588242, 222.05110174417496, -188.8721724525094]","[100, 100, 100, 100, 100, 100, 100, 100, 14, 100]",1.2345175609598698,2.378194616344282,0.2297615622903159,3.0489242083171155,0.0
-245.30165177583694,-190.7907106205821,-151.49361454150997,92.53846153846153,13,0,3,0,0,18036,685824,18036,685824,1002,85504,18036,85504,18036,False,187,18,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-42-49,1675950169,51.91252279281616,477.7900643348694,27220,Daniel,192.168.152.36,477.7900643348694,0,18,8.03538990020752,18036,685824,18036,685824,245.30165177583694,-190.7907106205821,-151.49361454150997,92.53846153846153,13,0,"[-189.98709934949875, -186.22795210778713, -180.3633166104555, -171.97964797914028, 245.30165177583694, -185.072070825845, -190.7907106205821, -189.38212056457996, -189.09738334268332, -181.19575117528439, -190.57463803887367, -175.16957204043865, -184.87837816029787]","[100, 100, 100, 100, 3, 100, 100, 100, 100, 100, 100, 100, 100]",1.239852264521028,2.3967594590375136,0.2322289224160125,3.0544810132903852,0.0,152.151,18036,685824,18036,685824,39.63661971830986,86.65492957746481,"[-189.98709934949875, -186.22795210778713, -180.3633166104555, -171.97964797914028, 245.30165177583694, -185.072070825845, -190.7907106205821, -189.38212056457996, -189.09738334268332, -181.19575117528439, -190.57463803887367, -175.16957204043865, -184.87837816029787]","[100, 100, 100, 100, 3, 100, 100, 100, 100, 100, 100, 100, 100]",1.239852264521028,2.3967594590375136,0.2322289224160125,3.0544810132903852,0.0
--165.1230638846755,-194.33256532251835,-181.8145749858684,100.0,9,0,3,0,0,19038,771328,19038,771328,1002,85504,19038,85504,19038,False,196,19,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-43-41,1675950221,52.18798112869263,529.978045463562,27220,Daniel,192.168.152.36,529.978045463562,0,19,8.03538990020752,19038,771328,19038,771328,-165.1230638846755,-194.33256532251835,-181.8145749858684,100.0,9,0,"[-174.89069928228855, -172.24453258514404, -183.67306399345398, -184.5737228691578, -194.33256532251835, -183.55377605557442, -191.13914181292057, -186.8006090670824, -165.1230638846755]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2281198573208902,2.3886849165125543,0.23054858728038882,3.03391563586218,0.0,153.136,19038,771328,19038,771328,39.94444444444444,86.58749999999999,"[-174.89069928228855, -172.24453258514404, -183.67306399345398, -184.5737228691578, -194.33256532251835, -183.55377605557442, -191.13914181292057, -186.8006090670824, -165.1230638846755]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2281198573208902,2.3886849165125543,0.23054858728038882,3.03391563586218,0.0
--162.97039559483528,-192.73386228084564,-180.43006274104118,100.0,9,0,3,0,0,20040,856832,20040,856832,1002,85504,20040,85504,20040,False,205,20,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-44-33,1675950273,51.79817724227905,581.7762227058411,27220,Daniel,192.168.152.36,581.7762227058411,0,20,8.03538990020752,20040,856832,20040,856832,-162.97039559483528,-192.73386228084564,-180.43006274104118,100.0,9,0,"[-185.02881395816803, -186.0774904191494, -183.38704292476177, -192.73386228084564, -185.16548888385296, -162.97039559483528, -185.83342100679874, -171.34927606582642, -171.3247735351324]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2231326439848964,2.386453081163432,0.2300773309042358,3.0260792405687518,0.0,152.251,20040,856832,20040,856832,38.9,86.6450704225352,"[-185.02881395816803, -186.0774904191494, -183.38704292476177, -192.73386228084564, -185.16548888385296, -162.97039559483528, -185.83342100679874, -171.34927606582642, -171.3247735351324]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2231326439848964,2.386453081163432,0.2300773309042358,3.0260792405687518,0.0
--167.6864303201437,-193.03460130095482,-179.939817359671,100.0,12,0,3,0,0,21042,942336,21042,942336,1002,85504,21042,85504,21042,False,217,21,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-45-25,1675950325,52.11804485321045,633.8942675590515,27220,Daniel,192.168.152.36,633.8942675590515,0,21,8.03538990020752,21042,942336,21042,942336,-167.6864303201437,-193.03460130095482,-179.939817359671,100.0,12,0,"[-179.2956598252058, -193.03460130095482, -188.71201647818089, -167.6864303201437, -174.62564761936665, -187.33417315781116, -191.16441805660725, -167.98305432498455, -187.39179661870003, -175.97241815179586, -174.4930499047041, -171.58454255759716]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.218624244140712,2.386070651604745,0.22939708969830386,3.020549619189348,0.0,156.891,21042,942336,21042,942336,39.804225352112674,87.39999999999999,"[-179.2956598252058, -193.03460130095482, -188.71201647818089, -167.6864303201437, -174.62564761936665, -187.33417315781116, -191.16441805660725, -167.98305432498455, -187.39179661870003, -175.97241815179586, -174.4930499047041, -171.58454255759716]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.218624244140712,2.386070651604745,0.22939708969830386,3.020549619189348,0.0
-240.51233860850334,-192.8343891054392,-143.5046384178102,90.6,10,0,3,0,0,22044,1027840,22044,1027840,1002,85504,22044,85504,22044,False,227,22,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-46-18,1675950378,52.17977786064148,686.074045419693,27220,Daniel,192.168.152.36,686.074045419693,0,22,8.03538990020752,22044,1027840,22044,1027840,240.51233860850334,-192.8343891054392,-143.5046384178102,90.6,10,0,"[-190.34558657556772, -189.03799837827682, -182.9403861016035, -192.8343891054392, -182.12118066847324, -182.52771258354187, -183.80604764819145, -181.47512324154377, 240.51233860850334, -190.47029848396778]","[100, 100, 100, 100, 100, 100, 100, 100, 6, 100]",1.2070074878204178,2.376503135934462,0.22752439104662345,3.0037685581933466,0.0,158.137,22044,1027840,22044,1027840,39.729577464788726,87.57042253521126,"[-190.34558657556772, -189.03799837827682, -182.9403861016035, -192.8343891054392, -182.12118066847324, -182.52771258354187, -183.80604764819145, -181.47512324154377, 240.51233860850334, -190.47029848396778]","[100, 100, 100, 100, 100, 100, 100, 100, 6, 100]",1.2070074878204178,2.376503135934462,0.22752439104662345,3.0037685581933466,0.0
--180.80819918960333,-189.49578461796045,-185.28221337000528,100.0,9,0,3,0,0,23046,1113344,23046,1113344,1002,85504,23046,85504,23046,False,236,23,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-47-10,1675950430,52.58064889907837,738.6546943187714,27220,Daniel,192.168.152.36,738.6546943187714,0,23,8.03538990020752,23046,1113344,23046,1113344,-180.80819918960333,-189.49578461796045,-185.28221337000528,100.0,9,0,"[-185.17319969832897, -189.49578461796045, -185.4290170520544, -184.17229868471622, -180.80819918960333, -185.28492912650108, -182.13111406564713, -186.03017409145832, -189.0152038037777]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2112649290094852,2.387282563795045,0.228742057627838,3.012530451674509,0.0,165.749,23046,1113344,23046,1113344,39.96666666666667,88.01249999999999,"[-185.17319969832897, -189.49578461796045, -185.4290170520544, -184.17229868471622, -180.80819918960333, -185.28492912650108, -182.13111406564713, -186.03017409145832, -189.0152038037777]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2112649290094852,2.387282563795045,0.228742057627838,3.012530451674509,0.0
--167.0836452692747,-192.73049069941044,-181.414447566325,100.0,11,0,3,0,0,24048,1198848,24048,1198848,1002,85504,24048,85504,24048,False,247,24,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-48-03,1675950483,53.02470254898071,791.6793968677521,27220,Daniel,192.168.152.36,791.6793968677521,0,24,8.03538990020752,24048,1198848,24048,1198848,-167.0836452692747,-192.73049069941044,-181.414447566325,100.0,11,0,"[-175.82527719438076, -184.22177052497864, -187.69586757570505, -172.4897821843624, -192.73049069941044, -167.0836452692747, -188.32941034436226, -167.21700128912926, -184.5859683305025, -191.19055130332708, -184.18915851414204]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2163927521911584,2.3985208746908047,0.23055632720791194,3.020841886882943,0.0,153.057,24048,1198848,24048,1198848,40.81232876712329,85.16986301369863,"[-175.82527719438076, -184.22177052497864, -187.69586757570505, -172.4897821843624, -192.73049069941044, -167.0836452692747, -188.32941034436226, -167.21700128912926, -184.5859683305025, -191.19055130332708, -184.18915851414204]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2163927521911584,2.3985208746908047,0.23055632720791194,3.020841886882943,0.0
--165.90026652812958,-193.58011861145496,-183.67756756171585,100.0,10,0,3,0,0,25050,1284352,25050,1284352,1002,85504,25050,85504,25050,False,257,25,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-48-55,1675950535,51.68060851097107,843.3600053787231,27220,Daniel,192.168.152.36,843.3600053787231,0,25,8.03538990020752,25050,1284352,25050,1284352,-165.90026652812958,-193.58011861145496,-183.67756756171585,100.0,10,0,"[-190.5865334123373, -193.58011861145496, -176.13220999389887, -165.90026652812958, -189.8196080327034, -187.95404055714607, -186.96187537908554, -189.27582755684853, -167.71022468805313, -188.85497085750103]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.196401868090917,2.37448568073465,0.2272829211781716,2.9915450476069836,0.0,164.173,25050,1284352,25050,1284352,39.101408450704234,84.95633802816903,"[-190.5865334123373, -193.58011861145496, -176.13220999389887, -165.90026652812958, -189.8196080327034, -187.95404055714607, -186.96187537908554, -189.27582755684853, -167.71022468805313, -188.85497085750103]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.196401868090917,2.37448568073465,0.2272829211781716,2.9915450476069836,0.0
-104.79555989056826,-196.84813330322504,-155.78133221939206,98.9,10,0,3,0,0,26052,1369856,26052,1369856,1002,85504,26052,85504,26052,False,267,26,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-49-48,1675950588,52.71587014198303,896.0758755207062,27220,Daniel,192.168.152.36,896.0758755207062,0,26,8.03538990020752,26052,1369856,26052,1369856,104.79555989056826,-196.84813330322504,-155.78133221939206,98.9,10,0,"[-189.5461689978838, -181.7891598045826, -170.71410140395164, -186.50357760488987, 104.79555989056826, -184.66212909668684, -187.025663793087, -184.1057424992323, -196.84813330322504, -181.41420558094978]","[100, 100, 100, 100, 89, 100, 100, 100, 100, 100]",1.201522469726457,2.3861516640662597,0.22841283351303038,3.0006745140238196,0.0,154.707,26052,1369856,26052,1369856,40.63333333333334,85.14583333333331,"[-189.5461689978838, -181.7891598045826, -170.71410140395164, -186.50357760488987, 104.79555989056826, -184.66212909668684, -187.025663793087, -184.1057424992323, -196.84813330322504, -181.41420558094978]","[100, 100, 100, 100, 89, 100, 100, 100, 100, 100]",1.201522469726457,2.3861516640662597,0.22841283351303038,3.0006745140238196,0.0
-235.7953718304634,-194.87835419923067,-148.95618642059466,92.41666666666667,12,0,3,0,0,27054,1455360,27054,1455360,1002,85504,27054,85504,27054,False,279,27,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-50-40,1675950640,52.54960870742798,948.6254842281342,27220,Daniel,192.168.152.36,948.6254842281342,0,27,8.03538990020752,27054,1455360,27054,1455360,235.7953718304634,-194.87835419923067,-148.95618642059466,92.41666666666667,12,0,"[-179.7902166247368, -184.14923545718193, -177.52521464973688, -184.4634026736021, -194.87835419923067, -185.0952292829752, -182.19644275307655, 235.7953718304634, -183.53830267488956, -189.59883634746075, -187.72424747794867, -174.31012673676014]","[100, 100, 100, 100, 100, 100, 100, 9, 100, 100, 100, 100]",1.2006379770510929,2.387234433005618,0.22830351425494042,2.9964881350928283,0.0,174.477,27054,1455360,27054,1455360,39.520833333333336,85.50972222222221,"[-179.7902166247368, -184.14923545718193, -177.52521464973688, -184.4634026736021, -194.87835419923067, -185.0952292829752, -182.19644275307655, 235.7953718304634, -183.53830267488956, -189.59883634746075, -187.72424747794867, -174.31012673676014]","[100, 100, 100, 100, 100, 100, 100, 9, 100, 100, 100, 100]",1.2006379770510929,2.387234433005618,0.22830351425494042,2.9964881350928283,0.0
--174.9978152513504,-191.81628845632076,-184.93254377030664,100.0,9,0,3,0,0,28056,1540864,28056,1540864,1002,85504,28056,85504,28056,False,288,28,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-51-33,1675950693,52.111942529678345,1000.7374267578125,27220,Daniel,192.168.152.36,1000.7374267578125,0,28,8.03538990020752,28056,1540864,28056,1540864,-174.9978152513504,-191.81628845632076,-184.93254377030664,100.0,9,0,"[-182.1208277195692, -181.4783052355051, -189.16457533091307, -188.128092110157, -184.45729556679726, -174.9978152513504, -191.81628845632076, -183.39122223854065, -188.8384720236063]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1983537135237556,2.3881018750194034,0.22789582186871268,2.993765507460176,0.0,155.265,28056,1540864,28056,1540864,40.079166666666666,85.79305555555555,"[-182.1208277195692, -181.4783052355051, -189.16457533091307, -188.128092110157, -184.45729556679726, -174.9978152513504, -191.81628845632076, -183.39122223854065, -188.8384720236063]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1983537135237556,2.3881018750194034,0.22789582186871268,2.993765507460176,0.0
--165.28807239234447,-186.11187045276165,-179.79279124902354,100.0,9,0,3,0,0,29058,1626368,29058,1626368,1002,85504,29058,85504,29058,False,297,29,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-52-24,1675950744,51.92955803871155,1052.666984796524,27220,Daniel,192.168.152.36,1052.666984796524,0,29,8.03538990020752,29058,1626368,29058,1626368,-165.28807239234447,-186.11187045276165,-179.79279124902354,100.0,9,0,"[-165.28807239234447, -183.26285406947136, -185.33110982179642, -171.89848959445953, -182.58071744441986, -174.39229675382376, -184.68148090690374, -184.5882298052311, -186.11187045276165]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1955892172943008,2.3876602161300227,0.22757435274864152,2.9902814986073163,0.0,152.676,29058,1626368,29058,1626368,38.74857142857144,85.87285714285714,"[-165.28807239234447, -183.26285406947136, -185.33110982179642, -171.89848959445953, -182.58071744441986, -174.39229675382376, -184.68148090690374, -184.5882298052311, -186.11187045276165]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1955892172943008,2.3876602161300227,0.22757435274864152,2.9902814986073163,0.0
--171.31990517675877,-191.378743365407,-181.32259718639156,100.0,12,0,3,0,0,30060,1711872,30060,1711872,1002,85504,30060,85504,30060,False,309,30,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-53-16,1675950796,51.66289401054382,1104.3298788070679,27220,Daniel,192.168.152.36,1104.3298788070679,0,30,8.03538990020752,30060,1711872,30060,1711872,-171.31990517675877,-191.378743365407,-181.32259718639156,100.0,12,0,"[-171.31990517675877, -178.29683908075094, -185.04229144752026, -181.9416538849473, -191.378743365407, -176.74997402727604, -183.82910177111626, -184.22023870795965, -184.56751142442226, -180.58851619809866, -186.21546549350023, -171.72092565894127]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1928832622574135,2.3861331338238165,0.22721143078630338,2.985315654693604,0.0,150.817,30060,1711872,30060,1711872,39.05070422535212,85.91408450704229,"[-171.31990517675877, -178.29683908075094, -185.04229144752026, -181.9416538849473, -191.378743365407, -176.74997402727604, -183.82910177111626, -184.22023870795965, -184.56751142442226, -180.58851619809866, -186.21546549350023, -171.72092565894127]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1928832622574135,2.3861331338238165,0.22721143078630338,2.985315654693604,0.0
--170.7668997272849,-190.305157661438,-181.9360129882892,100.0,9,0,3,0,0,31062,1797376,31062,1797376,1002,85504,31062,85504,31062,False,318,31,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-54-08,1675950848,51.94841027259827,1156.2782890796661,27220,Daniel,192.168.152.36,1156.2782890796661,0,31,8.03538990020752,31062,1797376,31062,1797376,-170.7668997272849,-190.305157661438,-181.9360129882892,100.0,9,0,"[-170.7668997272849, -190.305157661438, -179.89977310597897, -188.1753682643175, -184.18184988200665, -173.57543017715216, -188.62158800661564, -184.76127146184444, -177.13677860796452]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1903425278380435,2.385300015090803,0.22709432209284433,2.982719328674778,0.0,151.28,31062,1797376,31062,1797376,39.06619718309858,86.00845070422534,"[-170.7668997272849, -190.305157661438, -179.89977310597897, -188.1753682643175, -184.18184988200665, -173.57543017715216, -188.62158800661564, -184.76127146184444, -177.13677860796452]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1903425278380435,2.385300015090803,0.22709432209284433,2.982719328674778,0.0
--164.80321660637856,-187.43193179368973,-182.1963997989893,100.0,10,0,3,0,0,32064,1882880,32064,1882880,1002,85504,32064,85504,32064,False,328,32,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-55-02,1675950902,53.40508961677551,1209.6833786964417,27220,Daniel,192.168.152.36,1209.6833786964417,0,32,8.03538990020752,32064,1882880,32064,1882880,-164.80321660637856,-187.43193179368973,-182.1963997989893,100.0,10,0,"[-183.12496840953827, -182.12688202410936, -186.79230985045433, -164.80321660637856, -185.30594304203987, -187.1081513389945, -187.43193179368973, -184.00115877389908, -182.56623475253582, -178.70320139825344]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1881879096682941,2.384701148978965,0.22696769095881303,2.9804390957161666,0.0,156.982,32064,1882880,32064,1882880,41.141891891891895,86.18648648648649,"[-183.12496840953827, -182.12688202410936, -186.79230985045433, -164.80321660637856, -185.30594304203987, -187.1081513389945, -187.43193179368973, -184.00115877389908, -182.56623475253582, -178.70320139825344]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1881879096682941,2.384701148978965,0.22696769095881303,2.9804390957161666,0.0
-153.87228658795357,-190.63950316607952,-153.11610210551456,96.0,11,0,3,0,0,33066,1968384,33066,1968384,1002,85504,33066,85504,33066,False,339,33,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-55-54,1675950954,52.189106941223145,1261.8724856376648,27220,Daniel,192.168.152.36,1261.8724856376648,0,33,8.03538990020752,33066,1968384,33066,1968384,153.87228658795357,-190.63950316607952,-153.11610210551456,96.0,11,0,"[-187.40898069739342, -174.2771219164133, -190.63950316607952, -181.0851944386959, -185.4829898774624, -184.66287402808666, -185.1458716392517, -187.64949890226126, -182.7697090804577, 153.87228658795357, -179.02766600251198]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 56, 100]",1.1883810116213538,2.3876240459653335,0.22735068186804572,2.9812074931202925,0.0,161.289,33066,1968384,33066,1968384,39.38194444444444,86.125,"[-187.40898069739342, -174.2771219164133, -190.63950316607952, -181.0851944386959, -185.4829898774624, -184.66287402808666, -185.1458716392517, -187.64949890226126, -182.7697090804577, 153.87228658795357, -179.02766600251198]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 56, 100]",1.1883810116213538,2.3876240459653335,0.22735068186804572,2.9812074931202925,0.0
--168.78121964633465,-185.78847029060125,-181.12046305007405,100.0,9,0,3,0,0,34068,2053888,34068,2053888,1002,85504,34068,85504,34068,False,348,34,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-56-50,1675951010,55.86729431152344,1317.7397799491882,27220,Daniel,192.168.152.36,1317.7397799491882,0,34,8.03538990020752,34068,2053888,34068,2053888,-168.78121964633465,-185.78847029060125,-181.12046305007405,100.0,9,0,"[-183.19660459458828, -184.6687048599124, -185.1236521154642, -171.8001147210598, -183.45194736123085, -183.7468140721321, -185.78847029060125, -168.78121964633465, -183.52663978934288]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1891045844263446,2.390704021032316,0.2275375570991581,2.9852456347578684,0.0,152.01,34068,2053888,34068,2053888,51.04805194805194,86.30519480519479,"[-183.19660459458828, -184.6687048599124, -185.1236521154642, -171.8001147210598, -183.45194736123085, -183.7468140721321, -185.78847029060125, -168.78121964633465, -183.52663978934288]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1891045844263446,2.390704021032316,0.2275375570991581,2.9852456347578684,0.0
-138.08201134204865,-187.7539255991578,-129.5451263921956,95.25,12,0,3,0,0,35070,2139392,35070,2139392,1002,85504,35070,85504,35070,False,360,35,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-57-43,1675951063,52.851844787597656,1370.591624736786,27220,Daniel,192.168.152.36,1370.591624736786,0,35,8.03538990020752,35070,2139392,35070,2139392,138.08201134204865,-187.7539255991578,-129.5451263921956,95.25,12,0,"[117.21727380901575, 138.08201134204865, -187.7539255991578, -181.55882640182972, -183.39881467819214, -186.3256485313177, -182.53403153270483, -173.93451785296202, -183.73162057995796, -174.1911989748478, -181.75915682315826, -174.65306088328362]","[80, 63, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1874720697661543,2.3906589305537143,0.22707527120836724,2.9826807179748864,0.0,158.663,35070,2139392,35070,2139392,39.04657534246576,86.82465753424658,"[117.21727380901575, 138.08201134204865, -187.7539255991578, -181.55882640182972, -183.39881467819214, -186.3256485313177, -182.53403153270483, -173.93451785296202, -183.73162057995796, -174.1911989748478, -181.75915682315826, -174.65306088328362]","[80, 63, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1874720697661543,2.3906589305537143,0.22707527120836724,2.9826807179748864,0.0
--168.14107708632946,-182.89673117548227,-177.47968737118774,100.0,9,0,3,0,0,36072,2224896,36072,2224896,1002,85504,36072,85504,36072,False,369,36,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-58-35,1675951115,52.450255393981934,1423.0418801307678,27220,Daniel,192.168.152.36,1423.0418801307678,0,36,8.03538990020752,36072,2224896,36072,2224896,-168.14107708632946,-182.89673117548227,-177.47968737118774,100.0,9,0,"[-182.89673117548227, -180.76931977272034, -180.18828734010458, -182.54403713345528, -174.68762480467558, -172.4507051408291, -174.89911195635796, -180.7402919307351, -168.14107708632946]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1854629159717203,2.389867634551854,0.22681519791886615,2.9796439281207197,0.0,153.144,36072,2224896,36072,2224896,39.722535211267605,86.9507042253521,"[-182.89673117548227, -180.76931977272034, -180.18828734010458, -182.54403713345528, -174.68762480467558, -172.4507051408291, -174.89911195635796, -180.7402919307351, -168.14107708632946]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1854629159717203,2.389867634551854,0.22681519791886615,2.9796439281207197,0.0
--169.104292050004,-186.18423768877983,-179.24181281104683,100.0,10,0,3,0,0,37074,2310400,37074,2310400,1002,85504,37074,85504,37074,False,379,37,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_14-59-28,1675951168,52.780232429504395,1475.8221125602722,27220,Daniel,192.168.152.36,1475.8221125602722,0,37,8.03538990020752,37074,2310400,37074,2310400,-169.104292050004,-186.18423768877983,-179.24181281104683,100.0,10,0,"[-170.27307602763176, -186.18423768877983, -180.45594291388988, -177.72986532747746, -183.33996964991093, -185.95709364116192, -184.1188800856471, -184.27896517515182, -169.104292050004, -170.97580555081367]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1950584819511898,2.404987818794118,0.2284700309721935,2.997615144653839,0.0,165.181,37074,2310400,37074,2310400,39.94657534246575,87.16164383561645,"[-170.27307602763176, -186.18423768877983, -180.45594291388988, -177.72986532747746, -183.33996964991093, -185.95709364116192, -184.1188800856471, -184.27896517515182, -169.104292050004, -170.97580555081367]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1950584819511898,2.404987818794118,0.2284700309721935,2.997615144653839,0.0
--167.79456190764904,-187.31731226295233,-180.16447783667934,100.0,11,0,3,0,0,38076,2395904,38076,2395904,1002,85504,38076,85504,38076,False,390,38,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-00-21,1675951221,52.70646548271179,1528.528578042984,27220,Daniel,192.168.152.36,1528.528578042984,0,38,8.03538990020752,38076,2395904,38076,2395904,-167.79456190764904,-187.31731226295233,-180.16447783667934,100.0,11,0,"[-176.87502232193947, -180.9338716417551, -186.6096629947424, -180.62424564361572, -187.31731226295233, -186.28135040402412, -182.3141679316759, -175.285037368536, -167.79456190764904, -176.8871919736266, -180.8868317529559]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1740423125345325,2.3758274100308228,0.2249584694701285,2.963985615089851,0.0,165.954,38076,2395904,38076,2395904,40.26986301369863,87.39863013698628,"[-176.87502232193947, -180.9338716417551, -186.6096629947424, -180.62424564361572, -187.31731226295233, -186.28135040402412, -182.3141679316759, -175.285037368536, -167.79456190764904, -176.8871919736266, -180.8868317529559]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1740423125345325,2.3758274100308228,0.2249584694701285,2.963985615089851,0.0
-192.6706669330597,-188.9914527386427,-141.5072754085064,93.3,10,0,3,0,0,39078,2481408,39078,2481408,1002,85504,39078,85504,39078,False,400,39,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-01-14,1675951274,52.93822193145752,1581.4667999744415,27220,Daniel,192.168.152.36,1581.4667999744415,0,39,8.03538990020752,39078,2481408,39078,2481408,192.6706669330597,-188.9914527386427,-141.5072754085064,93.3,10,0,"[-174.1753051429987, -182.44336192309856, 192.6706669330597, -168.0125610306859, -188.9914527386427, -180.85813285410404, -183.84055003523827, -173.8211519420147, -179.11471580713987, -176.4861895442009]","[100, 100, 33, 100, 100, 100, 100, 100, 100, 100]",1.1934070637671388,2.404424186458223,0.22896348977112724,2.9971746488040996,0.0,189.773,39078,2481408,39078,2481408,39.670833333333334,87.56944444444444,"[-174.1753051429987, -182.44336192309856, 192.6706669330597, -168.0125610306859, -188.9914527386427, -180.85813285410404, -183.84055003523827, -173.8211519420147, -179.11471580713987, -176.4861895442009]","[100, 100, 33, 100, 100, 100, 100, 100, 100, 100]",1.1934070637671388,2.404424186458223,0.22896348977112724,2.9971746488040996,0.0
--168.3656321167946,-184.26397243887186,-177.43997548686133,100.0,9,0,3,0,0,40080,2566912,40080,2566912,1002,85504,40080,85504,40080,False,409,40,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-02-07,1675951327,53.56896924972534,1635.0357692241669,27220,Daniel,192.168.152.36,1635.0357692241669,0,40,8.03538990020752,40080,2566912,40080,2566912,-168.3656321167946,-184.26397243887186,-177.43997548686133,100.0,9,0,"[-181.22941114008427, -182.0724149569869, -174.7681783437729, -168.3656321167946, -180.22953482717276, -171.86355243623257, -174.27145668119192, -179.89562644064426, -184.26397243887186]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1817531201682596,2.389162917891725,0.22715000449232636,2.9810903921927463,0.0,156.589,40080,2566912,40080,2566912,40.58243243243243,87.7445945945946,"[-181.22941114008427, -182.0724149569869, -174.7681783437729, -168.3656321167946, -180.22953482717276, -171.86355243623257, -174.27145668119192, -179.89562644064426, -184.26397243887186]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1817531201682596,2.389162917891725,0.22715000449232636,2.9810903921927463,0.0
--163.83987384289503,-187.10371681302786,-178.45808702955642,100.0,12,0,3,0,0,41082,2652416,41082,2652416,1002,85504,41082,85504,41082,False,421,41,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-03-01,1675951381,53.288047552108765,1688.3238167762756,27220,Daniel,192.168.152.36,1688.3238167762756,0,41,8.03538990020752,41082,2652416,41082,2652416,-163.83987384289503,-187.10371681302786,-178.45808702955642,100.0,12,0,"[-178.34522638469934, -183.75319823622704, -185.9970791861415, -177.59257932007313, -187.10371681302786, -185.4290682822466, -182.764564730227, -173.81865569204092, -179.22336603701115, -168.72168152034283, -163.83987384289503, -174.90803430974483]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.180918489158828,2.3901687191251395,0.22722392588821191,2.9826144805365966,0.0,177.233,41082,2652416,41082,2652416,40.98918918918919,88.09864864864863,"[-178.34522638469934, -183.75319823622704, -185.9970791861415, -177.59257932007313, -187.10371681302786, -185.4290682822466, -182.764564730227, -173.81865569204092, -179.22336603701115, -168.72168152034283, -163.83987384289503, -174.90803430974483]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.180918489158828,2.3901687191251395,0.22722392588821191,2.9826144805365966,0.0
-180.91379027813673,-187.11290511488914,-116.10810863152146,93.2,10,0,3,0,0,42084,2737920,42084,2737920,1002,85504,42084,85504,42084,False,431,42,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-03-54,1675951434,53.3751220703125,1741.6989388465881,27220,Daniel,192.168.152.36,1741.6989388465881,0,42,8.03538990020752,42084,2737920,42084,2737920,180.91379027813673,-187.11290511488914,-116.10810863152146,93.2,10,0,"[-180.63632839918137, 180.91379027813673, -182.74909734725952, -186.68236726522446, -166.189367569983, -184.58452029526234, 96.62216354161501, -178.2939925789833, -172.36846156418324, -187.11290511488914]","[100, 41, 100, 100, 100, 100, 91, 100, 100, 100]",1.191112938895264,2.4060518762511136,0.22949094620746185,2.999420322026927,0.0,156.819,42084,2737920,42084,2737920,40.37534246575343,88.15890410958905,"[-180.63632839918137, 180.91379027813673, -182.74909734725952, -186.68236726522446, -166.189367569983, -184.58452029526234, 96.62216354161501, -178.2939925789833, -172.36846156418324, -187.11290511488914]","[100, 41, 100, 100, 100, 100, 91, 100, 100, 100]",1.191112938895264,2.4060518762511136,0.22949094620746185,2.999420322026927,0.0
--168.88876070827246,-187.7259635925293,-177.95538324366012,100.0,9,0,3,0,0,43086,2823424,43086,2823424,1002,85504,43086,85504,43086,False,440,43,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-04-47,1675951487,52.78848600387573,1794.4874248504639,27220,Daniel,192.168.152.36,1794.4874248504639,0,43,8.03538990020752,43086,2823424,43086,2823424,-168.88876070827246,-187.7259635925293,-177.95538324366012,100.0,9,0,"[-172.41410469263792, -187.7259635925293, -185.0848912000656, -169.18732691556215, -178.81310380995274, -178.75061001628637, -181.12918283045292, -179.60450542718172, -168.88876070827246]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1787363645656328,2.3891664867670697,0.2274294961239977,2.9815346242579803,0.0,158.221,43086,2823424,43086,2823424,40.00000000000001,88.40684931506848,"[-172.41410469263792, -187.7259635925293, -185.0848912000656, -169.18732691556215, -178.81310380995274, -178.75061001628637, -181.12918283045292, -179.60450542718172, -168.88876070827246]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1787363645656328,2.3891664867670697,0.2274294961239977,2.9815346242579803,0.0
-246.4839284569025,-184.4967777505517,-114.73694654554129,89.08333333333333,12,0,3,0,0,44088,2908928,44088,2908928,1002,85504,44088,85504,44088,False,452,44,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-05-39,1675951539,51.63157558441162,1846.1190004348755,27220,Daniel,192.168.152.36,1846.1190004348755,0,44,8.03538990020752,44088,2908928,44088,2908928,246.4839284569025,-184.4967777505517,-114.73694654554129,89.08333333333333,12,0,"[-167.30752436816692, -176.83662459999323, -184.4967777505517, -178.40541774779558, -173.2690906599164, -172.38881369680166, 140.20121035724878, -169.0239269733429, -181.60337759554386, -182.68479396402836, -177.5121500045061, 246.4839284569025]","[100, 100, 100, 100, 100, 100, 67, 100, 100, 100, 100, 2]",1.1598800450799327,2.363374713911461,0.22409406793798592,2.9512557957767265,0.0,156.148,44088,2908928,44088,2908928,38.8549295774648,88.67464788732394,"[-167.30752436816692, -176.83662459999323, -184.4967777505517, -178.40541774779558, -173.2690906599164, -172.38881369680166, 140.20121035724878, -169.0239269733429, -181.60337759554386, -182.68479396402836, -177.5121500045061, 246.4839284569025]","[100, 100, 100, 100, 100, 100, 67, 100, 100, 100, 100, 2]",1.1598800450799327,2.363374713911461,0.22409406793798592,2.9512557957767265,0.0
--164.93139814585447,-184.66212997585535,-173.97430018931627,100.0,10,0,3,0,0,45090,2994432,45090,2994432,1002,85504,45090,85504,45090,False,462,45,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-06-31,1675951591,52.04433584213257,1898.163336277008,27220,Daniel,192.168.152.36,1898.163336277008,0,45,8.03538990020752,45090,2994432,45090,2994432,-164.93139814585447,-184.66212997585535,-173.97430018931627,100.0,10,0,"[-175.16701660305262, -171.22391971945763, -180.22801702469587, -164.93139814585447, -175.00142758339643, -174.2958224490285, -174.6481312662363, -173.2648135572672, -184.66212997585535, -166.32032556831837]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.187749493027723,2.403977553166043,0.229260214201015,2.998773847525011,0.0,152.399,45090,2994432,45090,2994432,39.16197183098592,89.17464788732397,"[-175.16701660305262, -171.22391971945763, -180.22801702469587, -164.93139814585447, -175.00142758339643, -174.2958224490285, -174.6481312662363, -173.2648135572672, -184.66212997585535, -166.32032556831837]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.187749493027723,2.403977553166043,0.229260214201015,2.998773847525011,0.0
--159.62204612791538,-188.7975147664547,-173.51912591867148,100.0,10,0,3,0,0,46092,3079936,46092,3079936,1002,85504,46092,85504,46092,False,472,46,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-07-22,1675951642,51.68443274497986,1949.847769021988,27220,Daniel,192.168.152.36,1949.847769021988,0,46,8.03538990020752,46092,3079936,46092,3079936,-159.62204612791538,-188.7975147664547,-173.51912591867148,100.0,10,0,"[-184.3933058977127, -159.85871002078056, -182.05973440408707, -174.52376528084278, -177.9114715717733, -188.7975147664547, -177.67379681766033, -163.71339911222458, -166.6375151872635, -159.62204612791538]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1734883792230448,2.3844269188614957,0.22661155727993498,2.977860643465667,0.0,154.273,46092,3079936,46092,3079936,38.12857142857142,89.73714285714283,"[-184.3933058977127, -159.85871002078056, -182.05973440408707, -174.52376528084278, -177.9114715717733, -188.7975147664547, -177.67379681766033, -163.71339911222458, -166.6375151872635, -159.62204612791538]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1734883792230448,2.3844269188614957,0.22661155727993498,2.977860643465667,0.0
--156.76976097002625,-182.86714262515306,-168.8070443738252,100.0,10,0,3,0,0,47094,3165440,47094,3165440,1002,85504,47094,85504,47094,False,482,47,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-08-15,1675951695,52.2833309173584,2002.1310999393463,27220,Daniel,192.168.152.36,2002.1310999393463,0,47,8.03538990020752,47094,3165440,47094,3165440,-156.76976097002625,-182.86714262515306,-168.8070443738252,100.0,10,0,"[-160.15382880717516, -166.3982791826129, -180.81407899409533, -182.86714262515306, -156.76976097002625, -163.0765529051423, -168.91380199044943, -167.2463010251522, -170.40086115896702, -171.42983607947826]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1631953912947963,2.3701897122478917,0.22504626128983213,2.9598141044589,0.0,156.113,47094,3165440,47094,3165440,39.10277777777778,89.8138888888889,"[-160.15382880717516, -166.3982791826129, -180.81407899409533, -182.86714262515306, -156.76976097002625, -163.0765529051423, -168.91380199044943, -167.2463010251522, -170.40086115896702, -171.42983607947826]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1631953912947963,2.3701897122478917,0.22504626128983213,2.9598141044589,0.0
-134.60009190440178,-187.80273082852364,-146.0879253826358,97.63636363636364,11,0,3,0,0,48096,3250944,48096,3250944,1002,85504,48096,85504,48096,False,493,48,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-09-07,1675951747,52.59737300872803,2054.7284729480743,27220,Daniel,192.168.152.36,2054.7284729480743,0,48,8.03538990020752,48096,3250944,48096,3250944,134.60009190440178,-187.80273082852364,-146.0879253826358,97.63636363636364,11,0,"[-156.90459544211626, -172.33873042464256, -177.08846881985664, -174.41388424485922, -166.60171175003052, -168.72993633896112, 134.60009190440178, -187.80273082852364, -179.12906210124493, -171.90995248407125, -186.64819867908955]","[100, 100, 100, 100, 100, 100, 74, 100, 100, 100, 100]",1.181873496777882,2.3961599049570044,0.2283518083855446,2.9955742633765268,0.0,152.22,48096,3250944,48096,3250944,39.9986111111111,89.19166666666666,"[-156.90459544211626, -172.33873042464256, -177.08846881985664, -174.41388424485922, -166.60171175003052, -168.72993633896112, 134.60009190440178, -187.80273082852364, -179.12906210124493, -171.90995248407125, -186.64819867908955]","[100, 100, 100, 100, 100, 100, 74, 100, 100, 100, 100]",1.181873496777882,2.3961599049570044,0.2283518083855446,2.9955742633765268,0.0
--157.72101052105427,-187.16704893112183,-171.52214821014138,100.0,9,0,3,0,0,49098,3336448,49098,3336448,1002,85504,49098,85504,49098,False,502,49,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-10-00,1675951800,52.084834814071655,2106.813307762146,27220,Daniel,192.168.152.36,2106.813307762146,0,49,8.03538990020752,49098,3336448,49098,3336448,-157.72101052105427,-187.16704893112183,-171.52214821014138,100.0,9,0,"[-164.02385437488556, -165.1729513183236, -167.72791469842196, -169.36041093617678, -187.16704893112183, -166.19394103437662, -184.12222132086754, -157.72101052105427, -182.2099807560444]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.171389737271677,2.382384325267802,0.22673174717336908,2.976710819517779,0.0,163.143,49098,3336448,49098,3336448,39.35833333333333,89.12777777777778,"[-164.02385437488556, -165.1729513183236, -167.72791469842196, -169.36041093617678, -187.16704893112183, -166.19394103437662, -184.12222132086754, -157.72101052105427, -182.2099807560444]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.171389737271677,2.382384325267802,0.22673174717336908,2.976710819517779,0.0
--152.31337993592024,-180.45381225645542,-167.01164238378405,100.0,10,0,3,0,0,50100,3421952,50100,3421952,1002,85504,50100,85504,50100,False,512,50,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-10-52,1675951852,52.5621771812439,2159.37548494339,27220,Daniel,192.168.152.36,2159.37548494339,0,50,8.03538990020752,50100,3421952,50100,3421952,-152.31337993592024,-180.45381225645542,-167.01164238378405,100.0,10,0,"[-166.2010705396533, -165.15286721289158, -177.13387587666512, -172.71380574256182, -180.45381225645542, -152.31337993592024, -169.01329336315393, -162.11746937781572, -170.08409921824932, -154.9327503144741]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1597138351683458,2.3676077310685364,0.22488010978207645,2.959579776471321,0.0,156.406,50100,3421952,50100,3421952,39.669444444444444,89.3736111111111,"[-166.2010705396533, -165.15286721289158, -177.13387587666512, -172.71380574256182, -180.45381225645542, -152.31337993592024, -169.01329336315393, -162.11746937781572, -170.08409921824932, -154.9327503144741]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1597138351683458,2.3676077310685364,0.22488010978207645,2.959579776471321,0.0
--152.7232918664813,-184.36629006266594,-171.7524909885092,100.0,11,0,3,0,0,51102,3507456,51102,3507456,1002,85504,51102,85504,51102,False,523,51,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-11-45,1675951905,52.303550243377686,2211.6790351867676,27220,Daniel,192.168.152.36,2211.6790351867676,0,51,8.03538990020752,51102,3507456,51102,3507456,-152.7232918664813,-184.36629006266594,-171.7524909885092,100.0,11,0,"[-177.88127502799034, -180.92025382816792, -176.51851931214333, -167.0416279733181, -174.85611286759377, -184.36629006266594, -164.09691985696554, -167.74666656553745, -152.7232918664813, -175.44189263135195, -167.6845508813858]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1784930727564988,2.395031319027933,0.22804207476988883,2.99466412626673,0.0,154.129,51102,3507456,51102,3507456,39.91111111111112,89.57222222222222,"[-177.88127502799034, -180.92025382816792, -176.51851931214333, -167.0416279733181, -174.85611286759377, -184.36629006266594, -164.09691985696554, -167.74666656553745, -152.7232918664813, -175.44189263135195, -167.6845508813858]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1784930727564988,2.395031319027933,0.22804207476988883,2.99466412626673,0.0
--158.65478856116533,-187.4124725162983,-177.02790573984385,100.0,9,0,3,0,0,52104,3592960,52104,3592960,1002,85504,52104,85504,52104,False,532,52,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-12-37,1675951957,52.606945514678955,2264.2859807014465,27220,Daniel,192.168.152.36,2264.2859807014465,0,52,8.03538990020752,52104,3592960,52104,3592960,-158.65478856116533,-187.4124725162983,-177.02790573984385,100.0,9,0,"[-179.92599292099476, -170.8820983171463, -176.1663973480463, -183.63343332707882, -184.38870468735695, -178.17410226166248, -174.01316171884537, -158.65478856116533, -187.4124725162983]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1683279984762422,2.3820202711216147,0.22645537656995302,2.980423446745467,0.0,153.388,52104,3592960,52104,3592960,39.75694444444444,89.59166666666665,"[-179.92599292099476, -170.8820983171463, -176.1663973480463, -183.63343332707882, -184.38870468735695, -178.17410226166248, -174.01316171884537, -158.65478856116533, -187.4124725162983]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1683279984762422,2.3820202711216147,0.22645537656995302,2.980423446745467,0.0
--162.54527327418327,-180.6045781970024,-173.49289328232408,100.0,10,0,3,0,0,53106,3678464,53106,3678464,1002,85504,53106,85504,53106,False,542,53,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-13-30,1675952010,52.932852268218994,2317.2188329696655,27220,Daniel,192.168.152.36,2317.2188329696655,0,53,8.03538990020752,53106,3678464,53106,3678464,-162.54527327418327,-180.6045781970024,-173.49289328232408,100.0,10,0,"[-170.80859266221523, -162.54527327418327, -180.6045781970024, -168.33786635100842, -176.6122608780861, -178.73005056381226, -174.1295227855444, -171.88962145149708, -179.38428509235382, -171.88688156753778]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1573509450000015,2.36857895904198,0.22478369759320066,2.961575403823857,0.0,178.635,53106,3678464,53106,3678464,41.131506849315066,89.5095890410959,"[-170.80859266221523, -162.54527327418327, -180.6045781970024, -168.33786635100842, -176.6122608780861, -178.73005056381226, -174.1295227855444, -171.88962145149708, -179.38428509235382, -171.88688156753778]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1573509450000015,2.36857895904198,0.22478369759320066,2.961575403823857,0.0
-172.17469937354326,-178.04978723824024,-111.83921558206731,92.54545454545455,11,0,3,0,0,54108,3763968,54108,3763968,1002,85504,54108,85504,54108,False,553,54,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-14-27,1675952067,56.83306169509888,2374.0518946647644,27220,Daniel,192.168.152.36,2374.0518946647644,0,54,8.03538990020752,54108,3763968,54108,3763968,172.17469937354326,-178.04978723824024,-111.83921558206731,92.54545454545455,11,0,"[-152.32089486718178, -168.6792200356722, 172.17469937354326, -174.37111976742744, -178.04978723824024, -161.35409639030695, -173.27450999617577, -175.17871895432472, -175.17226216197014, -168.80600002408028, 124.80053865909576]","[100, 100, 45, 100, 100, 100, 100, 100, 100, 100, 73]",1.1781361143589992,2.3995323424176904,0.22811804378349382,3.0050410073267106,0.0,172.22,54108,3763968,54108,3763968,45.34358974358974,90.55128205128203,"[-152.32089486718178, -168.6792200356722, 172.17469937354326, -174.37111976742744, -178.04978723824024, -161.35409639030695, -173.27450999617577, -175.17871895432472, -175.17226216197014, -168.80600002408028, 124.80053865909576]","[100, 100, 45, 100, 100, 100, 100, 100, 100, 100, 73]",1.1781361143589992,2.3995323424176904,0.22811804378349382,3.0050410073267106,0.0
--162.88143733888865,-178.88590398430824,-173.37141248854724,100.0,11,0,3,0,0,55110,3849472,55110,3849472,1002,85504,55110,85504,55110,False,564,55,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-15-22,1675952122,54.77003026008606,2428.8219249248505,27220,Daniel,192.168.152.36,2428.8219249248505,0,55,8.03538990020752,55110,3849472,55110,3849472,-162.88143733888865,-178.88590398430824,-173.37141248854724,100.0,11,0,"[-178.19854023307562, -162.88143733888865, -177.13169145584106, -173.54518923163414, -178.88590398430824, -173.42413312196732, -174.1886915564537, -171.58526647090912, -175.8660365343094, -166.32416386902332, -175.05448357760906]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1695335327833603,2.3877673399442436,0.2269276792489708,2.9990432795473727,0.0,165.069,55110,3849472,55110,3849472,43.56891891891892,90.65270270270271,"[-178.19854023307562, -162.88143733888865, -177.13169145584106, -173.54518923163414, -178.88590398430824, -173.42413312196732, -174.1886915564537, -171.58526647090912, -175.8660365343094, -166.32416386902332, -175.05448357760906]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1695335327833603,2.3877673399442436,0.2269276792489708,2.9990432795473727,0.0
-145.30291169136763,-177.46829970180988,-134.47186732706098,95.66666666666667,9,0,3,0,0,56112,3934976,56112,3934976,1002,85504,56112,85504,56112,False,573,56,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-16-15,1675952175,52.84667134284973,2481.6685962677,27220,Daniel,192.168.152.36,2481.6685962677,0,56,8.03538990020752,56112,3934976,56112,3934976,145.30291169136763,-177.46829970180988,-134.47186732706098,95.66666666666667,9,0,"[-177.46829970180988, -172.56263116002083, -169.99527460336685, -168.33745901286602, -165.01786890625954, -175.25372545421124, -152.16031700372696, 145.30291169136763, -174.754141792655]","[100, 100, 100, 100, 100, 100, 100, 61, 100]",1.168446624532885,2.384881392037668,0.2264207307852431,3.0027140719595513,0.0,155.194,56112,3934976,56112,3934976,40.38904109589041,90.55616438356165,"[-177.46829970180988, -172.56263116002083, -169.99527460336685, -168.33745901286602, -165.01786890625954, -175.25372545421124, -152.16031700372696, 145.30291169136763, -174.754141792655]","[100, 100, 100, 100, 100, 100, 100, 61, 100]",1.168446624532885,2.384881392037668,0.2264207307852431,3.0027140719595513,0.0
-190.71583554148674,-177.23308964073658,-135.2146406566555,94.0,11,0,3,0,0,57114,4020480,57114,4020480,1002,85504,57114,85504,57114,False,584,57,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-17-06,1675952226,51.583651542663574,2533.2522478103638,27220,Daniel,192.168.152.36,2533.2522478103638,0,57,8.03538990020752,57114,4020480,57114,4020480,190.71583554148674,-177.23308964073658,-135.2146406566555,94.0,11,0,"[-174.89020885527134, -171.159431964159, -157.92751325666904, -159.18436642736197, 190.71583554148674, -172.40087322890759, -157.3429071456194, -162.45721162110567, -177.23308964073658, -172.98275361955166, -172.49852700531483]","[100, 100, 100, 100, 34, 100, 100, 100, 100, 100, 100]",1.1567281180468754,2.3690804976669826,0.2244683446426464,2.98578306030845,0.0,153.721,57114,4020480,57114,4020480,38.728169014084514,90.64929577464792,"[-174.89020885527134, -171.159431964159, -157.92751325666904, -159.18436642736197, 190.71583554148674, -172.40087322890759, -157.3429071456194, -162.45721162110567, -177.23308964073658, -172.98275361955166, -172.49852700531483]","[100, 100, 100, 100, 34, 100, 100, 100, 100, 100, 100]",1.1567281180468754,2.3690804976669826,0.2244683446426464,2.98578306030845,0.0
-235.2074180394411,-181.51839230954647,-107.81507757926981,86.75,12,0,3,0,0,58116,4105984,58116,4105984,1002,85504,58116,85504,58116,False,596,58,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-17-58,1675952278,51.68439030647278,2584.9366381168365,27220,Daniel,192.168.152.36,2584.9366381168365,0,58,8.03538990020752,58116,4105984,58116,4105984,235.2074180394411,-181.51839230954647,-107.81507757926981,86.75,12,0,"[-169.1734808459878, -165.13312735408545, -181.51839230954647, 195.56617008149624, 235.2074180394411, -170.57011537253857, -176.20819710195065, -180.06366753578186, -176.26358722895384, -167.89460321515799, -171.07733319699764, -166.65201491117477]","[100, 100, 100, 31, 10, 100, 100, 100, 100, 100, 100, 100]",1.184853309958937,2.409731862418623,0.22906245486115503,3.0413982721293067,0.0,149.844,58116,4105984,58116,4105984,38.939436619718315,90.74084507042252,"[-169.1734808459878, -165.13312735408545, -181.51839230954647, 195.56617008149624, 235.2074180394411, -170.57011537253857, -176.20819710195065, -180.06366753578186, -176.26358722895384, -167.89460321515799, -171.07733319699764, -166.65201491117477]","[100, 100, 100, 31, 10, 100, 100, 100, 100, 100, 100, 100]",1.184853309958937,2.409731862418623,0.22906245486115503,3.0413982721293067,0.0
--163.9477882012725,-182.78319193422794,-171.1263469800353,100.0,10,0,3,0,0,59118,4191488,59118,4191488,1002,85504,59118,85504,59118,False,606,59,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-18-50,1675952330,51.56728720664978,2636.5039253234863,27220,Daniel,192.168.152.36,2636.5039253234863,0,59,8.03538990020752,59118,4191488,59118,4191488,-163.9477882012725,-182.78319193422794,-171.1263469800353,100.0,10,0,"[-168.76183578372002, -182.78319193422794, -163.9477882012725, -172.7225134074688, -169.8990863710642, -174.10112477838993, -167.67432311177254, -167.00066530704498, -172.57840389758348, -171.79453700780869]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.177199225499035,2.399099586325378,0.22786457849406644,3.0333925552937258,0.0,155.741,59118,4191488,59118,4191488,38.85211267605633,90.81408450704222,"[-168.76183578372002, -182.78319193422794, -163.9477882012725, -172.7225134074688, -169.8990863710642, -174.10112477838993, -167.67432311177254, -167.00066530704498, -172.57840389758348, -171.79453700780869]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.177199225499035,2.399099586325378,0.22786457849406644,3.0333925552937258,0.0
--149.96378096938133,-184.42970390617847,-170.0797163911164,100.0,10,0,3,0,0,60120,4276992,60120,4276992,1002,85504,60120,85504,60120,False,616,60,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-19-42,1675952382,52.56097674369812,2689.0649020671844,27220,Daniel,192.168.152.36,2689.0649020671844,0,60,8.03538990020752,60120,4276992,60120,4276992,-149.96378096938133,-184.42970390617847,-170.0797163911164,100.0,10,0,"[-172.28781836479902, -149.96378096938133, -176.29950307309628, -183.52996740490198, -184.42970390617847, -168.78611098229885, -170.16987989842892, -166.8136347681284, -157.78914754092693, -170.72761700302362]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1547097593038822,2.3676612694685426,0.22422665875386674,2.9974517419686677,0.0,150.598,60120,4276992,60120,4276992,40.18472222222223,90.86944444444445,"[-172.28781836479902, -149.96378096938133, -176.29950307309628, -183.52996740490198, -184.42970390617847, -168.78611098229885, -170.16987989842892, -166.8136347681284, -157.78914754092693, -170.72761700302362]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1547097593038822,2.3676612694685426,0.22422665875386674,2.9974517419686677,0.0
-183.24299144744873,-175.62199070304632,-135.15221174332228,94.72727272727273,11,0,3,0,0,61122,4362496,61122,4362496,1002,85504,61122,85504,61122,False,627,61,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-20-34,1675952434,52.008280992507935,2741.0731830596924,27220,Daniel,192.168.152.36,2741.0731830596924,0,61,8.03538990020752,61122,4362496,61122,4362496,183.24299144744873,-175.62199070304632,-135.15221174332228,94.72727272727273,11,0,"[-152.1386574730277, -172.1268064752221, 183.24299144744873, -167.3796276524663, -168.53416009247303, -175.62199070304632, -157.11144542694092, -171.20542296767235, -171.28015413880348, -167.0303348749876, -167.48872081935406]","[100, 100, 42, 100, 100, 100, 100, 100, 100, 100, 100]",1.1737715077014588,2.394903638279112,0.22766215829163106,3.0354324836539486,0.0,149.664,61122,4362496,61122,4362496,39.582857142857144,91.12999999999998,"[-152.1386574730277, -172.1268064752221, 183.24299144744873, -167.3796276524663, -168.53416009247303, -175.62199070304632, -157.11144542694092, -171.20542296767235, -171.28015413880348, -167.0303348749876, -167.48872081935406]","[100, 100, 42, 100, 100, 100, 100, 100, 100, 100, 100]",1.1737715077014588,2.394903638279112,0.22766215829163106,3.0354324836539486,0.0
-239.73450852930546,-185.16179871559143,-67.65054373849522,79.81818181818181,11,0,3,0,0,62124,4448000,62124,4448000,1002,85504,62124,85504,62124,False,638,62,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-21-26,1675952486,51.265044927597046,2792.3382279872894,27220,Daniel,192.168.152.36,2792.3382279872894,0,62,8.03538990020752,62124,4448000,62124,4448000,239.73450852930546,-185.16179871559143,-67.65054373849522,79.81818181818181,11,0,"[-166.44169382750988, -163.61962708085775, -165.41450536251068, 164.16573779284954, -156.2493090108037, -184.68035705387592, 239.73450852930546, -176.2363166809082, 211.67640355974436, -185.16179871559143, -161.9290232732892]","[100, 100, 100, 50, 100, 100, 6, 100, 22, 100, 100]",1.1522581986748532,2.365065178609856,0.22422213681630165,3.000933015446322,0.0,150.051,62124,4448000,62124,4448000,38.511267605633805,91.45492957746481,"[-166.44169382750988, -163.61962708085775, -165.41450536251068, 164.16573779284954, -156.2493090108037, -184.68035705387592, 239.73450852930546, -176.2363166809082, 211.67640355974436, -185.16179871559143, -161.9290232732892]","[100, 100, 100, 50, 100, 100, 6, 100, 22, 100, 100]",1.1522581986748532,2.365065178609856,0.22422213681630165,3.000933015446322,0.0
--164.83878053724766,-184.31719098985195,-172.19335282345614,100.0,12,0,3,0,0,63126,4533504,63126,4533504,1002,85504,63126,85504,63126,False,650,63,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-22-17,1675952537,50.72093605995178,2843.059164047241,27220,Daniel,192.168.152.36,2843.059164047241,0,63,8.03538990020752,63126,4533504,63126,4533504,-164.83878053724766,-184.31719098985195,-172.19335282345614,100.0,12,0,"[-173.22791515290737, -166.02916425466537, -184.31719098985195, -164.90399967879057, -167.61980755627155, -172.49408177286386, -181.30813418328762, -164.83878053724766, -167.37792050093412, -175.67796140164137, -165.0356966406107, -183.4895812124014]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.161695348102149,2.3783665558109326,0.2257217219056826,3.018582295305679,0.0,149.157,63126,4533504,63126,4533504,37.994202898550725,91.45072463768112,"[-173.22791515290737, -166.02916425466537, -184.31719098985195, -164.90399967879057, -167.61980755627155, -172.49408177286386, -181.30813418328762, -164.83878053724766, -167.37792050093412, -175.67796140164137, -165.0356966406107, -183.4895812124014]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.161695348102149,2.3783665558109326,0.2257217219056826,3.018582295305679,0.0
-155.9317017197609,-178.00977374613285,-131.80782703227467,95.55555555555556,9,0,3,0,0,64128,4619008,64128,4619008,1002,85504,64128,85504,64128,False,659,64,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-23-08,1675952588,51.817686319351196,2894.8768503665924,27220,Daniel,192.168.152.36,2894.8768503665924,0,64,8.03538990020752,64128,4619008,64128,4619008,155.9317017197609,-178.00977374613285,-131.80782703227467,95.55555555555556,9,0,"[-161.44142983853817, -168.61906314641237, -178.00977374613285, -177.75505349040031, -159.45529536157846, -171.50798258930445, -161.90505647659302, -163.5084903612733, 155.9317017197609]","[100, 100, 100, 100, 100, 100, 100, 100, 60]",1.1606687460805056,2.3775513035971017,0.22564693327857632,3.0192040532362205,0.0,147.258,64128,4619008,64128,4619008,38.774647887323944,92.03098591549295,"[-161.44142983853817, -168.61906314641237, -178.00977374613285, -177.75505349040031, -159.45529536157846, -171.50798258930445, -161.90505647659302, -163.5084903612733, 155.9317017197609]","[100, 100, 100, 100, 100, 100, 100, 100, 60]",1.1606687460805056,2.3775513035971017,0.22564693327857632,3.0192040532362205,0.0
-183.30390575528145,-179.6067262738943,-138.66359566835067,94.91666666666667,12,0,3,0,0,65130,4704512,65130,4704512,1002,85504,65130,85504,65130,False,671,65,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-23-59,1675952639,50.45256757736206,2945.3294179439545,27220,Daniel,192.168.152.36,2945.3294179439545,0,65,8.03538990020752,65130,4704512,65130,4704512,183.30390575528145,-179.6067262738943,-138.66359566835067,94.91666666666667,12,0,"[183.30390575528145, -171.12455678731203, -155.62387500703335, -173.1842506080866, -158.1185237467289, -164.1399745941162, -168.26139509677887, -171.55332411825657, -179.6067262738943, -172.7773946300149, -167.53122694790363, -165.34580596536398]","[39, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.159725753217009,2.375829445487214,0.2255228950784308,3.0170383087027477,0.0,150.034,65130,4704512,65130,4704512,37.38260869565218,92.10579710144927,"[183.30390575528145, -171.12455678731203, -155.62387500703335, -173.1842506080866, -158.1185237467289, -164.1399745941162, -168.26139509677887, -171.55332411825657, -179.6067262738943, -172.7773946300149, -167.53122694790363, -165.34580596536398]","[39, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.159725753217009,2.375829445487214,0.2255228950784308,3.0170383087027477,0.0
-198.18074981868267,-188.14086382091045,-74.54947767271237,83.81818181818181,11,0,3,0,0,66132,4790016,66132,4790016,1002,85504,66132,85504,66132,False,682,66,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-24-50,1675952690,50.996140241622925,2996.3255581855774,27220,Daniel,192.168.152.36,2996.3255581855774,0,66,8.03538990020752,66132,4790016,66132,4790016,198.18074981868267,-188.14086382091045,-74.54947767271237,83.81818181818181,11,0,"[-157.19410021603107, -188.14086382091045, -169.11975614726543, -170.2193198800087, 171.1429763957858, 179.46075742691755, 198.18074981868267, -160.25839917361736, -170.5428620427847, -167.42007557302713, -185.93336118757725]","[100, 100, 100, 100, 47, 43, 32, 100, 100, 100, 100]",1.156295746163601,2.370544130692677,0.22472781337053033,3.0111810920602227,0.0,152.797,66132,4790016,66132,4790016,38.16285714285714,92.06714285714285,"[-157.19410021603107, -188.14086382091045, -169.11975614726543, -170.2193198800087, 171.1429763957858, 179.46075742691755, 198.18074981868267, -160.25839917361736, -170.5428620427847, -167.42007557302713, -185.93336118757725]","[100, 100, 100, 100, 47, 43, 32, 100, 100, 100, 100]",1.156295746163601,2.370544130692677,0.22472781337053033,3.0111810920602227,0.0
--167.23506778478622,-194.75925220549107,-176.44510723650455,100.0,10,0,3,0,0,67134,4875520,67134,4875520,1002,85504,67134,85504,67134,False,692,67,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-25-40,1675952740,50.382936000823975,3046.7084941864014,27220,Daniel,192.168.152.36,3046.7084941864014,0,67,8.03538990020752,67134,4875520,67134,4875520,-167.23506778478622,-194.75925220549107,-176.44510723650455,100.0,10,0,"[-194.75925220549107, -167.45148000121117, -173.71280989050865, -183.20505180954933, -167.3187713623047, -167.23506778478622, -172.46199409663677, -187.53810274600983, -176.63034914433956, -174.13819332420826]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1692303371970652,2.38934916249069,0.2271182778171509,3.0354050711250755,0.0,153.466,67134,4875520,67134,4875520,37.724999999999994,92.01617647058823,"[-194.75925220549107, -167.45148000121117, -173.71280989050865, -183.20505180954933, -167.3187713623047, -167.23506778478622, -172.46199409663677, -187.53810274600983, -176.63034914433956, -174.13819332420826]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1692303371970652,2.38934916249069,0.2271182778171509,3.0354050711250755,0.0
-199.47801526635885,-185.48150983452797,-137.65783218362114,93.54545454545455,11,0,3,0,0,68136,4961024,68136,4961024,1002,85504,68136,85504,68136,False,703,68,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-26-32,1675952792,51.47679924964905,3098.1852934360504,27220,Daniel,192.168.152.36,3098.1852934360504,0,68,8.03538990020752,68136,4961024,68136,4961024,199.47801526635885,-185.48150983452797,-137.65783218362114,93.54545454545455,11,0,"[-178.56572143733501, -167.55778631567955, -166.04872252047062, 199.47801526635885, -169.49843569099903, -169.19959335029125, -162.0254235714674, -167.34990080446005, -171.22927805781364, -185.48150983452797, -176.75779770314693]","[100, 100, 100, 29, 100, 100, 100, 100, 100, 100, 100]",1.1574515099040548,2.372989675802231,0.22532611039577824,3.0180462109730666,0.0,156.16,68136,4961024,68136,4961024,38.94788732394366,92.24788732394362,"[-178.56572143733501, -167.55778631567955, -166.04872252047062, 199.47801526635885, -169.49843569099903, -169.19959335029125, -162.0254235714674, -167.34990080446005, -171.22927805781364, -185.48150983452797, -176.75779770314693]","[100, 100, 100, 29, 100, 100, 100, 100, 100, 100, 100]",1.1574515099040548,2.372989675802231,0.22532611039577824,3.0180462109730666,0.0
-110.41143734753132,-182.64592268317938,-143.69641439914705,97.9,10,0,3,0,0,69138,5046528,69138,5046528,1002,85504,69138,85504,69138,False,713,69,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-27-23,1675952843,51.41184735298157,3149.597140789032,27220,Daniel,192.168.152.36,3149.597140789032,0,69,8.03538990020752,69138,5046528,69138,5046528,110.41143734753132,-182.64592268317938,-143.69641439914705,97.9,10,0,"[-170.87691847980022, -171.50100470334291, -166.9094069674611, -170.9276044666767, -182.64592268317938, -176.23206087201834, -166.06158356368542, -171.75342164933681, -170.46765795350075, 110.41143734753132]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 79]",1.1538557444145536,2.368648111077976,0.224642295943334,3.019898236845302,0.0,155.399,69138,5046528,69138,5046528,38.508571428571436,92.4457142857143,"[-170.87691847980022, -171.50100470334291, -166.9094069674611, -170.9276044666767, -182.64592268317938, -176.23206087201834, -166.06158356368542, -171.75342164933681, -170.46765795350075, 110.41143734753132]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 79]",1.1538557444145536,2.368648111077976,0.224642295943334,3.019898236845302,0.0
-119.72416963428259,-178.23986833542585,-109.35119683519005,95.2,10,0,3,0,0,70140,5132032,70140,5132032,1002,85504,70140,85504,70140,False,723,70,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-28-14,1675952894,50.57467818260193,3200.171818971634,27220,Daniel,192.168.152.36,3200.171818971634,0,70,8.03538990020752,70140,5132032,70140,5132032,119.72416963428259,-178.23986833542585,-109.35119683519005,95.2,10,0,"[-169.28218329697847, 116.13884158432484, -170.0493287369609, -178.23986833542585, -157.2627425789833, -156.08764888346195, -171.0137109681964, -160.89349257946014, 119.72416963428259, -166.546004191041]","[100, 77, 100, 100, 100, 100, 100, 100, 75, 100]",1.1433648928508524,2.355041298332556,0.22310589322541716,3.0036732575467266,0.0,151.217,70140,5132032,70140,5132032,38.649275362318846,91.87101449275363,"[-169.28218329697847, 116.13884158432484, -170.0493287369609, -178.23986833542585, -157.2627425789833, -156.08764888346195, -171.0137109681964, -160.89349257946014, 119.72416963428259, -166.546004191041]","[100, 77, 100, 100, 100, 100, 100, 100, 75, 100]",1.1433648928508524,2.355041298332556,0.22310589322541716,3.0036732575467266,0.0
--159.49032779037952,-175.48708271980286,-165.0475115455687,100.0,10,0,3,0,0,71142,5217536,71142,5217536,1002,85504,71142,85504,71142,False,733,71,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-29-05,1675952945,51.007408618927,3251.179227590561,27220,Daniel,192.168.152.36,3251.179227590561,0,71,8.03538990020752,71142,5217536,71142,5217536,-159.49032779037952,-175.48708271980286,-165.0475115455687,100.0,10,0,"[-165.38771004229784, -165.03332306444645, -161.53718860447407, -159.81730138510466, -172.05934658646584, -159.49032779037952, -164.55455171316862, -175.48708271980286, -165.7156725153327, -161.3926110342145]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.165176470420945,2.3855955008085132,0.2266659787906113,3.0395015030502393,0.0,149.864,71142,5217536,71142,5217536,38.505714285714284,91.11000000000001,"[-165.38771004229784, -165.03332306444645, -161.53718860447407, -159.81730138510466, -172.05934658646584, -159.49032779037952, -164.55455171316862, -175.48708271980286, -165.7156725153327, -161.3926110342145]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.165176470420945,2.3855955008085132,0.2266659787906113,3.0395015030502393,0.0
-148.31048257648945,-185.2264585196972,-143.34482212613025,96.83333333333333,12,0,3,0,0,72144,5303040,72144,5303040,1002,85504,72144,85504,72144,False,745,72,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-29-57,1675952997,51.67850995063782,3302.8577375411987,27220,Daniel,192.168.152.36,3302.8577375411987,0,72,8.03538990020752,72144,5303040,72144,5303040,148.31048257648945,-185.2264585196972,-143.34482212613025,96.83333333333333,12,0,"[-171.61356304585934, -185.2264585196972, 148.31048257648945, -166.364186309278, -161.1578652113676, -166.60447953641415, -177.44498451054096, -165.76431642472744, -161.29296194761992, -175.79897065460682, -168.94946272671223, -168.23109920322895]","[100, 100, 62, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1524487637560776,2.3680322193092507,0.22460716169622386,3.018858441130469,0.0,167.624,72144,5303040,72144,5303040,39.270422535211274,91.16056338028169,"[-171.61356304585934, -185.2264585196972, 148.31048257648945, -166.364186309278, -161.1578652113676, -166.60447953641415, -177.44498451054096, -165.76431642472744, -161.29296194761992, -175.79897065460682, -168.94946272671223, -168.23109920322895]","[100, 100, 62, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1524487637560776,2.3680322193092507,0.22460716169622386,3.018858441130469,0.0
--143.17557802051306,-172.038729429245,-161.87674024452767,100.0,9,0,3,0,0,73146,5388544,73146,5388544,1002,85504,73146,85504,73146,False,754,73,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-30-52,1675953052,54.81452250480652,3357.6722600460052,27220,Daniel,192.168.152.36,3357.6722600460052,0,73,8.03538990020752,73146,5388544,73146,5388544,-143.17557802051306,-172.038729429245,-161.87674024452767,100.0,9,0,"[-172.038729429245, -143.17557802051306, -168.86351500451565, -159.019325658679, -156.78222466260195, -160.2406881302595, -171.39745411276817, -165.27322578430176, -160.09992139786482]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1529814176975732,2.368934296390233,0.22488786435361607,3.018615387568453,0.0,157.749,73146,5388544,73146,5388544,43.33866666666667,91.6786666666667,"[-172.038729429245, -143.17557802051306, -168.86351500451565, -159.019325658679, -156.78222466260195, -160.2406881302595, -171.39745411276817, -165.27322578430176, -160.09992139786482]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1529814176975732,2.368934296390233,0.22488786435361607,3.018615387568453,0.0
-191.80275205522776,-173.12717425823212,-128.55730764120818,93.6,10,0,3,0,0,74148,5474048,74148,5474048,1002,85504,74148,85504,74148,False,764,74,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-31-46,1675953106,54.20589566230774,3411.878155708313,27220,Daniel,192.168.152.36,3411.878155708313,0,74,8.03538990020752,74148,5474048,74148,5474048,191.80275205522776,-173.12717425823212,-128.55730764120818,93.6,10,0,"[-172.25843781232834, -171.56783711910248, -154.89343477785587, -165.64450925588608, -154.28777254372835, -146.19070403277874, -173.0055277645588, -166.4004309028387, -173.12717425823212, 191.80275205522776]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 36]",1.1425050200008482,2.3547043165458557,0.22346309971769837,2.9981971235584326,0.0,173.058,74148,5474048,74148,5474048,41.764,91.61466666666666,"[-172.25843781232834, -171.56783711910248, -154.89343477785587, -165.64450925588608, -154.28777254372835, -146.19070403277874, -173.0055277645588, -166.4004309028387, -173.12717425823212, 191.80275205522776]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 36]",1.1425050200008482,2.3547043165458557,0.22346309971769837,2.9981971235584326,0.0
-124.93473886698484,-172.29703122377396,-135.55750901590693,98.9090909090909,11,0,3,0,0,75150,5559552,75150,5559552,1002,85504,75150,85504,75150,False,775,75,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-32-43,1675953163,56.431779861450195,3468.309935569763,27220,Daniel,192.168.152.36,3468.309935569763,0,75,8.03538990020752,75150,5559552,75150,5559552,124.93473886698484,-172.29703122377396,-135.55750901590693,98.9090909090909,11,0,"[124.93473886698484, -163.0180952101946, -161.28063073009253, -167.00439904630184, -151.3675112053752, -160.56970743089914, -158.76533725112677, -161.2794821932912, -172.29703122377396, -161.53198893368244, -158.95315481722355]","[88, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1636558597515732,2.3856886428337463,0.22670400744381095,3.035813006661667,0.0,175.662,75150,5559552,75150,5559552,44.26538461538461,92.00384615384613,"[124.93473886698484, -163.0180952101946, -161.28063073009253, -167.00439904630184, -151.3675112053752, -160.56970743089914, -158.76533725112677, -161.2794821932912, -172.29703122377396, -161.53198893368244, -158.95315481722355]","[88, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1636558597515732,2.3856886428337463,0.22670400744381095,3.035813006661667,0.0
-169.6803795993328,-182.34440790116787,-131.51495799273252,95.2,10,0,3,0,0,76152,5645056,76152,5645056,1002,85504,76152,85504,76152,False,785,76,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-33-36,1675953216,53.583471059799194,3521.8934066295624,27220,Daniel,192.168.152.36,3521.8934066295624,0,76,8.03538990020752,76152,5645056,76152,5645056,169.6803795993328,-182.34440790116787,-131.51495799273252,95.2,10,0,"[169.6803795993328, -161.44799581170082, -159.49181184917688, -164.70041462033987, -163.04296263307333, -171.42047108709812, -163.48527751863003, -182.34440790116787, -153.71747366338968, -165.17914444208145]","[52, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.143030667600844,2.3581014065519903,0.22341121292640218,2.999100585563318,0.0,150.224,76152,5645056,76152,5645056,41.509459459459464,91.6527027027027,"[169.6803795993328, -161.44799581170082, -159.49181184917688, -164.70041462033987, -163.04296263307333, -171.42047108709812, -163.48527751863003, -182.34440790116787, -153.71747366338968, -165.17914444208145]","[52, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.143030667600844,2.3581014065519903,0.22341121292640218,2.999100585563318,0.0
--152.8951591551304,-181.0063157826662,-163.9134340003133,100.0,10,0,3,0,0,77154,5730560,77154,5730560,1002,85504,77154,85504,77154,False,795,77,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-34-28,1675953268,51.772043228149414,3573.665449857712,27220,Daniel,192.168.152.36,3573.665449857712,0,77,8.03538990020752,77154,5730560,77154,5730560,-152.8951591551304,-181.0063157826662,-163.9134340003133,100.0,10,0,"[-167.2451076209545, -167.8662877753377, -156.23243982344866, -159.70816734433174, -157.71184766292572, -181.0063157826662, -164.72998490184546, -152.8951591551304, -165.67885532975197, -166.06017460674047]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.16559326604679,2.390617717827612,0.22710014953459026,3.0347617196556547,0.0,156.099,77154,5730560,77154,5730560,38.29859154929578,91.60422535211268,"[-167.2451076209545, -167.8662877753377, -156.23243982344866, -159.70816734433174, -157.71184766292572, -181.0063157826662, -164.72998490184546, -152.8951591551304, -165.67885532975197, -166.06017460674047]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.16559326604679,2.390617717827612,0.22710014953459026,3.0347617196556547,0.0
-218.4875881522894,-170.17647764086723,-104.9829066991806,89.41666666666667,12,0,3,0,0,78156,5816064,78156,5816064,1002,85504,78156,85504,78156,False,807,78,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-35-20,1675953320,52.28432488441467,3625.9497747421265,27220,Daniel,192.168.152.36,3625.9497747421265,0,78,8.03538990020752,78156,5816064,78156,5816064,218.4875881522894,-170.17647764086723,-104.9829066991806,89.41666666666667,12,0,"[-163.60555607825518, -156.57682275772095, 167.93389448523521, -169.0568140000105, -162.2520575746894, -165.49506570398808, -170.17647764086723, -162.3308557420969, -161.8372429832816, 218.4875881522894, -164.90873232483864, -169.97673822194338]","[100, 100, 54, 100, 100, 100, 100, 100, 100, 19, 100, 100]",1.152931325341899,2.3722291811777336,0.2249989798580283,3.00977597008278,0.0,151.968,78156,5816064,78156,5816064,38.680281690140845,91.58309859154932,"[-163.60555607825518, -156.57682275772095, 167.93389448523521, -169.0568140000105, -162.2520575746894, -165.49506570398808, -170.17647764086723, -162.3308557420969, -161.8372429832816, 218.4875881522894, -164.90873232483864, -169.97673822194338]","[100, 100, 54, 100, 100, 100, 100, 100, 100, 19, 100, 100]",1.152931325341899,2.3722291811777336,0.2249989798580283,3.00977597008278,0.0
-236.46240736544132,-167.6678908020258,-119.44905663728714,90.8,10,0,3,0,0,79158,5901568,79158,5901568,1002,85504,79158,85504,79158,False,817,79,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-36-12,1675953372,51.4840521812439,3677.4338269233704,27220,Daniel,192.168.152.36,3677.4338269233704,0,79,8.03538990020752,79158,5901568,79158,5901568,236.46240736544132,-167.6678908020258,-119.44905663728714,90.8,10,0,"[-155.22694990038872, -148.03948517143726, -167.6678908020258, -155.15678357332945, -165.17036618292332, -160.64602085202932, -150.88469261676073, -160.58221770077944, 236.46240736544132, -167.5785669386387]","[100, 100, 100, 100, 100, 100, 100, 100, 8, 100]",1.1416198350112192,2.3564032897142537,0.22313536539423637,2.986136513552914,0.0,169.556,79158,5901568,79158,5901568,38.80704225352113,91.643661971831,"[-155.22694990038872, -148.03948517143726, -167.6678908020258, -155.15678357332945, -165.17036618292332, -160.64602085202932, -150.88469261676073, -160.58221770077944, 236.46240736544132, -167.5785669386387]","[100, 100, 100, 100, 100, 100, 100, 100, 8, 100]",1.1416198350112192,2.3564032897142537,0.22313536539423637,2.986136513552914,0.0
-202.65034437179565,-171.65506206452847,-72.34385556727648,87.9090909090909,11,0,3,0,0,80160,5987072,80160,5987072,1002,85504,80160,85504,80160,False,828,80,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-37-05,1675953425,53.07296299934387,3730.5067899227142,27220,Daniel,192.168.152.36,3730.5067899227142,0,80,8.03538990020752,80160,5987072,80160,5987072,202.65034437179565,-171.65506206452847,-72.34385556727648,87.9090909090909,11,0,"[-157.27118510007858, -157.589127920568, 185.27401945739985, 105.5456792935729, -160.14251535385847, -150.72022999078035, -162.02908248454332, -167.57097980380058, -162.2742716446519, -171.65506206452847, 202.65034437179565]","[100, 100, 41, 91, 100, 100, 100, 100, 100, 100, 35]",1.153527292950288,2.3734114411963905,0.22518350289518166,3.001164451690306,0.0,149.957,80160,5987072,80160,5987072,39.76111111111111,92.28888888888888,"[-157.27118510007858, -157.589127920568, 185.27401945739985, 105.5456792935729, -160.14251535385847, -150.72022999078035, -162.02908248454332, -167.57097980380058, -162.2742716446519, -171.65506206452847, 202.65034437179565]","[100, 100, 41, 91, 100, 100, 100, 100, 100, 100, 35]",1.153527292950288,2.3734114411963905,0.22518350289518166,3.001164451690306,0.0
--154.69595033675432,-169.51182003319263,-163.94407005201685,100.0,11,0,3,0,0,81162,6072576,81162,6072576,1002,85504,81162,85504,81162,False,839,81,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-38-00,1675953480,54.99451732635498,3785.501307249069,27220,Daniel,192.168.152.36,3785.501307249069,0,81,8.03538990020752,81162,6072576,81162,6072576,-154.69595033675432,-169.51182003319263,-163.94407005201685,100.0,11,0,"[-154.69595033675432, -167.14128770679235, -158.10850709676743, -163.40271547436714, -169.51182003319263, -165.15099102258682, -164.1226975172758, -167.97480914741755, -168.13703125715256, -158.33018220961094, -166.80877877026796]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1417591448234448,2.357316551901309,0.22299008308480256,2.9778798295714495,0.0,155.935,81162,6072576,81162,6072576,42.6671052631579,92.41578947368421,"[-154.69595033675432, -167.14128770679235, -158.10850709676743, -163.40271547436714, -169.51182003319263, -165.15099102258682, -164.1226975172758, -167.97480914741755, -168.13703125715256, -158.33018220961094, -166.80877877026796]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1417591448234448,2.357316551901309,0.22299008308480256,2.9778798295714495,0.0
--157.24960503727198,-173.6255514100194,-166.47019824162126,100.0,10,0,3,0,0,82164,6158080,82164,6158080,1002,85504,82164,85504,82164,False,849,82,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-38-53,1675953533,52.590951442718506,3838.0922586917877,27220,Daniel,192.168.152.36,3838.0922586917877,0,82,8.03538990020752,82164,6158080,82164,6158080,-157.24960503727198,-173.6255514100194,-166.47019824162126,100.0,10,0,"[-170.27957665920258, -157.24960503727198, -163.69376994669437, -164.1087070927024, -172.31269567459822, -170.56378097832203, -173.6255514100194, -164.81482111662626, -162.75537701696157, -165.29809748381376]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1648231139557876,2.3901475864727812,0.22689543721309308,3.01333411708145,0.0,168.648,82164,6158080,82164,6158080,39.136986301369866,92.25342465753424,"[-170.27957665920258, -157.24960503727198, -163.69376994669437, -164.1087070927024, -172.31269567459822, -170.56378097832203, -173.6255514100194, -164.81482111662626, -162.75537701696157, -165.29809748381376]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1648231139557876,2.3901475864727812,0.22689543721309308,3.01333411708145,0.0
--155.88041848689318,-182.67987783253193,-167.41055427657233,100.0,9,0,3,0,0,83166,6243584,83166,6243584,1002,85504,83166,85504,83166,False,858,83,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-39-45,1675953585,51.881720304489136,3889.973978996277,27220,Daniel,192.168.152.36,3889.973978996277,0,83,8.03538990020752,83166,6243584,83166,6243584,-155.88041848689318,-182.67987783253193,-167.41055427657233,100.0,9,0,"[-167.6507991850376, -164.94820032268763, -167.69518004357815, -155.88041848689318, -161.4360726773739, -161.96245819330215, -182.67987783253193, -166.42907927930355, -178.01290246844292]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1521882233077718,2.3723068846645345,0.2247445888845171,2.9907422299139625,0.0,151.715,83166,6243584,83166,6243584,38.653521126760566,92.30985915492958,"[-167.6507991850376, -164.94820032268763, -167.69518004357815, -155.88041848689318, -161.4360726773739, -161.96245819330215, -182.67987783253193, -166.42907927930355, -178.01290246844292]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1521882233077718,2.3723068846645345,0.2247445888845171,2.9907422299139625,0.0
-235.32005356252193,-185.71455730497837,-132.62824469680587,92.41666666666667,12,0,3,0,0,84168,6329088,84168,6329088,1002,85504,84168,85504,84168,False,870,84,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-40-37,1675953637,52.08914613723755,3942.0631251335144,27220,Daniel,192.168.152.36,3942.0631251335144,0,84,8.03538990020752,84168,6329088,84168,6329088,235.32005356252193,-185.71455730497837,-132.62824469680587,92.41666666666667,12,0,"[-160.01942837238312, -163.05039732903242, -161.80853130668402, -185.71455730497837, -161.9875973314047, 235.32005356252193, -170.23530074954033, -168.93036127090454, -160.30008805543184, -159.32205363363028, -162.01179118454456, -173.47888338565826]","[100, 100, 100, 100, 100, 9, 100, 100, 100, 100, 100, 100]",1.140347353751047,2.3561442448285557,0.22263646435957693,2.969679595119118,0.0,150.337,84168,6329088,84168,6329088,38.732394366197184,92.33521126760563,"[-160.01942837238312, -163.05039732903242, -161.80853130668402, -185.71455730497837, -161.9875973314047, 235.32005356252193, -170.23530074954033, -168.93036127090454, -160.30008805543184, -159.32205363363028, -162.01179118454456, -173.47888338565826]","[100, 100, 100, 100, 100, 9, 100, 100, 100, 100, 100, 100]",1.140347353751047,2.3561442448285557,0.22263646435957693,2.969679595119118,0.0
-184.66164003312588,-173.31338399648666,-130.5925468192859,94.54545454545455,11,0,3,0,0,85170,6414592,85170,6414592,1002,85504,85170,85504,85170,False,881,85,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-41-28,1675953688,51.67122197151184,3993.7343471050262,27220,Daniel,192.168.152.36,3993.7343471050262,0,85,8.03538990020752,85170,6414592,85170,6414592,184.66164003312588,-173.31338399648666,-130.5925468192859,94.54545454545455,11,0,"[-166.68649516254663, -164.28171659260988, -154.92491586506367, -156.71664660423994, -165.8630260154605, -154.7869249433279, -161.24581636488438, -159.81006494164467, -163.5506645590067, -173.31338399648666, 184.66164003312588]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 40]",1.1526175684105326,2.373707121128328,0.22506819372605777,2.985176637973296,0.0,152.385,85170,6414592,85170,6414592,38.81126760563381,92.39999999999999,"[-166.68649516254663, -164.28171659260988, -154.92491586506367, -156.71664660423994, -165.8630260154605, -154.7869249433279, -161.24581636488438, -159.81006494164467, -163.5506645590067, -173.31338399648666, 184.66164003312588]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 40]",1.1526175684105326,2.373707121128328,0.22506819372605777,2.985176637973296,0.0
--153.46866038441658,-166.27869933843613,-162.08506232086154,100.0,9,0,3,0,0,86172,6500096,86172,6500096,1002,85504,86172,85504,86172,False,890,86,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-42-20,1675953740,51.89799118041992,4045.632338285446,27220,Daniel,192.168.152.36,4045.632338285446,0,86,8.03538990020752,86172,6500096,86172,6500096,-153.46866038441658,-166.27869933843613,-162.08506232086154,100.0,9,0,"[-165.28804403543472, -164.42760507762432, -164.16389498859644, -153.46866038441658, -159.4734928458929, -162.59226347506046, -166.27869933843613, -158.57809130102396, -164.49480944126844]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1510292675172136,2.3711743173579873,0.2247322100226278,2.980617783814539,0.0,152.652,86172,6500096,86172,6500096,38.54571428571428,92.55857142857144,"[-165.28804403543472, -164.42760507762432, -164.16389498859644, -153.46866038441658, -159.4734928458929, -162.59226347506046, -166.27869933843613, -158.57809130102396, -164.49480944126844]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1510292675172136,2.3711743173579873,0.2247322100226278,2.980617783814539,0.0
--151.91925486177206,-171.7965495660901,-162.73048628270627,100.0,10,0,3,0,0,87174,6585600,87174,6585600,1002,85504,87174,85504,87174,False,900,87,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-43-12,1675953792,51.8021285533905,4097.434466838837,27220,Daniel,192.168.152.36,4097.434466838837,0,87,8.03538990020752,87174,6585600,87174,6585600,-151.91925486177206,-171.7965495660901,-162.73048628270627,100.0,10,0,"[-163.47354861348867, -159.60192592442036, -159.82647239416838, -171.7965495660901, -162.7164184898138, -165.72435009479523, -164.9394108504057, -151.91925486177206, -166.3302129805088, -160.9767190515995]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1492450770821787,2.3687048925536764,0.2242143723792312,2.976488948110384,0.0,150.575,87174,6585600,87174,6585600,38.05915492957747,92.6887323943662,"[-163.47354861348867, -159.60192592442036, -159.82647239416838, -171.7965495660901, -162.7164184898138, -165.72435009479523, -164.9394108504057, -151.91925486177206, -166.3302129805088, -160.9767190515995]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1492450770821787,2.3687048925536764,0.2242143723792312,2.976488948110384,0.0
--156.1016564965248,-170.0796898379922,-164.2917529276826,100.0,11,0,3,0,0,88176,6671104,88176,6671104,1002,85504,88176,85504,88176,False,911,88,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-44-05,1675953845,52.44793081283569,4149.882397651672,27220,Daniel,192.168.152.36,4149.882397651672,0,88,8.03538990020752,88176,6671104,88176,6671104,-156.1016564965248,-170.0796898379922,-164.2917529276826,100.0,11,0,"[-164.5030802488327, -167.48114255815744, -170.059987090528, -165.85304640233517, -170.0796898379922, -159.18565671890974, -165.7829701602459, -157.2049067541957, -167.67788741737604, -156.1016564965248, -163.2792585194111]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.151577075730743,2.373204907738784,0.22478061207663913,2.9787773901250194,0.0,152.106,88176,6671104,88176,6671104,40.39718309859154,92.4323943661972,"[-164.5030802488327, -167.48114255815744, -170.059987090528, -165.85304640233517, -170.0796898379922, -159.18565671890974, -165.7829701602459, -157.2049067541957, -167.67788741737604, -156.1016564965248, -163.2792585194111]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.151577075730743,2.373204907738784,0.22478061207663913,2.9787773901250194,0.0
--158.87991008907557,-169.21210058033466,-162.74230231841406,100.0,9,0,3,0,0,89178,6756608,89178,6756608,1002,85504,89178,85504,89178,False,920,89,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-44-58,1675953898,53.125832080841064,4203.008229732513,27220,Daniel,192.168.152.36,4203.008229732513,0,89,8.03538990020752,89178,6756608,89178,6756608,-158.87991008907557,-169.21210058033466,-162.74230231841406,100.0,9,0,"[-163.5076039582491, -169.21210058033466, -163.12153916060925, -159.87924586236477, -162.154753819108, -162.94538602232933, -160.52441777288914, -164.45576360076666, -158.87991008907557]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1502112785785326,2.371285132558934,0.22432462738222242,2.9768634551727513,0.0,173.897,89178,6756608,89178,6756608,39.5041095890411,91.7794520547945,"[-163.5076039582491, -169.21210058033466, -163.12153916060925, -159.87924586236477, -162.154753819108, -162.94538602232933, -160.52441777288914, -164.45576360076666, -158.87991008907557]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1502112785785326,2.371285132558934,0.22432462738222242,2.9768634551727513,0.0
--156.73972097039223,-166.99343679845333,-160.53335815891623,100.0,10,0,3,0,0,90180,6842112,90180,6842112,1002,85504,90180,85504,90180,False,930,90,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-45-54,1675953954,56.28673553466797,4259.294965267181,27220,Daniel,192.168.152.36,4259.294965267181,0,90,8.03538990020752,90180,6842112,90180,6842112,-156.73972097039223,-166.99343679845333,-160.53335815891623,100.0,10,0,"[-159.25795275717974, -160.70894014835358, -163.50751739740372, -156.82570430636406, -158.63912008702755, -158.23399524390697, -166.99343679845333, -166.2922261506319, -156.73972097039223, -158.13496772944927]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1495080767806936,2.370609497461668,0.22403262125581666,2.9754040313494317,0.0,159.581,90180,6842112,90180,6842112,44.65,92.50128205128205,"[-159.25795275717974, -160.70894014835358, -163.50751739740372, -156.82570430636406, -158.63912008702755, -158.23399524390697, -166.99343679845333, -166.2922261506319, -156.73972097039223, -158.13496772944927]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1495080767806936,2.370609497461668,0.22403262125581666,2.9754040313494317,0.0
--157.62588857859373,-175.4449739009142,-165.10529938475653,100.0,11,0,3,0,0,91182,6927616,91182,6927616,1002,85504,91182,85504,91182,False,941,91,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-46-47,1675954007,52.957135915756226,4312.252101182938,27220,Daniel,192.168.152.36,4312.252101182938,0,91,8.03538990020752,91182,6927616,91182,6927616,-157.62588857859373,-175.4449739009142,-165.10529938475653,100.0,11,0,"[-173.59496247768402, -157.62588857859373, -163.65194728970528, -173.4839808344841, -163.4090384989977, -160.20602338016033, -158.4435018748045, -175.4449739009142, -158.57148788124323, -163.02650000154972, -168.69998851418495]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.151831271387451,2.374597188984983,0.22474329743525576,2.976213228665286,0.0,160.068,91182,6927616,91182,6927616,40.03287671232877,92.83561643835617,"[-173.59496247768402, -157.62588857859373, -163.65194728970528, -173.4839808344841, -163.4090384989977, -160.20602338016033, -158.4435018748045, -175.4449739009142, -158.57148788124323, -163.02650000154972, -168.69998851418495]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.151831271387451,2.374597188984983,0.22474329743525576,2.976213228665286,0.0
--156.71330001950264,-175.22207672894,-165.44531422439547,100.0,9,0,3,0,0,92184,7013120,92184,7013120,1002,85504,92184,85504,92184,False,950,92,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-47-40,1675954060,52.25436735153198,4364.50646853447,27220,Daniel,192.168.152.36,4364.50646853447,0,92,8.03538990020752,92184,7013120,92184,7013120,-156.71330001950264,-175.22207672894,-165.44531422439547,100.0,9,0,"[-165.96954829245806, -159.57600800693035, -167.9090326204896, -156.71330001950264, -175.22207672894, -165.48352535814047, -171.91609977185726, -164.62368296086788, -161.59455426037312]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1503810262489185,2.3722372279850514,0.22436720904887877,2.9723903036712906,0.0,153.792,92184,7013120,92184,7013120,38.668055555555554,93.0638888888889,"[-165.96954829245806, -159.57600800693035, -167.9090326204896, -156.71330001950264, -175.22207672894, -165.48352535814047, -171.91609977185726, -164.62368296086788, -161.59455426037312]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1503810262489185,2.3722372279850514,0.22436720904887877,2.9723903036712906,0.0
-238.12474328279495,-176.24535179138184,-125.79478149590167,91.54545454545455,11,0,3,0,0,93186,7098624,93186,7098624,1002,85504,93186,85504,93186,False,961,93,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-48-32,1675954112,52.6350040435791,4417.141472578049,27220,Daniel,192.168.152.36,4417.141472578049,0,93,8.03538990020752,93186,7098624,93186,7098624,238.12474328279495,-176.24535179138184,-125.79478149590167,91.54545454545455,11,0,"[-168.18348839879036, -156.66778661310673, -155.13520281016827, 238.12474328279495, -176.24535179138184, -161.23434637486935, -157.87939385324717, -169.99454993009567, -155.0685104727745, -158.8690266609192, -162.58968283236027]","[100, 100, 100, 7, 100, 100, 100, 100, 100, 100, 100]",1.1603782725080254,2.385702065161388,0.22589508560454455,2.986991892835226,0.0,152.447,93186,7098624,93186,7098624,39.330555555555556,92.93194444444444,"[-168.18348839879036, -156.66778661310673, -155.13520281016827, 238.12474328279495, -176.24535179138184, -161.23434637486935, -157.87939385324717, -169.99454993009567, -155.0685104727745, -158.8690266609192, -162.58968283236027]","[100, 100, 100, 7, 100, 100, 100, 100, 100, 100, 100]",1.1603782725080254,2.385702065161388,0.22589508560454455,2.986991892835226,0.0
--154.56762316077948,-178.36534713208675,-163.2691681749291,100.0,9,0,3,0,1,94187,7217152,94187,7217152,1001,118528,94187,118528,94187,False,970,94,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-50-00,1675954200,87.86418461799622,4505.005657196045,27220,Daniel,192.168.152.36,4505.005657196045,0,94,8.03538990020752,94187,7217152,94187,7217152,-154.56762316077948,-178.36534713208675,-163.2691681749291,100.0,9,0,"[-154.56762316077948, -157.97888205945492, -168.01060539484024, -155.74629651755095, -178.36534713208675, -160.69070971012115, -160.33285997062922, -173.4498615860939, -160.2803280428052]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2149404141522893,2.4628728493502248,0.23445714047499497,3.0789653348426285,0.0,150.844,94187,7217152,94187,7217152,54.59672131147541,93.40655737704918,"[-154.56762316077948, -157.97888205945492, -168.01060539484024, -155.74629651755095, -178.36534713208675, -160.69070971012115, -160.33285997062922, -173.4498615860939, -160.2803280428052]","[100, 100, 100, 100, 100, 100, 100, 100, 100]",1.2149404141522893,2.4628728493502248,0.23445714047499497,3.0789653348426285,0.0
--156.6723095625639,-192.23799195885658,-170.1869695238769,100.0,10,0,3,0,1,95189,7302656,95189,7302656,1002,85504,95189,85504,95189,False,980,95,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-50-54,1675954254,53.69957256317139,4558.705229759216,27220,Daniel,192.168.152.36,4558.705229759216,0,95,8.03538990020752,95189,7302656,95189,7302656,-156.6723095625639,-192.23799195885658,-170.1869695238769,100.0,10,0,"[-181.44102519750595, -159.14853070676327, -181.65320862829685, -156.6723095625639, -158.50095066428185, -192.23799195885658, -185.5121323019266, -162.85226867347956, -162.07650634646416, -161.77477119863033]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1583545836665539,2.359211233054439,0.22630920684336164,2.931337780849296,0.0,154.413,95189,7302656,95189,7302656,40.03918918918919,91.60945945945946,"[-181.44102519750595, -159.14853070676327, -181.65320862829685, -156.6723095625639, -158.50095066428185, -192.23799195885658, -185.5121323019266, -162.85226867347956, -162.07650634646416, -161.77477119863033]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1583545836665539,2.359211233054439,0.22630920684336164,2.931337780849296,0.0
--150.85336953401566,-189.18622064590454,-170.80289669409393,100.0,10,0,3,0,1,96191,7388160,96191,7388160,1002,85504,96191,85504,96191,False,990,96,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-51-47,1675954307,53.450644731521606,4612.155874490738,27220,Daniel,192.168.152.36,4612.155874490738,0,96,8.03538990020752,96191,7388160,96191,7388160,-150.85336953401566,-189.18622064590454,-170.80289669409393,100.0,10,0,"[-162.73517979681492, -179.5418940782547, -178.2555582523346, -178.4172960817814, -150.85336953401566, -189.18622064590454, -185.8527176976204, -161.5672971457243, -167.36814042925835, -154.2512932792306]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.161554194486781,2.375757882929913,0.22735235751034014,2.9422637459483254,0.0,153.424,96191,7388160,96191,7388160,39.78378378378379,91.25405405405405,"[-162.73517979681492, -179.5418940782547, -178.2555582523346, -178.4172960817814, -150.85336953401566, -189.18622064590454, -185.8527176976204, -161.5672971457243, -167.36814042925835, -154.2512932792306]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.161554194486781,2.375757882929913,0.22735235751034014,2.9422637459483254,0.0
--156.1826542466879,-191.28636541962624,-169.9554263330996,100.0,10,0,3,0,1,97193,7473664,97193,7473664,1002,85504,97193,85504,97193,False,1000,97,80340_00000,4d5d6cddaea7444681811f5901f7f828,2023-02-09_15-52-40,1675954360,52.549543619155884,4664.705418109894,27220,Daniel,192.168.152.36,4664.705418109894,0,97,8.03538990020752,97193,7473664,97193,7473664,-156.1826542466879,-191.28636541962624,-169.9554263330996,100.0,10,0,"[-156.1826542466879, -169.85423006117344, -162.02638640999794, -185.1279215067625, -186.65800455212593, -163.31539402902126, -191.28636541962624, -157.43947839736938, -171.26552772521973, -156.39830098301172]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1364653920600976,2.3486854601514455,0.22231085102003592,2.9007591400230686,0.0,161.318,97193,7473664,97193,7473664,39.38055555555556,91.3138888888889,"[-156.1826542466879, -169.85423006117344, -162.02638640999794, -185.1279215067625, -186.65800455212593, -163.31539402902126, -191.28636541962624, -157.43947839736938, -171.26552772521973, -156.39830098301172]","[100, 100, 100, 100, 100, 100, 100, 100, 100, 100]",1.1364653920600976,2.3486854601514455,0.22231085102003592,2.9007591400230686,0.0
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/result.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/result.json
deleted file mode 100644
index ce9f9fa..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/result.json
+++ /dev/null
@@ -1,97 +0,0 @@
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 1002, "num_env_steps_trained": 0, "num_agent_steps_sampled": 1002, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": -172.03659576177597, "episode_reward_min": -195.72291019558907, "episode_reward_mean": -188.20978297458754, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-195.72291019558907, -187.1162899285555, -190.60696797072887, -189.89828623831272, -190.89283438771963, -191.54977372288704, -189.29449943453074, -172.03659576177597, -186.7698891311884], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.427876296921156, "mean_inference_ms": 2.599548937669441, "mean_action_processing_ms": 0.2599483698754762, "mean_env_wait_ms": 3.5897183774122556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -172.03659576177597, "episode_reward_min": -195.72291019558907, "episode_reward_mean": -188.20978297458754, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-195.72291019558907, -187.1162899285555, -190.60696797072887, -189.89828623831272, -190.89283438771963, -191.54977372288704, -189.29449943453074, -172.03659576177597, -186.7698891311884], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.427876296921156, "mean_inference_ms": 2.599548937669441, "mean_action_processing_ms": 0.2599483698754762, "mean_env_wait_ms": 3.5897183774122556, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 1002, "num_agent_steps_trained": 0, "num_env_steps_sampled": 1002, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 1002, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 1002, "timers": {"training_iteration_time_ms": 11.747}, "counters": {"num_env_steps_sampled": 1002, "num_env_steps_trained": 0, "num_agent_steps_sampled": 1002, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 9, "training_iteration": 1, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-34-56", "timestamp": 1675949696, "time_this_iter_s": 5.359312057495117, "time_total_s": 5.359312057495117, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ab700>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3808eb80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 5.359312057495117, "timesteps_since_restore": 0, "iterations_since_restore": 1, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 77.2875, "ram_util_percent": 82.25}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 2004, "num_env_steps_trained": 0, "num_agent_steps_sampled": 2004, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 181.36450699716806, "episode_reward_min": -188.52998483181, "episode_reward_mean": -116.5225211687386, "episode_len_mean": 91.6, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.0414990633726, -181.82346287369728, -187.07104221731424, 181.36450699716806, -188.52998483181, -186.8800953477621, -183.72251315414906, 119.88127318024635, -168.5321788340807, -183.87021554261446], "episode_lengths": [100, 100, 100, 40, 100, 100, 100, 76, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3483278063558857, "mean_inference_ms": 2.4592295534051227, "mean_action_processing_ms": 0.24587505779636992, "mean_env_wait_ms": 3.358560185795942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 181.36450699716806, "episode_reward_min": -188.52998483181, "episode_reward_mean": -116.5225211687386, "episode_len_mean": 91.6, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-186.0414990633726, -181.82346287369728, -187.07104221731424, 181.36450699716806, -188.52998483181, -186.8800953477621, -183.72251315414906, 119.88127318024635, -168.5321788340807, -183.87021554261446], "episode_lengths": [100, 100, 100, 40, 100, 100, 100, 76, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3483278063558857, "mean_inference_ms": 2.4592295534051227, "mean_action_processing_ms": 0.24587505779636992, "mean_env_wait_ms": 3.358560185795942, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 2004, "num_agent_steps_trained": 0, "num_env_steps_sampled": 2004, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 2004, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 2004, "timers": {"training_iteration_time_ms": 15.164}, "counters": {"num_env_steps_sampled": 2004, "num_env_steps_trained": 0, "num_agent_steps_sampled": 2004, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 19, "training_iteration": 2, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-00", "timestamp": 1675949700, "time_this_iter_s": 4.41457462310791, "time_total_s": 9.773886680603027, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380930a0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde38127040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 9.773886680603027, "timesteps_since_restore": 0, "iterations_since_restore": 2, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 66.68333333333332, "ram_util_percent": 81.83333333333333}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 3006, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3006, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": -166.59257543087006, "episode_reward_min": -190.71805255115032, "episode_reward_mean": -183.2389093122699, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.16230046749115, -190.71805255115032, -186.63101022690535, -185.4745416790247, -189.33403262495995, -190.39464975893497, -187.7986584380269, -172.52650797367096, -182.9834259748459, -166.59257543087006, -177.0122473090887], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3246139718951833, "mean_inference_ms": 2.436714203481088, "mean_action_processing_ms": 0.23946076628844823, "mean_env_wait_ms": 3.264693760930233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -166.59257543087006, "episode_reward_min": -190.71805255115032, "episode_reward_mean": -183.2389093122699, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-186.16230046749115, -190.71805255115032, -186.63101022690535, -185.4745416790247, -189.33403262495995, -190.39464975893497, -187.7986584380269, -172.52650797367096, -182.9834259748459, -166.59257543087006, -177.0122473090887], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3246139718951833, "mean_inference_ms": 2.436714203481088, "mean_action_processing_ms": 0.23946076628844823, "mean_env_wait_ms": 3.264693760930233, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3006, "num_agent_steps_trained": 0, "num_env_steps_sampled": 3006, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 3006, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 3006, "timers": {"training_iteration_time_ms": 23.176}, "counters": {"num_env_steps_sampled": 3006, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3006, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 30, "training_iteration": 3, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-05", "timestamp": 1675949705, "time_this_iter_s": 4.316670894622803, "time_total_s": 14.09055757522583, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a580>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac550>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 14.09055757522583, "timesteps_since_restore": 0, "iterations_since_restore": 3, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 65.94285714285714, "ram_util_percent": 82.0}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 4008, "num_env_steps_trained": 0, "num_agent_steps_sampled": 4008, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": -178.81081108748913, "episode_reward_min": -189.48420125246048, "episode_reward_mean": -184.38521087418, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.48420125246048, -179.4162740111351, -178.81081108748913, -185.32138426601887, -185.3411936312914, -187.57649797201157, -181.8119632154703, -186.94552153348923, -184.75905089825392], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3515723967189595, "mean_inference_ms": 2.523937655695951, "mean_action_processing_ms": 0.25009217330031014, "mean_env_wait_ms": 3.3161904086082306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -178.81081108748913, "episode_reward_min": -189.48420125246048, "episode_reward_mean": -184.38521087418, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.48420125246048, -179.4162740111351, -178.81081108748913, -185.32138426601887, -185.3411936312914, -187.57649797201157, -181.8119632154703, -186.94552153348923, -184.75905089825392], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3515723967189595, "mean_inference_ms": 2.523937655695951, "mean_action_processing_ms": 0.25009217330031014, "mean_env_wait_ms": 3.3161904086082306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 4008, "num_agent_steps_trained": 0, "num_env_steps_sampled": 4008, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 4008, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 4008, "timers": {"training_iteration_time_ms": 18.62}, "counters": {"num_env_steps_sampled": 4008, "num_env_steps_trained": 0, "num_agent_steps_sampled": 4008, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 39, "training_iteration": 4, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-10", "timestamp": 1675949710, "time_this_iter_s": 5.069538831710815, "time_total_s": 19.160096406936646, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805aaf0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 19.160096406936646, "timesteps_since_restore": 0, "iterations_since_restore": 4, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 73.22857142857141, "ram_util_percent": 82.17142857142856}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 5010, "num_env_steps_trained": 0, "num_agent_steps_sampled": 5010, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": -160.33254747092724, "episode_reward_min": -195.33662481606007, "episode_reward_mean": -183.9175837755203, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-195.33662481606007, -192.1119733080268, -160.33254747092724, -185.65166425704956, -182.5882617160678, -191.72356040775776, -171.65736323595047, -183.66383278369904, -191.31481182575226, -184.79519793391228], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3377852385661904, "mean_inference_ms": 2.473846600485162, "mean_action_processing_ms": 0.24650890195105762, "mean_env_wait_ms": 3.2866380230385976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -160.33254747092724, "episode_reward_min": -195.33662481606007, "episode_reward_mean": -183.9175837755203, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-195.33662481606007, -192.1119733080268, -160.33254747092724, -185.65166425704956, -182.5882617160678, -191.72356040775776, -171.65736323595047, -183.66383278369904, -191.31481182575226, -184.79519793391228], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3377852385661904, "mean_inference_ms": 2.473846600485162, "mean_action_processing_ms": 0.24650890195105762, "mean_env_wait_ms": 3.2866380230385976, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 5010, "num_agent_steps_trained": 0, "num_env_steps_sampled": 5010, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 5010, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 5010, "timers": {"training_iteration_time_ms": 12.028}, "counters": {"num_env_steps_sampled": 5010, "num_env_steps_trained": 0, "num_agent_steps_sampled": 5010, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 49, "training_iteration": 5, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-14", "timestamp": 1675949714, "time_this_iter_s": 4.382728338241577, "time_total_s": 23.542824745178223, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805afd0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac4c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 23.542824745178223, "timesteps_since_restore": 0, "iterations_since_restore": 5, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 69.1, "ram_util_percent": 82.26666666666667}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 6012, "num_env_steps_trained": 0, "num_agent_steps_sampled": 6012, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 139.6858552545309, "episode_reward_min": -196.0045984685421, "episode_reward_mean": -156.94192648244402, "episode_len_mean": 96.75, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.58302499353886, -184.5064988285303, -187.74731319397688, -181.47071016579866, -183.56445981562138, -196.0045984685421, -190.47504161298275, 139.6858552545309, -188.03654915094376, -171.9393027573824, -181.4177524521947, -168.24372160434723], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 61, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3299502834913044, "mean_inference_ms": 2.4597411738369526, "mean_action_processing_ms": 0.2425731665277521, "mean_env_wait_ms": 3.2661979830671335, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 139.6858552545309, "episode_reward_min": -196.0045984685421, "episode_reward_mean": -156.94192648244402, "episode_len_mean": 96.75, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.58302499353886, -184.5064988285303, -187.74731319397688, -181.47071016579866, -183.56445981562138, -196.0045984685421, -190.47504161298275, 139.6858552545309, -188.03654915094376, -171.9393027573824, -181.4177524521947, -168.24372160434723], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 61, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3299502834913044, "mean_inference_ms": 2.4597411738369526, "mean_action_processing_ms": 0.2425731665277521, "mean_env_wait_ms": 3.2661979830671335, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 6012, "num_agent_steps_trained": 0, "num_env_steps_sampled": 6012, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 6012, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 6012, "timers": {"training_iteration_time_ms": 12.158}, "counters": {"num_env_steps_sampled": 6012, "num_env_steps_trained": 0, "num_agent_steps_sampled": 6012, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 61, "training_iteration": 6, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-19", "timestamp": 1675949719, "time_this_iter_s": 4.379156827926636, "time_total_s": 27.92198157310486, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2550>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b670>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 27.92198157310486, "timesteps_since_restore": 0, "iterations_since_restore": 6, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 65.83333333333334, "ram_util_percent": 82.35000000000001}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 7014, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7014, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 196.41344634443521, "episode_reward_min": -190.28570076823235, "episode_reward_mean": -143.89437042698265, "episode_len_mean": 93.4, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-190.12851731479168, -169.1818624585867, -190.28570076823235, -175.12801945209503, -181.12022495269775, -183.9177276864648, 196.41344634443521, -185.67551515996456, -183.3443570137024, -176.57522580772638], "episode_lengths": [100, 100, 100, 100, 100, 100, 34, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3077645283471118, "mean_inference_ms": 2.4002063880878004, "mean_action_processing_ms": 0.23739599885977242, "mean_env_wait_ms": 3.2092160065493145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 196.41344634443521, "episode_reward_min": -190.28570076823235, "episode_reward_mean": -143.89437042698265, "episode_len_mean": 93.4, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-190.12851731479168, -169.1818624585867, -190.28570076823235, -175.12801945209503, -181.12022495269775, -183.9177276864648, 196.41344634443521, -185.67551515996456, -183.3443570137024, -176.57522580772638], "episode_lengths": [100, 100, 100, 100, 100, 100, 34, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.3077645283471118, "mean_inference_ms": 2.4002063880878004, "mean_action_processing_ms": 0.23739599885977242, "mean_env_wait_ms": 3.2092160065493145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 7014, "num_agent_steps_trained": 0, "num_env_steps_sampled": 7014, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 7014, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 7014, "timers": {"training_iteration_time_ms": 12.716}, "counters": {"num_env_steps_sampled": 7014, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7014, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 71, "training_iteration": 7, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-23", "timestamp": 1675949723, "time_this_iter_s": 3.9633991718292236, "time_total_s": 31.885380744934082, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2940>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac550>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 31.885380744934082, "timesteps_since_restore": 0, "iterations_since_restore": 7, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 62.88333333333333, "ram_util_percent": 82.39999999999999}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 8016, "num_env_steps_trained": 0, "num_agent_steps_sampled": 8016, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 210.6578472852707, "episode_reward_min": -189.2391362041235, "episode_reward_mean": -143.9040757663548, "episode_len_mean": 92.3, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-188.13962118327618, -188.73138186335564, -184.52830079942942, -166.40105326473713, -185.9469074010849, -177.44468593597412, -184.1500248014927, 210.6578472852707, -189.2391362041235, -185.11749349534512], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 23, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2881654859971698, "mean_inference_ms": 2.3555338449617294, "mean_action_processing_ms": 0.23198582641738566, "mean_env_wait_ms": 3.1648960802111783, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 210.6578472852707, "episode_reward_min": -189.2391362041235, "episode_reward_mean": -143.9040757663548, "episode_len_mean": 92.3, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-188.13962118327618, -188.73138186335564, -184.52830079942942, -166.40105326473713, -185.9469074010849, -177.44468593597412, -184.1500248014927, 210.6578472852707, -189.2391362041235, -185.11749349534512], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 23, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2881654859971698, "mean_inference_ms": 2.3555338449617294, "mean_action_processing_ms": 0.23198582641738566, "mean_env_wait_ms": 3.1648960802111783, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8016, "num_agent_steps_trained": 0, "num_env_steps_sampled": 8016, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 8016, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 8016, "timers": {"training_iteration_time_ms": 11.496}, "counters": {"num_env_steps_sampled": 8016, "num_env_steps_trained": 0, "num_agent_steps_sampled": 8016, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 81, "training_iteration": 8, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-27", "timestamp": 1675949727, "time_this_iter_s": 3.8648064136505127, "time_total_s": 35.750187158584595, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb910>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ba280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 35.750187158584595, "timesteps_since_restore": 0, "iterations_since_restore": 8, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 61.51666666666667, "ram_util_percent": 82.5}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {}, "num_env_steps_sampled": 9018, "num_env_steps_trained": 0, "num_agent_steps_sampled": 9018, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 77.90451084077358, "episode_reward_min": -194.82577526569366, "episode_reward_mean": -163.0946609432047, "episode_len_mean": 99.9090909090909, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-188.0968882739544, -188.9403100013733, -174.04480615258217, -194.82577526569366, -183.58984605967999, -190.4420650601387, 77.90451084077358, -186.39500673115253, -184.86948497593403, -190.73766081035137, -190.00393788516521], "episode_lengths": [100, 100, 100, 100, 100, 100, 99, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2782163796158317, "mean_inference_ms": 2.326747967981566, "mean_action_processing_ms": 0.22898460741317284, "mean_env_wait_ms": 3.134211638452612, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 77.90451084077358, "episode_reward_min": -194.82577526569366, "episode_reward_mean": -163.0946609432047, "episode_len_mean": 99.9090909090909, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-188.0968882739544, -188.9403100013733, -174.04480615258217, -194.82577526569366, -183.58984605967999, -190.4420650601387, 77.90451084077358, -186.39500673115253, -184.86948497593403, -190.73766081035137, -190.00393788516521], "episode_lengths": [100, 100, 100, 100, 100, 100, 99, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2782163796158317, "mean_inference_ms": 2.326747967981566, "mean_action_processing_ms": 0.22898460741317284, "mean_env_wait_ms": 3.134211638452612, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 9018, "num_agent_steps_trained": 0, "num_env_steps_sampled": 9018, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 0, "timesteps_total": 9018, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 9018, "timers": {"training_iteration_time_ms": 11.428}, "counters": {"num_env_steps_sampled": 9018, "num_env_steps_trained": 0, "num_agent_steps_sampled": 9018, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 92, "training_iteration": 9, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-30", "timestamp": 1675949730, "time_this_iter_s": 3.912569999694824, "time_total_s": 39.66275715827942, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbd60>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3808ef70>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 39.66275715827942, "timesteps_since_restore": 0, "iterations_since_restore": 9, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 61.86, "ram_util_percent": 82.5}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.365665435791016, "actor_loss": -3.411156177520752, "critic_loss": 0.2495899796485901, "alpha_loss": -0.015058223158121109, "alpha_value": 0.9982016086578369, "log_alpha_value": -0.0018000031122937799, "target_entropy": -5.0, "policy_t": 0.020382240414619446, "mean_q": 0.06157306209206581, "max_q": 0.09083694219589233, "min_q": 0.00958795566111803}, "td_error": [1.3185367584228516, 1.2280157804489136, 1.4065968990325928, 1.7010862827301025, 0.4197019934654236, 1.087616205215454, 1.7405219078063965, 1.3288644552230835, 2.9003963470458984, 1.3851890563964844, 1.2215750217437744, 0.6947187781333923, 1.4812591075897217, 1.2177960872650146, 1.2101038694381714, 0.8059608340263367, 0.9576714038848877, 0.6693849563598633, 1.546180009841919, 0.7461481094360352, 1.5402195453643799, 1.99819016456604, 0.3833698034286499, 1.4670686721801758, 1.8911620378494263, 0.4032559394836426, 0.7525947690010071, 1.1940172910690308, 1.370521068572998, 2.567263126373291, 1.959290623664856, 1.03787362575531, 1.5003838539123535, 2.1481575965881348, 1.4019629955291748, 0.8060194849967957, 1.3350443840026855, 2.8280482292175293, 1.9701075553894043, 0.9403769969940186, 1.7149336338043213, 1.1523933410644531, 2.1020450592041016, 1.6078869104385376, 1.6996955871582031, 0.6570667028427124, 0.6902530193328857, 1.00625479221344, 0.7693280577659607, 1.8954253196716309, 0.6487562656402588, 1.5537142753601074, 1.3812003135681152, 0.4858476221561432, 2.1275711059570312, 0.7487964630126953, 1.518225908279419, 1.3383855819702148, 1.884366750717163, 1.2956912517547607, 1.695961833000183, 0.8640455007553101, 2.6894187927246094, 2.522029161453247, 2.06387996673584, 1.3247592449188232, 1.4389550685882568, 0.7676127552986145, 0.9943188428878784, 2.687204360961914, 1.7416446208953857, 2.0075502395629883, 1.3065543174743652, 0.8251889944076538, 1.8459111452102661, 1.1573503017425537, 1.4612773656845093, 2.4079010486602783, 1.176494836807251, 1.3147850036621094, 0.7392984628677368, 2.170764684677124, 0.6582323312759399, 2.24416446685791, 1.8237969875335693, 2.378964424133301, 2.378892421722412, 2.4742579460144043, 2.2580134868621826, 0.6986127495765686, 1.697399616241455, 1.340524435043335, 1.1119681596755981, 2.0811026096343994, 1.289820909500122, 2.121999502182007, 1.537924885749817, 1.9541330337524414, 0.9136663675308228, 1.5466228723526, 1.5908849239349365, 1.4810407161712646, 2.93221116065979, 0.6205251216888428, 1.1943747997283936, 1.299978494644165, 0.5129227638244629, 0.5236935615539551, 2.193760395050049, 1.481729507446289, 1.4441962242126465, 1.2625131607055664, 0.9757746458053589, 2.3994498252868652, 1.1483968496322632, 0.7261057496070862, 0.7626340389251709, 2.1854004859924316, 1.8405258655548096, 1.3124213218688965, 1.3189525604248047, 1.1892831325531006, 2.481365203857422, 0.41432440280914307, 1.7341798543930054, 2.7099528312683105, 0.4057821035385132, 2.1424977779388428, 2.6682991981506348, 0.5400500297546387, 0.04188734292984009, 1.005199909210205, 1.072239875793457, 1.1332874298095703, 1.832565188407898, 2.0778210163116455, 1.7059228420257568, 1.0169954299926758, 1.0597994327545166, 0.5924985408782959, 1.5275602340698242, 1.8389976024627686, 2.147923707962036, 0.3922009766101837, 1.5644068717956543, 0.8111405372619629, 0.8878360986709595, 0.07274813950061798, 1.2676472663879395, 1.6115121841430664, 2.8559999465942383, 1.450704574584961, 1.7390116453170776, 1.4585552215576172, 2.3065414428710938, 0.9582952260971069, 2.9556667804718018, 2.007136106491089, 1.489963173866272, 0.6115288734436035, 1.3705687522888184, 2.5587387084960938, 1.086707353591919, 0.3630583584308624, 0.5671560764312744, 2.197035551071167, 2.4592552185058594, 2.017704486846924, 1.0779021978378296, 1.8146697282791138, 1.3516602516174316, 1.6818374395370483, 0.07810600101947784, 0.6118909120559692, 3.473689556121826, 2.2183971405029297, 2.075593948364258, 1.7959728240966797, 1.2928191423416138, 1.8903394937515259, 0.9675636291503906, 2.4538822174072266, 1.7024915218353271, 2.2276201248168945, 1.5036015510559082, 1.2774267196655273, 1.2227476835250854, 0.8193143606185913, 1.7804131507873535, 2.257645606994629, 1.0488816499710083, 1.9774651527404785, 1.4600002765655518, 0.4529704451560974, 1.420897126197815, 0.9410004019737244, 1.1671597957611084, 0.575869083404541, 2.0785117149353027, 1.1935429573059082, 1.7373757362365723, 1.500403881072998, 0.677668571472168, 0.7031981945037842, 0.829198956489563, 2.4151086807250977, 1.4933525323867798, 1.899132251739502, 1.4723503589630127, 0.9485198855400085, 0.8394956588745117, 1.833927869796753, 1.8354902267456055, 2.2097058296203613, 0.692946195602417, 2.6271512508392334, 2.470083236694336, 1.3667829036712646, 2.6886141300201416, 2.1937055587768555, 1.5060956478118896, 1.159076452255249, 1.3008570671081543, 0.9887397289276123, 0.4364650249481201, 0.3249785006046295, 2.267460346221924, 2.5179028511047363, 0.9769163131713867, 0.40560516715049744, 0.9984363317489624, 0.08509281277656555, 0.7031269669532776, 2.6658544540405273, 2.1298398971557617, 1.8475816249847412, 2.279758930206299, 1.4530603885650635, 1.089623212814331, 0.8706256151199341, 1.1558632850646973, 1.9458458423614502, 1.9266917705535889, 0.8123155832290649, 0.6360049247741699, 0.6736932992935181, 1.988769292831421, 1.4610872268676758, 1.2595502138137817, 1.88081693649292, 2.129823684692383, 2.458590030670166, 2.2027788162231445, 0.9022721648216248, 1.4231376647949219, 0.4274405241012573], "mean_td_error": 1.4600703716278076, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 7.0, "diff_num_grad_updates_vs_sampler_policy": 6.0}}, "num_env_steps_sampled": 10020, "num_env_steps_trained": 1792, "num_agent_steps_sampled": 10020, "num_agent_steps_trained": 1792, "last_target_update_ts": 10020, "num_target_updates": 7}, "sampler_results": {"episode_reward_max": 116.67252637445927, "episode_reward_min": -192.85324969142675, "episode_reward_mean": -154.39962305948137, "episode_len_mean": 97.3, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.45449054986238, -185.60987342894077, 116.67252637445927, -188.42734596133232, -182.72036488354206, -184.69620841741562, -192.85324969142675, -185.26639138907194, -177.13239042460918, -189.50844222307205], "episode_lengths": [100, 100, 73, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2687550729993073, "mean_inference_ms": 2.304896534791573, "mean_action_processing_ms": 0.22676882362765344, "mean_env_wait_ms": 3.106975455513903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 116.67252637445927, "episode_reward_min": -192.85324969142675, "episode_reward_mean": -154.39962305948137, "episode_len_mean": 97.3, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-174.45449054986238, -185.60987342894077, 116.67252637445927, -188.42734596133232, -182.72036488354206, -184.69620841741562, -192.85324969142675, -185.26639138907194, -177.13239042460918, -189.50844222307205], "episode_lengths": [100, 100, 73, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2687550729993073, "mean_inference_ms": 2.304896534791573, "mean_action_processing_ms": 0.22676882362765344, "mean_env_wait_ms": 3.106975455513903, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 10020, "num_agent_steps_trained": 1792, "num_env_steps_sampled": 10020, "num_env_steps_trained": 1792, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 1792, "timesteps_total": 10020, "num_steps_trained_this_iter": 1792, "agent_timesteps_total": 10020, "timers": {"training_iteration_time_ms": 110.046, "load_time_ms": 0.254, "load_throughput": 1008614.166, "learn_time_ms": 27.281, "learn_throughput": 9383.851, "synch_weights_time_ms": 6.972}, "counters": {"num_env_steps_sampled": 10020, "num_env_steps_trained": 1792, "num_agent_steps_sampled": 10020, "num_agent_steps_trained": 1792, "last_target_update_ts": 10020, "num_target_updates": 7}, "done": false, "episodes_total": 102, "training_iteration": 10, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-35-36", "timestamp": 1675949736, "time_this_iter_s": 5.076626777648926, "time_total_s": 44.739383935928345, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2070>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 44.739383935928345, "timesteps_since_restore": 0, "iterations_since_restore": 10, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 58.837500000000006, "ram_util_percent": 82.1375}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.398829460144043, "actor_loss": -5.026538848876953, "critic_loss": 0.847157895565033, "alpha_loss": -0.8564916253089905, "alpha_value": 0.903049886226654, "log_alpha_value": -0.10197750478982925, "target_entropy": -5.0, "policy_t": -0.003639528062194586, "mean_q": 2.0263235569000244, "max_q": 2.739400625228882, "min_q": 0.7679574489593506}, "td_error": [0.6585747003555298, 0.8738628625869751, 0.7065528631210327, 0.8189159035682678, 0.608775794506073, 0.2830398678779602, 0.6464482545852661, 0.46962153911590576, 3.7901523113250732, 0.5683779716491699, 0.9397041201591492, 0.9055530428886414, 0.7351264357566833, 1.0670777559280396, 0.8128513097763062, 246.68960571289062, 0.5370097160339355, 1.4318623542785645, 246.4784698486328, 0.31215059757232666, 0.4367717504501343, 246.54556274414062, 0.6192935705184937, 0.7037096619606018, 0.5938444137573242, 0.1642380952835083, 246.29251098632812, 0.2546536922454834, 0.35511696338653564, 3.740342140197754, 0.23417586088180542, 0.6552184224128723, 0.5999836921691895, 1.0036680698394775, 0.19231045246124268, 0.2518528699874878, 0.20438319444656372, 1.2288167476654053, 1.974305510520935, 0.6848703622817993, 1.1005570888519287, 0.4326881170272827, 0.4214656352996826, 0.6522160768508911, 0.18710029125213623, 0.6093077659606934, 0.5145235657691956, 4.19765043258667, 246.52996826171875, 1.337580680847168, 0.9632208943367004, 4.154871940612793, 0.641913652420044, 0.7683653831481934, 0.06333029270172119, 0.5571757555007935, 0.0957748293876648, 1.0807746648788452, 246.9417724609375, 1.335484266281128, 0.7924790382385254, 0.8935057520866394, 0.5379564762115479, 246.29251098632812, 0.6014651656150818, 0.37868499755859375, 0.977074921131134, 1.0552515983581543, 0.3956303000450134, 0.9542779326438904, 0.3440355658531189, 0.9238750338554382, 0.44185125827789307, 0.9748650193214417, 0.6420082449913025, 0.3368028402328491, 0.07465153932571411, 0.45881152153015137, 0.21106880903244019, 0.28888118267059326, 0.48004651069641113, 0.05078482627868652, 0.053395867347717285, 0.02935999631881714, 0.2865774631500244, 0.12331390380859375, 0.22021901607513428, 0.43918275833129883, 246.52996826171875, 0.34504449367523193, 3.177401542663574, 0.3518049716949463, 0.6921061277389526, 0.259324312210083, 0.938307523727417, 1.2188880443572998, 0.636826753616333, 1.4724239110946655, 0.09122788906097412, 0.3132900595664978, 4.025937080383301, 0.47054576873779297, 3.148301124572754, 0.5473413467407227, 0.49328315258026123, 0.03423595428466797, 0.9580258131027222, 0.8400509357452393, 0.394437313079834, 0.9570180773735046, 0.9166032075881958, 0.9277191758155823, 0.5845875144004822, 0.5317416191101074, 0.4739120602607727, 0.5430521368980408, 0.33305323123931885, 1.3671009540557861, 0.2251523733139038, 0.5494860410690308, 0.5876561403274536, 0.5904028415679932, 0.8228887319564819, 0.28215324878692627, 0.09560286998748779, 0.20837390422821045, 0.2865253686904907, 246.29251098632812, 1.1162855625152588, 0.7025413513183594, 0.6376149654388428, 0.048253417015075684, 4.206428527832031, 0.9872683882713318, 0.7221412658691406, 0.46220219135284424, 0.4057309627532959, 0.875106930732727, 0.3496384620666504, 0.282085657119751, 3.4099349975585938, 0.33291077613830566, 0.5405759811401367, 0.3390401005744934, 246.68960571289062, 0.7609761953353882, 1.1458861827850342, 0.8092429041862488, 0.5773850679397583, 0.6608290076255798, 1.3483357429504395, 3.835315704345703, 246.9417724609375, 0.5774635672569275, 0.37658828496932983, 0.6775052547454834, 0.49700605869293213, 0.7010231018066406, 0.7747977375984192, 0.3735259771347046, 0.11033451557159424, 0.566450834274292, 0.08573687076568604, 0.7109018564224243, 0.10659289360046387, 0.9238723516464233, 0.17580902576446533, 1.0095140933990479, 0.26109880208969116, 0.2925642728805542, 0.6916924715042114, 0.5619228482246399, 1.0427626371383667, 0.384321928024292, 4.258707046508789, 0.3500481843948364, 0.2079932689666748, 0.6486891508102417, 0.5645790696144104, 0.5677523612976074, 246.4784698486328, 0.6529325246810913, 0.3638269305229187, 0.7814075350761414, 0.44039493799209595, 0.612364649772644, 1.0106279850006104, 246.29251098632812, 0.13217198848724365, 0.5332459211349487, 1.0567586421966553, 0.8452528715133667, 0.47799623012542725, 0.4635199308395386, 0.5918866395950317, 1.6720306873321533, 0.500644326210022, 1.0052671432495117, 0.8716051578521729, 3.928730010986328, 0.6645305156707764, 0.6780260801315308, 0.7712103128433228, 0.5758968591690063, 0.8007698059082031, 0.7464066743850708, 1.0206446647644043, 1.0946033000946045, 3.115699291229248, 0.949699878692627, 0.6192659139633179, 246.52996826171875, 246.79458618164062, 0.6943017840385437, 0.7680536508560181, 0.8182655572891235, 0.821963906288147, 0.6529991030693054, 0.4051826000213623, 0.6223673820495605, 0.7762800455093384, 0.867861270904541, 0.685678243637085, 0.14251351356506348, 0.9404348731040955, 1.2954351902008057, 0.7258179187774658, 0.4077674150466919, 0.5034986734390259, 0.6240147948265076, 0.18284523487091064, 246.54556274414062, 0.6268342733383179, 0.5067070722579956, 0.5986496210098267, 0.13385093212127686, 0.0749552845954895, 0.1340709924697876, 1.2665677070617676, 0.0737500786781311, 0.41878068447113037, 3.177401542663574, 0.21964585781097412, 0.10980868339538574, 0.6604099273681641, 1.1179386377334595, 0.577418863773346, 0.8069130182266235, 0.062285542488098145, 0.4691990613937378, 0.6429939866065979, 0.5110169649124146, 0.5621175765991211, 0.6325368881225586, 0.45218563079833984, 0.09978508949279785], "mean_td_error": 16.14298439025879, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 341.0, "diff_num_grad_updates_vs_sampler_policy": 340.0}}, "num_env_steps_sampled": 11022, "num_env_steps_trained": 87296, "num_agent_steps_sampled": 11022, "num_agent_steps_trained": 87296, "last_target_update_ts": 11022, "num_target_updates": 341}, "sampler_results": {"episode_reward_max": 216.8899323642254, "episode_reward_min": -192.72066298127174, "episode_reward_mean": -145.74130786880852, "episode_len_mean": 91.8, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-186.25547470152378, 216.8899323642254, -192.72066298127174, -188.17130488157272, -189.20812480151653, -184.5493537336588, -176.92795492708683, -189.55872742831707, -184.22501057386398, -182.686397023499], "episode_lengths": [100, 18, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2638436207154984, "mean_inference_ms": 2.3208301699891387, "mean_action_processing_ms": 0.22811111138791457, "mean_env_wait_ms": 3.0926660485819086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 216.8899323642254, "episode_reward_min": -192.72066298127174, "episode_reward_mean": -145.74130786880852, "episode_len_mean": 91.8, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-186.25547470152378, 216.8899323642254, -192.72066298127174, -188.17130488157272, -189.20812480151653, -184.5493537336588, -176.92795492708683, -189.55872742831707, -184.22501057386398, -182.686397023499], "episode_lengths": [100, 18, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2638436207154984, "mean_inference_ms": 2.3208301699891387, "mean_action_processing_ms": 0.22811111138791457, "mean_env_wait_ms": 3.0926660485819086, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 11022, "num_agent_steps_trained": 87296, "num_env_steps_sampled": 11022, "num_env_steps_trained": 87296, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 11022, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 11022, "timers": {"training_iteration_time_ms": 150.498, "load_time_ms": 0.291, "load_throughput": 880621.524, "learn_time_ms": 24.989, "learn_throughput": 10244.426, "synch_weights_time_ms": 5.868}, "counters": {"num_env_steps_sampled": 11022, "num_env_steps_trained": 87296, "num_agent_steps_sampled": 11022, "num_agent_steps_trained": 87296, "last_target_update_ts": 11022, "num_target_updates": 341}, "done": false, "episodes_total": 112, "training_iteration": 11, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-36-28", "timestamp": 1675949788, "time_this_iter_s": 51.98261213302612, "time_total_s": 96.72199606895447, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2970>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde38127040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 96.72199606895447, "timesteps_since_restore": 0, "iterations_since_restore": 11, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.026760563380286, "ram_util_percent": 82.74647887323943}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.433147430419922, "actor_loss": -5.7090559005737305, "critic_loss": 0.46832334995269775, "alpha_loss": -1.7051738500595093, "alpha_value": 0.8169323801994324, "log_alpha_value": -0.20219895243644714, "target_entropy": -5.0, "policy_t": -0.00027922019944526255, "mean_q": 2.9561119079589844, "max_q": 3.5262773036956787, "min_q": 2.3523964881896973}, "td_error": [0.3999365568161011, 0.40118420124053955, 0.5210956335067749, 0.2879246473312378, 0.415818452835083, 0.024892330169677734, 0.7695763111114502, 0.6351369619369507, 0.06635880470275879, 0.2660050392150879, 0.7141258716583252, 0.5599365234375, 0.4290189743041992, 0.5600886344909668, 0.06131720542907715, 1.0962077379226685, 5.3343963623046875, 0.26830148696899414, 0.287847638130188, 0.7013128995895386, 0.48451685905456543, 0.16229331493377686, 0.5317308902740479, 0.46505141258239746, 245.39500427246094, 0.2977713346481323, 0.6708109378814697, 0.8108500242233276, 0.20673561096191406, 0.8376915454864502, 1.2506906986236572, 0.582744836807251, 0.3297145366668701, 0.8426485061645508, 0.7248913049697876, 0.6437532901763916, 0.3909783363342285, 0.23024678230285645, 0.35397279262542725, 0.25475072860717773, 0.5171053409576416, 0.7692753076553345, 0.4930546283721924, 0.7254759073257446, 0.350536584854126, 245.46090698242188, 1.0215624570846558, 0.05503106117248535, 0.3439154624938965, 0.4328348636627197, 0.8295625448226929, 0.20258963108062744, 0.2451937198638916, 0.5012874603271484, 0.322163462638855, 0.2446519136428833, 0.30683255195617676, 0.48079705238342285, 0.48673009872436523, 0.3677171468734741, 0.1108248233795166, 0.4310561418533325, 0.15088605880737305, 0.5142122507095337, 0.15298223495483398, 0.3501756191253662, 0.41176462173461914, 0.2842649221420288, 5.028299331665039, 0.4651089906692505, 1.2069988250732422, 0.3876609802246094, 4.203792572021484, 0.5444929599761963, 0.6529301404953003, 0.2888585329055786, 0.403220534324646, 0.4467560052871704, 0.04807710647583008, 0.2993718385696411, 0.9362049102783203, 0.46456682682037354, 0.38542449474334717, 0.2638043165206909, 0.6756594181060791, 0.5111292600631714, 0.22219598293304443, 0.14594244956970215, 0.4621307849884033, 0.6297709941864014, 0.6541903018951416, 245.49737548828125, 0.2680811882019043, 0.5222294330596924, 245.51641845703125, 1.131527304649353, 0.7226384878158569, 0.6572524309158325, 0.7069176435470581, 0.5204496383666992, 0.5710692405700684, 0.6784470081329346, 0.22626423835754395, 0.2581157684326172, 0.7417401075363159, 0.6173702478408813, 0.46953368186950684, 0.3869267702102661, 0.42597150802612305, 0.45235109329223633, 0.6549859046936035, 0.542108416557312, 0.45595085620880127, 0.03418231010437012, 0.5655643939971924, 0.545941948890686, 0.6344350576400757, 0.59710693359375, 0.3986164331436157, 0.5371958017349243, 0.17324376106262207, 0.46150195598602295, 0.4458143711090088, 3.959343910217285, 0.33980274200439453, 0.7946399450302124, 0.572190523147583, 0.4601658582687378, 4.4752702713012695, 1.0785144567489624, 0.5301611423492432, 0.26884710788726807, 0.41536879539489746, 0.2818593978881836, 0.7081894874572754, 0.26928794384002686, 0.15209925174713135, 0.6242311000823975, 0.34108638763427734, 0.9132344722747803, 0.5005534887313843, 0.29855430126190186, 0.11918604373931885, 0.9876182079315186, 0.40550971031188965, 0.7174063920974731, 0.21954619884490967, 0.41101670265197754, 0.37355566024780273, 0.1926708221435547, 0.4877370595932007, 0.4692724943161011, 245.7100830078125, 0.4155036211013794, 0.2912241220474243, 0.5858032703399658, 0.8126416206359863, 0.9861102104187012, 4.219021320343018, 0.03693723678588867, 245.46090698242188, 0.629233717918396, 0.141990065574646, 0.07070517539978027, 0.6306426525115967, 0.2747753858566284, 0.36010265350341797, 0.7675372362136841, 0.30640602111816406, 0.4533909559249878, 0.07568526268005371, 0.13847756385803223, 0.4299652576446533, 0.29236364364624023, 0.7546699047088623, 5.195793628692627, 0.2928274869918823, 0.13083624839782715, 0.721359133720398, 0.3377114534378052, 0.003538370132446289, 0.37301599979400635, 0.6557909250259399, 1.1284077167510986, 0.26849234104156494, 0.22594666481018066, 0.6059865951538086, 0.16212105751037598, 0.05048251152038574, 245.5517120361328, 0.6838512420654297, 1.423526644706726, 0.5392265319824219, 0.27261126041412354, 5.1266937255859375, 0.29356157779693604, 0.28036069869995117, 0.05984222888946533, 0.4820307493209839, 0.033699989318847656, 0.03592526912689209, 4.310914039611816, 0.7147265672683716, 0.6889915466308594, 0.459192156791687, 0.5573059320449829, 0.34707844257354736, 0.5592144727706909, 0.18258702754974365, 0.30176258087158203, 1.956089973449707, 0.9454605579376221, 0.2429804801940918, 0.5996894836425781, 0.8373959064483643, 0.6543208360671997, 0.5994621515274048, 0.2829643487930298, 0.25340843200683594, 0.13629496097564697, 245.7100830078125, 0.25788378715515137, 0.046476006507873535, 0.7469203472137451, 0.6130238771438599, 0.161687970161438, 0.6346191167831421, 0.10217571258544922, 0.3722686767578125, 0.34253156185150146, 5.3343963623046875, 0.7266737222671509, 0.6061367988586426, 0.8684340715408325, 0.694420576095581, 0.4200059175491333, 0.6615173816680908, 4.644852638244629, 0.3389155864715576, 0.6552824974060059, 0.4392799139022827, 0.3475710153579712, 0.25115442276000977, 0.6085923910140991, 0.4655303955078125, 0.48193395137786865, 0.25679445266723633, 1.0437374114990234, 0.2919656038284302, 0.2716028690338135, 0.08336257934570312, 0.9027012586593628, 0.5031049251556396, 0.7015665769577026, 0.9319605827331543, 0.5106407403945923], "mean_td_error": 8.313987731933594, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 675.0, "diff_num_grad_updates_vs_sampler_policy": 674.0}}, "num_env_steps_sampled": 12024, "num_env_steps_trained": 172800, "num_agent_steps_sampled": 12024, "num_agent_steps_trained": 172800, "last_target_update_ts": 12024, "num_target_updates": 675}, "sampler_results": {"episode_reward_max": 163.30143769085407, "episode_reward_min": -189.49322356283665, "episode_reward_mean": -154.7683419138193, "episode_len_mean": 95.75, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-187.0355889648199, -184.92422227561474, -180.11302310228348, -189.49322356283665, -188.7259154766798, 163.30143769085407, -171.60176420211792, -185.7771929204464, -185.78353460133076, -186.6463469490409, -184.1562127098441, -176.26451589167118], "episode_lengths": [100, 100, 100, 100, 100, 49, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.251722379268787, "mean_inference_ms": 2.321900696570889, "mean_action_processing_ms": 0.2274580644909021, "mean_env_wait_ms": 3.0715565853129996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 163.30143769085407, "episode_reward_min": -189.49322356283665, "episode_reward_mean": -154.7683419138193, "episode_len_mean": 95.75, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-187.0355889648199, -184.92422227561474, -180.11302310228348, -189.49322356283665, -188.7259154766798, 163.30143769085407, -171.60176420211792, -185.7771929204464, -185.78353460133076, -186.6463469490409, -184.1562127098441, -176.26451589167118], "episode_lengths": [100, 100, 100, 100, 100, 49, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.251722379268787, "mean_inference_ms": 2.321900696570889, "mean_action_processing_ms": 0.2274580644909021, "mean_env_wait_ms": 3.0715565853129996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 12024, "num_agent_steps_trained": 172800, "num_env_steps_sampled": 12024, "num_env_steps_trained": 172800, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 12024, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 12024, "timers": {"training_iteration_time_ms": 147.041, "load_time_ms": 0.252, "load_throughput": 1014112.036, "learn_time_ms": 24.088, "learn_throughput": 10627.877, "synch_weights_time_ms": 5.172}, "counters": {"num_env_steps_sampled": 12024, "num_env_steps_trained": 172800, "num_agent_steps_sampled": 12024, "num_agent_steps_trained": 172800, "last_target_update_ts": 12024, "num_target_updates": 675}, "done": false, "episodes_total": 124, "training_iteration": 12, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-37-20", "timestamp": 1675949840, "time_this_iter_s": 52.209973096847534, "time_total_s": 148.931969165802, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a4f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 148.931969165802, "timesteps_since_restore": 0, "iterations_since_restore": 12, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.1263888888889, "ram_util_percent": 82.9236111111111}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.388399124145508, "actor_loss": -6.173399448394775, "critic_loss": 0.5435880422592163, "alpha_loss": -2.5387825965881348, "alpha_value": 0.738854706287384, "log_alpha_value": -0.3026539981365204, "target_entropy": -5.0, "policy_t": -0.018861841410398483, "mean_q": 3.711930274963379, "max_q": 4.37608528137207, "min_q": 2.9426848888397217}, "td_error": [0.34319841861724854, 0.39004528522491455, 244.62245178222656, 0.6956772804260254, 0.12279093265533447, 0.40367209911346436, 0.6045287847518921, 0.2608565092086792, 0.14178025722503662, 0.06912147998809814, 5.996213436126709, 0.48825228214263916, 0.24404311180114746, 0.3278442621231079, 0.6268258094787598, 244.8533477783203, 0.41325807571411133, 0.20746338367462158, 0.7853386402130127, 0.7075245380401611, 0.12249112129211426, 0.4042459726333618, 0.11425316333770752, 0.5035686492919922, 0.3393338918685913, 0.4918954372406006, 0.24656438827514648, 0.2221308946609497, 0.26217925548553467, 0.2837989330291748, 0.5384416580200195, 0.4683496952056885, 0.05154216289520264, 0.8569399118423462, 0.7556856870651245, 0.2513974905014038, 0.5228744745254517, 0.7320133447647095, 0.5982993841171265, 0.7186323404312134, 0.7300146818161011, 0.45802342891693115, 0.5130828619003296, 0.27360785007476807, 0.3681894540786743, 0.22211241722106934, 0.6827232837677002, 0.3954329490661621, 0.4596383571624756, 0.10249996185302734, 0.1857752799987793, 0.7823642492294312, 0.49178528785705566, 0.4967755079269409, 0.5429080724716187, 0.6424049139022827, 0.19839704036712646, 0.5488194227218628, 0.2928636074066162, 0.4683288335800171, 0.5788096189498901, 0.8549935817718506, 244.61972045898438, 0.33274924755096436, 0.09325206279754639, 244.8533477783203, 0.9351593255996704, 0.052280426025390625, 0.3948432207107544, 4.906545639038086, 0.1403712034225464, 5.703518867492676, 0.08951258659362793, 0.6732982397079468, 0.8414725065231323, 244.62245178222656, 0.5063809156417847, 5.306927680969238, 0.2346409559249878, 0.11005651950836182, 0.4340723752975464, 0.36898016929626465, 0.2696352005004883, 0.20298421382904053, 0.6605223417282104, 0.250244140625, 0.5315983295440674, 0.37893402576446533, 0.4343219995498657, 0.1462993621826172, 0.43001747131347656, 0.2755633592605591, 0.5089815855026245, 0.9289499521255493, 0.5639218091964722, 0.4054601192474365, 0.19061076641082764, 0.20734548568725586, 0.9078962802886963, 0.5449510812759399, 0.5852760076522827, 0.2892061471939087, 0.5711604356765747, 0.7033017873764038, 0.3879352807998657, 0.37142908573150635, 0.3507643938064575, 0.5653345584869385, 0.33961987495422363, 0.5714571475982666, 0.07948529720306396, 0.3472055196762085, 0.18302786350250244, 0.36208319664001465, 0.409218430519104, 0.4781668186187744, 0.32332682609558105, 0.4809836149215698, 0.5148077011108398, 0.9371705055236816, 0.2668699026107788, 0.033376216888427734, 4.906545639038086, 0.19281339645385742, 0.2970743179321289, 244.8533477783203, 0.7999006509780884, 0.5892682075500488, 0.5753021240234375, 0.3154480457305908, 0.9933311939239502, 0.20094835758209229, 0.7980266809463501, 0.18604159355163574, 0.6078542470932007, 0.1764841079711914, 0.5459808111190796, 0.6561747789382935, 6.317460060119629, 0.30301904678344727, 0.15368306636810303, 0.22611570358276367, 0.22543954849243164, 0.4132990837097168, 0.7005933523178101, 0.8441371917724609, 0.30129384994506836, 0.4100484848022461, 0.3087424039840698, 0.49655258655548096, 0.4881017208099365, 0.3402050733566284, 0.6745790243148804, 0.3873494863510132, 244.8533477783203, 0.36450862884521484, 0.1664808988571167, 0.767815351486206, 1.1933748722076416, 0.7160066366195679, 6.108166694641113, 0.5433964729309082, 0.02817249298095703, 0.5411711931228638, 0.27047646045684814, 0.5266691446304321, 0.7653135061264038, 0.1779388189315796, 0.30886614322662354, 0.5097280740737915, 0.6379604339599609, 0.42904913425445557, 0.05567467212677002, 0.07259023189544678, 0.3199390172958374, 1.3678741455078125, 0.29181790351867676, 0.5512590408325195, 0.41020727157592773, 0.20460128784179688, 0.14600145816802979, 0.12169253826141357, 0.40461206436157227, 0.835790753364563, 0.34260356426239014, 0.35106515884399414, 0.5139793157577515, 1.020847201347351, 244.34713745117188, 0.3690546751022339, 0.24183964729309082, 0.7829058170318604, 0.6676737070083618, 0.01092684268951416, 0.5190824270248413, 0.2529393434524536, 0.641745924949646, 0.27764892578125, 0.569904088973999, 0.22540855407714844, 0.424405574798584, 0.1670088768005371, 4.80547571182251, 0.5050976276397705, 0.3042283058166504, 0.5536770820617676, 0.2414923906326294, 1.093301773071289, 0.606269359588623, 0.4616173505783081, 0.34850239753723145, 0.4704984426498413, 0.39244842529296875, 0.35276639461517334, 0.5526258945465088, 0.16946887969970703, 0.18131840229034424, 0.5649091005325317, 0.5507388114929199, 0.6677385568618774, 1.1095267534255981, 0.4353678226470947, 0.27089905738830566, 0.614565372467041, 0.3775824308395386, 4.77046012878418, 0.6191576719284058, 1.0550419092178345, 0.9657658338546753, 0.6367524862289429, 0.3274390697479248, 0.664792537689209, 0.6174507141113281, 0.3111053705215454, 0.3079618215560913, 0.5882858037948608, 0.08211135864257812, 0.33713841438293457, 0.29859113693237305, 0.16449880599975586, 245.05123901367188, 0.339310884475708, 0.6667909622192383, 0.5402367115020752, 0.16451144218444824, 0.8105990886688232, 0.21014583110809326, 5.876260280609131, 0.5286314487457275, 0.22233176231384277, 244.8533477783203, 0.79925537109375, 0.9245724678039551, 0.21124053001403809, 0.3409968614578247, 0.5040535926818848], "mean_td_error": 10.18519401550293, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 1009.0, "diff_num_grad_updates_vs_sampler_policy": 1008.0}}, "num_env_steps_sampled": 13026, "num_env_steps_trained": 258304, "num_agent_steps_sampled": 13026, "num_agent_steps_trained": 258304, "last_target_update_ts": 13026, "num_target_updates": 1009}, "sampler_results": {"episode_reward_max": -171.10303102433681, "episode_reward_min": -193.52067467570305, "episode_reward_mean": -185.084595805241, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-190.27473078668118, -193.52067467570305, -189.55877432227135, -173.10080946981907, -171.10303102433681, -192.36377274990082, -188.57738538086414, -190.57767274975777, -176.68451108783484], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2485003268254837, "mean_inference_ms": 2.3459321896802416, "mean_action_processing_ms": 0.22930553259729874, "mean_env_wait_ms": 3.0790619092943188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -171.10303102433681, "episode_reward_min": -193.52067467570305, "episode_reward_mean": -185.084595805241, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-190.27473078668118, -193.52067467570305, -189.55877432227135, -173.10080946981907, -171.10303102433681, -192.36377274990082, -188.57738538086414, -190.57767274975777, -176.68451108783484], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2485003268254837, "mean_inference_ms": 2.3459321896802416, "mean_action_processing_ms": 0.22930553259729874, "mean_env_wait_ms": 3.0790619092943188, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 13026, "num_agent_steps_trained": 258304, "num_env_steps_sampled": 13026, "num_env_steps_trained": 258304, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 13026, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 13026, "timers": {"training_iteration_time_ms": 150.548, "load_time_ms": 0.271, "load_throughput": 943451.212, "learn_time_ms": 24.342, "learn_throughput": 10516.663, "synch_weights_time_ms": 6.467}, "counters": {"num_env_steps_sampled": 13026, "num_env_steps_trained": 258304, "num_agent_steps_sampled": 13026, "num_agent_steps_trained": 258304, "last_target_update_ts": 13026, "num_target_updates": 1009}, "done": false, "episodes_total": 133, "training_iteration": 13, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-38-17", "timestamp": 1675949897, "time_this_iter_s": 56.6564667224884, "time_total_s": 205.5884358882904, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2c70>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cdca0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 205.5884358882904, "timesteps_since_restore": 0, "iterations_since_restore": 13, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 47.40886075949367, "ram_util_percent": 84.63417721518991}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.39486026763916, "actor_loss": -6.580883979797363, "critic_loss": 0.4550599455833435, "alpha_loss": -3.383199691772461, "alpha_value": 0.6683064699172974, "log_alpha_value": -0.40300846099853516, "target_entropy": -5.0, "policy_t": -0.03436039388179779, "mean_q": 4.342226505279541, "max_q": 5.156735420227051, "min_q": 3.575044631958008}, "td_error": [0.6254079341888428, 0.4576563835144043, 0.6035199165344238, 0.5360026359558105, 0.5369706153869629, 0.3542978763580322, 0.6396689414978027, 0.4395068883895874, 0.30898547172546387, 0.3576359748840332, 0.258436918258667, 244.24386596679688, 0.6236624717712402, 1.0298093557357788, 0.3792154788970947, 0.5885179042816162, 0.6842892169952393, 0.36911630630493164, 0.24983906745910645, 0.3147544860839844, 0.4777158498764038, 0.20441174507141113, 0.2544424533843994, 0.47385430335998535, 0.6352274417877197, 244.24386596679688, 0.22937607765197754, 0.19195795059204102, 1.1908977031707764, 0.2774667739868164, 0.7461147308349609, 0.5380594730377197, 0.28580498695373535, 0.48387598991394043, 0.4773087501525879, 0.311539888381958, 0.18242692947387695, 0.40938568115234375, 0.04497385025024414, 0.3571746349334717, 0.45586490631103516, 0.5577480792999268, 0.312131404876709, 0.616410493850708, 0.7976324558258057, 0.5520389080047607, 0.06383466720581055, 0.34150099754333496, 0.1786518096923828, 0.43705248832702637, 0.09354877471923828, 0.4829599857330322, 0.5663487911224365, 0.3676600456237793, 0.6781759262084961, 0.3586968183517456, 0.7908012866973877, 0.3267192840576172, 0.43091678619384766, 0.29990553855895996, 0.38590550422668457, 0.288360595703125, 0.5786349773406982, 0.5674598217010498, 0.053336381912231445, 5.722746849060059, 6.222573280334473, 0.4253113269805908, 0.36855268478393555, 0.2537696361541748, 0.591278076171875, 0.3947608470916748, 0.49604010581970215, 244.24386596679688, 0.39734339714050293, 0.5889797210693359, 6.526153087615967, 0.04127955436706543, 0.4185318946838379, 0.5242950916290283, 0.2295229434967041, 0.1314706802368164, 0.1073005199432373, 0.5526819229125977, 0.4646894931793213, 0.4254477024078369, 0.8099410533905029, 0.5732910633087158, 0.46431756019592285, 0.9765419960021973, 0.5612947940826416, 0.5198166370391846, 0.46256256103515625, 0.32733678817749023, 0.3497934341430664, 0.553473949432373, 0.650313138961792, 0.5642673969268799, 0.3459737300872803, 0.4524381160736084, 0.424025297164917, 0.5865132808685303, 1.122661828994751, 0.1828610897064209, 0.4900376796722412, 0.49098777770996094, 0.5180544853210449, 0.816896915435791, 0.8041210174560547, 0.6475319862365723, 0.6103866100311279, 0.4380068778991699, 0.021849393844604492, 0.3007540702819824, 0.20346689224243164, 0.43718981742858887, 0.07867264747619629, 0.4279770851135254, 0.28174805641174316, 1.075214147567749, 0.11570906639099121, 0.43866562843322754, 0.2773449420928955, 0.5718874931335449, 6.687023162841797, 0.37410497665405273, 0.4704897403717041, 244.28756713867188, 0.2168712615966797, 0.16757845878601074, 0.1690993309020996, 5.760127067565918, 0.6628923416137695, 0.34381604194641113, 0.5736837387084961, 5.694042205810547, 0.6950452327728271, 0.37642836570739746, 6.4249420166015625, 0.4445815086364746, 0.5250129699707031, 0.5712037086486816, 0.5011913776397705, 5.88551664352417, 0.4816014766693115, 0.19192814826965332, 0.5149321556091309, 0.7904350757598877, 1.0468114614486694, 0.47878098487854004, 0.5133228302001953, 0.504601001739502, 0.33191776275634766, 0.5170900821685791, 0.04079747200012207, 0.2068026065826416, 0.6428492069244385, 0.3963831663131714, 0.7517478466033936, 0.4511294364929199, 0.5239002704620361, 0.4355466365814209, 0.8948974609375, 0.45726537704467773, 0.48996448516845703, 0.4600181579589844, 0.32921409606933594, 0.7297616004943848, 0.514765739440918, 0.44994020462036133, 0.3455979824066162, 0.6735754013061523, 0.3685007095336914, 0.1333022117614746, 0.3008153438568115, 0.047243356704711914, 0.5423390865325928, 0.3553898334503174, 0.6163444519042969, 0.8919651508331299, 0.2889425754547119, 5.596837043762207, 0.40648484230041504, 0.20235538482666016, 0.19109606742858887, 0.6569609642028809, 5.630196571350098, 0.35394930839538574, 0.26782989501953125, 0.5655725002288818, 0.958838939666748, 0.5198414325714111, 0.6842832565307617, 0.775517463684082, 0.21740031242370605, 0.313417911529541, 243.98997497558594, 0.0806875228881836, 0.49486243724823, 0.45796942710876465, 243.58419799804688, 0.6491167545318604, 0.5756785869598389, 0.3220643997192383, 0.38403773307800293, 0.013797998428344727, 0.6562252044677734, 6.750804901123047, 0.22412586212158203, 0.5636169910430908, 0.13913512229919434, 0.7066822052001953, 0.4501364231109619, 0.3797271251678467, 0.24033665657043457, 1.0932443141937256, 1.4943323135375977, 0.19672846794128418, 0.5240259170532227, 0.243300199508667, 1.007401466369629, 0.5233433246612549, 0.5380008220672607, 0.6767392158508301, 0.5232534408569336, 0.5858995914459229, 0.13278627395629883, 0.43292975425720215, 0.5690722465515137, 0.6697993278503418, 1.194169282913208, 0.21429204940795898, 0.33362865447998047, 0.5508432388305664, 0.5300241708755493, 0.5673744678497314, 0.26911234855651855, 243.58419799804688, 0.2897794246673584, 0.7088372707366943, 0.7989654541015625, 0.4236311912536621, 243.84716796875, 0.11563801765441895, 0.20128178596496582, 0.5328538417816162, 0.7303400039672852, 0.5006818771362305, 6.526153087615967, 0.2653920650482178, 0.5262269973754883, 0.4802970886230469, 0.572441577911377, 0.6108267307281494, 0.9579716920852661, 0.35520434379577637], "mean_td_error": 8.342748641967773, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 1343.0, "diff_num_grad_updates_vs_sampler_policy": 1342.0}}, "num_env_steps_sampled": 14028, "num_env_steps_trained": 343808, "num_agent_steps_sampled": 14028, "num_agent_steps_trained": 343808, "last_target_update_ts": 14028, "num_target_updates": 1343}, "sampler_results": {"episode_reward_max": -167.73383703827858, "episode_reward_min": -193.160078458488, "episode_reward_mean": -181.85733484476805, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-191.58597734570503, -190.74350184202194, -167.73383703827858, -184.81242395937443, -172.80720306932926, -193.160078458488, -171.496223077178, -177.10790572315454, -187.26886308938265], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2571061467183018, "mean_inference_ms": 2.3783673479538177, "mean_action_processing_ms": 0.23117343083424405, "mean_env_wait_ms": 3.096820011455652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.73383703827858, "episode_reward_min": -193.160078458488, "episode_reward_mean": -181.85733484476805, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-191.58597734570503, -190.74350184202194, -167.73383703827858, -184.81242395937443, -172.80720306932926, -193.160078458488, -171.496223077178, -177.10790572315454, -187.26886308938265], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2571061467183018, "mean_inference_ms": 2.3783673479538177, "mean_action_processing_ms": 0.23117343083424405, "mean_env_wait_ms": 3.096820011455652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 14028, "num_agent_steps_trained": 343808, "num_env_steps_sampled": 14028, "num_env_steps_trained": 343808, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 14028, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 14028, "timers": {"training_iteration_time_ms": 158.074, "load_time_ms": 0.312, "load_throughput": 821468.766, "learn_time_ms": 26.655, "learn_throughput": 9604.062, "synch_weights_time_ms": 5.892}, "counters": {"num_env_steps_sampled": 14028, "num_env_steps_trained": 343808, "num_agent_steps_sampled": 14028, "num_agent_steps_trained": 343808, "last_target_update_ts": 14028, "num_target_updates": 1343}, "done": false, "episodes_total": 142, "training_iteration": 14, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-39-18", "timestamp": 1675949958, "time_this_iter_s": 61.66024971008301, "time_total_s": 267.2486855983734, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105ef040>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd3a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 267.2486855983734, "timesteps_since_restore": 0, "iterations_since_restore": 14, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 52.06941176470589, "ram_util_percent": 87.08588235294118}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.438075065612793, "actor_loss": -6.517789363861084, "critic_loss": 0.6616898775100708, "alpha_loss": -4.246946334838867, "alpha_value": 0.6045279502868652, "log_alpha_value": -0.5033074021339417, "target_entropy": -5.0, "policy_t": -0.005959862377494574, "mean_q": 4.486087322235107, "max_q": 5.304399013519287, "min_q": 3.3463962078094482}, "td_error": [0.47981858253479004, 0.7543179988861084, 0.1868751049041748, 0.2871211767196655, 0.16702508926391602, 0.4017765522003174, 0.26991868019104004, 0.37041163444519043, 5.672990798950195, 0.36109066009521484, 0.2962613105773926, 0.4811890125274658, 0.5455725193023682, 0.25661611557006836, 0.20891165733337402, 0.5859222412109375, 0.2518801689147949, 0.3698105812072754, 6.084485054016113, 0.058666229248046875, 0.26058530807495117, 0.5089011192321777, 0.42206311225891113, 0.9519252777099609, 0.25579094886779785, 0.7817761898040771, 0.4241514205932617, 0.5071771144866943, 0.4140942096710205, 0.26749253273010254, 0.4310169219970703, 0.08950471878051758, 0.07058048248291016, 0.5383768081665039, 0.26488685607910156, 243.4713897705078, 0.6479306221008301, 0.25555992126464844, 0.09090781211853027, 0.5662939548492432, 5.4984893798828125, 0.7972054481506348, 0.9000229835510254, 0.6404545307159424, 0.31438755989074707, 0.4458768367767334, 0.08510470390319824, 0.038373589515686035, 0.31830620765686035, 0.10654759407043457, 6.260519981384277, 0.767803430557251, 0.4041175842285156, 0.5343718528747559, 0.2792680263519287, 0.909857988357544, 0.4104487895965576, 0.9700579643249512, 0.3517799377441406, 0.12521767616271973, 0.38475561141967773, 0.6789157390594482, 0.6453535556793213, 0.2876112461090088, 1.1323118209838867, 0.7506682872772217, 0.5847406387329102, 0.11010241508483887, 0.691169023513794, 0.383803129196167, 0.3493635654449463, 243.7198944091797, 0.5387654304504395, 0.03244376182556152, 0.36286306381225586, 6.381653308868408, 0.6942474842071533, 0.3555111885070801, 0.4040791988372803, 0.33783650398254395, 243.99240112304688, 0.4240725040435791, 0.2897522449493408, 0.5586609840393066, 0.293057918548584, 0.396575927734375, 6.610151767730713, 0.12065720558166504, 0.12328553199768066, 0.4184994697570801, 0.48740220069885254, 0.361191987991333, 0.6291487216949463, 0.40165209770202637, 0.4061617851257324, 0.6415050029754639, 0.6588988304138184, 0.5064537525177002, 6.475439548492432, 0.3545393943786621, 0.46855950355529785, 0.29918980598449707, 0.4883749485015869, 0.19910240173339844, 0.3704676628112793, 0.8581855297088623, 0.25212204456329346, 0.7718279361724854, 0.7038037776947021, 0.15036320686340332, 0.49291515350341797, 0.2564094066619873, 1.0583164691925049, 0.31717586517333984, 0.7199685573577881, 0.4129054546356201, 0.3089714050292969, 0.48326730728149414, 0.8057646751403809, 243.99240112304688, 0.5899569988250732, 0.4625742435455322, 0.4081575870513916, 0.04591965675354004, 0.5601518154144287, 0.21509885787963867, 0.26410913467407227, 0.40087080001831055, 0.665902853012085, 6.3179426193237305, 0.5335659980773926, 5.99179744720459, 0.9249582290649414, 0.5286529064178467, 0.5272586345672607, 0.6900475025177002, 243.7981414794922, 6.238022804260254, 0.9183909893035889, 0.5494985580444336, 0.5092425346374512, 0.2816329002380371, 0.6334693431854248, 0.09291410446166992, 0.30849170684814453, 0.3597378730773926, 0.7638139724731445, 0.42487168312072754, 1.0307517051696777, 0.30045151710510254, 0.17431354522705078, 0.4050755500793457, 0.5441615581512451, 0.10437607765197754, 0.42934584617614746, 243.4713897705078, 0.6060371398925781, 0.4030263423919678, 0.323836088180542, 0.5214130878448486, 0.2513611316680908, 0.4041585922241211, 0.25664567947387695, 243.4713897705078, 0.48810040950775146, 0.07634472846984863, 0.3239717483520508, 0.23706412315368652, 0.6323165893554688, 7.187526226043701, 0.44204115867614746, 0.6479759216308594, 0.804685115814209, 0.2539699077606201, 0.5240294933319092, 0.30632662773132324, 0.5087659358978271, 0.545020341873169, 0.6804420948028564, 0.08130502700805664, 1.0827796459197998, 0.361696720123291, 0.6138896942138672, 0.39427638053894043, 0.026388168334960938, 0.29219913482666016, 0.17983579635620117, 0.27193450927734375, 0.9802002906799316, 0.5358004570007324, 0.08593082427978516, 243.96014404296875, 0.3258178234100342, 6.676774501800537, 0.5376472473144531, 0.2503020763397217, 0.6655480861663818, 243.73953247070312, 0.5558929443359375, 6.198899269104004, 0.37361598014831543, 0.3309190273284912, 0.6486377716064453, 0.7481870651245117, 0.24414348602294922, 0.6360597610473633, 0.6219711303710938, 0.4617764949798584, 1.029555082321167, 7.306449890136719, 0.8207488059997559, 0.20837152004241943, 0.6427841186523438, 0.18178153038024902, 0.6758112907409668, 0.24411559104919434, 0.650648832321167, 0.8140900135040283, 243.7981414794922, 0.3811202049255371, 5.516759872436523, 0.9486885070800781, 0.4363102912902832, 0.6058984994888306, 0.4728579521179199, 0.2730156183242798, 0.3912966251373291, 0.6363940238952637, 0.7029550075531006, 5.516567230224609, 0.12064146995544434, 0.3829522132873535, 0.5738694667816162, 0.24988579750061035, 0.3394296169281006, 0.15549087524414062, 0.11550068855285645, 0.03770756721496582, 0.59250807762146, 6.79447078704834, 243.96014404296875, 0.7709510326385498, 0.6415443420410156, 0.437821626663208, 0.5304038524627686, 0.39275622367858887, 0.1707613468170166, 0.25655627250671387, 0.10273337364196777, 0.5169522762298584, 0.7500581741333008, 243.54901123046875, 0.34938931465148926, 0.5660133361816406, 0.36699843406677246, 0.6853852272033691], "mean_td_error": 12.24126148223877, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 1677.0, "diff_num_grad_updates_vs_sampler_policy": 1676.0}}, "num_env_steps_sampled": 15030, "num_env_steps_trained": 429312, "num_agent_steps_sampled": 15030, "num_agent_steps_trained": 429312, "last_target_update_ts": 15030, "num_target_updates": 1677}, "sampler_results": {"episode_reward_max": -167.4954197704792, "episode_reward_min": -191.98499378561974, "episode_reward_mean": -184.26235711947083, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.570613399148, -191.98499378561974, -187.01995192468166, -186.29515251517296, -187.99071127176285, -190.23062424361706, -185.3246492445469, -167.4954197704792, -185.65701182186604, -189.5101600587368, -181.4457355439663, -189.62326185405254], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2540615208410804, "mean_inference_ms": 2.3901244801516417, "mean_action_processing_ms": 0.23206122611594004, "mean_env_wait_ms": 3.0908723684125796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.4954197704792, "episode_reward_min": -191.98499378561974, "episode_reward_mean": -184.26235711947083, "episode_len_mean": 100.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-168.570613399148, -191.98499378561974, -187.01995192468166, -186.29515251517296, -187.99071127176285, -190.23062424361706, -185.3246492445469, -167.4954197704792, -185.65701182186604, -189.5101600587368, -181.4457355439663, -189.62326185405254], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2540615208410804, "mean_inference_ms": 2.3901244801516417, "mean_action_processing_ms": 0.23206122611594004, "mean_env_wait_ms": 3.0908723684125796, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15030, "num_agent_steps_trained": 429312, "num_env_steps_sampled": 15030, "num_env_steps_trained": 429312, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 15030, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 15030, "timers": {"training_iteration_time_ms": 153.463, "load_time_ms": 0.265, "load_throughput": 967858.143, "learn_time_ms": 24.791, "learn_throughput": 10326.337, "synch_weights_time_ms": 5.938}, "counters": {"num_env_steps_sampled": 15030, "num_env_steps_trained": 429312, "num_agent_steps_sampled": 15030, "num_agent_steps_trained": 429312, "last_target_update_ts": 15030, "num_target_updates": 1677}, "done": false, "episodes_total": 154, "training_iteration": 15, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-40-13", "timestamp": 1675950013, "time_this_iter_s": 55.12917709350586, "time_total_s": 322.3778626918793, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2bb0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105dd430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 322.3778626918793, "timesteps_since_restore": 0, "iterations_since_restore": 15, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 44.62894736842105, "ram_util_percent": 86.69868421052634}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.388799667358398, "actor_loss": -6.19097900390625, "critic_loss": 0.5511590838432312, "alpha_loss": -5.063154220581055, "alpha_value": 0.5468606948852539, "log_alpha_value": -0.6035611629486084, "target_entropy": -5.0, "policy_t": -0.02631387487053871, "mean_q": 4.3530802726745605, "max_q": 5.15280818939209, "min_q": 3.2963123321533203}, "td_error": [0.546483039855957, 0.747718095779419, 0.8234460353851318, 1.004972219467163, 0.5272982120513916, 0.7837238311767578, 0.42446351051330566, 0.053075313568115234, 0.3193953037261963, 0.45099377632141113, 0.3038468360900879, 0.15726661682128906, 0.7298228740692139, 0.4966428279876709, 0.36344289779663086, 0.2247152328491211, 0.24259734153747559, 0.1790027618408203, 0.4136378765106201, 0.5698373317718506, 0.6198639869689941, 0.23072218894958496, 0.21469426155090332, 0.6363735198974609, 0.0704953670501709, 0.45461392402648926, 1.0266754627227783, 0.34597039222717285, 0.36706113815307617, 0.7414987087249756, 0.7387316226959229, 6.803676605224609, 0.18467330932617188, 6.014864444732666, 0.5619583129882812, 5.807435035705566, 0.25154566764831543, 0.8804385662078857, 244.09561157226562, 0.37009382247924805, 243.719970703125, 0.3024122714996338, 0.10955595970153809, 0.22024893760681152, 0.3690521717071533, 0.3815784454345703, 0.6389470100402832, 0.784693717956543, 0.638878583908081, 0.47525763511657715, 1.1253411769866943, 0.552269697189331, 0.5284411907196045, 0.8102595806121826, 0.534102201461792, 1.021935224533081, 0.400676965713501, 243.83338928222656, 243.719970703125, 0.8715412616729736, 0.37963998317718506, 0.6681175231933594, 0.7070755958557129, 7.076222896575928, 1.107527732849121, 0.45630669593811035, 0.35660767555236816, 0.48764872550964355, 0.5412673950195312, 0.31737303733825684, 0.23153352737426758, 0.6668219566345215, 0.2495431900024414, 0.5336840152740479, 0.538386344909668, 0.5558559894561768, 0.20081281661987305, 0.37341761589050293, 0.6040704250335693, 0.2201216220855713, 0.495103120803833, 0.16297626495361328, 0.6840827465057373, 0.7782814502716064, 0.45796942710876465, 0.9569828510284424, 0.07504856586456299, 0.026129722595214844, 0.8929980993270874, 0.7143205404281616, 0.6127104759216309, 0.3338918685913086, 0.4667537212371826, 0.43289637565612793, 0.2873258590698242, 0.16301846504211426, 0.3945963382720947, 0.5462844371795654, 0.4607679843902588, 0.30681490898132324, 0.45913636684417725, 243.77322387695312, 0.27971792221069336, 0.32976627349853516, 0.3369715213775635, 0.48317885398864746, 0.48691892623901367, 0.4764981269836426, 0.496337890625, 0.21517252922058105, 0.4355137348175049, 6.540530681610107, 0.6854705810546875, 243.9404296875, 0.48069000244140625, 0.6611833572387695, 0.6668436527252197, 0.32708144187927246, 0.4054446220397949, 7.157933712005615, 0.18787050247192383, 0.3750190734863281, 0.49196791648864746, 0.3857618570327759, 0.5994353294372559, 5.3610053062438965, 0.525076150894165, 0.4035966396331787, 0.6981556415557861, 0.5317592620849609, 6.2042436599731445, 1.028360366821289, 0.04449939727783203, 0.172943115234375, 0.844738245010376, 0.025747299194335938, 0.055939674377441406, 243.77322387695312, 0.3644289970397949, 0.12224698066711426, 0.49350130558013916, 0.2925722599029541, 0.23320341110229492, 0.40133213996887207, 0.5923256874084473, 0.8105518817901611, 0.3684396743774414, 0.10930514335632324, 0.10084867477416992, 0.24973726272583008, 0.19111204147338867, 0.46030449867248535, 5.4782915115356445, 0.4286656379699707, 0.3567931652069092, 0.4551882743835449, 0.10304880142211914, 0.642669677734375, 0.5006227493286133, 0.4159759283065796, 0.5432237386703491, 6.108126640319824, 0.3224228620529175, 243.719970703125, 0.6029314994812012, 0.22050738334655762, 0.33893704414367676, 0.55190110206604, 0.3173050880432129, 0.35433948040008545, 0.4074580669403076, 0.48322391510009766, 0.2617323398590088, 0.5288887023925781, 0.6091156005859375, 0.2866208553314209, 0.8127429485321045, 5.675558567047119, 0.5716867446899414, 6.755984783172607, 0.7872903347015381, 0.18435359001159668, 0.45465826988220215, 0.3913203477859497, 0.6911239624023438, 0.6859438419342041, 0.8235268592834473, 0.6814281940460205, 0.2927513122558594, 0.09163427352905273, 0.44540297985076904, 0.15478086471557617, 0.5783917903900146, 0.3383486270904541, 0.18317341804504395, 0.4337441921234131, 0.5356066226959229, 0.6906349658966064, 0.5257163047790527, 0.7749874591827393, 0.4641643762588501, 0.6155908107757568, 0.35258054733276367, 0.6316311359405518, 243.9404296875, 0.4712865352630615, 0.814197301864624, 0.4977149963378906, 0.429396390914917, 0.40160250663757324, 0.5270771980285645, 0.700420618057251, 0.46312928199768066, 0.5320818424224854, 0.38669896125793457, 0.3000617027282715, 0.2895216941833496, 6.040875434875488, 0.6043694019317627, 6.769172191619873, 0.18741345405578613, 0.4081183671951294, 0.4216766357421875, 0.6008987426757812, 0.9402525424957275, 5.675558567047119, 0.6347672939300537, 0.5943701267242432, 0.4638071060180664, 0.39574241638183594, 0.5506834983825684, 0.2517707347869873, 0.23205232620239258, 0.35809850692749023, 5.533134937286377, 0.48674488067626953, 0.23645448684692383, 0.47632479667663574, 0.4180755615234375, 0.560133695602417, 0.5264585018157959, 5.0314860343933105, 0.6879281997680664, 0.3449375629425049, 6.608227729797363, 1.160703420639038, 0.22780179977416992, 0.654620885848999, 0.46422410011291504, 0.5044970512390137, 0.44538259506225586, 0.8679308891296387, 0.31552648544311523, 0.11214923858642578, 0.5663101673126221, 243.83338928222656], "mean_td_error": 10.375330924987793, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 2011.0, "diff_num_grad_updates_vs_sampler_policy": 2010.0}}, "num_env_steps_sampled": 16032, "num_env_steps_trained": 514816, "num_agent_steps_sampled": 16032, "num_agent_steps_trained": 514816, "last_target_update_ts": 16032, "num_target_updates": 2011}, "sampler_results": {"episode_reward_max": 239.49217422306538, "episode_reward_min": -193.72556272149086, "episode_reward_mean": -115.78511388227344, "episode_len_mean": 90.5, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-190.27600866556168, -186.49399116635323, -185.00045055150986, -192.42266704142094, 239.49217422306538, -167.23813240230083, -181.1968899667263, -187.67299080640078, 86.68338027596474, -193.72556272149086], "episode_lengths": [100, 100, 100, 100, 6, 100, 100, 100, 99, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2443106368504693, "mean_inference_ms": 2.3827020468502207, "mean_action_processing_ms": 0.23075704601348507, "mean_env_wait_ms": 3.0683417003549516, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 239.49217422306538, "episode_reward_min": -193.72556272149086, "episode_reward_mean": -115.78511388227344, "episode_len_mean": 90.5, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-190.27600866556168, -186.49399116635323, -185.00045055150986, -192.42266704142094, 239.49217422306538, -167.23813240230083, -181.1968899667263, -187.67299080640078, 86.68338027596474, -193.72556272149086], "episode_lengths": [100, 100, 100, 100, 6, 100, 100, 100, 99, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2443106368504693, "mean_inference_ms": 2.3827020468502207, "mean_action_processing_ms": 0.23075704601348507, "mean_env_wait_ms": 3.0683417003549516, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 16032, "num_agent_steps_trained": 514816, "num_env_steps_sampled": 16032, "num_env_steps_trained": 514816, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 16032, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 16032, "timers": {"training_iteration_time_ms": 148.121, "load_time_ms": 0.265, "load_throughput": 966290.338, "learn_time_ms": 24.422, "learn_throughput": 10482.361, "synch_weights_time_ms": 5.192}, "counters": {"num_env_steps_sampled": 16032, "num_env_steps_trained": 514816, "num_agent_steps_sampled": 16032, "num_agent_steps_trained": 514816, "last_target_update_ts": 16032, "num_target_updates": 2011}, "done": false, "episodes_total": 164, "training_iteration": 16, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-41-04", "timestamp": 1675950064, "time_this_iter_s": 50.25693893432617, "time_total_s": 372.63480162620544, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a100>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105dd670>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 372.63480162620544, "timesteps_since_restore": 0, "iterations_since_restore": 16, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.28529411764706, "ram_util_percent": 85.86470588235292}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.389810562133789, "actor_loss": -5.6056904792785645, "critic_loss": 0.4769948720932007, "alpha_loss": -5.904650688171387, "alpha_value": 0.4947076439857483, "log_alpha_value": -0.7037882804870605, "target_entropy": -5.0, "policy_t": -0.07027190923690796, "mean_q": 3.9583210945129395, "max_q": 4.776210784912109, "min_q": 3.061530113220215}, "td_error": [0.28691554069519043, 0.18503475189208984, 0.45020413398742676, 0.410650372505188, 0.32334208488464355, 0.4078938961029053, 0.34220683574676514, 0.7017775774002075, 0.8333098888397217, 0.4499797821044922, 0.2633765935897827, 0.49543333053588867, 0.5784258842468262, 0.6849726438522339, 0.6990154981613159, 0.3184473514556885, 0.5453238487243652, 4.868492603302002, 0.45685434341430664, 0.4764174222946167, 0.34881484508514404, 0.6018414497375488, 0.5673880577087402, 0.49883460998535156, 0.36060094833374023, 0.4880028963088989, 0.2542874813079834, 0.6168665885925293, 0.6246547698974609, 244.02523803710938, 0.6418654918670654, 0.5568501949310303, 0.5739681720733643, 0.48374438285827637, 0.5155569314956665, 0.5105831623077393, 0.6637418270111084, 0.43364691734313965, 0.7420532703399658, 0.6471363306045532, 0.6025419235229492, 0.6482729911804199, 0.41949462890625, 0.2694401741027832, 0.5033564567565918, 0.4888879060745239, 0.31295454502105713, 0.9591326713562012, 0.2665281295776367, 0.4965553283691406, 0.7192237377166748, 0.6400880813598633, 0.3015803098678589, 0.27632975578308105, 0.23725628852844238, 0.4443478584289551, 0.4717381000518799, 6.479362487792969, 0.5601480007171631, 0.6020008325576782, 0.31708765029907227, 0.4298962354660034, 0.4846482276916504, 0.506079912185669, 0.7548775672912598, 0.422709584236145, 0.5448921918869019, 0.48970746994018555, 0.5187636613845825, 0.2481759786605835, 0.06287646293640137, 0.574103593826294, 0.21907567977905273, 0.5018235445022583, 0.7280583381652832, 0.3879193067550659, 0.6877868175506592, 0.40426695346832275, 0.5214518308639526, 0.6227008104324341, 0.3006390333175659, 0.519010066986084, 0.05170583724975586, 6.076663017272949, 0.6372809410095215, 0.6881881952285767, 0.47609400749206543, 0.7457935810089111, 0.38602447509765625, 4.832059383392334, 0.5113189220428467, 0.7167526483535767, 0.46504974365234375, 0.6801520586013794, 0.4849708080291748, 0.30300378799438477, 0.5484969615936279, 0.5948812961578369, 0.9923968315124512, 0.27170681953430176, 0.006952404975891113, 0.9373984336853027, 0.3550196886062622, 0.3004751205444336, 0.6113355159759521, 0.49283671379089355, 0.26576149463653564, 0.5305154323577881, 0.32883405685424805, 0.2554885149002075, 244.46676635742188, 5.006045341491699, 0.16823077201843262, 0.16489577293395996, 244.02523803710938, 0.5897843837738037, 0.1551213264465332, 6.652106285095215, 0.49098122119903564, 0.4573237895965576, 0.5249543190002441, 0.08069682121276855, 0.12958848476409912, 0.5120890140533447, 0.37712907791137695, 0.5066425800323486, 0.4559894800186157, 0.24230265617370605, 0.3835291862487793, 5.487079620361328, 0.392179012298584, 5.7043867111206055, 0.6230745315551758, 0.4702799320220947, 0.4979516267776489, 0.44565868377685547, 5.091597080230713, 0.30122876167297363, 0.15357446670532227, 0.5357203483581543, 0.9853973388671875, 0.29329657554626465, 0.735880970954895, 0.7586729526519775, 0.3039543628692627, 5.975065231323242, 0.7913730144500732, 244.1645965576172, 0.43322956562042236, 0.3531978130340576, 0.28241801261901855, 0.33780205249786377, 0.39167261123657227, 0.4998934268951416, 0.4863086938858032, 0.6784842014312744, 244.12640380859375, 0.37962424755096436, 0.4870181083679199, 0.39505982398986816, 0.3601858615875244, 6.156213283538818, 0.6673583984375, 0.39392030239105225, 0.531488299369812, 0.5056979656219482, 0.19174981117248535, 0.15915560722351074, 0.18590402603149414, 0.35013532638549805, 0.42273759841918945, 0.3475162982940674, 0.5970479249954224, 0.6876006126403809, 0.41265296936035156, 0.41460108757019043, 0.191025972366333, 0.7710180282592773, 5.2329630851745605, 0.43640851974487305, 0.37204861640930176, 0.5379931926727295, 0.660057544708252, 0.5064404010772705, 0.8876123428344727, 0.5801035165786743, 0.6104614734649658, 0.3453408479690552, 0.4444315433502197, 0.4306124448776245, 0.5673234462738037, 6.544678211212158, 0.5577731132507324, 0.28386926651000977, 0.6329524517059326, 0.5366314649581909, 0.24235010147094727, 0.48169469833374023, 0.3262803554534912, 5.748862266540527, 0.43594229221343994, 0.418692946434021, 0.5963292121887207, 0.366682767868042, 0.3665347099304199, 0.6915048360824585, 0.4685162305831909, 0.5184946060180664, 0.619774580001831, 0.7826584577560425, 0.6647481918334961, 0.34223616123199463, 0.05587029457092285, 0.3866029977798462, 0.3055572509765625, 0.5225274562835693, 0.4952278137207031, 0.5776861906051636, 0.22211050987243652, 0.5103858709335327, 0.542313814163208, 0.20721864700317383, 244.42626953125, 244.78952026367188, 0.70306396484375, 0.8265175819396973, 0.33707404136657715, 0.3149583339691162, 244.46676635742188, 0.2810170650482178, 0.5288741588592529, 244.15603637695312, 5.174442291259766, 0.44011402130126953, 0.4246417284011841, 0.14475679397583008, 244.15603637695312, 0.1584937572479248, 0.07328462600708008, 0.49005556106567383, 0.6408491134643555, 0.6327096223831177, 0.4307289123535156, 0.2852334976196289, 244.3525390625, 0.032555580139160156, 0.647346019744873, 0.35468292236328125, 0.6101913452148438, 0.7257001399993896, 0.5151122808456421, 6.0725555419921875, 0.5330197811126709, 0.6717944145202637, 0.73048996925354, 0.1667560338973999], "mean_td_error": 11.269855499267578, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 2345.0, "diff_num_grad_updates_vs_sampler_policy": 2344.0}}, "num_env_steps_sampled": 17034, "num_env_steps_trained": 600320, "num_agent_steps_sampled": 17034, "num_agent_steps_trained": 600320, "last_target_update_ts": 17034, "num_target_updates": 2345}, "sampler_results": {"episode_reward_max": 222.05110174417496, "episode_reward_min": -190.09670834243298, "episode_reward_mean": -143.9502118192613, "episode_len_mean": 91.4, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.53125815093517, -183.7729166597128, -170.50420750677586, -187.2069180160761, -187.8617040514946, -178.82971841096878, -190.09670834243298, -184.87761634588242, 222.05110174417496, -188.8721724525094], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 14, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2345175609598698, "mean_inference_ms": 2.378194616344282, "mean_action_processing_ms": 0.2297615622903159, "mean_env_wait_ms": 3.0489242083171155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 222.05110174417496, "episode_reward_min": -190.09670834243298, "episode_reward_mean": -143.9502118192613, "episode_len_mean": 91.4, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.53125815093517, -183.7729166597128, -170.50420750677586, -187.2069180160761, -187.8617040514946, -178.82971841096878, -190.09670834243298, -184.87761634588242, 222.05110174417496, -188.8721724525094], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 14, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2345175609598698, "mean_inference_ms": 2.378194616344282, "mean_action_processing_ms": 0.2297615622903159, "mean_env_wait_ms": 3.0489242083171155, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 17034, "num_agent_steps_trained": 600320, "num_env_steps_sampled": 17034, "num_env_steps_trained": 600320, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 17034, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 17034, "timers": {"training_iteration_time_ms": 179.179, "load_time_ms": 0.323, "load_throughput": 793014.641, "learn_time_ms": 27.722, "learn_throughput": 9234.558, "synch_weights_time_ms": 6.559}, "counters": {"num_env_steps_sampled": 17034, "num_env_steps_trained": 600320, "num_agent_steps_sampled": 17034, "num_agent_steps_trained": 600320, "last_target_update_ts": 17034, "num_target_updates": 2345}, "done": false, "episodes_total": 174, "training_iteration": 17, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-41-57", "timestamp": 1675950117, "time_this_iter_s": 53.24273991584778, "time_total_s": 425.8775415420532, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580850>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a4160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 425.8775415420532, "timesteps_since_restore": 0, "iterations_since_restore": 17, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.40405405405406, "ram_util_percent": 86.22567567567567}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.397686958312988, "actor_loss": -4.830838203430176, "critic_loss": 0.2381262630224228, "alpha_loss": -6.751639366149902, "alpha_value": 0.44754064083099365, "log_alpha_value": -0.8039879202842712, "target_entropy": -5.0, "policy_t": -0.03821723535656929, "mean_q": 3.3357093334198, "max_q": 4.247195720672607, "min_q": 2.3344931602478027}, "td_error": [0.2951009273529053, 0.5300713777542114, 0.2615865468978882, 0.4607245922088623, 0.9004980325698853, 0.34378349781036377, 0.6237635612487793, 0.42708122730255127, 0.5939065217971802, 0.38850677013397217, 0.38510453701019287, 0.78834068775177, 0.6144112348556519, 0.23207509517669678, 0.09300529956817627, 0.2809242010116577, 0.5623844861984253, 0.6824022531509399, 0.34506309032440186, 0.24999773502349854, 0.5121631622314453, 0.45713794231414795, 0.48974907398223877, 0.44452035427093506, 0.5900309085845947, 0.2180025577545166, 0.7575317621231079, 0.4593491554260254, 0.7250171899795532, 0.7674612998962402, 0.5809170007705688, 0.572833776473999, 0.41904735565185547, 0.5796380043029785, 0.07293665409088135, 0.37933826446533203, 4.3453288078308105, 0.5349195003509521, 0.30672550201416016, 0.5711286067962646, 0.28580498695373535, 0.5000976324081421, 0.6530581712722778, 0.36036360263824463, 0.5098886489868164, 0.5776447057723999, 0.17963552474975586, 0.7790454626083374, 0.6160513162612915, 0.5095514059066772, 0.460635781288147, 0.6108578443527222, 0.22589266300201416, 0.412550687789917, 0.4501979351043701, 0.3979593515396118, 0.38696563243865967, 0.5770121812820435, 0.47207415103912354, 0.4558659791946411, 0.7523528337478638, 0.528822660446167, 0.25847625732421875, 0.21452486515045166, 0.5813455581665039, 0.41309654712677, 0.30791008472442627, 0.30662572383880615, 0.39392316341400146, 0.5061303377151489, 0.7745686769485474, 0.5007010698318481, 0.5147274732589722, 0.40886175632476807, 0.5176709890365601, 0.3156876564025879, 0.6641932725906372, 0.5084429979324341, 0.9822741746902466, 0.3419058322906494, 0.5511753559112549, 0.08106625080108643, 0.18043184280395508, 0.6555918455123901, 0.5006366968154907, 0.6358524560928345, 0.39897167682647705, 0.5408531427383423, 0.2806147336959839, 4.265738487243652, 0.43373215198516846, 0.4888880252838135, 0.7337769269943237, 4.587661266326904, 0.9668681621551514, 0.21999680995941162, 1.0277529954910278, 4.300480842590332, 0.17521119117736816, 0.4468616247177124, 0.5724388360977173, 0.5927354097366333, 244.71080017089844, 0.6448227167129517, 0.4646567106246948, 0.6279634237289429, 0.5219292640686035, 0.5688635110855103, 0.14236557483673096, 0.42958974838256836, 0.4580768346786499, 0.34368765354156494, 245.40577697753906, 0.4822072982788086, 0.24116957187652588, 0.46777021884918213, 0.5378919839859009, 0.5783654451370239, 0.48915553092956543, 0.4301353693008423, 0.523863673210144, 0.6632899045944214, 4.589816570281982, 0.14853918552398682, 0.644981861114502, 0.6384124755859375, 0.7821835279464722, 0.44133734703063965, 0.35932791233062744, 0.3104914426803589, 0.6959943771362305, 0.6327286958694458, 0.43269288539886475, 0.31903350353240967, 0.40323448181152344, 245.10580444335938, 0.22453582286834717, 0.38189995288848877, 0.729924201965332, 0.44479620456695557, 0.6995896100997925, 5.238100051879883, 0.7519098520278931, 0.42923200130462646, 0.29371869564056396, 0.4039931297302246, 0.49151504039764404, 0.3234652280807495, 0.4252575635910034, 0.3888293504714966, 3.905338764190674, 0.28157198429107666, 0.34944236278533936, 0.2575732469558716, 0.4237130880355835, 0.46343767642974854, 0.5647279024124146, 0.4980357885360718, 0.5379694700241089, 0.3754950761795044, 1.1448941230773926, 0.5940452814102173, 6.061611652374268, 0.3657679557800293, 0.5944491624832153, 4.394709587097168, 0.2704368829727173, 0.6306657791137695, 0.49627482891082764, 0.23722398281097412, 0.695271372795105, 0.4079943895339966, 0.349798321723938, 0.6317566633224487, 0.3129793405532837, 0.03494298458099365, 0.03182351589202881, 0.4938863515853882, 0.5769782066345215, 0.5589736700057983, 0.6473634243011475, 1.1113742589950562, 0.6838891506195068, 0.6793348789215088, 0.2735511064529419, 0.4921356439590454, 0.2538093328475952, 0.36106908321380615, 0.5363641977310181, 5.962604999542236, 0.4335583448410034, 0.4028247594833374, 0.7996542453765869, 0.5770975351333618, 0.5665887594223022, 0.35793161392211914, 0.43048393726348877, 0.3148092031478882, 0.4949706792831421, 0.737909197807312, 0.29914283752441406, 0.40083086490631104, 0.08107864856719971, 0.3094121217727661, 0.15857672691345215, 0.42273902893066406, 0.3035522699356079, 0.25617945194244385, 0.43248450756073, 0.39365947246551514, 0.15523242950439453, 0.6364099979400635, 0.5001269578933716, 0.4133235216140747, 0.47518646717071533, 4.422977447509766, 0.47602546215057373, 0.6357220411300659, 0.6410995721817017, 0.48007309436798096, 6.124885559082031, 0.4537322521209717, 0.02333652973175049, 1.0577797889709473, 0.502687931060791, 0.5979310274124146, 0.024931788444519043, 0.31599414348602295, 0.22501039505004883, 0.6571762561798096, 6.185746192932129, 244.7658233642578, 0.260280966758728, 0.3806368112564087, 0.5980669260025024, 0.7981204986572266, 0.5403894186019897, 0.6137028932571411, 0.40929365158081055, 0.2559084892272949, 244.7071075439453, 0.4331932067871094, 0.4684295654296875, 0.5116766691207886, 0.5334395170211792, 0.5892190933227539, 0.10252177715301514, 0.2681924104690552, 0.8101478815078735, 0.4801987409591675, 0.30700528621673584, 0.11289834976196289, 0.4712768793106079, 0.2981768846511841, 0.1726309061050415, 0.5158418416976929], "mean_td_error": 5.4698567390441895, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 2679.0, "diff_num_grad_updates_vs_sampler_policy": 2678.0}}, "num_env_steps_sampled": 18036, "num_env_steps_trained": 685824, "num_agent_steps_sampled": 18036, "num_agent_steps_trained": 685824, "last_target_update_ts": 18036, "num_target_updates": 2679}, "sampler_results": {"episode_reward_max": 245.30165177583694, "episode_reward_min": -190.7907106205821, "episode_reward_mean": -151.49361454150997, "episode_len_mean": 92.53846153846153, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.98709934949875, -186.22795210778713, -180.3633166104555, -171.97964797914028, 245.30165177583694, -185.072070825845, -190.7907106205821, -189.38212056457996, -189.09738334268332, -181.19575117528439, -190.57463803887367, -175.16957204043865, -184.87837816029787], "episode_lengths": [100, 100, 100, 100, 3, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.239852264521028, "mean_inference_ms": 2.3967594590375136, "mean_action_processing_ms": 0.2322289224160125, "mean_env_wait_ms": 3.0544810132903852, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 245.30165177583694, "episode_reward_min": -190.7907106205821, "episode_reward_mean": -151.49361454150997, "episode_len_mean": 92.53846153846153, "episodes_this_iter": 13, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.98709934949875, -186.22795210778713, -180.3633166104555, -171.97964797914028, 245.30165177583694, -185.072070825845, -190.7907106205821, -189.38212056457996, -189.09738334268332, -181.19575117528439, -190.57463803887367, -175.16957204043865, -184.87837816029787], "episode_lengths": [100, 100, 100, 100, 3, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.239852264521028, "mean_inference_ms": 2.3967594590375136, "mean_action_processing_ms": 0.2322289224160125, "mean_env_wait_ms": 3.0544810132903852, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 18036, "num_agent_steps_trained": 685824, "num_env_steps_sampled": 18036, "num_env_steps_trained": 685824, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 18036, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 18036, "timers": {"training_iteration_time_ms": 152.151, "load_time_ms": 0.266, "load_throughput": 961961.856, "learn_time_ms": 24.681, "learn_throughput": 10372.142, "synch_weights_time_ms": 5.327}, "counters": {"num_env_steps_sampled": 18036, "num_env_steps_trained": 685824, "num_agent_steps_sampled": 18036, "num_agent_steps_trained": 685824, "last_target_update_ts": 18036, "num_target_updates": 2679}, "done": false, "episodes_total": 187, "training_iteration": 18, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-42-49", "timestamp": 1675950169, "time_this_iter_s": 51.91252279281616, "time_total_s": 477.7900643348694, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105882b0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a4af0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 477.7900643348694, "timesteps_since_restore": 0, "iterations_since_restore": 18, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.63661971830986, "ram_util_percent": 86.65492957746481}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.385964393615723, "actor_loss": -3.7739951610565186, "critic_loss": 0.45994797348976135, "alpha_loss": -7.582221031188965, "alpha_value": 0.40488338470458984, "log_alpha_value": -0.9041562080383301, "target_entropy": -5.0, "policy_t": -0.0500328466296196, "mean_q": 2.4238462448120117, "max_q": 3.4868509769439697, "min_q": 1.42137610912323}, "td_error": [0.394910991191864, 0.2628438472747803, 0.4017423391342163, 0.7906085252761841, 0.2573590874671936, 0.6423782110214233, 245.88772583007812, 0.3932042121887207, 5.59120512008667, 0.3633798360824585, 246.23895263671875, 0.6121361255645752, 0.2408233880996704, 0.5227920413017273, 0.6571712493896484, 0.24074184894561768, 0.6400727033615112, 0.460726797580719, 0.36129236221313477, 0.691757321357727, 0.44368088245391846, 0.42979323863983154, 0.06678950786590576, 0.6646156311035156, 0.03792119026184082, 0.24965989589691162, 0.5430482625961304, 4.686160564422607, 0.22374236583709717, 0.40298354625701904, 0.570361852645874, 0.3083411455154419, 0.5734424591064453, 0.5696547031402588, 246.3035125732422, 0.7441556453704834, 0.6987317800521851, 0.5714476108551025, 0.531324028968811, 0.31468361616134644, 0.06046020984649658, 0.764360785484314, 0.44781339168548584, 0.6927292346954346, 0.5291730761528015, 0.39976704120635986, 0.5216941833496094, 0.13183128833770752, 0.5599344372749329, 0.5769963264465332, 0.5736805200576782, 0.536696195602417, 0.989804744720459, 0.4074043035507202, 0.2364506721496582, 0.7207262516021729, 0.48425209522247314, 0.362329363822937, 0.4008105397224426, 245.35549926757812, 0.2554205656051636, 0.24267053604125977, 0.526089072227478, 0.46985435485839844, 0.5485398769378662, 0.4044121503829956, 0.35775113105773926, 0.4529736638069153, 0.22104895114898682, 0.37488728761672974, 0.37810957431793213, 0.5947524309158325, 0.02938365936279297, 0.4762014150619507, 0.6074114441871643, 0.3029390573501587, 0.9173831939697266, 0.8386657238006592, 0.44184333086013794, 0.2532082796096802, 0.35720759630203247, 0.791070818901062, 0.5076202154159546, 0.24991416931152344, 0.7795515060424805, 0.41728293895721436, 0.554948091506958, 3.8106703758239746, 0.4067126512527466, 0.3973581790924072, 0.4098062515258789, 0.3950035572052002, 0.39490807056427, 0.5484359264373779, 0.35810327529907227, 0.49945271015167236, 0.22456324100494385, 0.7886639833450317, 0.291337788105011, 0.3842194080352783, 0.4956579804420471, 0.2534463405609131, 0.6926441192626953, 0.28668034076690674, 0.6556148529052734, 0.421830415725708, 245.4654541015625, 0.719435453414917, 0.7444310188293457, 0.7715919613838196, 0.33767223358154297, 0.5190101861953735, 0.9542018175125122, 0.4372744560241699, 0.07865196466445923, 0.2884289026260376, 0.32875895500183105, 0.45849037170410156, 0.585167646408081, 0.5441964864730835, 0.5346540212631226, 0.46270811557769775, 0.6377924680709839, 0.5453131198883057, 0.1595165729522705, 0.46880829334259033, 0.09557068347930908, 0.45309507846832275, 0.3045804500579834, 0.5128308534622192, 4.474164962768555, 4.038353443145752, 0.09073770046234131, 0.4046677350997925, 0.24139916896820068, 0.33096468448638916, 0.2319338321685791, 5.114999771118164, 0.3085893392562866, 0.38757574558258057, 0.02403736114501953, 0.6291124820709229, 0.4703570604324341, 0.5190802812576294, 0.45181214809417725, 0.659011960029602, 0.4502485990524292, 0.5571601390838623, 3.4502220153808594, 0.4518376588821411, 0.6674740314483643, 0.6204067468643188, 0.3445640802383423, 0.17880117893218994, 0.5638304948806763, 0.14131224155426025, 0.1642131805419922, 0.30834877490997314, 0.49924564361572266, 0.4696359634399414, 0.43828725814819336, 0.3279399871826172, 0.5458101034164429, 245.88772583007812, 0.46244215965270996, 0.3317379951477051, 0.5007835626602173, 0.3126729726791382, 0.5263053178787231, 0.4165140390396118, 0.31228697299957275, 0.335651159286499, 0.40996384620666504, 0.619436502456665, 0.5426795482635498, 0.7304847240447998, 245.48599243164062, 0.3673959970474243, 0.32183408737182617, 0.3755403757095337, 0.2109280824661255, 0.5051699876785278, 0.6859761476516724, 0.5560386180877686, 0.6626095771789551, 0.5857183933258057, 0.38693439960479736, 0.6106091737747192, 0.38418352603912354, 0.47015392780303955, 0.4935130476951599, 0.40007174015045166, 0.260625422000885, 0.660132884979248, 0.38655734062194824, 0.6912552118301392, 0.3665940761566162, 0.6193928718566895, 0.5823854207992554, 0.40589988231658936, 245.93212890625, 0.27195024490356445, 0.28514182567596436, 0.6196141242980957, 0.7078256607055664, 0.6770950555801392, 0.6371610164642334, 245.88772583007812, 0.6048085689544678, 0.6474229097366333, 0.5370677709579468, 246.23895263671875, 0.3466893434524536, 0.4091874361038208, 0.37791895866394043, 0.46873295307159424, 0.14287495613098145, 0.2270493507385254, 0.7048720121383667, 0.5897319316864014, 0.47942662239074707, 0.24309825897216797, 0.5638831853866577, 1.20176362991333, 0.14444369077682495, 0.5704578757286072, 0.6870735883712769, 0.678199291229248, 0.3165566921234131, 0.6083974242210388, 0.13139557838439941, 0.7518117427825928, 0.4841567277908325, 0.30508625507354736, 0.5213923454284668, 0.19270455837249756, 0.552425742149353, 0.45769834518432617, 0.4266399145126343, 0.3166828155517578, 0.351742148399353, 0.4199066162109375, 0.7699737548828125, 245.4654541015625, 0.3518342971801758, 3.962533712387085, 0.38453763723373413, 0.422021746635437, 0.2805979251861572, 0.40048539638519287, 0.781794548034668, 0.5267387628555298, 0.48717260360717773, 0.48273766040802, 0.8787935972213745, 0.28841638565063477], "mean_td_error": 11.126697540283203, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 3013.0, "diff_num_grad_updates_vs_sampler_policy": 3012.0}}, "num_env_steps_sampled": 19038, "num_env_steps_trained": 771328, "num_agent_steps_sampled": 19038, "num_agent_steps_trained": 771328, "last_target_update_ts": 19038, "num_target_updates": 3013}, "sampler_results": {"episode_reward_max": -165.1230638846755, "episode_reward_min": -194.33256532251835, "episode_reward_mean": -181.8145749858684, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.89069928228855, -172.24453258514404, -183.67306399345398, -184.5737228691578, -194.33256532251835, -183.55377605557442, -191.13914181292057, -186.8006090670824, -165.1230638846755], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2281198573208902, "mean_inference_ms": 2.3886849165125543, "mean_action_processing_ms": 0.23054858728038882, "mean_env_wait_ms": 3.03391563586218, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -165.1230638846755, "episode_reward_min": -194.33256532251835, "episode_reward_mean": -181.8145749858684, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-174.89069928228855, -172.24453258514404, -183.67306399345398, -184.5737228691578, -194.33256532251835, -183.55377605557442, -191.13914181292057, -186.8006090670824, -165.1230638846755], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2281198573208902, "mean_inference_ms": 2.3886849165125543, "mean_action_processing_ms": 0.23054858728038882, "mean_env_wait_ms": 3.03391563586218, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19038, "num_agent_steps_trained": 771328, "num_env_steps_sampled": 19038, "num_env_steps_trained": 771328, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 19038, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 19038, "timers": {"training_iteration_time_ms": 153.136, "load_time_ms": 0.274, "load_throughput": 934501.152, "learn_time_ms": 25.042, "learn_throughput": 10222.666, "synch_weights_time_ms": 6.092}, "counters": {"num_env_steps_sampled": 19038, "num_env_steps_trained": 771328, "num_agent_steps_sampled": 19038, "num_agent_steps_trained": 771328, "last_target_update_ts": 19038, "num_target_updates": 3013}, "done": false, "episodes_total": 196, "training_iteration": 19, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-43-41", "timestamp": 1675950221, "time_this_iter_s": 52.18798112869263, "time_total_s": 529.978045463562, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588460>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1058b040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 529.978045463562, "timesteps_since_restore": 0, "iterations_since_restore": 19, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.94444444444444, "ram_util_percent": 86.58749999999999}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.39711856842041, "actor_loss": -2.4346561431884766, "critic_loss": 0.34377148747444153, "alpha_loss": -8.433076858520508, "alpha_value": 0.3663075566291809, "log_alpha_value": -1.004281997680664, "target_entropy": -5.0, "policy_t": -0.03771831467747688, "mean_q": 1.2214823961257935, "max_q": 2.5252320766448975, "min_q": 0.27782896161079407}, "td_error": [0.43131351470947266, 0.23862498998641968, 0.3459519147872925, 0.3174312114715576, 0.6633003354072571, 0.40486931800842285, 0.18641209602355957, 0.43599480390548706, 0.5369510650634766, 0.45826035737991333, 0.6021699905395508, 0.38298743963241577, 0.6965673565864563, 0.5552926063537598, 0.33146098256111145, 0.6677152514457703, 0.36263012886047363, 0.4075542688369751, 0.493217408657074, 0.12197573482990265, 0.5863733887672424, 0.5623564720153809, 0.45917120575904846, 0.447022408246994, 0.09169957041740417, 0.9050859212875366, 3.3141257762908936, 0.45911771059036255, 0.4654293656349182, 0.5202038884162903, 247.0439453125, 3.2932181358337402, 1.2495927810668945, 0.06806346774101257, 0.4562820792198181, 0.6144911646842957, 0.3753018379211426, 0.9154349565505981, 0.4804028272628784, 0.6891865730285645, 0.6386599540710449, 0.5669675469398499, 0.4666733145713806, 0.6515892744064331, 0.4362581670284271, 0.44680607318878174, 0.5327398777008057, 246.815673828125, 0.3901628851890564, 0.5093432068824768, 0.6292581558227539, 0.48171889781951904, 0.4650084972381592, 0.3420366048812866, 0.046936213970184326, 0.36328718066215515, 0.29382002353668213, 0.6221367716789246, 0.36043065786361694, 0.39655518531799316, 0.3234993517398834, 0.3513678014278412, 0.4879474639892578, 0.4808809459209442, 0.45783108472824097, 2.814396858215332, 0.41955462098121643, 0.4895632266998291, 0.27942368388175964, 0.433153361082077, 0.4573986530303955, 0.4445036053657532, 0.5724842548370361, 0.5182978510856628, 0.5654815435409546, 0.4203062057495117, 0.032978713512420654, 0.0712181031703949, 0.7094284296035767, 0.7031900882720947, 0.6919393539428711, 0.514389157295227, 0.2494751513004303, 2.8686583042144775, 0.7997313141822815, 0.3287367820739746, 0.6000406742095947, 0.46166419982910156, 0.5477617979049683, 0.3556674122810364, 0.47286686301231384, 0.3172603249549866, 0.38681524991989136, 246.32937622070312, 0.6940822005271912, 0.5285576581954956, 0.6171616315841675, 0.41735154390335083, 0.377725213766098, 0.6314413547515869, 0.4216507375240326, 0.5066007971763611, 0.6342012286186218, 0.5187870860099792, 0.4353627562522888, 0.23967796564102173, 247.1008758544922, 0.4696425795555115, 0.45590007305145264, 0.5327283143997192, 0.39013510942459106, 0.48843950033187866, 0.5533401370048523, 0.4319494664669037, 0.38321375846862793, 0.3570435643196106, 0.4318172335624695, 0.5121527910232544, 0.3891076445579529, 0.5245746374130249, 0.6897873282432556, 0.38936638832092285, 0.6077240705490112, 0.5667614340782166, 0.6930602788925171, 0.3734779357910156, 0.45242756605148315, 0.4347779154777527, 0.8881879448890686, 0.46206480264663696, 0.2237514853477478, 0.5646858215332031, 0.13400551676750183, 0.3669877052307129, 0.28529292345046997, 1.0300968885421753, 0.376806378364563, 3.17785906791687, 0.46438467502593994, 0.5562531352043152, 1.1434533596038818, 0.08590580523014069, 0.07123708724975586, 0.9901435375213623, 0.26116037368774414, 0.24951684474945068, 0.2984035015106201, 0.27234628796577454, 0.04114559292793274, 0.6121925115585327, 0.2641371786594391, 0.5454411506652832, 0.2511519193649292, 0.7127641439437866, 0.6308438181877136, 0.7749462127685547, 0.6543197631835938, 0.5146356225013733, 3.4983463287353516, 0.07254725694656372, 0.22337234020233154, 0.4177807569503784, 0.45289742946624756, 0.4928818345069885, 0.4207812547683716, 0.677737295627594, 0.47099360823631287, 0.45396918058395386, 0.38409245014190674, 0.4170868992805481, 0.6542566418647766, 0.6113505363464355, 0.539496123790741, 3.094233512878418, 0.2132435441017151, 0.46679162979125977, 247.1008758544922, 0.46356725692749023, 0.718112051486969, 0.2992290258407593, 0.2825879454612732, 0.6197595596313477, 0.36992695927619934, 0.2992231845855713, 0.23293691873550415, 0.5004488825798035, 0.5661985278129578, 0.46178191900253296, 246.94479370117188, 0.43547672033309937, 0.42556464672088623, 0.4700942635536194, 0.37115001678466797, 0.4039040803909302, 1.9483890533447266, 0.3222969174385071, 2.0409698486328125, 247.09432983398438, 0.40301525592803955, 0.3078502416610718, 0.3737676441669464, 0.2607581615447998, 0.6340166330337524, 0.2915620803833008, 0.6397556066513062, 0.6766482591629028, 0.4503626227378845, 0.33564215898513794, 0.5473787188529968, 0.5308709144592285, 0.2716105580329895, 0.6959229111671448, 0.4006386399269104, 0.16198450326919556, 0.8543975353240967, 0.5490132570266724, 0.3342821002006531, 0.5962952375411987, 0.5406793355941772, 0.7908567190170288, 0.320960134267807, 247.15762329101562, 0.5629262924194336, 0.30080848932266235, 0.05276674032211304, 0.6342025399208069, 0.39887356758117676, 0.7193541526794434, 0.38145264983177185, 3.5500621795654297, 0.6766764521598816, 0.6500935554504395, 2.9410243034362793, 0.597405195236206, 0.50987708568573, 0.5864880084991455, 0.3910965621471405, 0.5651043057441711, 0.5505111217498779, 0.30042022466659546, 0.5024309158325195, 0.17499327659606934, 0.2866929769515991, 0.5408392548561096, 0.05187958478927612, 0.38540589809417725, 0.40384188294410706, 0.39801156520843506, 0.12769263982772827, 0.39698082208633423, 0.4557046890258789, 0.16258090734481812, 0.35231414437294006, 0.44926875829696655, 0.08537435531616211, 0.03846198320388794], "mean_td_error": 8.267369270324707, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 3347.0, "diff_num_grad_updates_vs_sampler_policy": 3346.0}}, "num_env_steps_sampled": 20040, "num_env_steps_trained": 856832, "num_agent_steps_sampled": 20040, "num_agent_steps_trained": 856832, "last_target_update_ts": 20040, "num_target_updates": 3347}, "sampler_results": {"episode_reward_max": -162.97039559483528, "episode_reward_min": -192.73386228084564, "episode_reward_mean": -180.43006274104118, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-185.02881395816803, -186.0774904191494, -183.38704292476177, -192.73386228084564, -185.16548888385296, -162.97039559483528, -185.83342100679874, -171.34927606582642, -171.3247735351324], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2231326439848964, "mean_inference_ms": 2.386453081163432, "mean_action_processing_ms": 0.2300773309042358, "mean_env_wait_ms": 3.0260792405687518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -162.97039559483528, "episode_reward_min": -192.73386228084564, "episode_reward_mean": -180.43006274104118, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-185.02881395816803, -186.0774904191494, -183.38704292476177, -192.73386228084564, -185.16548888385296, -162.97039559483528, -185.83342100679874, -171.34927606582642, -171.3247735351324], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2231326439848964, "mean_inference_ms": 2.386453081163432, "mean_action_processing_ms": 0.2300773309042358, "mean_env_wait_ms": 3.0260792405687518, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 20040, "num_agent_steps_trained": 856832, "num_env_steps_sampled": 20040, "num_env_steps_trained": 856832, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 20040, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 20040, "timers": {"training_iteration_time_ms": 152.251, "load_time_ms": 0.269, "load_throughput": 951055.646, "learn_time_ms": 25.412, "learn_throughput": 10074.109, "synch_weights_time_ms": 5.859}, "counters": {"num_env_steps_sampled": 20040, "num_env_steps_trained": 856832, "num_agent_steps_sampled": 20040, "num_agent_steps_trained": 856832, "last_target_update_ts": 20040, "num_target_updates": 3347}, "done": false, "episodes_total": 205, "training_iteration": 20, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-44-33", "timestamp": 1675950273, "time_this_iter_s": 51.79817724227905, "time_total_s": 581.7762227058411, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbac0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a45e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 581.7762227058411, "timesteps_since_restore": 0, "iterations_since_restore": 20, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.9, "ram_util_percent": 86.6450704225352}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.378369331359863, "actor_loss": -1.1462726593017578, "critic_loss": 0.33888059854507446, "alpha_loss": -9.252996444702148, "alpha_value": 0.33141258358955383, "log_alpha_value": -1.1043912172317505, "target_entropy": -5.0, "policy_t": -0.028260355815291405, "mean_q": 0.03702754154801369, "max_q": 1.4440006017684937, "min_q": -0.8526847958564758}, "td_error": [0.4770467281341553, 0.4299864172935486, 0.6373506784439087, 0.32166528701782227, 0.4322088658809662, 2.011474609375, 0.5245293378829956, 0.4849337339401245, 0.5461462736129761, 0.6947281956672668, 0.5101229548454285, 0.22545385360717773, 0.15369652211666107, 0.40908217430114746, 0.5411048531532288, 0.48451000452041626, 0.3542185425758362, 0.061454325914382935, 0.34284478425979614, 0.589587926864624, 0.4915366470813751, 0.4751148521900177, 0.33138808608055115, 0.4700714349746704, 0.45121538639068604, 0.39414310455322266, 0.4773143529891968, 0.6389015913009644, 0.12529711425304413, 0.5235848426818848, 0.7016283273696899, 0.5044194459915161, 248.36184692382812, 0.4609985947608948, 0.5188171863555908, 0.6242727041244507, 0.22198200225830078, 0.4993423521518707, 0.6145718693733215, 0.355612576007843, 0.3550109267234802, 0.5377427339553833, 0.489568293094635, 0.3864070773124695, 0.5787477493286133, 0.4005858898162842, 0.5933955907821655, 0.4897647500038147, 0.6107628345489502, 0.4067632555961609, 0.5282701849937439, 0.3892655372619629, 0.14803998172283173, 1.4487911462783813, 0.280598908662796, 0.44593632221221924, 0.22734783589839935, 0.5001512765884399, 0.5493912100791931, 0.8362563848495483, 0.278435081243515, 0.4949609637260437, 0.2949451804161072, 0.5214220285415649, 0.37051141262054443, 0.3413849174976349, 0.4970329701900482, 0.7315206527709961, 0.8464748859405518, 0.45336732268333435, 0.7131185531616211, 0.2789316773414612, 0.5843822956085205, 0.6534821391105652, 0.3332984447479248, 0.4690658748149872, 0.4395132064819336, 0.240953266620636, 0.2793842852115631, 0.18706762790679932, 0.31514549255371094, 248.20176696777344, 0.41871345043182373, 0.8320963382720947, 0.5506276488304138, 0.5484371185302734, 0.04885970801115036, 0.30224287509918213, 0.6001985669136047, 0.5669189691543579, 0.3162223696708679, 0.2189340889453888, 0.5858825445175171, 0.3554012179374695, 0.7145729660987854, 0.47134771943092346, 0.6261852979660034, 0.010783791542053223, 0.3354363739490509, 0.4297500550746918, 0.3710940480232239, 0.678209662437439, 0.5001441240310669, 0.2768285870552063, 0.35329878330230713, 0.35758334398269653, 0.6192337274551392, 0.30775177478790283, 0.18081456422805786, 0.44763898849487305, 0.5156843662261963, 0.44112464785575867, 0.5706773996353149, 0.5602099895477295, 0.6192235946655273, 0.30818164348602295, 0.049795277416706085, 0.43085888028144836, 0.4806419909000397, 0.4141520857810974, 0.3889053463935852, 0.3950014114379883, 0.3198162615299225, 0.39914828538894653, 0.16036033630371094, 0.41591301560401917, 0.6738997101783752, 0.2888764441013336, 0.4794299006462097, 0.26141268014907837, 0.42953991889953613, 1.1424455642700195, 0.49233049154281616, 0.6129592657089233, 0.46802660822868347, 0.4949650466442108, 0.4769647717475891, 0.07349404692649841, 0.13215933740139008, 0.224662184715271, 0.3135334849357605, 248.20176696777344, 0.5784733295440674, 0.5081228613853455, 0.7449057102203369, 248.13739013671875, 3.624180555343628, 0.46076324582099915, 0.5430960059165955, 0.7654554843902588, 1.8484405279159546, 0.5107531547546387, 0.30109551548957825, 0.6907022595405579, 0.533195972442627, 0.46840089559555054, 0.3291986584663391, 0.6197736263275146, 0.40575262904167175, 0.6558277606964111, 0.3562306761741638, 1.9791377782821655, 248.24452209472656, 0.7182705402374268, 0.5590420961380005, 0.40643811225891113, 0.4180918335914612, 0.5694660544395447, 0.5753911733627319, 0.2500353455543518, 0.7172279357910156, 0.2175445258617401, 0.4258234202861786, 0.33480966091156006, 0.5565763115882874, 0.40437090396881104, 0.4018835425376892, 0.10769593715667725, 0.7346296310424805, 0.7331281304359436, 0.3576776087284088, 0.5840698480606079, 0.30311453342437744, 0.6931348443031311, 0.3488123118877411, 0.23065179586410522, 0.5469818115234375, 3.1282246112823486, 0.37539511919021606, 0.4785090982913971, 0.1964743435382843, 0.5017169117927551, 0.5424443483352661, 0.6041990518569946, 0.29702121019363403, 0.6603002548217773, 0.5344533920288086, 0.6319787502288818, 0.11871286481618881, 2.1465187072753906, 0.49629494547843933, 0.4821137487888336, 0.3418009281158447, 0.5958198308944702, 0.5824304819107056, 0.2309936285018921, 0.5449689030647278, 0.2481338083744049, 0.34424149990081787, 0.7907780408859253, 0.39152491092681885, 0.4981885552406311, 0.7680237293243408, 0.6705684661865234, 0.2149336338043213, 0.38822418451309204, 0.9790916442871094, 0.4521169066429138, 0.5312075614929199, 0.3982628583908081, 0.3806946575641632, 0.385680228471756, 0.3939254879951477, 248.60501098632812, 248.20176696777344, 0.34818124771118164, 0.32151466608047485, 0.4740479588508606, 0.44351130723953247, 0.33115679025650024, 0.7411002516746521, 0.35074928402900696, 0.5736442804336548, 0.5954192876815796, 0.36882030963897705, 0.25809353590011597, 0.45251381397247314, 0.873249888420105, 0.2777828872203827, 0.6791621446609497, 0.19161665439605713, 248.13739013671875, 0.5437303781509399, 0.41519713401794434, 0.8521048426628113, 0.3958228826522827, 0.6179636716842651, 0.7398141622543335, 0.273581862449646, 0.6737342476844788, 0.35104215145111084, 0.668419599533081, 0.46944886445999146, 0.5371466279029846, 0.35272979736328125, 0.2097807228565216], "mean_td_error": 8.25240707397461, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 3681.0, "diff_num_grad_updates_vs_sampler_policy": 3680.0}}, "num_env_steps_sampled": 21042, "num_env_steps_trained": 942336, "num_agent_steps_sampled": 21042, "num_agent_steps_trained": 942336, "last_target_update_ts": 21042, "num_target_updates": 3681}, "sampler_results": {"episode_reward_max": -167.6864303201437, "episode_reward_min": -193.03460130095482, "episode_reward_mean": -179.939817359671, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.2956598252058, -193.03460130095482, -188.71201647818089, -167.6864303201437, -174.62564761936665, -187.33417315781116, -191.16441805660725, -167.98305432498455, -187.39179661870003, -175.97241815179586, -174.4930499047041, -171.58454255759716], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.218624244140712, "mean_inference_ms": 2.386070651604745, "mean_action_processing_ms": 0.22939708969830386, "mean_env_wait_ms": 3.020549619189348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.6864303201437, "episode_reward_min": -193.03460130095482, "episode_reward_mean": -179.939817359671, "episode_len_mean": 100.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-179.2956598252058, -193.03460130095482, -188.71201647818089, -167.6864303201437, -174.62564761936665, -187.33417315781116, -191.16441805660725, -167.98305432498455, -187.39179661870003, -175.97241815179586, -174.4930499047041, -171.58454255759716], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.218624244140712, "mean_inference_ms": 2.386070651604745, "mean_action_processing_ms": 0.22939708969830386, "mean_env_wait_ms": 3.020549619189348, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 21042, "num_agent_steps_trained": 942336, "num_env_steps_sampled": 21042, "num_env_steps_trained": 942336, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 21042, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 21042, "timers": {"training_iteration_time_ms": 156.891, "load_time_ms": 0.283, "load_throughput": 904355.954, "learn_time_ms": 25.521, "learn_throughput": 10030.827, "synch_weights_time_ms": 6.516}, "counters": {"num_env_steps_sampled": 21042, "num_env_steps_trained": 942336, "num_agent_steps_sampled": 21042, "num_agent_steps_trained": 942336, "last_target_update_ts": 21042, "num_target_updates": 3681}, "done": false, "episodes_total": 217, "training_iteration": 21, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-45-25", "timestamp": 1675950325, "time_this_iter_s": 52.11804485321045, "time_total_s": 633.8942675590515, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380cfb20>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd5e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 633.8942675590515, "timesteps_since_restore": 0, "iterations_since_restore": 21, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.804225352112674, "ram_util_percent": 87.39999999999999}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.40589427947998, "actor_loss": 0.010127241723239422, "critic_loss": 0.3361027240753174, "alpha_loss": -10.124749183654785, "alpha_value": 0.29984724521636963, "log_alpha_value": -1.204482078552246, "target_entropy": -5.0, "policy_t": -0.013639705255627632, "mean_q": -1.0122102499008179, "max_q": 0.636811375617981, "min_q": -2.095050573348999}, "td_error": [0.4057937264442444, 0.21193712949752808, 0.40150660276412964, 0.6746391654014587, 0.4461689591407776, 0.3564269244670868, 0.5500780344009399, 0.599684476852417, 0.1682370901107788, 0.17738914489746094, 0.3345663249492645, 0.7133718729019165, 0.4191882610321045, 248.83474731445312, 0.4495241045951843, 0.38041138648986816, 0.4907727837562561, 0.2428215742111206, 0.5512993335723877, 0.3822813034057617, 0.7523033618927002, 0.5989571213722229, 0.41315948963165283, 0.4102850556373596, 0.33046966791152954, 0.38521724939346313, 0.5351959466934204, 0.5502880215644836, 0.3044740557670593, 0.7230451107025146, 0.5554122924804688, 0.28399592638015747, 0.6089479923248291, 0.2549089789390564, 0.4887315630912781, 0.4339461922645569, 0.4052528142929077, 0.5723710656166077, 0.5164968967437744, 0.47367286682128906, 0.46216970682144165, 0.11994808912277222, 0.8686490058898926, 0.08918654918670654, 0.4926060438156128, 0.4463791847229004, 0.211421936750412, 0.4928330183029175, 0.18851244449615479, 0.811231791973114, 0.41832995414733887, 249.38580322265625, 0.4129471778869629, 0.18487173318862915, 0.6662919521331787, 0.5756860971450806, 0.494231253862381, 0.6119292378425598, 0.7639319896697998, 0.6848875284194946, 0.1935354471206665, 0.4926818609237671, 0.36387044191360474, 0.44201648235321045, 0.749928891658783, 0.043963611125946045, 0.6634605526924133, 0.44473373889923096, 0.42097383737564087, 0.6038827896118164, 0.5004186630249023, 0.30241096019744873, 0.587613582611084, 0.7334430813789368, 0.27903884649276733, 0.41453421115875244, 0.3170315623283386, 0.4062184691429138, 0.6436464190483093, 0.652737557888031, 0.8399145603179932, 0.4542408585548401, 0.5841132998466492, 0.4421268701553345, 0.4995564818382263, 0.16469550132751465, 0.8398739099502563, 0.7535677552223206, 0.9898229837417603, 0.31994014978408813, 0.5822089314460754, 0.5978573560714722, 0.34699058532714844, 0.5392458438873291, 0.46718698740005493, 0.5331778526306152, 0.5393555760383606, 0.5588425397872925, 0.49929434061050415, 0.28491857647895813, 0.10522955656051636, 0.48603367805480957, 0.3307778835296631, 0.31660526990890503, 0.27212563157081604, 0.10782128572463989, 0.4001883864402771, 0.5735080242156982, 0.5465714335441589, 0.5193055868148804, 248.22866821289062, 0.6708012819290161, 0.8704984784126282, 0.597537636756897, 0.34427976608276367, 0.7058205604553223, 0.5566147565841675, 0.15477114915847778, 0.33997613191604614, 0.42280715703964233, 0.42665737867355347, 0.5912528038024902, 0.35120731592178345, 0.564368724822998, 0.5672280192375183, 0.4663897156715393, 0.297222375869751, 0.3950192928314209, 249.7141571044922, 0.4723725914955139, 0.6137678623199463, 0.5329605340957642, 0.16398707032203674, 0.28658968210220337, 249.6925048828125, 0.6319475173950195, 0.27785754203796387, 0.1609046459197998, 0.4174153208732605, 0.6970177888870239, 0.5828884840011597, 249.6925048828125, 0.30740100145339966, 0.26247960329055786, 0.5834058523178101, 0.6349920034408569, 0.34150904417037964, 0.5585076808929443, 0.44966620206832886, 0.5152169466018677, 0.21370619535446167, 0.6295304894447327, 0.374541312456131, 0.3593369722366333, 0.47011932730674744, 0.23107385635375977, 0.8112053871154785, 0.449444055557251, 0.6309118270874023, 0.7886395454406738, 0.5899434089660645, 0.2839491367340088, 0.17448920011520386, 0.46044209599494934, 0.8632166385650635, 0.4099884331226349, 0.4581388235092163, 0.3405141532421112, 0.4247815012931824, 0.8936871886253357, 0.606514573097229, 0.27170124650001526, 0.48678821325302124, 0.6393028497695923, 0.9775344133377075, 0.34231263399124146, 0.7233467102050781, 248.67227172851562, 0.2981274127960205, 0.5697203874588013, 0.553203821182251, 0.4152758717536926, 0.07417502999305725, 0.338604211807251, 0.5464912056922913, 0.600563645362854, 0.36172276735305786, 0.29790860414505005, 0.5756841897964478, 0.5935285091400146, 0.012033700942993164, 0.1382901668548584, 0.8823350071907043, 0.567075788974762, 0.6167328357696533, 0.31291061639785767, 0.41660594940185547, 0.5100963711738586, 0.4046747088432312, 0.44424882531166077, 0.3201006054878235, 0.4480670094490051, 0.25778114795684814, 1.3576549291610718, 0.43644750118255615, 0.5076820254325867, 0.27454930543899536, 0.53377366065979, 0.29224956035614014, 0.6194506883621216, 0.4769933819770813, 0.4829789400100708, 0.22834773361682892, 0.6204907894134521, 0.3508942723274231, 0.34903597831726074, 0.42070555686950684, 2.004178524017334, 0.43504345417022705, 0.5856280326843262, 0.4027990698814392, 0.7186062335968018, 0.4460718035697937, 0.5727843046188354, 0.34877443313598633, 0.6575485467910767, 0.6710357069969177, 0.39782029390335083, 0.6432360410690308, 0.6798933148384094, 0.7820611596107483, 0.24042659997940063, 0.6435049176216125, 0.3996138572692871, 0.7448657751083374, 0.4415537714958191, 0.21883153915405273, 0.5220440030097961, 0.44843509793281555, 0.6456485986709595, 0.4158572554588318, 0.21815931797027588, 0.43907761573791504, 0.5313904881477356, 0.012382805347442627, 0.21731063723564148, 0.16543996334075928, 0.41099220514297485, 0.6153082847595215, 0.6041637659072876, 0.5557907819747925, 0.4979221224784851, 249.38580322265625, 0.29977744817733765, 0.6433144211769104, 0.6081979274749756], "mean_td_error": 8.25007152557373, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 4015.0, "diff_num_grad_updates_vs_sampler_policy": 4014.0}}, "num_env_steps_sampled": 22044, "num_env_steps_trained": 1027840, "num_agent_steps_sampled": 22044, "num_agent_steps_trained": 1027840, "last_target_update_ts": 22044, "num_target_updates": 4015}, "sampler_results": {"episode_reward_max": 240.51233860850334, "episode_reward_min": -192.8343891054392, "episode_reward_mean": -143.5046384178102, "episode_len_mean": 90.6, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-190.34558657556772, -189.03799837827682, -182.9403861016035, -192.8343891054392, -182.12118066847324, -182.52771258354187, -183.80604764819145, -181.47512324154377, 240.51233860850334, -190.47029848396778], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 6, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2070074878204178, "mean_inference_ms": 2.376503135934462, "mean_action_processing_ms": 0.22752439104662345, "mean_env_wait_ms": 3.0037685581933466, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 240.51233860850334, "episode_reward_min": -192.8343891054392, "episode_reward_mean": -143.5046384178102, "episode_len_mean": 90.6, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-190.34558657556772, -189.03799837827682, -182.9403861016035, -192.8343891054392, -182.12118066847324, -182.52771258354187, -183.80604764819145, -181.47512324154377, 240.51233860850334, -190.47029848396778], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 6, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2070074878204178, "mean_inference_ms": 2.376503135934462, "mean_action_processing_ms": 0.22752439104662345, "mean_env_wait_ms": 3.0037685581933466, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 22044, "num_agent_steps_trained": 1027840, "num_env_steps_sampled": 22044, "num_env_steps_trained": 1027840, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 22044, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 22044, "timers": {"training_iteration_time_ms": 158.137, "load_time_ms": 0.307, "load_throughput": 832939.123, "learn_time_ms": 26.817, "learn_throughput": 9546.137, "synch_weights_time_ms": 5.88}, "counters": {"num_env_steps_sampled": 22044, "num_env_steps_trained": 1027840, "num_agent_steps_sampled": 22044, "num_agent_steps_trained": 1027840, "last_target_update_ts": 22044, "num_target_updates": 4015}, "done": false, "episodes_total": 227, "training_iteration": 22, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-46-18", "timestamp": 1675950378, "time_this_iter_s": 52.17977786064148, "time_total_s": 686.074045419693, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be064f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 686.074045419693, "timesteps_since_restore": 0, "iterations_since_restore": 22, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.729577464788726, "ram_util_percent": 87.57042253521126}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.382535934448242, "actor_loss": 1.417138934135437, "critic_loss": 0.33730459213256836, "alpha_loss": -10.935290336608887, "alpha_value": 0.2712993621826172, "log_alpha_value": -1.3045324087142944, "target_entropy": -5.0, "policy_t": -0.03352588787674904, "mean_q": -2.3116636276245117, "max_q": -0.4097386598587036, "min_q": -3.5393080711364746}, "td_error": [0.21046090126037598, 0.6573339700698853, 0.5967714190483093, 0.41906464099884033, 0.5498813390731812, 0.6089502573013306, 0.18513667583465576, 0.054346323013305664, 0.7385557293891907, 0.596469521522522, 0.41353046894073486, 0.5025835037231445, 0.4329054355621338, 0.3832739591598511, 0.6135755777359009, 0.2851743698120117, 0.34903109073638916, 0.4887511730194092, 0.6827131509780884, 0.5173364877700806, 0.843383252620697, 0.5567138195037842, 0.9826453924179077, 0.7374875545501709, 0.29109179973602295, 0.24359524250030518, 0.8142892122268677, 0.38520926237106323, 0.2484055757522583, 1.4251888990402222, 0.4130895733833313, 0.48351597785949707, 0.2780904173851013, 0.7382200360298157, 0.5111799240112305, 0.36573004722595215, 0.17955684661865234, 0.35428082942962646, 0.15356755256652832, 0.23443347215652466, 0.4342617988586426, 249.78854370117188, 0.12242376804351807, 0.5138356685638428, 0.39300957322120667, 0.3763033151626587, 0.3916900157928467, 0.3280033469200134, 0.5087399482727051, 0.5132814645767212, 0.5672634840011597, 0.15797209739685059, 0.3815094828605652, 0.34583473205566406, 0.4034388065338135, 0.28809940814971924, 0.27999448776245117, 0.34298551082611084, 0.3564640283584595, 0.7301956415176392, 0.45758533477783203, 0.44482600688934326, 0.32580792903900146, 0.09330374002456665, 0.4267195463180542, 0.41528093814849854, 0.36620640754699707, 0.4065013527870178, 0.6169543266296387, 0.6361523866653442, 0.17985165119171143, 0.7887392044067383, 0.7714540958404541, 0.38598060607910156, 0.08423137664794922, 0.5098807215690613, 0.5033124089241028, 0.6048707962036133, 0.3595890998840332, 0.48094087839126587, 0.040918707847595215, 0.5509869456291199, 0.3204076290130615, 0.46186113357543945, 0.640064001083374, 0.5911717414855957, 0.007191598415374756, 1.131937026977539, 250.27120971679688, 0.34816575050354004, 0.5313488245010376, 0.7237818837165833, 0.6506922245025635, 0.07184159755706787, 249.25082397460938, 0.4563639163970947, 0.27016210556030273, 0.5313827991485596, 0.2248992919921875, 0.2309984564781189, 0.7179064750671387, 0.2867174744606018, 0.013583779335021973, 0.34721052646636963, 0.23408293724060059, 0.3908116817474365, 0.5250136852264404, 0.12503647804260254, 0.30161595344543457, 0.4338153600692749, 0.5735315084457397, 0.6941019296646118, 0.4093815088272095, 0.6975923776626587, 0.4364033341407776, 0.24086683988571167, 0.3312767744064331, 0.6049104332923889, 0.23959875106811523, 0.7971938252449036, 0.557532548904419, 0.4104989767074585, 0.4197721481323242, 0.30501431226730347, 0.5732617378234863, 0.4926762580871582, 0.7327606081962585, 0.30510973930358887, 0.3544420003890991, 0.6738113760948181, 0.5266009569168091, 0.5006526708602905, 0.5944838523864746, 0.5240501165390015, 0.7218706607818604, 0.5560230016708374, 0.3324626684188843, 0.3415083885192871, 0.6368464231491089, 0.3740888833999634, 0.5738832950592041, 0.5797147750854492, 0.6570765972137451, 0.6524412631988525, 0.5682766437530518, 0.6912943124771118, 0.6275904178619385, 0.566068172454834, 0.6628273129463196, 0.4839293956756592, 0.4780045747756958, 0.48806387186050415, 0.8751722574234009, 0.6272985339164734, 0.5336812734603882, 0.3958383798599243, 0.6875064373016357, 0.37645649909973145, 249.83209228515625, 250.39146423339844, 0.34645920991897583, 0.6750349402427673, 0.6731109619140625, 0.7006499767303467, 0.06625401973724365, 0.3827352523803711, 0.15848469734191895, 0.7814584970474243, 0.4204976558685303, 0.43226784467697144, 0.1080864667892456, 0.43294572830200195, 0.5394332408905029, 0.35036325454711914, 0.5885578989982605, 0.5270776748657227, 0.6178052425384521, 0.4258146286010742, 0.7783786058425903, 0.5531617403030396, 0.49466079473495483, 0.32836610078811646, 0.5377665758132935, 0.46250593662261963, 0.40181565284729004, 0.8150666952133179, 0.7816159725189209, 0.5984268188476562, 0.3760915994644165, 0.18732202053070068, 0.6351698040962219, 0.47813594341278076, 0.3265082836151123, 0.4442431926727295, 0.5211272835731506, 0.4383199214935303, 0.7256631255149841, 0.38415277004241943, 0.6320098042488098, 0.6321848630905151, 0.4446815252304077, 0.6180324554443359, 0.6856759190559387, 0.5880286693572998, 0.42440366744995117, 0.6159291863441467, 0.3115118741989136, 0.4443349242210388, 0.5521467328071594, 0.24935364723205566, 0.44589078426361084, 0.5945566892623901, 0.6948679685592651, 0.739281952381134, 0.2612549066543579, 0.286301851272583, 0.5637834668159485, 0.3612288236618042, 0.4269484877586365, 0.5264698266983032, 0.30076587200164795, 0.617217481136322, 0.4418572187423706, 250.96578979492188, 0.36557328701019287, 0.5029134750366211, 0.383378803730011, 250.639404296875, 0.5190095901489258, 0.12623834609985352, 0.5628753900527954, 0.420434832572937, 0.6786396503448486, 0.3721088171005249, 0.4642293453216553, 0.439206600189209, 0.40242505073547363, 250.8885498046875, 0.4272316098213196, 0.32643914222717285, 0.31537365913391113, 0.46481454372406006, 0.14226901531219482, 0.5332574248313904, 0.5250203609466553, 0.4601393938064575, 0.45080268383026123, 0.5294077396392822, 1.71389639377594, 0.44710052013397217, 0.4219510555267334, 0.347670316696167, 0.5776402950286865, 0.37254583835601807, 0.3339504301548004, 0.6390162706375122], "mean_td_error": 8.28011703491211, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 4349.0, "diff_num_grad_updates_vs_sampler_policy": 4348.0}}, "num_env_steps_sampled": 23046, "num_env_steps_trained": 1113344, "num_agent_steps_sampled": 23046, "num_agent_steps_trained": 1113344, "last_target_update_ts": 23046, "num_target_updates": 4349}, "sampler_results": {"episode_reward_max": -180.80819918960333, "episode_reward_min": -189.49578461796045, "episode_reward_mean": -185.28221337000528, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-185.17319969832897, -189.49578461796045, -185.4290170520544, -184.17229868471622, -180.80819918960333, -185.28492912650108, -182.13111406564713, -186.03017409145832, -189.0152038037777], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2112649290094852, "mean_inference_ms": 2.387282563795045, "mean_action_processing_ms": 0.228742057627838, "mean_env_wait_ms": 3.012530451674509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -180.80819918960333, "episode_reward_min": -189.49578461796045, "episode_reward_mean": -185.28221337000528, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-185.17319969832897, -189.49578461796045, -185.4290170520544, -184.17229868471622, -180.80819918960333, -185.28492912650108, -182.13111406564713, -186.03017409145832, -189.0152038037777], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2112649290094852, "mean_inference_ms": 2.387282563795045, "mean_action_processing_ms": 0.228742057627838, "mean_env_wait_ms": 3.012530451674509, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23046, "num_agent_steps_trained": 1113344, "num_env_steps_sampled": 23046, "num_env_steps_trained": 1113344, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 23046, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 23046, "timers": {"training_iteration_time_ms": 165.749, "load_time_ms": 0.276, "load_throughput": 926998.035, "learn_time_ms": 26.412, "learn_throughput": 9692.726, "synch_weights_time_ms": 6.134}, "counters": {"num_env_steps_sampled": 23046, "num_env_steps_trained": 1113344, "num_agent_steps_sampled": 23046, "num_agent_steps_trained": 1113344, "last_target_update_ts": 23046, "num_target_updates": 4349}, "done": false, "episodes_total": 236, "training_iteration": 23, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-47-10", "timestamp": 1675950430, "time_this_iter_s": 52.58064889907837, "time_total_s": 738.6546943187714, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb070>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a0d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 738.6546943187714, "timesteps_since_restore": 0, "iterations_since_restore": 23, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.96666666666667, "ram_util_percent": 88.01249999999999}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.376197814941406, "actor_loss": 2.920299530029297, "critic_loss": 0.421129047870636, "alpha_loss": -11.764652252197266, "alpha_value": 0.24548152089118958, "log_alpha_value": -1.4045336246490479, "target_entropy": -5.0, "policy_t": -0.029200296849012375, "mean_q": -3.7106029987335205, "max_q": -2.0804409980773926, "min_q": -5.027530193328857}, "td_error": [0.5018326044082642, 0.7150397300720215, 251.74554443359375, 0.09754061698913574, 0.3658539056777954, 0.8623273372650146, 0.4127357006072998, 0.21909618377685547, 0.3477131128311157, 0.2690451145172119, 0.22003436088562012, 0.14467108249664307, 0.6667265892028809, 0.49518465995788574, 0.13692808151245117, 0.5895651578903198, 0.5271764993667603, 3.296005964279175, 0.4317220449447632, 251.09136962890625, 0.06354928016662598, 0.6000974178314209, 252.15304565429688, 0.5510690212249756, 0.41814565658569336, 2.1292572021484375, 0.5639050006866455, 0.4704442024230957, 0.1954634189605713, 0.6219121217727661, 0.3254743814468384, 0.5362775325775146, 0.07080519199371338, 0.6686621904373169, 0.418010950088501, 0.07242894172668457, 0.40874814987182617, 0.05957186222076416, 0.4051426649093628, 0.7175405025482178, 0.2998974323272705, 0.2667720317840576, 0.816063404083252, 0.29995548725128174, 0.45367431640625, 0.33191442489624023, 0.7851407527923584, 0.6623067855834961, 0.1377544403076172, 0.24586868286132812, 0.4914513826370239, 0.0550307035446167, 0.25597524642944336, 0.6574323177337646, 0.5704244375228882, 0.28434085845947266, 0.6551934480667114, 0.4417152404785156, 0.26001811027526855, 0.5218172073364258, 0.28247737884521484, 0.6725180149078369, 0.3335222005844116, 0.4203364849090576, 0.38398444652557373, 0.2729182243347168, 0.6001894474029541, 0.3851633071899414, 0.17801713943481445, 0.49923503398895264, 0.29063212871551514, 251.60107421875, 0.015741944313049316, 0.1809554100036621, 252.22750854492188, 0.09625029563903809, 0.4101743698120117, 0.5508246421813965, 0.6434458494186401, 0.5532805919647217, 0.49046623706817627, 0.44703102111816406, 0.7980005741119385, 0.6095366477966309, 0.3704383373260498, 0.26427149772644043, 0.3383772373199463, 0.36493396759033203, 0.121634840965271, 0.6895716190338135, 0.02263665199279785, 2.0311996936798096, 0.526957631111145, 0.14982473850250244, 0.6172534227371216, 0.5968999862670898, 1.0534515380859375, 0.6122066974639893, 0.5052862167358398, 0.346169114112854, 0.115653395652771, 0.4304410219192505, 252.28076171875, 0.0422971248626709, 0.3397979736328125, 0.6335283517837524, 0.37801873683929443, 0.5025933980941772, 0.5867395401000977, 0.5495291948318481, 0.49690091609954834, 0.28936195373535156, 0.7976089715957642, 0.6379926204681396, 0.5766557455062866, 0.40496397018432617, 0.9916888475418091, 0.23310446739196777, 0.34772610664367676, 0.7289929389953613, 0.33318400382995605, 0.06952273845672607, 0.5999753475189209, 3.0368499755859375, 0.5212321281433105, 0.6713544130325317, 0.5047764778137207, 251.74554443359375, 0.6275818347930908, 0.7292766571044922, 0.5413765907287598, 0.31290578842163086, 0.3572577238082886, 0.42680883407592773, 0.6297564506530762, 0.8694634437561035, 0.7503961324691772, 0.8810365200042725, 0.482985258102417, 0.21868634223937988, 0.5742775201797485, 0.2518746852874756, 0.5096004009246826, 0.4441688060760498, 0.2978328466415405, 0.48286914825439453, 0.11985456943511963, 0.5257567167282104, 3.0352470874786377, 0.7334902286529541, 0.9990241527557373, 0.6126437187194824, 0.4678761959075928, 0.5221050977706909, 0.39612483978271484, 0.45183610916137695, 0.5227138996124268, 0.32774269580841064, 0.21011948585510254, 0.43607234954833984, 0.2626856565475464, 0.3528085947036743, 0.26708388328552246, 0.06565189361572266, 0.3587515354156494, 0.6259191036224365, 251.80523681640625, 0.5990372896194458, 0.44588935375213623, 0.2542116641998291, 0.6455396413803101, 0.3445475101470947, 0.24738776683807373, 0.32388877868652344, 0.051654934883117676, 0.3858060836791992, 251.74588012695312, 0.2481234073638916, 0.43948864936828613, 0.3354628086090088, 0.20987510681152344, 0.6383072137832642, 0.5834037065505981, 1.1485873460769653, 0.38868141174316406, 0.27218353748321533, 0.7493908405303955, 0.39406609535217285, 0.5988352298736572, 0.9216456413269043, 0.3606231212615967, 0.6671360731124878, 0.5617278814315796, 0.3737785816192627, 0.7065809965133667, 0.713881254196167, 0.6482489109039307, 0.6078081130981445, 0.25593101978302, 0.3326895236968994, 0.5781798362731934, 0.19959628582000732, 0.3833017349243164, 1.2890663146972656, 0.4877781867980957, 252.28076171875, 0.13805508613586426, 0.4611048698425293, 0.36195552349090576, 0.3190758228302002, 0.4078744649887085, 0.2984849214553833, 0.18270814418792725, 0.47956597805023193, 0.514934778213501, 0.43836188316345215, 0.0758981704711914, 0.09350037574768066, 0.20740532875061035, 0.7037895917892456, 0.2971152067184448, 0.4134523868560791, 0.3079211711883545, 0.7525150775909424, 0.5393860340118408, 0.47448527812957764, 0.6350008249282837, 0.7404168844223022, 0.3980100154876709, 0.5125625133514404, 0.48478472232818604, 0.31213510036468506, 0.6345700025558472, 0.5160188674926758, 0.22101569175720215, 0.33220767974853516, 0.6504952907562256, 0.4045729637145996, 0.3916085958480835, 0.703976035118103, 0.8241798877716064, 0.45540523529052734, 0.2598602771759033, 0.17984068393707275, 0.34577369689941406, 0.5003219842910767, 0.8088583946228027, 0.23618710041046143, 0.2688344717025757, 0.3045675754547119, 0.6398144960403442, 0.6529570817947388, 0.3896496295928955, 0.3285115957260132, 0.7618141174316406, 0.6672096252441406], "mean_td_error": 10.314118385314941, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 4683.0, "diff_num_grad_updates_vs_sampler_policy": 4682.0}}, "num_env_steps_sampled": 24048, "num_env_steps_trained": 1198848, "num_agent_steps_sampled": 24048, "num_agent_steps_trained": 1198848, "last_target_update_ts": 24048, "num_target_updates": 4683}, "sampler_results": {"episode_reward_max": -167.0836452692747, "episode_reward_min": -192.73049069941044, "episode_reward_mean": -181.414447566325, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-175.82527719438076, -184.22177052497864, -187.69586757570505, -172.4897821843624, -192.73049069941044, -167.0836452692747, -188.32941034436226, -167.21700128912926, -184.5859683305025, -191.19055130332708, -184.18915851414204], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2163927521911584, "mean_inference_ms": 2.3985208746908047, "mean_action_processing_ms": 0.23055632720791194, "mean_env_wait_ms": 3.020841886882943, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.0836452692747, "episode_reward_min": -192.73049069941044, "episode_reward_mean": -181.414447566325, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-175.82527719438076, -184.22177052497864, -187.69586757570505, -172.4897821843624, -192.73049069941044, -167.0836452692747, -188.32941034436226, -167.21700128912926, -184.5859683305025, -191.19055130332708, -184.18915851414204], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2163927521911584, "mean_inference_ms": 2.3985208746908047, "mean_action_processing_ms": 0.23055632720791194, "mean_env_wait_ms": 3.020841886882943, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 24048, "num_agent_steps_trained": 1198848, "num_env_steps_sampled": 24048, "num_env_steps_trained": 1198848, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 24048, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 24048, "timers": {"training_iteration_time_ms": 153.057, "load_time_ms": 0.267, "load_throughput": 960327.184, "learn_time_ms": 24.745, "learn_throughput": 10345.729, "synch_weights_time_ms": 6.247}, "counters": {"num_env_steps_sampled": 24048, "num_env_steps_trained": 1198848, "num_agent_steps_sampled": 24048, "num_agent_steps_trained": 1198848, "last_target_update_ts": 24048, "num_target_updates": 4683}, "done": false, "episodes_total": 247, "training_iteration": 24, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-48-03", "timestamp": 1675950483, "time_this_iter_s": 53.02470254898071, "time_total_s": 791.6793968677521, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105efc70>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a940>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 791.6793968677521, "timesteps_since_restore": 0, "iterations_since_restore": 24, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.81232876712329, "ram_util_percent": 85.16986301369863}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.375699996948242, "actor_loss": 4.743227481842041, "critic_loss": 0.23512327671051025, "alpha_loss": -12.600970268249512, "alpha_value": 0.2221354991197586, "log_alpha_value": -1.5044677257537842, "target_entropy": -5.0, "policy_t": -0.046188171952962875, "mean_q": -5.445430278778076, "max_q": -3.6264865398406982, "min_q": -6.720507621765137}, "td_error": [0.3568911552429199, 0.5055737495422363, 0.5030162334442139, 0.8155980110168457, 0.11155843734741211, 0.455843448638916, 0.4187948703765869, 0.8245234489440918, 0.27774810791015625, 0.6322140693664551, 0.3444511890411377, 0.6767997741699219, 0.678380012512207, 4.28721809387207, 0.6005700826644897, 0.19606494903564453, 0.3980879783630371, 0.5375387668609619, 0.49683594703674316, 0.24769973754882812, 0.4154696464538574, 253.42355346679688, 0.4456977844238281, 0.3670845031738281, 253.29190063476562, 0.5745525360107422, 0.7122762203216553, 0.5184392929077148, 0.43946123123168945, 0.24693942070007324, 0.5472006797790527, 0.3860893249511719, 0.5687696933746338, 0.08164358139038086, 0.4487318992614746, 0.8342709541320801, 4.537684917449951, 0.5129578113555908, 4.537439823150635, 0.43057894706726074, 0.27645325660705566, 0.5979897975921631, 0.6581676006317139, 0.2737710475921631, 0.4050283432006836, 0.32711172103881836, 0.2817206382751465, 0.390533447265625, 0.42759275436401367, 0.40329837799072266, 0.5995664596557617, 0.5831418037414551, 0.5871940851211548, 0.5001623630523682, 0.8563902378082275, 0.572667121887207, 0.36076927185058594, 0.37120485305786133, 0.4156677722930908, 0.7172377109527588, 0.8043861389160156, 4.090599060058594, 0.5482032299041748, 0.3264937400817871, 0.6241188049316406, 0.7521305084228516, 4.075014114379883, 0.5256762504577637, 0.5875058174133301, 0.20749568939208984, 0.613898754119873, 0.3739280700683594, 0.4934403896331787, 0.951909065246582, 0.0679619312286377, 0.13834667205810547, 0.8315930366516113, 0.10620546340942383, 0.46865248680114746, 0.8996870517730713, 0.3630542755126953, 0.48459863662719727, 0.4177974462509155, 0.34472131729125977, 0.5955896377563477, 0.5256843566894531, 0.6607916355133057, 253.3529815673828, 0.0574948787689209, 0.42972755432128906, 0.1628413200378418, 0.3970813751220703, 0.47977960109710693, 0.03379178047180176, 0.4283027648925781, 0.6288890838623047, 0.5255260467529297, 0.49836158752441406, 0.6844964027404785, 0.589308500289917, 0.3200247287750244, 0.30655837059020996, 0.028887033462524414, 0.36656880378723145, 0.5538883209228516, 0.14992570877075195, 0.09035348892211914, 0.28389692306518555, 0.20583200454711914, 0.3702383041381836, 0.3097352981567383, 0.34683752059936523, 0.22758245468139648, 0.44466614723205566, 0.7940678596496582, 0.38573312759399414, 0.4390132427215576, 0.6711235046386719, 0.777597188949585, 0.5641515254974365, 0.5966665744781494, 0.47466516494750977, 0.8057651519775391, 0.5269684791564941, 0.2947118282318115, 0.22279715538024902, 0.5906355381011963, 0.3844585418701172, 0.5426573753356934, 0.3758571147918701, 0.3560018539428711, 0.22684144973754883, 0.5193154811859131, 0.8121771812438965, 4.91758918762207, 0.3783538341522217, 0.36078882217407227, 0.6263248920440674, 0.5827395915985107, 253.3529815673828, 0.17307686805725098, 0.14109516143798828, 0.23772907257080078, 0.30763816833496094, 0.5167441368103027, 0.8552615642547607, 0.33266115188598633, 0.4704486131668091, 0.3772106170654297, 0.25610029697418213, 0.43250441551208496, 0.3748745918273926, 0.7631487846374512, 0.5575313568115234, 0.4745628833770752, 0.7602014541625977, 0.315474271774292, 0.29891514778137207, 0.5445241928100586, 0.5317814350128174, 0.71659255027771, 0.6256792545318604, 0.49468278884887695, 3.4846291542053223, 0.3876030445098877, 0.021610736846923828, 0.5905747413635254, 0.3921360969543457, 0.5861091613769531, 0.10366535186767578, 0.5911321640014648, 0.3103957176208496, 0.4526512622833252, 0.33051085472106934, 0.7345452308654785, 0.5263683795928955, 0.5630197525024414, 0.6706712245941162, 0.2938389778137207, 0.380173921585083, 0.15254974365234375, 0.44683241844177246, 0.5514869689941406, 0.21088361740112305, 0.21908068656921387, 0.4974839687347412, 0.08414697647094727, 0.5262303352355957, 0.4711282253265381, 0.4183502197265625, 0.4774341583251953, 0.30358099937438965, 5.288222312927246, 0.40714597702026367, 0.5768799781799316, 0.5607705116271973, 0.6342148780822754, 0.2714097499847412, 0.14194107055664062, 0.3312249183654785, 4.259186267852783, 0.1957719326019287, 0.2994730472564697, 0.43235254287719727, 0.204437255859375, 0.052680015563964844, 0.6796343326568604, 0.5267577171325684, 0.2010202407836914, 0.34484708309173584, 0.0906519889831543, 0.47504377365112305, 0.024439096450805664, 0.42024707794189453, 0.19396138191223145, 0.2624095678329468, 0.27475953102111816, 0.392775297164917, 0.0694575309753418, 0.05239248275756836, 0.8283028602600098, 0.27716946601867676, 0.6642975807189941, 0.5596537590026855, 0.3226938247680664, 4.209084987640381, 0.27513837814331055, 0.21462130546569824, 0.5428709983825684, 0.5274300575256348, 0.763535737991333, 0.7387220859527588, 0.30043983459472656, 0.1375741958618164, 0.2768270969390869, 0.5617194175720215, 0.7091331481933594, 0.5770695209503174, 0.5863354206085205, 0.7056319713592529, 0.3842325210571289, 0.745537281036377, 0.30071020126342773, 0.6368045806884766, 0.5051751136779785, 0.6623468399047852, 0.45171475410461426, 0.4390568733215332, 0.8062050342559814, 0.37344956398010254, 0.3885326385498047, 0.482623815536499, 0.4397304058074951, 0.4325838088989258, 254.02676391601562, 0.6308515071868896], "mean_td_error": 5.54105806350708, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 5017.0, "diff_num_grad_updates_vs_sampler_policy": 5016.0}}, "num_env_steps_sampled": 25050, "num_env_steps_trained": 1284352, "num_agent_steps_sampled": 25050, "num_agent_steps_trained": 1284352, "last_target_update_ts": 25050, "num_target_updates": 5017}, "sampler_results": {"episode_reward_max": -165.90026652812958, "episode_reward_min": -193.58011861145496, "episode_reward_mean": -183.67756756171585, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-190.5865334123373, -193.58011861145496, -176.13220999389887, -165.90026652812958, -189.8196080327034, -187.95404055714607, -186.96187537908554, -189.27582755684853, -167.71022468805313, -188.85497085750103], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.196401868090917, "mean_inference_ms": 2.37448568073465, "mean_action_processing_ms": 0.2272829211781716, "mean_env_wait_ms": 2.9915450476069836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -165.90026652812958, "episode_reward_min": -193.58011861145496, "episode_reward_mean": -183.67756756171585, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-190.5865334123373, -193.58011861145496, -176.13220999389887, -165.90026652812958, -189.8196080327034, -187.95404055714607, -186.96187537908554, -189.27582755684853, -167.71022468805313, -188.85497085750103], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.196401868090917, "mean_inference_ms": 2.37448568073465, "mean_action_processing_ms": 0.2272829211781716, "mean_env_wait_ms": 2.9915450476069836, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 25050, "num_agent_steps_trained": 1284352, "num_env_steps_sampled": 25050, "num_env_steps_trained": 1284352, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 25050, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 25050, "timers": {"training_iteration_time_ms": 164.173, "load_time_ms": 0.312, "load_throughput": 820276.413, "learn_time_ms": 25.391, "learn_throughput": 10082.32, "synch_weights_time_ms": 5.923}, "counters": {"num_env_steps_sampled": 25050, "num_env_steps_trained": 1284352, "num_agent_steps_sampled": 25050, "num_agent_steps_trained": 1284352, "last_target_update_ts": 25050, "num_target_updates": 5017}, "done": false, "episodes_total": 257, "training_iteration": 25, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-48-55", "timestamp": 1675950535, "time_this_iter_s": 51.68060851097107, "time_total_s": 843.3600053787231, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105ef4f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 843.3600053787231, "timesteps_since_restore": 0, "iterations_since_restore": 25, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.101408450704234, "ram_util_percent": 84.95633802816903}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.354990005493164, "actor_loss": 6.466113567352295, "critic_loss": 0.44027960300445557, "alpha_loss": -13.403553009033203, "alpha_value": 0.20103885233402252, "log_alpha_value": -1.6042571067810059, "target_entropy": -5.0, "policy_t": -0.028097297996282578, "mean_q": -7.114222526550293, "max_q": -4.820324420928955, "min_q": -8.5482759475708}, "td_error": [0.17177486419677734, 1.0363361835479736, 0.5341529846191406, 0.21745872497558594, 0.19423294067382812, 255.17892456054688, 0.2027277946472168, 0.6249666213989258, 0.46440649032592773, 4.8779144287109375, 0.4334540367126465, 254.29476928710938, 0.5450100898742676, 0.4171760082244873, 0.3072695732116699, 0.3909320831298828, 0.5326635837554932, 0.348541259765625, 0.64035964012146, 0.5744037628173828, 0.2789897918701172, 0.5682275295257568, 0.7277271747589111, 0.5404105186462402, 0.6941657066345215, 0.17521142959594727, 0.2812056541442871, 0.45157694816589355, 5.360420227050781, 0.5455198287963867, 0.5967011451721191, 0.43839597702026367, 0.4070568084716797, 3.463449716567993, 6.4695868492126465, 0.5411598682403564, 254.94033813476562, 0.46468496322631836, 0.5872220993041992, 0.5493514537811279, 0.6381509304046631, 0.5320675373077393, 0.6934411525726318, 0.4204447269439697, 0.3532254695892334, 0.20682287216186523, 0.4385662078857422, 0.4618794918060303, 0.4401683807373047, 0.023536205291748047, 0.45152759552001953, 0.6599526405334473, 0.9721813201904297, 0.26964592933654785, 0.4231240749359131, 0.60622239112854, 0.5072548389434814, 0.45300960540771484, 0.5334367752075195, 4.494403839111328, 0.6125822067260742, 0.2944941520690918, 0.750438928604126, 0.6770448684692383, 0.36603260040283203, 0.42000627517700195, 0.281296968460083, 0.8312773704528809, 0.6281044483184814, 0.6324746608734131, 0.513798713684082, 0.27620768547058105, 0.45990657806396484, 255.62583923339844, 0.44812512397766113, 0.3433830738067627, 0.27986693382263184, 0.6435031890869141, 6.6076765060424805, 0.10352230072021484, 0.7628908157348633, 0.8212475776672363, 0.2990872859954834, 0.4765455722808838, 0.6073007583618164, 0.26416778564453125, 0.4056098461151123, 0.843113899230957, 0.34001922607421875, 0.6558551788330078, 0.5671217441558838, 0.45433712005615234, 0.05422377586364746, 5.51461935043335, 0.4300265312194824, 0.7099487781524658, 0.3255772590637207, 0.42624974250793457, 0.9187812805175781, 0.3669545650482178, 0.47695183753967285, 0.46813082695007324, 0.5501847267150879, 0.8660731315612793, 0.499971866607666, 0.36727190017700195, 0.3966507911682129, 0.7695326805114746, 0.9228987693786621, 0.12302589416503906, 0.4905717372894287, 0.5967414379119873, 0.11222600936889648, 0.6841280460357666, 0.5859332084655762, 0.6482348442077637, 0.9141905307769775, 0.05355095863342285, 0.40151166915893555, 0.04815864562988281, 0.3675367832183838, 0.48427820205688477, 0.1799485683441162, 0.47771286964416504, 0.13588523864746094, 0.5496413707733154, 0.7342138290405273, 5.609098434448242, 5.780981063842773, 0.4768352508544922, 0.2433316707611084, 0.6747779846191406, 0.34190988540649414, 0.6391942501068115, 0.400768518447876, 0.4083414077758789, 0.483370304107666, 0.744391918182373, 0.09100651741027832, 0.5861594676971436, 0.25832533836364746, 0.29309773445129395, 0.7751271724700928, 0.2272176742553711, 0.4002985954284668, 0.2364053726196289, 0.08444881439208984, 0.4962923526763916, 0.6221816539764404, 253.6692657470703, 0.6035795211791992, 0.3510878086090088, 0.5663480758666992, 0.7591347694396973, 0.25881052017211914, 0.29351234436035156, 0.5019567012786865, 0.6500735282897949, 0.22092819213867188, 0.16942691802978516, 0.031616926193237305, 0.1842327117919922, 0.4035825729370117, 0.4805312156677246, 0.6667969226837158, 0.12225699424743652, 0.4276542663574219, 0.6120166778564453, 0.3049912452697754, 0.19611620903015137, 0.42531514167785645, 0.8429815769195557, 0.6408364772796631, 0.5484654903411865, 0.3605227470397949, 0.45305633544921875, 0.7542383670806885, 0.5179347991943359, 0.38947105407714844, 0.12007927894592285, 0.48586511611938477, 0.5489332675933838, 0.49983978271484375, 0.6740715503692627, 0.5656871795654297, 0.5265746116638184, 0.22732925415039062, 0.42821764945983887, 0.5002679824829102, 0.29399752616882324, 0.5308418273925781, 0.4860405921936035, 0.8384218215942383, 0.6121652126312256, 0.6635351181030273, 0.7532806396484375, 0.5153040885925293, 0.7257809638977051, 0.8774194717407227, 0.391176700592041, 0.5825200080871582, 0.18387222290039062, 0.15692543983459473, 0.4794735908508301, 0.8779265880584717, 0.34210777282714844, 255.46630859375, 0.8581497669219971, 0.9087409973144531, 0.48383617401123047, 0.49169278144836426, 0.36615467071533203, 0.39477109909057617, 0.3382284641265869, 0.5835926532745361, 0.10390329360961914, 0.9895567893981934, 0.5487768650054932, 0.5147178173065186, 0.37296342849731445, 0.6925139427185059, 0.1200876235961914, 255.1219024658203, 0.43169307708740234, 0.6009504795074463, 0.6066436767578125, 0.35236167907714844, 0.1136617660522461, 0.49968981742858887, 255.17892456054688, 0.1515350341796875, 0.3364143371582031, 0.8204734325408936, 0.5011096000671387, 4.668099880218506, 0.43208813667297363, 0.17538690567016602, 255.62583923339844, 0.8687729835510254, 0.8857531547546387, 0.6082160472869873, 0.16507840156555176, 0.3142545223236084, 0.6300373077392578, 0.3700218200683594, 0.39055347442626953, 0.28835463523864746, 0.5582995414733887, 0.7933979034423828, 1.1387906074523926, 0.5217571258544922, 0.3522837162017822, 0.43407726287841797, 255.11941528320312, 0.29942989349365234, 0.12037968635559082], "mean_td_error": 10.607305526733398, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 5351.0, "diff_num_grad_updates_vs_sampler_policy": 5350.0}}, "num_env_steps_sampled": 26052, "num_env_steps_trained": 1369856, "num_agent_steps_sampled": 26052, "num_agent_steps_trained": 1369856, "last_target_update_ts": 26052, "num_target_updates": 5351}, "sampler_results": {"episode_reward_max": 104.79555989056826, "episode_reward_min": -196.84813330322504, "episode_reward_mean": -155.78133221939206, "episode_len_mean": 98.9, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-189.5461689978838, -181.7891598045826, -170.71410140395164, -186.50357760488987, 104.79555989056826, -184.66212909668684, -187.025663793087, -184.1057424992323, -196.84813330322504, -181.41420558094978], "episode_lengths": [100, 100, 100, 100, 89, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.201522469726457, "mean_inference_ms": 2.3861516640662597, "mean_action_processing_ms": 0.22841283351303038, "mean_env_wait_ms": 3.0006745140238196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 104.79555989056826, "episode_reward_min": -196.84813330322504, "episode_reward_mean": -155.78133221939206, "episode_len_mean": 98.9, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-189.5461689978838, -181.7891598045826, -170.71410140395164, -186.50357760488987, 104.79555989056826, -184.66212909668684, -187.025663793087, -184.1057424992323, -196.84813330322504, -181.41420558094978], "episode_lengths": [100, 100, 100, 100, 89, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.201522469726457, "mean_inference_ms": 2.3861516640662597, "mean_action_processing_ms": 0.22841283351303038, "mean_env_wait_ms": 3.0006745140238196, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 26052, "num_agent_steps_trained": 1369856, "num_env_steps_sampled": 26052, "num_env_steps_trained": 1369856, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 26052, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 26052, "timers": {"training_iteration_time_ms": 154.707, "load_time_ms": 0.274, "load_throughput": 934826.592, "learn_time_ms": 26.032, "learn_throughput": 9834.196, "synch_weights_time_ms": 5.472}, "counters": {"num_env_steps_sampled": 26052, "num_env_steps_trained": 1369856, "num_agent_steps_sampled": 26052, "num_agent_steps_trained": 1369856, "last_target_update_ts": 26052, "num_target_updates": 5351}, "done": false, "episodes_total": 267, "training_iteration": 26, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-49-48", "timestamp": 1675950588, "time_this_iter_s": 52.71587014198303, "time_total_s": 896.0758755207062, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2f10>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a45e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 896.0758755207062, "timesteps_since_restore": 0, "iterations_since_restore": 26, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.63333333333334, "ram_util_percent": 85.14583333333331}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.304916381835938, "actor_loss": 8.21774673461914, "critic_loss": 0.4199783205986023, "alpha_loss": -14.151106834411621, "alpha_value": 0.18196453154087067, "log_alpha_value": -1.7039434909820557, "target_entropy": -5.0, "policy_t": -0.081812284886837, "mean_q": -8.781582832336426, "max_q": -6.173750400543213, "min_q": -10.386088371276855}, "td_error": [1.1991221904754639, 0.19868850708007812, 0.4276151657104492, 0.678591251373291, 0.28447723388671875, 0.40309667587280273, 0.6054320335388184, 0.4550018310546875, 0.6659359931945801, 0.18532562255859375, 0.24169540405273438, 0.44630908966064453, 255.98062133789062, 0.04818248748779297, 0.3911747932434082, 0.4000263214111328, 0.6224832534790039, 0.7495319843292236, 0.741450309753418, 0.5204715728759766, 0.6314256191253662, 0.5990662574768066, 1.0403659343719482, 0.2985548973083496, 0.5005755424499512, 0.7421526908874512, 0.17465829849243164, 0.1561589241027832, 0.14804744720458984, 0.3612828254699707, 0.7428092956542969, 0.2788815498352051, 0.7081623077392578, 0.8057332038879395, 0.08330774307250977, 0.3812437057495117, 0.8622035980224609, 0.06236553192138672, 0.2393178939819336, 0.4406576156616211, 0.4122605323791504, 0.5444412231445312, 0.7054877281188965, 0.5092000961303711, 0.9021749496459961, 0.4364924430847168, 0.3715071678161621, 0.2964134216308594, 0.44831132888793945, 256.15655517578125, 0.17147350311279297, 6.351179122924805, 0.38921689987182617, 8.032285690307617, 0.6738185882568359, 0.17293024063110352, 0.17510318756103516, 0.40542054176330566, 0.6224856376647949, 0.6012461185455322, 0.519805908203125, 0.42455101013183594, 0.8444690704345703, 0.4686546325683594, 0.5152697563171387, 0.5367231369018555, 0.6425762176513672, 0.4009895324707031, 0.40465688705444336, 0.27133703231811523, 0.6537690162658691, 0.5957474708557129, 0.2598998546600342, 0.278348445892334, 0.3619368076324463, 0.36886167526245117, 0.42437028884887695, 0.12571144104003906, 0.37802982330322266, 0.39827871322631836, 0.6329009532928467, 1.2556991577148438, 0.47191667556762695, 0.48482179641723633, 0.5988597869873047, 0.39979028701782227, 0.3366570472717285, 0.4833202362060547, 0.2992558479309082, 1.2011055946350098, 0.787797212600708, 0.2915763854980469, 1.1221308708190918, 0.6629257202148438, 6.182528495788574, 0.36832380294799805, 0.4686706066131592, 0.5797076225280762, 0.1209268569946289, 0.7219185829162598, 0.16359281539916992, 5.919803619384766, 0.5209360122680664, 7.090293884277344, 0.5792064666748047, 0.252138614654541, 0.2460308074951172, 0.20944595336914062, 0.3841524124145508, 0.08936595916748047, 0.5523064136505127, 0.37430477142333984, 0.2957139015197754, 0.7311697006225586, 256.9389953613281, 0.4881172180175781, 0.36931562423706055, 6.886416435241699, 0.4817924499511719, 0.6750679016113281, 0.7135634422302246, 8.07154369354248, 0.5318145751953125, 0.5277748107910156, 0.39513063430786133, 0.47029590606689453, 0.6857709884643555, 0.6739583015441895, 0.10248231887817383, 7.25301456451416, 0.30008792877197266, 0.17149972915649414, 1.0448579788208008, 0.5661427974700928, 0.5610270500183105, 0.5878396034240723, 255.98062133789062, 7.047342300415039, 0.04625988006591797, 0.6032581329345703, 0.5469112396240234, 0.2602047920227051, 0.30083608627319336, 0.6558880805969238, 0.19640159606933594, 0.38048887252807617, 0.5357191562652588, 0.7172036170959473, 0.5851287841796875, 0.3543405532836914, 0.5031094551086426, 0.15195131301879883, 255.03091430664062, 0.635556697845459, 0.09511470794677734, 0.01760721206665039, 6.448508262634277, 0.12798786163330078, 0.39470887184143066, 5.942835807800293, 0.4276728630065918, 0.5199418067932129, 0.5251588821411133, 0.82920241355896, 0.5794529914855957, 0.4465022087097168, 0.5478112697601318, 0.4017672538757324, 0.7827925682067871, 0.40386390686035156, 0.47190260887145996, 0.12314701080322266, 0.40029478073120117, 0.1539134979248047, 0.422853946685791, 0.3076291084289551, 0.3883829116821289, 0.45394396781921387, 0.2535672187805176, 0.42145538330078125, 0.2732510566711426, 0.10780763626098633, 0.7230610847473145, 0.03293180465698242, 0.2585611343383789, 0.4025874137878418, 0.5193006992340088, 0.7024636268615723, 0.7062106132507324, 0.3926701545715332, 0.4486074447631836, 0.497267484664917, 0.0910787582397461, 0.7820677757263184, 0.2821645736694336, 0.532994270324707, 1.0768423080444336, 0.3552417755126953, 8.461165428161621, 0.14632940292358398, 0.011354923248291016, 0.4521965980529785, 0.24834728240966797, 0.32256555557250977, 0.823763370513916, 0.26331615447998047, 0.02114105224609375, 0.5932326316833496, 0.6339378356933594, 0.6242260932922363, 256.15655517578125, 0.24371719360351562, 0.7329444885253906, 0.3958091735839844, 0.7634720802307129, 0.5365710258483887, 0.3308229446411133, 0.59271240234375, 0.576451301574707, 0.4310874938964844, 6.964386463165283, 0.5710692405700684, 0.6216025352478027, 0.5053973197937012, 0.3342881202697754, 0.5181279182434082, 0.35941123962402344, 7.714571475982666, 0.7615633010864258, 255.03091430664062, 0.6557233333587646, 0.6069567203521729, 0.5879130363464355, 0.3320584297180176, 0.2593655586242676, 0.4051365852355957, 0.4224724769592285, 0.8671050071716309, 257.57135009765625, 0.25842952728271484, 0.3466663360595703, 0.667853832244873, 0.5375392436981201, 0.3047671318054199, 0.45860910415649414, 0.2702045440673828, 0.6720547676086426, 0.5103292465209961, 0.7360444068908691, 0.04609489440917969, 8.060715675354004, 0.2788224220275879, 257.3223876953125, 6.194634437561035, 0.432889461517334, 0.2553396224975586], "mean_td_error": 9.865389823913574, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 5685.0, "diff_num_grad_updates_vs_sampler_policy": 5684.0}}, "num_env_steps_sampled": 27054, "num_env_steps_trained": 1455360, "num_agent_steps_sampled": 27054, "num_agent_steps_trained": 1455360, "last_target_update_ts": 27054, "num_target_updates": 5685}, "sampler_results": {"episode_reward_max": 235.7953718304634, "episode_reward_min": -194.87835419923067, "episode_reward_mean": -148.95618642059466, "episode_len_mean": 92.41666666666667, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.7902166247368, -184.14923545718193, -177.52521464973688, -184.4634026736021, -194.87835419923067, -185.0952292829752, -182.19644275307655, 235.7953718304634, -183.53830267488956, -189.59883634746075, -187.72424747794867, -174.31012673676014], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 9, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2006379770510929, "mean_inference_ms": 2.387234433005618, "mean_action_processing_ms": 0.22830351425494042, "mean_env_wait_ms": 2.9964881350928283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 235.7953718304634, "episode_reward_min": -194.87835419923067, "episode_reward_mean": -148.95618642059466, "episode_len_mean": 92.41666666666667, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-179.7902166247368, -184.14923545718193, -177.52521464973688, -184.4634026736021, -194.87835419923067, -185.0952292829752, -182.19644275307655, 235.7953718304634, -183.53830267488956, -189.59883634746075, -187.72424747794867, -174.31012673676014], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 9, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2006379770510929, "mean_inference_ms": 2.387234433005618, "mean_action_processing_ms": 0.22830351425494042, "mean_env_wait_ms": 2.9964881350928283, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 27054, "num_agent_steps_trained": 1455360, "num_env_steps_sampled": 27054, "num_env_steps_trained": 1455360, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 27054, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 27054, "timers": {"training_iteration_time_ms": 174.477, "load_time_ms": 0.285, "load_throughput": 896802.659, "learn_time_ms": 25.971, "learn_throughput": 9857.109, "synch_weights_time_ms": 6.223}, "counters": {"num_env_steps_sampled": 27054, "num_env_steps_trained": 1455360, "num_agent_steps_sampled": 27054, "num_agent_steps_trained": 1455360, "last_target_update_ts": 27054, "num_target_updates": 5685}, "done": false, "episodes_total": 279, "training_iteration": 27, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-50-40", "timestamp": 1675950640, "time_this_iter_s": 52.54960870742798, "time_total_s": 948.6254842281342, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2070>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105b0310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 948.6254842281342, "timesteps_since_restore": 0, "iterations_since_restore": 27, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.520833333333336, "ram_util_percent": 85.50972222222221}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.306199073791504, "actor_loss": 10.140007019042969, "critic_loss": 0.4332728087902069, "alpha_loss": -14.980199813842773, "alpha_value": 0.16472193598747253, "log_alpha_value": -1.8034964799880981, "target_entropy": -5.0, "policy_t": -0.06521089375019073, "mean_q": -10.681135177612305, "max_q": -8.258990287780762, "min_q": -12.280961036682129}, "td_error": [0.5722341537475586, 0.29477787017822266, 0.7643513679504395, 0.48410797119140625, 0.32782840728759766, 0.47890186309814453, 0.1640491485595703, 0.2656745910644531, 0.4547300338745117, 0.20643997192382812, 0.5456700325012207, 0.4617586135864258, 0.6427364349365234, 0.5281505584716797, 0.6963820457458496, 0.4799375534057617, 0.6231551170349121, 9.587077140808105, 0.6136231422424316, 0.28888368606567383, 0.03934288024902344, 0.2425680160522461, 0.4280085563659668, 0.698051929473877, 0.6311211585998535, 0.09091377258300781, 0.36975955963134766, 0.38648414611816406, 0.3179597854614258, 9.211711883544922, 0.3296341896057129, 9.331293106079102, 0.28453588485717773, 257.93017578125, 0.28302717208862305, 0.777315616607666, 0.0137481689453125, 0.5965447425842285, 0.34774351119995117, 0.38106632232666016, 0.4496922492980957, 0.6108241081237793, 0.6807174682617188, 0.31568431854248047, 0.10001850128173828, 0.36762046813964844, 0.5929164886474609, 0.3767404556274414, 0.10174942016601562, 0.41086864471435547, 0.4994802474975586, 0.42369651794433594, 0.616551399230957, 257.017578125, 0.20519065856933594, 0.5818314552307129, 0.5184364318847656, 0.5153765678405762, 0.5966753959655762, 0.5727076530456543, 0.5281877517700195, 0.5820174217224121, 0.49077415466308594, 9.17593765258789, 6.513951778411865, 0.5349431037902832, 0.2365283966064453, 0.47677183151245117, 0.26175642013549805, 0.7829189300537109, 0.9260740280151367, 0.6995644569396973, 0.4862351417541504, 0.3205265998840332, 0.7588005065917969, 0.5349979400634766, 0.34313154220581055, 0.3621940612792969, 0.7206997871398926, 0.34862327575683594, 0.3151097297668457, 0.586003303527832, 0.7281579971313477, 0.3818230628967285, 0.7250809669494629, 0.37166738510131836, 258.99853515625, 0.7417163848876953, 0.23424148559570312, 0.24578094482421875, 0.7166476249694824, 0.7552742958068848, 0.7857918739318848, 10.02175521850586, 0.3183135986328125, 0.5089068412780762, 0.2630467414855957, 0.4110755920410156, 258.82037353515625, 0.43299198150634766, 0.31081438064575195, 0.3738546371459961, 0.5220851898193359, 0.11487340927124023, 0.5334014892578125, 0.40723228454589844, 0.3558835983276367, 0.47499656677246094, 258.441650390625, 259.5360107421875, 0.08867931365966797, 0.36624622344970703, 0.36167001724243164, 0.055500030517578125, 0.5461711883544922, 0.38235044479370117, 9.219409942626953, 0.23906421661376953, 0.4044809341430664, 0.7519083023071289, 0.3186187744140625, 257.70147705078125, 0.2289714813232422, 0.5556173324584961, 0.7571020126342773, 0.5014610290527344, 0.46105527877807617, 0.043021202087402344, 0.5015430450439453, 0.5455350875854492, 0.3035397529602051, 0.5707964897155762, 0.5443720817565918, 0.27498722076416016, 0.9159417152404785, 8.257989883422852, 0.43256187438964844, 0.10674190521240234, 0.6895561218261719, 0.6462221145629883, 0.2960081100463867, 9.381525039672852, 0.5228586196899414, 0.4461936950683594, 8.0909423828125, 0.49268484115600586, 0.7336750030517578, 0.25349950790405273, 0.25804710388183594, 0.32181453704833984, 0.38345813751220703, 0.6680974960327148, 0.5157546997070312, 0.1571950912475586, 0.45841312408447266, 0.781956672668457, 0.4470505714416504, 0.19037628173828125, 0.653376579284668, 0.5490784645080566, 0.47815465927124023, 0.9227185249328613, 0.1985483169555664, 9.356040000915527, 0.4525914192199707, 0.1393280029296875, 0.5269207954406738, 0.2086334228515625, 0.26319122314453125, 8.885875701904297, 0.24637556076049805, 0.4882626533508301, 10.073846817016602, 0.05295991897583008, 0.5838742256164551, 0.2995762825012207, 0.4261460304260254, 0.30429935455322266, 0.29036521911621094, 0.44420576095581055, 0.6638603210449219, 0.7998027801513672, 0.08437776565551758, 0.560272216796875, 0.35257720947265625, 0.5560636520385742, 0.35376739501953125, 0.47208070755004883, 0.1882343292236328, 0.2047443389892578, 259.22283935546875, 6.444809913635254, 0.29679393768310547, 0.7425251007080078, 0.09256935119628906, 0.47279834747314453, 0.6518125534057617, 0.7034831047058105, 0.747220516204834, 0.46189117431640625, 0.05745077133178711, 0.902374267578125, 0.482297420501709, 0.7191333770751953, 0.3683743476867676, 0.6922526359558105, 0.34425878524780273, 0.2625861167907715, 0.39510059356689453, 0.39510393142700195, 8.257989883422852, 0.5672168731689453, 0.32112646102905273, 6.946345806121826, 0.4070734977722168, 0.48342466354370117, 0.5156216621398926, 0.3440823554992676, 0.20784235000610352, 0.586977481842041, 1.187124252319336, 7.4076247215271, 0.5007123947143555, 0.31557226181030273, 0.7443652153015137, 0.9350943565368652, 8.553186416625977, 0.5235037803649902, 0.55810546875, 0.4479942321777344, 0.41951894760131836, 0.36562108993530273, 0.2833595275878906, 0.5732197761535645, 0.3610100746154785, 0.27129268646240234, 0.5466709136962891, 0.8172149658203125, 0.14242839813232422, 0.6109137535095215, 0.5346832275390625, 0.38802433013916016, 0.11028385162353516, 0.5278058052062988, 0.7602105140686035, 0.3538479804992676, 0.7034964561462402, 0.5015244483947754, 0.3094644546508789, 0.41283702850341797, 0.43075037002563477, 0.34737300872802734, 0.32015085220336914, 0.2872734069824219, 0.41953039169311523, 257.017578125], "mean_td_error": 10.088196754455566, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 6019.0, "diff_num_grad_updates_vs_sampler_policy": 6018.0}}, "num_env_steps_sampled": 28056, "num_env_steps_trained": 1540864, "num_agent_steps_sampled": 28056, "num_agent_steps_trained": 1540864, "last_target_update_ts": 28056, "num_target_updates": 6019}, "sampler_results": {"episode_reward_max": -174.9978152513504, "episode_reward_min": -191.81628845632076, "episode_reward_mean": -184.93254377030664, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-182.1208277195692, -181.4783052355051, -189.16457533091307, -188.128092110157, -184.45729556679726, -174.9978152513504, -191.81628845632076, -183.39122223854065, -188.8384720236063], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1983537135237556, "mean_inference_ms": 2.3881018750194034, "mean_action_processing_ms": 0.22789582186871268, "mean_env_wait_ms": 2.993765507460176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -174.9978152513504, "episode_reward_min": -191.81628845632076, "episode_reward_mean": -184.93254377030664, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-182.1208277195692, -181.4783052355051, -189.16457533091307, -188.128092110157, -184.45729556679726, -174.9978152513504, -191.81628845632076, -183.39122223854065, -188.8384720236063], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1983537135237556, "mean_inference_ms": 2.3881018750194034, "mean_action_processing_ms": 0.22789582186871268, "mean_env_wait_ms": 2.993765507460176, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 28056, "num_agent_steps_trained": 1540864, "num_env_steps_sampled": 28056, "num_env_steps_trained": 1540864, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 28056, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 28056, "timers": {"training_iteration_time_ms": 155.265, "load_time_ms": 0.276, "load_throughput": 928681.737, "learn_time_ms": 25.085, "learn_throughput": 10205.187, "synch_weights_time_ms": 5.126}, "counters": {"num_env_steps_sampled": 28056, "num_env_steps_trained": 1540864, "num_agent_steps_sampled": 28056, "num_agent_steps_trained": 1540864, "last_target_update_ts": 28056, "num_target_updates": 6019}, "done": false, "episodes_total": 288, "training_iteration": 28, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-51-33", "timestamp": 1675950693, "time_this_iter_s": 52.111942529678345, "time_total_s": 1000.7374267578125, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3811e4c0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105b0040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1000.7374267578125, "timesteps_since_restore": 0, "iterations_since_restore": 28, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.079166666666666, "ram_util_percent": 85.79305555555555}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.198616027832031, "actor_loss": 12.253852844238281, "critic_loss": 0.45653581619262695, "alpha_loss": -15.60132122039795, "alpha_value": 0.14913232624530792, "log_alpha_value": -1.9029213190078735, "target_entropy": -5.0, "policy_t": -0.07686205953359604, "mean_q": -12.703788757324219, "max_q": -9.90217399597168, "min_q": -14.19073486328125}, "td_error": [0.41864633560180664, 261.1307067871094, 0.5693902969360352, 0.1011343002319336, 0.42035722732543945, 0.5199799537658691, 0.2401103973388672, 0.5993928909301758, 0.29506635665893555, 0.2628307342529297, 0.4931163787841797, 0.09174203872680664, 260.70941162109375, 0.2097940444946289, 0.37191057205200195, 0.5076165199279785, 0.6143107414245605, 0.3906116485595703, 0.25751352310180664, 9.792040824890137, 10.170208930969238, 9.553277015686035, 0.6735110282897949, 0.09017086029052734, 0.5860395431518555, 0.09689140319824219, 0.3175196647644043, 0.07760000228881836, 260.70941162109375, 11.057357788085938, 0.616727352142334, 0.5575580596923828, 0.5026164054870605, 0.262972354888916, 0.6439957618713379, 0.4135918617248535, 10.75228500366211, 0.49913644790649414, 0.36997222900390625, 0.16344165802001953, 0.311431884765625, 0.6533026695251465, 0.9924221038818359, 0.3774700164794922, 0.45406007766723633, 0.3595161437988281, 0.9035139083862305, 10.826308250427246, 0.19370222091674805, 0.13376522064208984, 0.3845024108886719, 0.15429115295410156, 0.4212813377380371, 0.14910650253295898, 0.5900602340698242, 0.4282388687133789, 0.3086576461791992, 0.2369861602783203, 0.6133432388305664, 12.5555419921875, 0.5881571769714355, 0.5182900428771973, 0.8492817878723145, 0.18937969207763672, 0.4769473075866699, 0.6400208473205566, 0.6922607421875, 0.372438907623291, 0.5365471839904785, 0.2026209831237793, 0.4751429557800293, 0.4386448860168457, 0.5276031494140625, 0.43471336364746094, 0.49892377853393555, 0.9351592063903809, 0.5133519172668457, 0.17733001708984375, 0.23754310607910156, 0.560753345489502, 0.398129940032959, 0.5191969871520996, 11.90584659576416, 0.3531942367553711, 9.701705932617188, 0.5785741806030273, 0.532477855682373, 0.37769508361816406, 0.7452325820922852, 0.05308818817138672, 0.25625085830688477, 0.29413366317749023, 0.3853926658630371, 0.4837169647216797, 0.2601618766784668, 0.6545023918151855, 0.48903942108154297, 0.2029132843017578, 0.2938499450683594, 0.030037879943847656, 0.5711302757263184, 0.2589735984802246, 0.5528912544250488, 0.5360713005065918, 0.5854067802429199, 0.4281778335571289, 0.4959554672241211, 0.3648872375488281, 0.8901629447937012, 0.6846084594726562, 0.48514270782470703, 0.3654823303222656, 0.43532705307006836, 0.3902902603149414, 1.054542064666748, 0.42654895782470703, 0.5443944931030273, 0.3907151222229004, 0.5519928932189941, 0.20167922973632812, 0.1690526008605957, 0.6154513359069824, 0.4421977996826172, 0.5827422142028809, 0.5807676315307617, 0.6567625999450684, 0.6051478385925293, 0.26660585403442383, 0.21924066543579102, 0.4153456687927246, 0.24144983291625977, 1.032412052154541, 0.3852834701538086, 0.7181901931762695, 11.340845108032227, 0.1428666114807129, 0.43572473526000977, 0.5945639610290527, 0.6625814437866211, 0.39432859420776367, 0.4284954071044922, 0.32751893997192383, 0.5405983924865723, 0.7008833885192871, 0.5293154716491699, 0.7539815902709961, 0.49724769592285156, 0.6725907325744629, 0.7938261032104492, 0.4596548080444336, 0.8669447898864746, 0.09665918350219727, 0.1873912811279297, 0.8065028190612793, 0.3850417137145996, 0.38802576065063477, 0.34521055221557617, 0.6720724105834961, 0.7006688117980957, 0.09335708618164062, 0.5781540870666504, 12.542360305786133, 8.845710754394531, 0.48505449295043945, 9.701705932617188, 1.0364532470703125, 0.5270586013793945, 258.6363525390625, 0.4706735610961914, 0.5637454986572266, 0.8163542747497559, 0.4384922981262207, 0.19354581832885742, 0.3445415496826172, 0.5460867881774902, 0.2663750648498535, 0.41297388076782227, 0.20784235000610352, 0.6903653144836426, 0.42300844192504883, 11.52640151977539, 0.45932435989379883, 0.5125389099121094, 0.06628847122192383, 258.6363525390625, 0.6613726615905762, 0.4230537414550781, 0.2436203956604004, 0.4670858383178711, 1.3135838508605957, 0.2574739456176758, 0.1253657341003418, 0.28882265090942383, 0.18208599090576172, 11.084553718566895, 10.62193489074707, 0.5544142723083496, 0.27530574798583984, 10.021207809448242, 0.44433069229125977, 0.5789351463317871, 0.6072726249694824, 11.23147964477539, 0.4642624855041504, 0.5766258239746094, 0.23089933395385742, 0.5038599967956543, 10.492377281188965, 0.5110683441162109, 0.029005050659179688, 0.35023975372314453, 0.7656607627868652, 0.4217514991760254, 0.6337389945983887, 0.20001220703125, 11.06675910949707, 0.26457834243774414, 0.11652088165283203, 0.8295040130615234, 0.6333208084106445, 0.6409502029418945, 0.5333571434020996, 0.7079887390136719, 0.6713075637817383, 0.4333052635192871, 0.39266300201416016, 0.2941584587097168, 0.3672165870666504, 0.31287240982055664, 0.7725987434387207, 0.3690829277038574, 0.6451287269592285, 0.9138717651367188, 0.6497988700866699, 0.5392184257507324, 0.41495180130004883, 260.70941162109375, 0.04469442367553711, 260.6322326660156, 0.2647857666015625, 0.12874937057495117, 260.6373291015625, 0.7087550163269043, 0.2756204605102539, 0.45896100997924805, 260.59283447265625, 0.5798945426940918, 0.9179387092590332, 0.4008469581604004, 0.09355640411376953, 10.971145629882812, 0.15135860443115234, 0.7378811836242676, 0.5361003875732422, 0.2911801338195801, 0.2900428771972656], "mean_td_error": 10.433521270751953, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 6353.0, "diff_num_grad_updates_vs_sampler_policy": 6352.0}}, "num_env_steps_sampled": 29058, "num_env_steps_trained": 1626368, "num_agent_steps_sampled": 29058, "num_agent_steps_trained": 1626368, "last_target_update_ts": 29058, "num_target_updates": 6353}, "sampler_results": {"episode_reward_max": -165.28807239234447, "episode_reward_min": -186.11187045276165, "episode_reward_mean": -179.79279124902354, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-165.28807239234447, -183.26285406947136, -185.33110982179642, -171.89848959445953, -182.58071744441986, -174.39229675382376, -184.68148090690374, -184.5882298052311, -186.11187045276165], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1955892172943008, "mean_inference_ms": 2.3876602161300227, "mean_action_processing_ms": 0.22757435274864152, "mean_env_wait_ms": 2.9902814986073163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -165.28807239234447, "episode_reward_min": -186.11187045276165, "episode_reward_mean": -179.79279124902354, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-165.28807239234447, -183.26285406947136, -185.33110982179642, -171.89848959445953, -182.58071744441986, -174.39229675382376, -184.68148090690374, -184.5882298052311, -186.11187045276165], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1955892172943008, "mean_inference_ms": 2.3876602161300227, "mean_action_processing_ms": 0.22757435274864152, "mean_env_wait_ms": 2.9902814986073163, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 29058, "num_agent_steps_trained": 1626368, "num_env_steps_sampled": 29058, "num_env_steps_trained": 1626368, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 29058, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 29058, "timers": {"training_iteration_time_ms": 152.676, "load_time_ms": 0.313, "load_throughput": 817403.946, "learn_time_ms": 25.16, "learn_throughput": 10174.938, "synch_weights_time_ms": 5.834}, "counters": {"num_env_steps_sampled": 29058, "num_env_steps_trained": 1626368, "num_agent_steps_sampled": 29058, "num_agent_steps_trained": 1626368, "last_target_update_ts": 29058, "num_target_updates": 6353}, "done": false, "episodes_total": 297, "training_iteration": 29, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-52-24", "timestamp": 1675950744, "time_this_iter_s": 51.92955803871155, "time_total_s": 1052.666984796524, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef760>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ac10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1052.666984796524, "timesteps_since_restore": 0, "iterations_since_restore": 29, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.74857142857144, "ram_util_percent": 85.87285714285714}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.176543235778809, "actor_loss": 14.262129783630371, "critic_loss": 0.49781909584999084, "alpha_loss": -16.36933135986328, "alpha_value": 0.1350667029619217, "log_alpha_value": -2.001986503601074, "target_entropy": -5.0, "policy_t": -0.08200980722904205, "mean_q": -14.685535430908203, "max_q": -12.068277359008789, "min_q": -16.381649017333984}, "td_error": [0.5169129371643066, 0.7184710502624512, 13.297897338867188, 0.013391494750976562, 0.5472598075866699, 13.820511817932129, 1.045712947845459, 0.3421468734741211, 0.6365199089050293, 12.436391830444336, 0.6216516494750977, 0.28237104415893555, 14.60114574432373, 0.3503141403198242, 0.4563908576965332, 13.400625228881836, 12.987543106079102, 0.21875953674316406, 0.35204219818115234, 0.6107892990112305, 0.3968186378479004, 0.2709493637084961, 0.42278003692626953, 0.23363780975341797, 0.5909624099731445, 0.3068118095397949, 0.2962346076965332, 0.05676603317260742, 0.2452387809753418, 0.5653934478759766, 0.39080381393432617, 0.4071207046508789, 0.5183634757995605, 0.2275218963623047, 262.11761474609375, 0.7313852310180664, 0.3103675842285156, 0.6875753402709961, 0.3945131301879883, 13.544700622558594, 0.3555269241333008, 0.34593677520751953, 0.6657929420471191, 0.6382722854614258, 0.34773731231689453, 0.15704107284545898, 0.13150930404663086, 0.43026018142700195, 0.5192828178405762, 0.4395747184753418, 0.6028680801391602, 262.8706359863281, 0.3841085433959961, 13.503620147705078, 0.6947002410888672, 0.507929801940918, 0.40714263916015625, 0.5340938568115234, 0.15931987762451172, 0.33913326263427734, 0.6511154174804688, 0.5367131233215332, 0.19943475723266602, 0.6136736869812012, 0.5138692855834961, 0.5653133392333984, 0.3922891616821289, 0.3716564178466797, 0.12614822387695312, 0.5439543724060059, 0.35351085662841797, 0.38957738876342773, 0.5826177597045898, 0.18555164337158203, 0.26394081115722656, 0.02959299087524414, 0.6206355094909668, 0.6688752174377441, 0.14128398895263672, 0.5443167686462402, 0.41700220108032227, 0.6239418983459473, 0.04124116897583008, 0.5559067726135254, 0.4648418426513672, 0.2898569107055664, 0.2830486297607422, 0.2790861129760742, 0.6620922088623047, 0.3783698081970215, 262.79913330078125, 0.20964431762695312, 0.28067588806152344, 0.35431528091430664, 0.5572738647460938, 0.11497735977172852, 10.08730411529541, 0.6638579368591309, 0.12574100494384766, 0.18269920349121094, 0.4172205924987793, 0.5971622467041016, 13.462779998779297, 0.5354862213134766, 0.16242122650146484, 0.26679134368896484, 0.3207359313964844, 0.7062854766845703, 0.6532974243164062, 0.11729240417480469, 0.5682611465454102, 13.642340660095215, 0.6604681015014648, 0.7968988418579102, 0.06624603271484375, 0.3635745048522949, 0.6518559455871582, 0.40667057037353516, 0.18962574005126953, 10.556936264038086, 0.31520557403564453, 0.650545597076416, 0.5327506065368652, 0.6802730560302734, 0.5215797424316406, 0.7205166816711426, 262.77801513671875, 0.6762828826904297, 0.24588346481323242, 0.24893474578857422, 0.8696279525756836, 0.45975589752197266, 0.6479363441467285, 0.6888046264648438, 0.161346435546875, 0.533775806427002, 0.0911870002746582, 0.5206403732299805, 0.1639399528503418, 0.5755953788757324, 0.27698421478271484, 0.22359657287597656, 0.5533180236816406, 1.0184659957885742, 0.5255746841430664, 0.7200407981872559, 0.5120482444763184, 0.5991339683532715, 0.3590726852416992, 0.4465498924255371, 0.34162139892578125, 0.756227970123291, 0.5264062881469727, 0.5635695457458496, 0.6411828994750977, 0.47141551971435547, 0.5085530281066895, 0.5506868362426758, 0.30016613006591797, 0.11730480194091797, 0.5400981903076172, 0.5345067977905273, 0.4529256820678711, 0.6789851188659668, 0.46384525299072266, 0.5112972259521484, 0.2571406364440918, 0.16234636306762695, 0.27272844314575195, 0.7513384819030762, 0.6963677406311035, 0.5396337509155273, 0.6800603866577148, 0.38878822326660156, 0.7248373031616211, 0.5108528137207031, 0.18152904510498047, 0.43701744079589844, 0.8307514190673828, 0.3502693176269531, 0.3662242889404297, 0.5961089134216309, 0.6991186141967773, 0.14126205444335938, 0.4918355941772461, 0.5018410682678223, 0.6339502334594727, 1.0822372436523438, 0.33155155181884766, 0.46728038787841797, 0.711982250213623, 13.824459075927734, 0.7325835227966309, 0.5087132453918457, 0.5246200561523438, 0.19383907318115234, 0.42514848709106445, 13.514060974121094, 0.5417742729187012, 0.25911998748779297, 0.4697585105895996, 263.0944519042969, 0.06409454345703125, 0.5241250991821289, 0.8643021583557129, 0.728060245513916, 0.5871715545654297, 0.21628904342651367, 0.4432182312011719, 0.4520549774169922, 0.34536266326904297, 0.6170644760131836, 0.5185608863830566, 0.557215690612793, 0.3760414123535156, 0.35661745071411133, 0.875340461730957, 0.2731666564941406, 0.5971136093139648, 0.29430437088012695, 0.6222705841064453, 0.36830711364746094, 0.08762979507446289, 0.36696910858154297, 262.6874694824219, 0.2813911437988281, 0.4828977584838867, 0.32619476318359375, 12.134337425231934, 0.5290994644165039, 0.537104606628418, 0.3816828727722168, 13.241905212402344, 0.35425615310668945, 0.6963362693786621, 12.200905799865723, 0.24017095565795898, 0.6275262832641602, 0.5118484497070312, 0.652918815612793, 262.53509521484375, 0.13696527481079102, 0.05810832977294922, 12.716090202331543, 0.4321784973144531, 12.082273483276367, 0.3626437187194824, 0.3871631622314453, 0.37563133239746094, 0.1991291046142578, 0.14920616149902344, 262.8389892578125, 262.11761474609375, 0.11979341506958008, 0.1534419059753418, 0.4009075164794922], "mean_td_error": 10.586221694946289, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 6687.0, "diff_num_grad_updates_vs_sampler_policy": 6686.0}}, "num_env_steps_sampled": 30060, "num_env_steps_trained": 1711872, "num_agent_steps_sampled": 30060, "num_agent_steps_trained": 1711872, "last_target_update_ts": 30060, "num_target_updates": 6687}, "sampler_results": {"episode_reward_max": -171.31990517675877, "episode_reward_min": -191.378743365407, "episode_reward_mean": -181.32259718639156, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-171.31990517675877, -178.29683908075094, -185.04229144752026, -181.9416538849473, -191.378743365407, -176.74997402727604, -183.82910177111626, -184.22023870795965, -184.56751142442226, -180.58851619809866, -186.21546549350023, -171.72092565894127], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1928832622574135, "mean_inference_ms": 2.3861331338238165, "mean_action_processing_ms": 0.22721143078630338, "mean_env_wait_ms": 2.985315654693604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -171.31990517675877, "episode_reward_min": -191.378743365407, "episode_reward_mean": -181.32259718639156, "episode_len_mean": 100.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-171.31990517675877, -178.29683908075094, -185.04229144752026, -181.9416538849473, -191.378743365407, -176.74997402727604, -183.82910177111626, -184.22023870795965, -184.56751142442226, -180.58851619809866, -186.21546549350023, -171.72092565894127], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1928832622574135, "mean_inference_ms": 2.3861331338238165, "mean_action_processing_ms": 0.22721143078630338, "mean_env_wait_ms": 2.985315654693604, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 30060, "num_agent_steps_trained": 1711872, "num_env_steps_sampled": 30060, "num_env_steps_trained": 1711872, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 30060, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 30060, "timers": {"training_iteration_time_ms": 150.817, "load_time_ms": 0.277, "load_throughput": 924444.102, "learn_time_ms": 24.723, "learn_throughput": 10354.698, "synch_weights_time_ms": 5.255}, "counters": {"num_env_steps_sampled": 30060, "num_env_steps_trained": 1711872, "num_agent_steps_sampled": 30060, "num_agent_steps_trained": 1711872, "last_target_update_ts": 30060, "num_target_updates": 6687}, "done": false, "episodes_total": 309, "training_iteration": 30, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-53-16", "timestamp": 1675950796, "time_this_iter_s": 51.66289401054382, "time_total_s": 1104.3298788070679, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580ee0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105485e0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1104.3298788070679, "timesteps_since_restore": 0, "iterations_since_restore": 30, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.05070422535212, "ram_util_percent": 85.91408450704229}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.220098495483398, "actor_loss": 16.339153289794922, "critic_loss": 0.4311410188674927, "alpha_loss": -17.27072525024414, "alpha_value": 0.12232959270477295, "log_alpha_value": -2.101036310195923, "target_entropy": -5.0, "policy_t": -0.10327217727899551, "mean_q": -16.705907821655273, "max_q": -14.024883270263672, "min_q": -18.51666831970215}, "td_error": [0.31789159774780273, 0.25028514862060547, 0.5198297500610352, 264.25830078125, 0.7455301284790039, 0.7374210357666016, 0.6518816947937012, 264.83380126953125, 0.40146350860595703, 0.43791675567626953, 0.4431729316711426, 0.49263811111450195, 0.38957691192626953, 0.32103633880615234, 0.7352819442749023, 15.502177238464355, 0.32643604278564453, 0.5748510360717773, 0.4514150619506836, 0.706573486328125, 0.5971269607543945, 13.655034065246582, 1.0291566848754883, 0.3924531936645508, 0.38155269622802734, 0.42432212829589844, 0.570857048034668, 0.7257356643676758, 0.5684337615966797, 0.4682774543762207, 0.3244962692260742, 0.42156124114990234, 15.66948413848877, 0.27312374114990234, 0.20324039459228516, 0.11154460906982422, 0.675358772277832, 0.4373159408569336, 0.24089670181274414, 0.9625968933105469, 14.969822883605957, 0.7016935348510742, 0.5249090194702148, 0.484405517578125, 0.6501049995422363, 0.7097415924072266, 0.6738085746765137, 0.7510819435119629, 0.40145015716552734, 15.866201400756836, 0.3162546157836914, 0.2441549301147461, 0.6512699127197266, 0.13519954681396484, 0.6278247833251953, 0.6483297348022461, 0.3399038314819336, 0.2266230583190918, 13.650432586669922, 0.671473503112793, 0.23596763610839844, 0.5430364608764648, 0.09289073944091797, 0.4825153350830078, 0.5114450454711914, 0.8382902145385742, 0.6685290336608887, 0.24983596801757812, 0.22827434539794922, 0.43820667266845703, 0.42940282821655273, 0.1140146255493164, 0.13619375228881836, 0.42189455032348633, 0.4964113235473633, 0.16546249389648438, 0.22098970413208008, 0.5868363380432129, 0.769343376159668, 16.530277252197266, 0.36632728576660156, 0.5176715850830078, 0.5534200668334961, 0.5936460494995117, 0.4609503746032715, 0.2866058349609375, 0.4274783134460449, 0.282076358795166, 0.5011024475097656, 0.3388223648071289, 264.5252990722656, 0.6530117988586426, 15.702757835388184, 0.4216909408569336, 0.41876697540283203, 0.7671823501586914, 0.4909934997558594, 0.554715633392334, 0.31090736389160156, 0.36863231658935547, 0.5454607009887695, 0.051558494567871094, 0.26085948944091797, 0.8829598426818848, 0.848808765411377, 0.6859369277954102, 0.2132272720336914, 0.21366596221923828, 0.5357141494750977, 0.6034541130065918, 0.30431270599365234, 0.2776041030883789, 0.4217252731323242, 0.6290144920349121, 0.7751493453979492, 0.9232110977172852, 0.20888614654541016, 0.4396982192993164, 0.6171345710754395, 0.35768604278564453, 264.25830078125, 0.5881834030151367, 0.4226245880126953, 0.5362663269042969, 265.18682861328125, 1.0172405242919922, 0.3067317008972168, 0.1369013786315918, 15.817059516906738, 0.5726766586303711, 0.15407466888427734, 0.769047737121582, 0.38361167907714844, 0.6483869552612305, 0.18204021453857422, 0.44716453552246094, 0.2283773422241211, 0.5595598220825195, 0.3359403610229492, 1.1357917785644531, 0.17932891845703125, 0.40580177307128906, 0.5296816825866699, 16.128746032714844, 0.18434429168701172, 0.8456554412841797, 0.3722677230834961, 0.5805416107177734, 16.128746032714844, 0.4650239944458008, 0.7576351165771484, 0.37822818756103516, 0.4434776306152344, 0.3513040542602539, 0.38654422760009766, 0.6837625503540039, 0.1457967758178711, 0.6527285575866699, 264.5252990722656, 0.28499698638916016, 0.2094564437866211, 0.708592414855957, 0.1591958999633789, 0.3110799789428711, 15.367899894714355, 13.326281547546387, 0.4534111022949219, 15.657462120056152, 0.2746858596801758, 0.5368180274963379, 0.6298642158508301, 0.1402587890625, 0.4415779113769531, 0.47664690017700195, 0.5817642211914062, 0.33298301696777344, 0.18010807037353516, 0.3570423126220703, 0.7859411239624023, 0.5275087356567383, 0.6892538070678711, 0.3065319061279297, 0.5676698684692383, 0.38359737396240234, 0.5458889007568359, 0.822300910949707, 0.5223221778869629, 0.36376285552978516, 0.531275749206543, 0.8506002426147461, 0.5998353958129883, 0.30022716522216797, 0.39589595794677734, 14.969822883605957, 0.7142677307128906, 0.3884572982788086, 0.3933544158935547, 0.8937263488769531, 0.6524224281311035, 0.24724769592285156, 0.013788223266601562, 0.5333042144775391, 0.1907062530517578, 0.4564352035522461, 0.5479307174682617, 0.17970561981201172, 0.4716944694519043, 0.2870054244995117, 0.6994905471801758, 0.3720054626464844, 0.6305513381958008, 0.42813539505004883, 12.777067184448242, 0.5038833618164062, 0.6112594604492188, 15.702757835388184, 0.6722650527954102, 0.6015157699584961, 0.4152097702026367, 0.545985221862793, 0.5917973518371582, 0.7085657119750977, 0.3536815643310547, 0.050148963928222656, 0.6784472465515137, 0.33014965057373047, 0.5024881362915039, 0.7308549880981445, 0.25439929962158203, 0.9356145858764648, 0.39745426177978516, 0.1637125015258789, 0.5420713424682617, 15.604564666748047, 0.1051340103149414, 0.35767078399658203, 0.6547760963439941, 0.31957483291625977, 0.1995401382446289, 0.33543872833251953, 0.8332643508911133, 0.49011802673339844, 0.4077138900756836, 0.9718990325927734, 0.4234647750854492, 0.05347156524658203, 0.7336306571960449, 265.18682861328125, 0.9806060791015625, 0.9825081825256348, 15.098993301391602, 15.457298278808594, 0.7101459503173828, 0.9114170074462891, 0.2566194534301758, 0.37343883514404297], "mean_td_error": 8.851619720458984, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 7021.0, "diff_num_grad_updates_vs_sampler_policy": 7020.0}}, "num_env_steps_sampled": 31062, "num_env_steps_trained": 1797376, "num_agent_steps_sampled": 31062, "num_agent_steps_trained": 1797376, "last_target_update_ts": 31062, "num_target_updates": 7021}, "sampler_results": {"episode_reward_max": -170.7668997272849, "episode_reward_min": -190.305157661438, "episode_reward_mean": -181.9360129882892, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.7668997272849, -190.305157661438, -179.89977310597897, -188.1753682643175, -184.18184988200665, -173.57543017715216, -188.62158800661564, -184.76127146184444, -177.13677860796452], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1903425278380435, "mean_inference_ms": 2.385300015090803, "mean_action_processing_ms": 0.22709432209284433, "mean_env_wait_ms": 2.982719328674778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -170.7668997272849, "episode_reward_min": -190.305157661438, "episode_reward_mean": -181.9360129882892, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.7668997272849, -190.305157661438, -179.89977310597897, -188.1753682643175, -184.18184988200665, -173.57543017715216, -188.62158800661564, -184.76127146184444, -177.13677860796452], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1903425278380435, "mean_inference_ms": 2.385300015090803, "mean_action_processing_ms": 0.22709432209284433, "mean_env_wait_ms": 2.982719328674778, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 31062, "num_agent_steps_trained": 1797376, "num_env_steps_sampled": 31062, "num_env_steps_trained": 1797376, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 31062, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 31062, "timers": {"training_iteration_time_ms": 151.28, "load_time_ms": 0.256, "load_throughput": 999759.613, "learn_time_ms": 25.187, "learn_throughput": 10163.823, "synch_weights_time_ms": 6.125}, "counters": {"num_env_steps_sampled": 31062, "num_env_steps_trained": 1797376, "num_agent_steps_sampled": 31062, "num_agent_steps_trained": 1797376, "last_target_update_ts": 31062, "num_target_updates": 7021}, "done": false, "episodes_total": 318, "training_iteration": 31, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-54-08", "timestamp": 1675950848, "time_this_iter_s": 51.94841027259827, "time_total_s": 1156.2782890796661, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580fd0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105480d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1156.2782890796661, "timesteps_since_restore": 0, "iterations_since_restore": 31, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.06619718309858, "ram_util_percent": 86.00845070422534}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.9912333488464355, "actor_loss": 18.530818939208984, "critic_loss": 0.49380430579185486, "alpha_loss": -17.579965591430664, "alpha_value": 0.11081351339817047, "log_alpha_value": -2.199906587600708, "target_entropy": -5.0, "policy_t": -0.10590361058712006, "mean_q": -18.83350372314453, "max_q": -15.607584953308105, "min_q": -20.706010818481445}, "td_error": [0.5360832214355469, 0.2231435775756836, 0.345489501953125, 0.8093118667602539, 0.44814491271972656, 0.6533584594726562, 17.508892059326172, 16.868335723876953, 0.010885238647460938, 0.21433734893798828, 0.4476633071899414, 0.2732267379760742, 0.1287555694580078, 0.5431880950927734, 0.6185207366943359, 0.28139781951904297, 0.4808359146118164, 0.5345382690429688, 0.5503578186035156, 0.2941112518310547, 16.915069580078125, 0.3311748504638672, 0.3425111770629883, 15.509531021118164, 17.537521362304688, 0.4043560028076172, 0.20261478424072266, 0.39540672302246094, 0.4387340545654297, 0.2239999771118164, 0.6752109527587891, 17.823862075805664, 0.22146034240722656, 0.5623359680175781, 0.37788963317871094, 267.78271484375, 266.53424072265625, 0.5198497772216797, 0.04968833923339844, 266.9374694824219, 0.6323480606079102, 17.552257537841797, 15.685037612915039, 0.42313671112060547, 0.30945301055908203, 0.5532932281494141, 0.3541126251220703, 0.3350811004638672, 17.667184829711914, 0.14846038818359375, 0.4533042907714844, 0.14309024810791016, 0.2628355026245117, 0.1255474090576172, 0.6017522811889648, 0.07899665832519531, 0.5535755157470703, 0.36162567138671875, 0.1991424560546875, 0.5848321914672852, 0.5173177719116211, 0.05952739715576172, 0.6942348480224609, 16.902788162231445, 0.4163475036621094, 0.6585206985473633, 18.415359497070312, 0.5521984100341797, 0.17732715606689453, 0.47747039794921875, 0.49106407165527344, 0.14104938507080078, 0.6261968612670898, 0.12921810150146484, 0.7594070434570312, 0.15462303161621094, 0.3498573303222656, 0.3082914352416992, 0.4263591766357422, 17.884605407714844, 0.5160679817199707, 0.9607610702514648, 17.26427459716797, 0.23344802856445312, 1.1621074676513672, 0.6215295791625977, 0.28971195220947266, 0.1240835189819336, 0.11343955993652344, 0.40708255767822266, 0.3048973083496094, 0.12177848815917969, 17.71278953552246, 0.5573387145996094, 0.26264476776123047, 0.03314781188964844, 0.44825172424316406, 0.6426630020141602, 0.21144866943359375, 0.11007881164550781, 0.38025665283203125, 0.6438970565795898, 0.4281759262084961, 1.0538272857666016, 1.2169485092163086, 0.5181350708007812, 0.40499019622802734, 0.8377647399902344, 265.3937683105469, 0.1323556900024414, 0.45621204376220703, 0.2859058380126953, 18.39866828918457, 0.11737346649169922, 0.14902877807617188, 0.7853755950927734, 0.13581085205078125, 264.3160095214844, 0.8361072540283203, 0.4741859436035156, 0.10076332092285156, 0.44614601135253906, 0.7742128372192383, 0.4060249328613281, 0.12176513671875, 0.4112529754638672, 0.3392314910888672, 0.45564842224121094, 0.5813837051391602, 0.1851949691772461, 0.6412878036499023, 0.7419118881225586, 0.5994720458984375, 0.07616043090820312, 0.11386299133300781, 0.11408042907714844, 0.5893793106079102, 0.4844388961791992, 0.2364063262939453, 0.4273815155029297, 0.6291427612304688, 0.3255596160888672, 0.11904621124267578, 0.5194187164306641, 0.49842357635498047, 0.3321819305419922, 0.32067203521728516, 0.20103836059570312, 0.2290792465209961, 0.4563922882080078, 0.37222766876220703, 0.47370243072509766, 0.4480733871459961, 0.6811456680297852, 0.16156578063964844, 0.8303184509277344, 0.09768199920654297, 0.4243621826171875, 0.22875118255615234, 0.5073785781860352, 0.4643278121948242, 0.3897523880004883, 0.19641685485839844, 0.15914630889892578, 0.42431163787841797, 0.12669754028320312, 0.5233306884765625, 0.5806655883789062, 0.08997344970703125, 0.1000213623046875, 16.455333709716797, 0.399383544921875, 0.4238119125366211, 18.415359497070312, 0.5198507308959961, 0.38245296478271484, 0.6936712265014648, 0.6569738388061523, 17.725048065185547, 1.0263185501098633, 0.738163948059082, 0.31355857849121094, 0.7576789855957031, 0.5269498825073242, 0.41673755645751953, 0.6752252578735352, 0.5850439071655273, 0.5884780883789062, 0.4342784881591797, 0.21608638763427734, 0.7459917068481445, 0.21103191375732422, 0.852564811706543, 0.5134162902832031, 266.53424072265625, 0.5587930679321289, 0.5180015563964844, 0.2110004425048828, 0.4445924758911133, 0.6496753692626953, 0.31871795654296875, 0.11802864074707031, 0.1899576187133789, 0.5266847610473633, 0.4481201171875, 0.533146858215332, 0.7034406661987305, 0.09350967407226562, 0.3244028091430664, 0.5586452484130859, 0.5269451141357422, 0.4808006286621094, 0.21658992767333984, 0.473663330078125, 0.5244407653808594, 0.14307594299316406, 0.35324764251708984, 0.40045738220214844, 0.049007415771484375, 0.4663352966308594, 0.5519657135009766, 0.7312021255493164, 0.3112363815307617, 0.06270217895507812, 0.39691734313964844, 17.334091186523438, 0.17865467071533203, 0.2574596405029297, 1.2812623977661133, 0.5883865356445312, 0.2958660125732422, 0.1329498291015625, 0.7602272033691406, 0.6987447738647461, 14.566254615783691, 0.1499042510986328, 0.6186485290527344, 0.5387411117553711, 0.17848491668701172, 265.3937683105469, 0.6272115707397461, 0.6982088088989258, 0.12737083435058594, 0.3815736770629883, 18.199417114257812, 0.5615139007568359, 0.21251773834228516, 0.8346624374389648, 0.35103893280029297, 0.4425334930419922, 0.19631195068359375, 16.722381591796875, 0.4331932067871094, 0.9156656265258789, 0.27545738220214844, 266.9328308105469], "mean_td_error": 10.172346115112305, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 7355.0, "diff_num_grad_updates_vs_sampler_policy": 7354.0}}, "num_env_steps_sampled": 32064, "num_env_steps_trained": 1882880, "num_agent_steps_sampled": 32064, "num_agent_steps_trained": 1882880, "last_target_update_ts": 32064, "num_target_updates": 7355}, "sampler_results": {"episode_reward_max": -164.80321660637856, "episode_reward_min": -187.43193179368973, "episode_reward_mean": -182.1963997989893, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-183.12496840953827, -182.12688202410936, -186.79230985045433, -164.80321660637856, -185.30594304203987, -187.1081513389945, -187.43193179368973, -184.00115877389908, -182.56623475253582, -178.70320139825344], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1881879096682941, "mean_inference_ms": 2.384701148978965, "mean_action_processing_ms": 0.22696769095881303, "mean_env_wait_ms": 2.9804390957161666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -164.80321660637856, "episode_reward_min": -187.43193179368973, "episode_reward_mean": -182.1963997989893, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-183.12496840953827, -182.12688202410936, -186.79230985045433, -164.80321660637856, -185.30594304203987, -187.1081513389945, -187.43193179368973, -184.00115877389908, -182.56623475253582, -178.70320139825344], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1881879096682941, "mean_inference_ms": 2.384701148978965, "mean_action_processing_ms": 0.22696769095881303, "mean_env_wait_ms": 2.9804390957161666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 32064, "num_agent_steps_trained": 1882880, "num_env_steps_sampled": 32064, "num_env_steps_trained": 1882880, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 32064, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 32064, "timers": {"training_iteration_time_ms": 156.982, "load_time_ms": 0.306, "load_throughput": 836247.526, "learn_time_ms": 26.034, "learn_throughput": 9833.467, "synch_weights_time_ms": 6.176}, "counters": {"num_env_steps_sampled": 32064, "num_env_steps_trained": 1882880, "num_agent_steps_sampled": 32064, "num_agent_steps_trained": 1882880, "last_target_update_ts": 32064, "num_target_updates": 7355}, "done": false, "episodes_total": 328, "training_iteration": 32, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-55-02", "timestamp": 1675950902, "time_this_iter_s": 53.40508961677551, "time_total_s": 1209.6833786964417, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093eb0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a550>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1209.6833786964417, "timesteps_since_restore": 0, "iterations_since_restore": 32, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.141891891891895, "ram_util_percent": 86.18648648648649}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.997878074645996, "actor_loss": 20.471872329711914, "critic_loss": 0.40559208393096924, "alpha_loss": -18.38045310974121, "alpha_value": 0.10044285655021667, "log_alpha_value": -2.298166275024414, "target_entropy": -5.0, "policy_t": -0.11025051772594452, "mean_q": -20.791671752929688, "max_q": -17.213348388671875, "min_q": -23.346628189086914}, "td_error": [0.4268617630004883, 0.17775344848632812, 0.3248777389526367, 0.5335540771484375, 0.5515298843383789, 0.7528705596923828, 0.6455116271972656, 0.5748052597045898, 0.4543123245239258, 20.207050323486328, 0.18581390380859375, 0.5222854614257812, 18.833654403686523, 0.5637874603271484, 0.4989795684814453, 0.6334676742553711, 0.5011415481567383, 0.18097496032714844, 0.6380338668823242, 0.6863679885864258, 0.2779970169067383, 0.32327747344970703, 0.34889793395996094, 0.09228992462158203, 0.7232484817504883, 0.6787137985229492, 0.4906034469604492, 0.3801450729370117, 0.6594953536987305, 0.7652692794799805, 0.5825176239013672, 0.24857807159423828, 0.4306516647338867, 0.3352642059326172, 0.3195676803588867, 0.5344228744506836, 0.2473764419555664, 0.39046478271484375, 0.45590972900390625, 0.6169567108154297, 0.7270593643188477, 0.681488037109375, 0.37871837615966797, 0.6242341995239258, 0.4025382995605469, 0.7102985382080078, 0.09540557861328125, 0.3330955505371094, 0.628448486328125, 0.3433218002319336, 0.4766731262207031, 268.9637145996094, 0.6593751907348633, 0.5482625961303711, 0.1850137710571289, 0.28752994537353516, 0.023728370666503906, 0.6076736450195312, 0.38097572326660156, 0.6128883361816406, 0.20678997039794922, 0.4067249298095703, 0.4499788284301758, 0.4645366668701172, 0.9393529891967773, 0.1494884490966797, 0.7437715530395508, 0.3058328628540039, 0.4266176223754883, 0.21201133728027344, 0.043015480041503906, 0.3636360168457031, 0.32999706268310547, 0.6409683227539062, 0.4011096954345703, 0.532658576965332, 0.06308269500732422, 0.04161357879638672, 0.5085229873657227, 0.35500335693359375, 0.8823623657226562, 0.16098594665527344, 0.7530326843261719, 0.5780496597290039, 0.38759708404541016, 20.027952194213867, 0.17180633544921875, 0.12731647491455078, 0.17785930633544922, 0.3219327926635742, 0.3293790817260742, 0.6617517471313477, 0.11500930786132812, 0.7163925170898438, 0.7599725723266602, 0.5843076705932617, 0.04153728485107422, 0.1657886505126953, 0.7576532363891602, 0.5228309631347656, 20.453983306884766, 17.346405029296875, 20.142013549804688, 0.5937509536743164, 0.07944869995117188, 0.5778379440307617, 0.753504753112793, 0.7197427749633789, 0.2165679931640625, 19.82156753540039, 0.5179662704467773, 0.1420278549194336, 0.6266613006591797, 0.3091583251953125, 0.5777549743652344, 0.5585708618164062, 0.13950634002685547, 0.12940216064453125, 0.7616281509399414, 0.5083990097045898, 268.6937255859375, 16.697647094726562, 0.6128559112548828, 0.3253774642944336, 19.610004425048828, 0.6000614166259766, 0.35257911682128906, 0.12458515167236328, 19.843120574951172, 268.9637145996094, 0.11383438110351562, 0.39984893798828125, 0.29900074005126953, 0.8021583557128906, 0.557551383972168, 19.608322143554688, 0.26285839080810547, 0.7508401870727539, 0.09283161163330078, 0.11118412017822266, 20.243207931518555, 0.5594263076782227, 0.6601219177246094, 0.501582145690918, 0.3940467834472656, 0.666661262512207, 0.5029497146606445, 0.5347137451171875, 0.17444419860839844, 0.38999271392822266, 0.38779544830322266, 0.4979391098022461, 0.35964298248291016, 0.09124183654785156, 0.6152563095092773, 0.47775745391845703, 0.6201038360595703, 0.2749176025390625, 0.17461109161376953, 0.24679279327392578, 0.42238521575927734, 0.5374240875244141, 0.7863893508911133, 19.43950653076172, 0.034842491149902344, 20.120784759521484, 0.8635101318359375, 0.42670631408691406, 0.35863685607910156, 0.3969259262084961, 0.5683450698852539, 0.38973045349121094, 0.11598777770996094, 0.44847774505615234, 0.4379386901855469, 0.3843507766723633, 265.96905517578125, 265.9795227050781, 0.6775884628295898, 0.6612625122070312, 0.1371927261352539, 0.4611186981201172, 0.3159208297729492, 0.3419675827026367, 0.3378305435180664, 0.3640422821044922, 0.4696359634399414, 0.4687919616699219, 0.2788515090942383, 0.6972332000732422, 0.4011545181274414, 0.7523298263549805, 268.9637145996094, 0.43639087677001953, 0.3207120895385742, 0.30353260040283203, 0.9474115371704102, 0.566986083984375, 0.3877706527709961, 20.525917053222656, 19.914321899414062, 0.635807991027832, 0.5818033218383789, 0.37366771697998047, 20.742713928222656, 0.41446781158447266, 0.4710960388183594, 0.48012256622314453, 0.2509422302246094, 0.8599100112915039, 19.914321899414062, 0.5214910507202148, 0.055446624755859375, 0.6196613311767578, 0.10153388977050781, 0.13423919677734375, 0.4031553268432617, 0.4485769271850586, 0.32499027252197266, 0.20047950744628906, 0.573918342590332, 0.6671562194824219, 0.3806285858154297, 0.24477481842041016, 0.3132009506225586, 0.49301815032958984, 0.48126888275146484, 0.3086423873901367, 0.09152698516845703, 0.4758329391479492, 0.23871231079101562, 0.07868194580078125, 0.44167041778564453, 0.46389293670654297, 0.7088127136230469, 0.5838394165039062, 0.7888116836547852, 0.15605926513671875, 0.3222799301147461, 0.6375188827514648, 0.4669065475463867, 0.2455921173095703, 0.1550312042236328, 0.3765373229980469, 0.08160781860351562, 0.43697452545166016, 0.6977214813232422, 16.25406837463379, 0.4283742904663086, 0.4142885208129883, 0.37801170349121094, 0.2536954879760742, 15.460236549377441, 0.21843624114990234, 0.43475341796875, 0.4696073532104492], "mean_td_error": 8.17044448852539, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 7689.0, "diff_num_grad_updates_vs_sampler_policy": 7688.0}}, "num_env_steps_sampled": 33066, "num_env_steps_trained": 1968384, "num_agent_steps_sampled": 33066, "num_agent_steps_trained": 1968384, "last_target_update_ts": 33066, "num_target_updates": 7689}, "sampler_results": {"episode_reward_max": 153.87228658795357, "episode_reward_min": -190.63950316607952, "episode_reward_mean": -153.11610210551456, "episode_len_mean": 96.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-187.40898069739342, -174.2771219164133, -190.63950316607952, -181.0851944386959, -185.4829898774624, -184.66287402808666, -185.1458716392517, -187.64949890226126, -182.7697090804577, 153.87228658795357, -179.02766600251198], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 56, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1883810116213538, "mean_inference_ms": 2.3876240459653335, "mean_action_processing_ms": 0.22735068186804572, "mean_env_wait_ms": 2.9812074931202925, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 153.87228658795357, "episode_reward_min": -190.63950316607952, "episode_reward_mean": -153.11610210551456, "episode_len_mean": 96.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-187.40898069739342, -174.2771219164133, -190.63950316607952, -181.0851944386959, -185.4829898774624, -184.66287402808666, -185.1458716392517, -187.64949890226126, -182.7697090804577, 153.87228658795357, -179.02766600251198], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 56, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1883810116213538, "mean_inference_ms": 2.3876240459653335, "mean_action_processing_ms": 0.22735068186804572, "mean_env_wait_ms": 2.9812074931202925, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 33066, "num_agent_steps_trained": 1968384, "num_env_steps_sampled": 33066, "num_env_steps_trained": 1968384, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 33066, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 33066, "timers": {"training_iteration_time_ms": 161.289, "load_time_ms": 0.276, "load_throughput": 926678.022, "learn_time_ms": 25.989, "learn_throughput": 9850.508, "synch_weights_time_ms": 5.472}, "counters": {"num_env_steps_sampled": 33066, "num_env_steps_trained": 1968384, "num_agent_steps_sampled": 33066, "num_agent_steps_trained": 1968384, "last_target_update_ts": 33066, "num_target_updates": 7689}, "done": false, "episodes_total": 339, "training_iteration": 33, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-55-54", "timestamp": 1675950954, "time_this_iter_s": 52.189106941223145, "time_total_s": 1261.8724856376648, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbe50>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0820>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1261.8724856376648, "timesteps_since_restore": 0, "iterations_since_restore": 33, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.38194444444444, "ram_util_percent": 86.125}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 8.0326509475708, "actor_loss": 22.703147888183594, "critic_loss": 0.49385613203048706, "alpha_loss": -19.24779510498047, "alpha_value": 0.09106384217739105, "log_alpha_value": -2.3961944580078125, "target_entropy": -5.0, "policy_t": -0.12345375120639801, "mean_q": -22.948562622070312, "max_q": -19.19216537475586, "min_q": -24.88652801513672}, "td_error": [0.5445165634155273, 22.044652938842773, 0.2996788024902344, 0.6354551315307617, 0.6332197189331055, 0.31099796295166016, 0.2931680679321289, 0.27129650115966797, 22.134416580200195, 0.25834178924560547, 0.4822969436645508, 0.3600196838378906, 0.7996759414672852, 0.17002487182617188, 0.2520284652709961, 0.6460247039794922, 0.3409576416015625, 0.8284177780151367, 0.11775684356689453, 0.5616168975830078, 0.615290641784668, 0.14702320098876953, 21.40835952758789, 0.7945833206176758, 0.20146656036376953, 21.75768280029297, 0.5012054443359375, 0.6107378005981445, 0.48992252349853516, 0.3819093704223633, 0.4604330062866211, 270.53778076171875, 0.40038490295410156, 0.6785507202148438, 22.6446533203125, 0.2091827392578125, 0.7555675506591797, 0.45381927490234375, 0.13264846801757812, 0.047356605529785156, 0.34534454345703125, 0.4637775421142578, 0.362274169921875, 0.4232511520385742, 0.7226724624633789, 0.6528358459472656, 0.23086833953857422, 267.9953308105469, 0.6530704498291016, 22.0643253326416, 0.3360729217529297, 18.617530822753906, 20.684494018554688, 21.626502990722656, 0.7936954498291016, 1.0534772872924805, 0.6574935913085938, 21.72260284423828, 0.3156766891479492, 21.755939483642578, 21.75768280029297, 0.5262441635131836, 0.40671730041503906, 0.3562278747558594, 0.5027580261230469, 0.45644569396972656, 0.36478519439697266, 0.12320137023925781, 0.09629440307617188, 0.5679731369018555, 271.90350341796875, 0.23844146728515625, 0.6219053268432617, 0.4881744384765625, 0.6319513320922852, 0.5954465866088867, 0.45000743865966797, 22.01283836364746, 0.13348674774169922, 0.23795223236083984, 20.382314682006836, 0.1814708709716797, 0.5476818084716797, 0.6608667373657227, 0.45682716369628906, 0.19724369049072266, 0.2023906707763672, 18.62359619140625, 0.1392192840576172, 0.3167715072631836, 0.5443048477172852, 0.11847782135009766, 0.6765165328979492, 0.5671892166137695, 0.5022621154785156, 0.5635318756103516, 0.340850830078125, 0.7755393981933594, 0.9676275253295898, 0.25709056854248047, 0.08274173736572266, 0.2788209915161133, 0.41500377655029297, 0.2746553421020508, 0.2825002670288086, 0.3292827606201172, 0.6808462142944336, 0.052039146423339844, 0.6500740051269531, 0.48158740997314453, 0.40985965728759766, 0.06265830993652344, 0.24894046783447266, 0.4622001647949219, 0.12410831451416016, 0.6600217819213867, 0.13433074951171875, 0.1613912582397461, 0.05139446258544922, 0.49994850158691406, 0.4156322479248047, 0.1337890625, 0.4636678695678711, 0.161224365234375, 271.4949951171875, 0.33153343200683594, 0.3969764709472656, 22.481609344482422, 0.08638477325439453, 0.5426645278930664, 0.5714263916015625, 0.4182138442993164, 0.12307453155517578, 0.3641071319580078, 0.6088628768920898, 0.22995376586914062, 0.28269100189208984, 0.49628639221191406, 0.6700439453125, 0.66937255859375, 270.9493103027344, 0.13318347930908203, 0.32619285583496094, 0.07506179809570312, 0.31034278869628906, 0.36751365661621094, 0.21396350860595703, 0.48791980743408203, 0.45969676971435547, 0.5026779174804688, 0.49596118927001953, 0.5386905670166016, 0.1444721221923828, 0.5064783096313477, 0.3608741760253906, 21.364192962646484, 0.3854398727416992, 0.06325721740722656, 0.12746238708496094, 0.1738138198852539, 0.5061635971069336, 23.045486450195312, 0.3471803665161133, 0.272186279296875, 0.13785552978515625, 0.47571468353271484, 0.6786298751831055, 0.5004138946533203, 0.2181415557861328, 0.41239452362060547, 0.3246421813964844, 0.8055810928344727, 0.46221065521240234, 0.9237222671508789, 0.2921600341796875, 0.10863876342773438, 0.4261322021484375, 0.38427257537841797, 0.3798980712890625, 0.6796751022338867, 0.12926292419433594, 0.45157718658447266, 0.22530651092529297, 0.14004135131835938, 0.21846294403076172, 0.1551380157470703, 0.2542304992675781, 0.47801780700683594, 0.4284086227416992, 0.45558929443359375, 0.432647705078125, 0.3107156753540039, 1.010697364807129, 0.5939311981201172, 269.56805419921875, 0.136016845703125, 0.24911975860595703, 22.909866333007812, 21.74337387084961, 0.65692138671875, 0.9826192855834961, 0.4024810791015625, 0.45894527435302734, 0.2215261459350586, 0.0972738265991211, 0.44490718841552734, 0.5275115966796875, 0.719700813293457, 22.560876846313477, 0.8633489608764648, 0.2081136703491211, 0.7192420959472656, 0.585383415222168, 0.20124340057373047, 0.2805795669555664, 21.821378707885742, 0.2749490737915039, 0.4684181213378906, 1.067732810974121, 0.063812255859375, 0.32605457305908203, 0.29010486602783203, 0.20374584197998047, 0.3547658920288086, 269.56805419921875, 0.6532306671142578, 0.3944692611694336, 0.35585975646972656, 0.05256080627441406, 0.37163352966308594, 0.15552616119384766, 0.0750284194946289, 0.4039888381958008, 0.25878334045410156, 0.37758731842041016, 0.8696784973144531, 0.5630311965942383, 0.2205352783203125, 0.4879341125488281, 0.4184541702270508, 0.40856456756591797, 22.488636016845703, 0.8694887161254883, 0.25153541564941406, 0.11786556243896484, 22.392986297607422, 0.4943227767944336, 0.10471248626708984, 0.8537168502807617, 0.17731857299804688, 19.205204010009766, 0.3997039794921875, 0.4164915084838867, 0.4141979217529297, 0.8034849166870117, 0.19285964965820312], "mean_td_error": 9.852914810180664, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 8023.0, "diff_num_grad_updates_vs_sampler_policy": 8022.0}}, "num_env_steps_sampled": 34068, "num_env_steps_trained": 2053888, "num_agent_steps_sampled": 34068, "num_agent_steps_trained": 2053888, "last_target_update_ts": 34068, "num_target_updates": 8023}, "sampler_results": {"episode_reward_max": -168.78121964633465, "episode_reward_min": -185.78847029060125, "episode_reward_mean": -181.12046305007405, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-183.19660459458828, -184.6687048599124, -185.1236521154642, -171.8001147210598, -183.45194736123085, -183.7468140721321, -185.78847029060125, -168.78121964633465, -183.52663978934288], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1891045844263446, "mean_inference_ms": 2.390704021032316, "mean_action_processing_ms": 0.2275375570991581, "mean_env_wait_ms": 2.9852456347578684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -168.78121964633465, "episode_reward_min": -185.78847029060125, "episode_reward_mean": -181.12046305007405, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-183.19660459458828, -184.6687048599124, -185.1236521154642, -171.8001147210598, -183.45194736123085, -183.7468140721321, -185.78847029060125, -168.78121964633465, -183.52663978934288], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1891045844263446, "mean_inference_ms": 2.390704021032316, "mean_action_processing_ms": 0.2275375570991581, "mean_env_wait_ms": 2.9852456347578684, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 34068, "num_agent_steps_trained": 2053888, "num_env_steps_sampled": 34068, "num_env_steps_trained": 2053888, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 34068, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 34068, "timers": {"training_iteration_time_ms": 152.01, "load_time_ms": 0.278, "load_throughput": 922458.612, "learn_time_ms": 24.819, "learn_throughput": 10314.88, "synch_weights_time_ms": 5.845}, "counters": {"num_env_steps_sampled": 34068, "num_env_steps_trained": 2053888, "num_agent_steps_sampled": 34068, "num_agent_steps_trained": 2053888, "last_target_update_ts": 34068, "num_target_updates": 8023}, "done": false, "episodes_total": 348, "training_iteration": 34, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-56-50", "timestamp": 1675951010, "time_this_iter_s": 55.86729431152344, "time_total_s": 1317.7397799491882, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c29d0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1317.7397799491882, "timesteps_since_restore": 0, "iterations_since_restore": 34, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 51.04805194805194, "ram_util_percent": 86.30519480519479}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.746520042419434, "actor_loss": 24.901107788085938, "critic_loss": 0.3681386709213257, "alpha_loss": -19.320087432861328, "alpha_value": 0.08257614076137543, "log_alpha_value": -2.4940345287323, "target_entropy": -5.0, "policy_t": -0.1113440990447998, "mean_q": -25.173688888549805, "max_q": -21.745468139648438, "min_q": -27.141613006591797}, "td_error": [22.608142852783203, 0.17402935028076172, 0.3928213119506836, 0.18436336517333984, 0.27565765380859375, 0.20831775665283203, 0.07257843017578125, 0.3342409133911133, 23.944995880126953, 0.33721351623535156, 24.626543045043945, 0.08270454406738281, 0.6261415481567383, 0.48908138275146484, 0.3765268325805664, 0.3554353713989258, 0.21414756774902344, 0.3026714324951172, 0.21516895294189453, 273.1881103515625, 273.61224365234375, 0.5184316635131836, 0.4775714874267578, 0.5369663238525391, 0.16553306579589844, 273.2561340332031, 0.2319660186767578, 0.7712497711181641, 0.06875419616699219, 23.984962463378906, 0.3112144470214844, 0.30872440338134766, 0.43709564208984375, 0.43871498107910156, 0.5629415512084961, 0.6242704391479492, 0.21320438385009766, 0.5703887939453125, 0.3535127639770508, 0.11271095275878906, 0.36901187896728516, 0.7849655151367188, 0.46840667724609375, 0.5520334243774414, 0.21627521514892578, 0.13014793395996094, 0.09923648834228516, 0.23337650299072266, 0.5712862014770508, 0.5258197784423828, 20.51605987548828, 0.2639026641845703, 0.3206319808959961, 0.08367347717285156, 0.7035322189331055, 0.7039909362792969, 0.07040023803710938, 0.10226154327392578, 0.45371055603027344, 0.07224273681640625, 0.2504558563232422, 24.5517578125, 0.81109619140625, 0.5521793365478516, 0.0826101303100586, 23.985755920410156, 0.14952468872070312, 0.5230960845947266, 0.2275247573852539, 0.6934986114501953, 0.37584877014160156, 0.5908327102661133, 21.522140502929688, 0.7747669219970703, 0.42824459075927734, 0.4648590087890625, 0.1814403533935547, 0.4112224578857422, 0.16530609130859375, 0.3340415954589844, 22.33535385131836, 0.4653339385986328, 0.4786109924316406, 0.17310333251953125, 23.626310348510742, 0.6565046310424805, 0.260986328125, 0.4783935546875, 1.0210199356079102, 0.2170400619506836, 0.5506267547607422, 0.635340690612793, 0.7158470153808594, 0.7170066833496094, 0.25361156463623047, 0.7943859100341797, 20.51605987548828, 0.5733757019042969, 0.33873939514160156, 0.4658470153808594, 0.3968982696533203, 0.5054826736450195, 0.4226665496826172, 0.10957813262939453, 0.5145416259765625, 0.5072708129882812, 25.19528579711914, 22.858766555786133, 0.809941291809082, 0.4235696792602539, 0.9802980422973633, 0.48154258728027344, 0.3603534698486328, 0.20906829833984375, 0.5125465393066406, 0.6649208068847656, 0.4072141647338867, 0.728693962097168, 0.377532958984375, 0.1663808822631836, 0.47257328033447266, 0.47650814056396484, 0.29058361053466797, 0.5870075225830078, 0.17438125610351562, 0.6379985809326172, 0.28293609619140625, 0.1262216567993164, 0.27228546142578125, 0.35288238525390625, 0.28989410400390625, 0.5422191619873047, 0.2238931655883789, 0.5773715972900391, 0.8702316284179688, 0.5526580810546875, 24.6221923828125, 24.02503776550293, 0.13486480712890625, 0.3974781036376953, 23.033884048461914, 0.2704658508300781, 0.3306436538696289, 0.39063453674316406, 0.3212881088256836, 0.06760978698730469, 24.113388061523438, 0.2869300842285156, 0.48832225799560547, 0.3376636505126953, 0.293060302734375, 0.538691520690918, 0.24032974243164062, 0.46106624603271484, 0.6447105407714844, 0.2807960510253906, 0.7456798553466797, 0.7048454284667969, 0.40450191497802734, 0.3369569778442383, 0.4469261169433594, 0.10330772399902344, 0.4752197265625, 0.04817390441894531, 0.238037109375, 0.4456825256347656, 0.06837940216064453, 0.5180530548095703, 0.5040521621704102, 0.3814239501953125, 0.5142602920532227, 23.22504425048828, 0.5780467987060547, 273.1881103515625, 0.298553466796875, 0.4772930145263672, 0.5235509872436523, 0.22590255737304688, 24.41777801513672, 0.4502124786376953, 0.4485893249511719, 0.42971229553222656, 20.034088134765625, 0.42186641693115234, 0.20772552490234375, 0.4182157516479492, 0.6908483505249023, 24.548187255859375, 0.45403003692626953, 0.12497806549072266, 0.43619537353515625, 0.2736959457397461, 0.48904991149902344, 0.06502532958984375, 0.5467748641967773, 0.32015037536621094, 0.6056499481201172, 0.3526592254638672, 0.4696531295776367, 0.5827369689941406, 0.3332843780517578, 0.5356130599975586, 25.10321807861328, 0.10991764068603516, 0.2936887741088867, 0.30336570739746094, 0.2810335159301758, 0.659144401550293, 20.628761291503906, 0.4963979721069336, 20.08606719970703, 24.506572723388672, 0.3809671401977539, 0.29427146911621094, 24.518512725830078, 0.5335330963134766, 0.4347505569458008, 0.5546607971191406, 0.41324710845947266, 0.3873023986816406, 0.6232433319091797, 0.7676715850830078, 0.48891258239746094, 0.48302459716796875, 0.7784805297851562, 0.40938282012939453, 0.02337932586669922, 0.4643278121948242, 0.6073389053344727, 24.444469451904297, 0.3460121154785156, 0.45560550689697266, 0.3587799072265625, 0.5114898681640625, 21.452625274658203, 1.0562763214111328, 0.20452213287353516, 0.4053964614868164, 0.2075481414794922, 0.3057727813720703, 0.3413705825805664, 21.75809097290039, 0.4862985610961914, 0.26958656311035156, 0.3005037307739258, 0.15670299530029297, 0.335205078125, 0.4295654296875, 0.1641530990600586, 0.2217111587524414, 0.03651618957519531, 0.3128929138183594, 0.1679401397705078, 0.08517169952392578, 0.633000373840332, 21.624774932861328], "mean_td_error": 7.322692394256592, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 8357.0, "diff_num_grad_updates_vs_sampler_policy": 8356.0}}, "num_env_steps_sampled": 35070, "num_env_steps_trained": 2139392, "num_agent_steps_sampled": 35070, "num_agent_steps_trained": 2139392, "last_target_update_ts": 35070, "num_target_updates": 8357}, "sampler_results": {"episode_reward_max": 138.08201134204865, "episode_reward_min": -187.7539255991578, "episode_reward_mean": -129.5451263921956, "episode_len_mean": 95.25, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [117.21727380901575, 138.08201134204865, -187.7539255991578, -181.55882640182972, -183.39881467819214, -186.3256485313177, -182.53403153270483, -173.93451785296202, -183.73162057995796, -174.1911989748478, -181.75915682315826, -174.65306088328362], "episode_lengths": [80, 63, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1874720697661543, "mean_inference_ms": 2.3906589305537143, "mean_action_processing_ms": 0.22707527120836724, "mean_env_wait_ms": 2.9826807179748864, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 138.08201134204865, "episode_reward_min": -187.7539255991578, "episode_reward_mean": -129.5451263921956, "episode_len_mean": 95.25, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [117.21727380901575, 138.08201134204865, -187.7539255991578, -181.55882640182972, -183.39881467819214, -186.3256485313177, -182.53403153270483, -173.93451785296202, -183.73162057995796, -174.1911989748478, -181.75915682315826, -174.65306088328362], "episode_lengths": [80, 63, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1874720697661543, "mean_inference_ms": 2.3906589305537143, "mean_action_processing_ms": 0.22707527120836724, "mean_env_wait_ms": 2.9826807179748864, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 35070, "num_agent_steps_trained": 2139392, "num_env_steps_sampled": 35070, "num_env_steps_trained": 2139392, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 35070, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 35070, "timers": {"training_iteration_time_ms": 158.663, "load_time_ms": 0.295, "load_throughput": 867810.413, "learn_time_ms": 25.403, "learn_throughput": 10077.427, "synch_weights_time_ms": 5.836}, "counters": {"num_env_steps_sampled": 35070, "num_env_steps_trained": 2139392, "num_agent_steps_sampled": 35070, "num_agent_steps_trained": 2139392, "last_target_update_ts": 35070, "num_target_updates": 8357}, "done": false, "episodes_total": 360, "training_iteration": 35, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-57-43", "timestamp": 1675951063, "time_this_iter_s": 52.851844787597656, "time_total_s": 1370.591624736786, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb040>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef3a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1370.591624736786, "timesteps_since_restore": 0, "iterations_since_restore": 35, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.04657534246576, "ram_util_percent": 86.82465753424658}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.711314678192139, "actor_loss": 27.029306411743164, "critic_loss": 0.5317329168319702, "alpha_loss": -19.982624053955078, "alpha_value": 0.0749197006225586, "log_alpha_value": -2.5913383960723877, "target_entropy": -5.0, "policy_t": -0.13042889535427094, "mean_q": -27.225055694580078, "max_q": -23.35072898864746, "min_q": -29.55910301208496}, "td_error": [0.42412281036376953, 0.19390201568603516, 0.6979799270629883, 0.1227579116821289, 0.689122200012207, 24.812652587890625, 0.6750736236572266, 0.31749725341796875, 0.4209423065185547, 0.49166107177734375, 0.528712272644043, 0.36403369903564453, 0.602208137512207, 0.6971607208251953, 0.8004398345947266, 0.6133537292480469, 0.46476268768310547, 0.43761253356933594, 0.42649364471435547, 0.10005855560302734, 0.3545570373535156, 0.2067127227783203, 0.18920230865478516, 0.16220760345458984, 0.08967876434326172, 0.45426368713378906, 0.6242456436157227, 0.8382101058959961, 0.3717794418334961, 0.947260856628418, 0.3629598617553711, 0.28137969970703125, 0.30370616912841797, 0.5515756607055664, 0.6585149765014648, 26.268630981445312, 0.43041038513183594, 0.43291378021240234, 0.5748815536499023, 0.49176883697509766, 0.8536157608032227, 0.057166099548339844, 0.602935791015625, 0.17836475372314453, 23.997787475585938, 1.1601057052612305, 0.38429737091064453, 0.669154167175293, 25.227706909179688, 275.06842041015625, 0.3196296691894531, 0.28246402740478516, 0.27641773223876953, 0.33096790313720703, 0.5254716873168945, 26.135086059570312, 0.31682300567626953, 0.13976669311523438, 24.957599639892578, 0.6132841110229492, 0.19412612915039062, 0.4167652130126953, 0.1496572494506836, 0.7467145919799805, 0.7366971969604492, 276.32952880859375, 25.270545959472656, 0.20337963104248047, 1.014791488647461, 0.35465145111083984, 0.4723396301269531, 0.5092372894287109, 0.2752342224121094, 0.5763826370239258, 0.38681983947753906, 0.08802509307861328, 0.03743171691894531, 0.16133689880371094, 0.6341543197631836, 0.29840087890625, 0.6441450119018555, 0.07823753356933594, 0.27350902557373047, 0.5377626419067383, 0.7046842575073242, 272.0893249511719, 0.7397394180297852, 0.5755844116210938, 0.3334331512451172, 0.7281103134155273, 0.5287256240844727, 25.475440979003906, 0.5419511795043945, 0.25942420959472656, 0.32750797271728516, 0.3232307434082031, 0.5598421096801758, 0.6184110641479492, 0.34850597381591797, 0.08782291412353516, 0.5154380798339844, 0.326873779296875, 0.5937681198120117, 0.3336172103881836, 0.3767080307006836, 0.06566619873046875, 24.777565002441406, 0.6877546310424805, 274.7935791015625, 0.5662336349487305, 0.3869752883911133, 0.5532999038696289, 0.48032379150390625, 0.8912019729614258, 0.22764110565185547, 0.2680511474609375, 0.4653806686401367, 25.878612518310547, 0.3114957809448242, 0.3146820068359375, 0.12103843688964844, 26.773427963256836, 0.3567667007446289, 0.35767459869384766, 0.5100879669189453, 0.4521751403808594, 25.315065383911133, 0.811223030090332, 0.2449321746826172, 26.39368438720703, 0.11068153381347656, 0.4235391616821289, 0.7483682632446289, 0.5139427185058594, 0.8485345840454102, 0.5328245162963867, 0.2635345458984375, 0.5366477966308594, 0.3184661865234375, 0.19643211364746094, 0.47704029083251953, 0.6774816513061523, 0.26303577423095703, 0.28881263732910156, 25.867198944091797, 0.77813720703125, 0.2941932678222656, 0.3664588928222656, 25.067493438720703, 0.35616397857666016, 0.23070621490478516, 0.47261810302734375, 22.6976318359375, 0.2904167175292969, 26.663314819335938, 0.36705684661865234, 0.7597017288208008, 0.2371816635131836, 0.9560117721557617, 0.42473888397216797, 0.7594995498657227, 26.696239471435547, 0.4908256530761719, 0.5150728225708008, 0.6534662246704102, 0.11432361602783203, 0.39090919494628906, 24.935894012451172, 0.5765218734741211, 0.028299331665039062, 0.5662040710449219, 0.4282522201538086, 24.964786529541016, 0.7315769195556641, 0.27208423614501953, 0.5798463821411133, 0.3645505905151367, 0.35717010498046875, 26.39368438720703, 273.9085693359375, 274.84619140625, 24.187429428100586, 0.37183666229248047, 0.626307487487793, 0.4391822814941406, 26.875080108642578, 0.5655679702758789, 0.2709951400756836, 0.2626686096191406, 0.19642353057861328, 0.13808917999267578, 0.20810604095458984, 0.6132631301879883, 0.3154945373535156, 0.4142637252807617, 0.2978048324584961, 0.32730865478515625, 0.5527610778808594, 0.7246294021606445, 0.09319210052490234, 0.23964881896972656, 0.5920324325561523, 0.3838987350463867, 0.05188941955566406, 0.43533992767333984, 0.3313322067260742, 0.6147890090942383, 0.4840097427368164, 0.4633808135986328, 0.18259525299072266, 0.053511619567871094, 0.5090246200561523, 0.11165237426757812, 0.08018875122070312, 0.708953857421875, 0.7521944046020508, 0.4923124313354492, 23.32843017578125, 0.3106393814086914, 0.7022771835327148, 0.6695985794067383, 0.6560525894165039, 0.5280933380126953, 0.6745901107788086, 0.058180809020996094, 0.13805294036865234, 0.5638799667358398, 0.3840312957763672, 1.023667335510254, 0.812901496887207, 0.5011205673217773, 0.6550483703613281, 0.3631277084350586, 0.04929542541503906, 0.3851766586303711, 0.1394662857055664, 273.4835205078125, 0.428985595703125, 0.6074304580688477, 0.4132347106933594, 0.5145425796508789, 0.029195785522460938, 0.08796977996826172, 0.32094287872314453, 26.069931030273438, 0.24138450622558594, 0.8996381759643555, 0.39897727966308594, 0.019819259643554688, 23.389598846435547, 23.33725357055664, 0.4435691833496094, 0.10953044891357422, 0.2540712356567383, 275.32598876953125, 0.5487737655639648], "mean_td_error": 11.612471580505371, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 8691.0, "diff_num_grad_updates_vs_sampler_policy": 8690.0}}, "num_env_steps_sampled": 36072, "num_env_steps_trained": 2224896, "num_agent_steps_sampled": 36072, "num_agent_steps_trained": 2224896, "last_target_update_ts": 36072, "num_target_updates": 8691}, "sampler_results": {"episode_reward_max": -168.14107708632946, "episode_reward_min": -182.89673117548227, "episode_reward_mean": -177.47968737118774, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-182.89673117548227, -180.76931977272034, -180.18828734010458, -182.54403713345528, -174.68762480467558, -172.4507051408291, -174.89911195635796, -180.7402919307351, -168.14107708632946], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1854629159717203, "mean_inference_ms": 2.389867634551854, "mean_action_processing_ms": 0.22681519791886615, "mean_env_wait_ms": 2.9796439281207197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -168.14107708632946, "episode_reward_min": -182.89673117548227, "episode_reward_mean": -177.47968737118774, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-182.89673117548227, -180.76931977272034, -180.18828734010458, -182.54403713345528, -174.68762480467558, -172.4507051408291, -174.89911195635796, -180.7402919307351, -168.14107708632946], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1854629159717203, "mean_inference_ms": 2.389867634551854, "mean_action_processing_ms": 0.22681519791886615, "mean_env_wait_ms": 2.9796439281207197, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 36072, "num_agent_steps_trained": 2224896, "num_env_steps_sampled": 36072, "num_env_steps_trained": 2224896, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 36072, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 36072, "timers": {"training_iteration_time_ms": 153.144, "load_time_ms": 0.276, "load_throughput": 926198.416, "learn_time_ms": 25.042, "learn_throughput": 10222.978, "synch_weights_time_ms": 5.544}, "counters": {"num_env_steps_sampled": 36072, "num_env_steps_trained": 2224896, "num_agent_steps_sampled": 36072, "num_agent_steps_trained": 2224896, "last_target_update_ts": 36072, "num_target_updates": 8691}, "done": false, "episodes_total": 369, "training_iteration": 36, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-58-35", "timestamp": 1675951115, "time_this_iter_s": 52.450255393981934, "time_total_s": 1423.0418801307678, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb310>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef0d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1423.0418801307678, "timesteps_since_restore": 0, "iterations_since_restore": 36, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.722535211267605, "ram_util_percent": 86.9507042253521}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.642748832702637, "actor_loss": 28.965438842773438, "critic_loss": 0.4976688623428345, "alpha_loss": -20.548004150390625, "alpha_value": 0.06797861307859421, "log_alpha_value": -2.6885621547698975, "target_entropy": -5.0, "policy_t": -0.122919961810112, "mean_q": -29.15236473083496, "max_q": -25.191349029541016, "min_q": -31.351072311401367}, "td_error": [0.20620441436767578, 0.651310920715332, 0.4551267623901367, 0.1846942901611328, 0.5216484069824219, 0.6069746017456055, 0.16508197784423828, 0.4062976837158203, 0.7866849899291992, 0.23105812072753906, 0.3820676803588867, 0.48909664154052734, 28.016498565673828, 0.4575977325439453, 0.5443887710571289, 29.57190704345703, 0.19278240203857422, 0.4730081558227539, 0.2588033676147461, 0.36380863189697266, 0.40460872650146484, 28.415637969970703, 0.8755712509155273, 0.37603187561035156, 0.20758628845214844, 0.5798883438110352, 0.63250732421875, 0.6290273666381836, 0.7712955474853516, 0.3548011779785156, 0.46216678619384766, 0.3947172164916992, 0.48050594329833984, 0.41458797454833984, 0.4393644332885742, 0.4921875, 0.580535888671875, 0.22322559356689453, 0.4546375274658203, 0.1709451675415039, 0.3125600814819336, 0.09637451171875, 0.2941408157348633, 0.37841796875, 0.4993171691894531, 28.362895965576172, 0.05011940002441406, 0.31395435333251953, 0.4459409713745117, 28.577716827392578, 0.4333353042602539, 27.56637191772461, 0.38806629180908203, 0.6022424697875977, 25.63285255432129, 0.3210735321044922, 0.5778617858886719, 0.47000694274902344, 0.12033939361572266, 0.6997575759887695, 0.5982131958007812, 0.5022430419921875, 0.27225208282470703, 0.34086132049560547, 0.07526206970214844, 0.30761146545410156, 273.9499816894531, 1.0699644088745117, 0.6710987091064453, 0.7164812088012695, 0.5330038070678711, 0.5599403381347656, 0.7217206954956055, 0.6319370269775391, 0.45400524139404297, 0.5085945129394531, 0.41710758209228516, 26.745033264160156, 0.15186500549316406, 0.4593696594238281, 0.31438732147216797, 0.14117145538330078, 0.7185869216918945, 0.25303077697753906, 26.74203872680664, 0.3521108627319336, 0.6890459060668945, 0.3270397186279297, 0.25475502014160156, 0.43466758728027344, 0.4498777389526367, 0.5853996276855469, 0.46486759185791016, 0.28954315185546875, 0.7262458801269531, 25.052860260009766, 0.2690248489379883, 0.28745079040527344, 0.5577058792114258, 0.28650856018066406, 0.5949153900146484, 0.5204801559448242, 0.2756977081298828, 0.41793251037597656, 0.42615509033203125, 0.8387336730957031, 26.800457000732422, 0.38362884521484375, 0.12784481048583984, 0.844874382019043, 28.151897430419922, 0.4117593765258789, 277.78955078125, 0.4663982391357422, 0.14847850799560547, 28.87950325012207, 0.16253662109375, 0.46988677978515625, 0.22141456604003906, 0.3065919876098633, 0.3375368118286133, 0.3676881790161133, 0.5471105575561523, 0.45690155029296875, 0.5901012420654297, 0.1382150650024414, 27.367145538330078, 0.3653450012207031, 28.417510986328125, 26.86493682861328, 0.6630964279174805, 278.1983642578125, 0.864008903503418, 0.569331169128418, 0.4455413818359375, 0.38865089416503906, 0.4205636978149414, 28.11859893798828, 0.48854541778564453, 0.6818037033081055, 0.6667184829711914, 0.7070484161376953, 0.34457874298095703, 0.2129383087158203, 0.24816226959228516, 0.030739784240722656, 0.12073040008544922, 26.41629409790039, 0.5678014755249023, 0.3808269500732422, 0.28006649017333984, 0.4329862594604492, 27.764875411987305, 0.4796171188354492, 0.10558223724365234, 0.048877716064453125, 0.666010856628418, 0.15801334381103516, 0.6270170211791992, 0.18317222595214844, 0.5165910720825195, 27.749061584472656, 0.2068328857421875, 0.16165733337402344, 0.45781421661376953, 0.44345855712890625, 0.17127227783203125, 0.5090827941894531, 276.55841064453125, 0.10430526733398438, 0.6104822158813477, 0.10368537902832031, 0.44263267517089844, 0.4939155578613281, 0.39345359802246094, 0.6824350357055664, 0.8783273696899414, 0.20699119567871094, 0.5300416946411133, 0.8240127563476562, 0.35262107849121094, 0.6509714126586914, 0.7700319290161133, 0.7638921737670898, 0.547088623046875, 0.4316282272338867, 0.5863237380981445, 0.7421636581420898, 0.7191581726074219, 27.56637191772461, 0.5537643432617188, 27.365097045898438, 0.5401268005371094, 0.36223411560058594, 0.11132240295410156, 27.945066452026367, 0.2950010299682617, 0.6384372711181641, 27.454761505126953, 0.4983978271484375, 0.5926675796508789, 0.6685075759887695, 0.48450756072998047, 0.5402250289916992, 0.21691131591796875, 0.3428468704223633, 0.5656881332397461, 0.25298023223876953, 0.2155895233154297, 0.13260841369628906, 0.571843147277832, 0.48030948638916016, 0.6944131851196289, 0.6160879135131836, 0.3424997329711914, 0.9931650161743164, 0.11833953857421875, 0.15053653717041016, 28.298545837402344, 0.6032867431640625, 0.15798664093017578, 0.4480724334716797, 0.012866020202636719, 0.5886602401733398, 0.27454280853271484, 0.6352071762084961, 0.2151050567626953, 1.0372915267944336, 0.1686077117919922, 0.6115713119506836, 0.4642763137817383, 0.4628620147705078, 0.43873119354248047, 28.439651489257812, 273.9374694824219, 0.8161411285400391, 0.5655527114868164, 0.4206066131591797, 0.5131044387817383, 0.5638179779052734, 0.34069252014160156, 0.5104589462280273, 0.16202640533447266, 25.476913452148438, 28.12703514099121, 0.17940521240234375, 276.523681640625, 0.6139764785766602, 0.5305767059326172, 0.3585386276245117, 0.4110250473022461, 0.6365766525268555, 0.2434072494506836, 0.8241729736328125, 0.6199607849121094, 0.5131416320800781], "mean_td_error": 9.871042251586914, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 9025.0, "diff_num_grad_updates_vs_sampler_policy": 9024.0}}, "num_env_steps_sampled": 37074, "num_env_steps_trained": 2310400, "num_agent_steps_sampled": 37074, "num_agent_steps_trained": 2310400, "last_target_update_ts": 37074, "num_target_updates": 9025}, "sampler_results": {"episode_reward_max": -169.104292050004, "episode_reward_min": -186.18423768877983, "episode_reward_mean": -179.24181281104683, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.27307602763176, -186.18423768877983, -180.45594291388988, -177.72986532747746, -183.33996964991093, -185.95709364116192, -184.1188800856471, -184.27896517515182, -169.104292050004, -170.97580555081367], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1950584819511898, "mean_inference_ms": 2.404987818794118, "mean_action_processing_ms": 0.2284700309721935, "mean_env_wait_ms": 2.997615144653839, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -169.104292050004, "episode_reward_min": -186.18423768877983, "episode_reward_mean": -179.24181281104683, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.27307602763176, -186.18423768877983, -180.45594291388988, -177.72986532747746, -183.33996964991093, -185.95709364116192, -184.1188800856471, -184.27896517515182, -169.104292050004, -170.97580555081367], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1950584819511898, "mean_inference_ms": 2.404987818794118, "mean_action_processing_ms": 0.2284700309721935, "mean_env_wait_ms": 2.997615144653839, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 37074, "num_agent_steps_trained": 2310400, "num_env_steps_sampled": 37074, "num_env_steps_trained": 2310400, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 37074, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 37074, "timers": {"training_iteration_time_ms": 165.181, "load_time_ms": 0.304, "load_throughput": 843208.594, "learn_time_ms": 26.202, "learn_throughput": 9770.429, "synch_weights_time_ms": 5.855}, "counters": {"num_env_steps_sampled": 37074, "num_env_steps_trained": 2310400, "num_agent_steps_sampled": 37074, "num_agent_steps_trained": 2310400, "last_target_update_ts": 37074, "num_target_updates": 9025}, "done": false, "episodes_total": 379, "training_iteration": 37, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_14-59-28", "timestamp": 1675951168, "time_this_iter_s": 52.780232429504395, "time_total_s": 1475.8221125602722, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb1f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1475.8221125602722, "timesteps_since_restore": 0, "iterations_since_restore": 37, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.94657534246575, "ram_util_percent": 87.16164383561645}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.648930549621582, "actor_loss": 31.052967071533203, "critic_loss": 0.5826519131660461, "alpha_loss": -21.305782318115234, "alpha_value": 0.06170075759291649, "log_alpha_value": -2.785459041595459, "target_entropy": -5.0, "policy_t": -0.14987409114837646, "mean_q": -31.241458892822266, "max_q": -27.193740844726562, "min_q": -33.47929763793945}, "td_error": [30.840373992919922, 30.722909927368164, 0.07666587829589844, 0.6210088729858398, 0.18027782440185547, 0.2874116897583008, 0.6516237258911133, 0.5345058441162109, 0.21349430084228516, 0.1799602508544922, 0.6547555923461914, 0.14208030700683594, 0.2883930206298828, 0.8936452865600586, 0.1974506378173828, 0.2499094009399414, 0.2955656051635742, 0.2964649200439453, 0.027065277099609375, 0.060688018798828125, 29.728069305419922, 0.06987762451171875, 0.22113800048828125, 29.202285766601562, 0.10991859436035156, 0.4566364288330078, 0.4706287384033203, 30.347904205322266, 0.7421503067016602, 0.14969253540039062, 0.5411148071289062, 0.5683193206787109, 0.44095611572265625, 0.3504772186279297, 0.6878433227539062, 0.06642627716064453, 0.2754840850830078, 0.21049880981445312, 0.5204238891601562, 0.4386930465698242, 0.46771717071533203, 0.5164718627929688, 0.6450004577636719, 0.3187904357910156, 0.18134498596191406, 0.5591526031494141, 0.6445350646972656, 0.12789344787597656, 0.4535713195800781, 0.5542173385620117, 0.4571971893310547, 28.004283905029297, 0.2813701629638672, 29.668643951416016, 0.17467784881591797, 0.4507408142089844, 0.7181673049926758, 0.25890541076660156, 0.33581066131591797, 0.18349933624267578, 0.5187625885009766, 0.032683372497558594, 0.1880645751953125, 0.5406017303466797, 0.4237937927246094, 26.875869750976562, 0.06622505187988281, 0.0792684555053711, 0.5036563873291016, 0.45119190216064453, 0.5855884552001953, 0.5006294250488281, 0.3575096130371094, 0.36538124084472656, 0.19999122619628906, 0.6272954940795898, 0.6266794204711914, 0.5141773223876953, 0.8919973373413086, 0.6286220550537109, 0.4204692840576172, 0.46257972717285156, 0.05559349060058594, 279.9581298828125, 29.044532775878906, 0.2614727020263672, 0.2562141418457031, 0.3597736358642578, 0.2467498779296875, 0.5197067260742188, 0.15530014038085938, 0.385589599609375, 0.38242435455322266, 0.5030841827392578, 0.43596839904785156, 0.18796539306640625, 30.445911407470703, 0.2975120544433594, 0.2635231018066406, 0.29325008392333984, 0.2577228546142578, 0.43938446044921875, 0.6311302185058594, 0.6728420257568359, 0.01650238037109375, 0.6117162704467773, 30.840373992919922, 0.4383277893066406, 0.18990325927734375, 0.17113208770751953, 0.7286310195922852, 277.64373779296875, 0.34708309173583984, 0.5001964569091797, 0.5926742553710938, 0.30465030670166016, 0.6846189498901367, 0.5207557678222656, 0.38426971435546875, 0.42867565155029297, 0.6342010498046875, 0.11848926544189453, 0.1362295150756836, 0.3665151596069336, 0.48472118377685547, 0.2381296157836914, 0.37813854217529297, 0.38791751861572266, 0.08310794830322266, 0.7089996337890625, 0.6998224258422852, 0.528529167175293, 0.4078350067138672, 0.4351539611816406, 278.9635009765625, 0.7180871963500977, 0.5357799530029297, 0.1300029754638672, 0.2715110778808594, 0.19015789031982422, 0.7111692428588867, 0.4433879852294922, 0.5433673858642578, 0.3000354766845703, 0.7270231246948242, 0.048209190368652344, 29.107349395751953, 29.881885528564453, 0.6267366409301758, 0.3826122283935547, 0.5338554382324219, 0.07214927673339844, 0.04982757568359375, 0.12786388397216797, 0.8588008880615234, 30.90352439880371, 0.5266561508178711, 0.8525772094726562, 0.1607074737548828, 0.6466531753540039, 0.2331838607788086, 0.44864463806152344, 0.5133352279663086, 30.210662841796875, 0.6770772933959961, 0.4629096984863281, 27.820453643798828, 0.4851980209350586, 0.2978019714355469, 0.019390106201171875, 0.5041608810424805, 277.64373779296875, 0.5755186080932617, 0.9732646942138672, 0.35617637634277344, 0.46380138397216797, 0.45126914978027344, 0.5646877288818359, 29.14029312133789, 0.5445308685302734, 0.07946586608886719, 0.21736621856689453, 0.7035293579101562, 29.424774169921875, 0.290496826171875, 0.2995796203613281, 30.503868103027344, 0.3609790802001953, 0.24897384643554688, 0.21645069122314453, 0.7112607955932617, 0.12535858154296875, 0.35410594940185547, 275.935302734375, 0.41909217834472656, 0.15099048614501953, 30.646883010864258, 0.5749692916870117, 0.7159242630004883, 0.3294343948364258, 0.3801727294921875, 0.33246612548828125, 0.6641359329223633, 0.17420387268066406, 0.5111045837402344, 0.4475860595703125, 0.28087425231933594, 0.7958784103393555, 0.3430976867675781, 0.3607797622680664, 0.44876766204833984, 0.10689353942871094, 0.4656801223754883, 0.5840110778808594, 0.4036540985107422, 0.7185544967651367, 0.47415924072265625, 31.116254806518555, 0.4660987854003906, 0.061187744140625, 0.496917724609375, 1.3570184707641602, 0.2393655776977539, 0.17990875244140625, 0.767786979675293, 0.2110729217529297, 0.16901588439941406, 1.015690803527832, 0.5368862152099609, 30.513574600219727, 0.33783721923828125, 277.304931640625, 29.957605361938477, 26.009235382080078, 0.03031444549560547, 275.95672607421875, 0.6472387313842773, 0.17950725555419922, 0.19268417358398438, 0.6125154495239258, 30.85346794128418, 0.09305000305175781, 0.3835315704345703, 0.41055870056152344, 0.14722347259521484, 0.3938722610473633, 0.07873249053955078, 0.2858695983886719, 0.7620992660522461, 0.2830486297607422, 0.3348531723022461, 31.17646598815918, 0.20485496520996094, 0.871826171875, 0.24404525756835938, 279.0422668457031], "mean_td_error": 12.04830551147461, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 9359.0, "diff_num_grad_updates_vs_sampler_policy": 9358.0}}, "num_env_steps_sampled": 38076, "num_env_steps_trained": 2395904, "num_agent_steps_sampled": 38076, "num_agent_steps_trained": 2395904, "last_target_update_ts": 38076, "num_target_updates": 9359}, "sampler_results": {"episode_reward_max": -167.79456190764904, "episode_reward_min": -187.31731226295233, "episode_reward_mean": -180.16447783667934, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-176.87502232193947, -180.9338716417551, -186.6096629947424, -180.62424564361572, -187.31731226295233, -186.28135040402412, -182.3141679316759, -175.285037368536, -167.79456190764904, -176.8871919736266, -180.8868317529559], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1740423125345325, "mean_inference_ms": 2.3758274100308228, "mean_action_processing_ms": 0.2249584694701285, "mean_env_wait_ms": 2.963985615089851, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.79456190764904, "episode_reward_min": -187.31731226295233, "episode_reward_mean": -180.16447783667934, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-176.87502232193947, -180.9338716417551, -186.6096629947424, -180.62424564361572, -187.31731226295233, -186.28135040402412, -182.3141679316759, -175.285037368536, -167.79456190764904, -176.8871919736266, -180.8868317529559], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1740423125345325, "mean_inference_ms": 2.3758274100308228, "mean_action_processing_ms": 0.2249584694701285, "mean_env_wait_ms": 2.963985615089851, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 38076, "num_agent_steps_trained": 2395904, "num_env_steps_sampled": 38076, "num_env_steps_trained": 2395904, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 38076, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 38076, "timers": {"training_iteration_time_ms": 165.954, "load_time_ms": 0.292, "load_throughput": 876595.497, "learn_time_ms": 26.8, "learn_throughput": 9552.073, "synch_weights_time_ms": 6.332}, "counters": {"num_env_steps_sampled": 38076, "num_env_steps_trained": 2395904, "num_agent_steps_sampled": 38076, "num_agent_steps_trained": 2395904, "last_target_update_ts": 38076, "num_target_updates": 9359}, "done": false, "episodes_total": 390, "training_iteration": 38, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-00-21", "timestamp": 1675951221, "time_this_iter_s": 52.70646548271179, "time_total_s": 1528.528578042984, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2a30>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105efc10>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1528.528578042984, "timesteps_since_restore": 0, "iterations_since_restore": 38, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.26986301369863, "ram_util_percent": 87.39863013698628}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.287935256958008, "actor_loss": 33.44982147216797, "critic_loss": 0.6729735732078552, "alpha_loss": -21.00480842590332, "alpha_value": 0.056015100330114365, "log_alpha_value": -2.882133960723877, "target_entropy": -5.0, "policy_t": -0.1772211343050003, "mean_q": -33.59693908691406, "max_q": -29.977802276611328, "min_q": -36.001853942871094}, "td_error": [0.711822509765625, 28.09575653076172, 0.2126598358154297, 0.25942039489746094, 0.7565956115722656, 0.3120288848876953, 0.22978591918945312, 0.46133995056152344, 0.4147987365722656, 0.21104812622070312, 0.6124773025512695, 32.119895935058594, 0.699462890625, 29.6689453125, 0.028196334838867188, 0.4295663833618164, 0.24709320068359375, 0.009572982788085938, 0.6652297973632812, 0.21923255920410156, 0.5333824157714844, 0.16335678100585938, 1.0264091491699219, 0.5035076141357422, 0.40387725830078125, 0.41887855529785156, 0.8280792236328125, 0.2732429504394531, 0.22871112823486328, 0.29821014404296875, 0.14295387268066406, 31.077463150024414, 0.39579010009765625, 0.34672069549560547, 0.2785377502441406, 32.5003776550293, 0.5590744018554688, 0.20054149627685547, 0.5473575592041016, 0.7682247161865234, 0.15065574645996094, 0.25046348571777344, 0.15851402282714844, 32.81629943847656, 0.2631549835205078, 0.3031444549560547, 0.17546844482421875, 0.3521137237548828, 0.4906482696533203, 0.170745849609375, 0.21631240844726562, 31.67915916442871, 0.37573814392089844, 0.45914363861083984, 0.21573257446289062, 0.3901805877685547, 0.3014717102050781, 0.5887851715087891, 0.41300010681152344, 0.2927818298339844, 279.3426513671875, 0.17571449279785156, 30.54895782470703, 0.27624988555908203, 0.07284355163574219, 0.5842132568359375, 0.3934345245361328, 0.8230552673339844, 0.36058807373046875, 0.55755615234375, 0.1516246795654297, 0.4067955017089844, 0.849822998046875, 0.09832191467285156, 0.10181236267089844, 0.1417522430419922, 0.6533851623535156, 0.5395479202270508, 31.6082706451416, 0.7091083526611328, 0.9527320861816406, 0.16597557067871094, 0.19069671630859375, 0.28183746337890625, 0.26303863525390625, 0.17105865478515625, 0.4990119934082031, 0.10404586791992188, 0.4201641082763672, 0.1189117431640625, 33.098548889160156, 0.5043678283691406, 0.37212181091308594, 32.41276168823242, 0.2945404052734375, 0.22977256774902344, 0.5161342620849609, 0.08600616455078125, 0.4310007095336914, 32.60832595825195, 32.41276168823242, 282.255859375, 0.21088409423828125, 0.5490856170654297, 0.3766040802001953, 0.6452341079711914, 0.12148666381835938, 0.5255203247070312, 33.78071594238281, 0.12636566162109375, 0.12928390502929688, 281.164794921875, 282.22039794921875, 0.28002166748046875, 0.13544464111328125, 0.13325786590576172, 0.07269477844238281, 0.34360313415527344, 0.2768268585205078, 0.7366065979003906, 0.3594970703125, 0.1681060791015625, 0.05601692199707031, 0.28224945068359375, 0.2164325714111328, 0.49772071838378906, 0.15866661071777344, 282.62689208984375, 0.22602272033691406, 0.27892303466796875, 0.1557464599609375, 0.22684669494628906, 0.5371723175048828, 0.7151317596435547, 0.6133613586425781, 0.7316055297851562, 0.3377876281738281, 0.44718170166015625, 0.09638214111328125, 0.30843162536621094, 0.7054443359375, 31.748947143554688, 0.6989517211914062, 0.4725494384765625, 0.03771781921386719, 0.45426177978515625, 0.6700401306152344, 0.26962852478027344, 0.8041820526123047, 0.5848484039306641, 29.02355194091797, 0.42658233642578125, 0.87603759765625, 32.60664367675781, 0.8230094909667969, 32.51283264160156, 31.439815521240234, 33.17321014404297, 0.4019489288330078, 282.877197265625, 0.16029739379882812, 0.7302970886230469, 0.3062248229980469, 0.76983642578125, 28.97785186767578, 0.08752059936523438, 0.34435462951660156, 32.796897888183594, 0.6430988311767578, 0.4891490936279297, 0.6961650848388672, 0.5129661560058594, 0.6724262237548828, 32.5023193359375, 32.624977111816406, 281.164794921875, 0.15468502044677734, 0.14035987854003906, 0.1490039825439453, 0.7748489379882812, 0.1145172119140625, 0.2899951934814453, 0.6894454956054688, 0.4659404754638672, 0.07434844970703125, 0.09911346435546875, 0.2560863494873047, 0.5056600570678711, 0.05581474304199219, 0.4322032928466797, 33.335208892822266, 0.3250999450683594, 0.40213966369628906, 0.16247177124023438, 0.4669628143310547, 0.2752838134765625, 0.5111141204833984, 0.6367874145507812, 0.16576576232910156, 32.22901153564453, 0.5658645629882812, 0.3877391815185547, 0.3700370788574219, 0.2498016357421875, 0.11314201354980469, 0.11475563049316406, 0.1489105224609375, 0.17402076721191406, 0.1525421142578125, 32.248687744140625, 0.18702316284179688, 0.5408058166503906, 0.5879230499267578, 0.4452991485595703, 33.1566047668457, 0.8489599227905273, 0.6078357696533203, 0.6508674621582031, 0.360321044921875, 0.5436477661132812, 0.7140426635742188, 0.3865203857421875, 0.5141391754150391, 0.6266908645629883, 0.27081298828125, 0.2884082794189453, 0.7616767883300781, 0.3920783996582031, 33.50275421142578, 0.5230255126953125, 0.07245063781738281, 0.3829689025878906, 0.5325517654418945, 0.3399848937988281, 0.1235504150390625, 31.81051254272461, 0.3054656982421875, 0.3639354705810547, 31.81051254272461, 31.324270248413086, 0.08330535888671875, 0.43141937255859375, 31.292312622070312, 279.7727355957031, 0.3774909973144531, 0.26117897033691406, 0.7244377136230469, 0.13724136352539062, 0.4048728942871094, 0.5022983551025391, 32.59809112548828, 0.9745216369628906, 31.630775451660156, 0.5132942199707031, 0.4719867706298828, 0.8940238952636719], "mean_td_error": 13.48026180267334, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 9693.0, "diff_num_grad_updates_vs_sampler_policy": 9692.0}}, "num_env_steps_sampled": 39078, "num_env_steps_trained": 2481408, "num_agent_steps_sampled": 39078, "num_agent_steps_trained": 2481408, "last_target_update_ts": 39078, "num_target_updates": 9693}, "sampler_results": {"episode_reward_max": 192.6706669330597, "episode_reward_min": -188.9914527386427, "episode_reward_mean": -141.5072754085064, "episode_len_mean": 93.3, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.1753051429987, -182.44336192309856, 192.6706669330597, -168.0125610306859, -188.9914527386427, -180.85813285410404, -183.84055003523827, -173.8211519420147, -179.11471580713987, -176.4861895442009], "episode_lengths": [100, 100, 33, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1934070637671388, "mean_inference_ms": 2.404424186458223, "mean_action_processing_ms": 0.22896348977112724, "mean_env_wait_ms": 2.9971746488040996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 192.6706669330597, "episode_reward_min": -188.9914527386427, "episode_reward_mean": -141.5072754085064, "episode_len_mean": 93.3, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-174.1753051429987, -182.44336192309856, 192.6706669330597, -168.0125610306859, -188.9914527386427, -180.85813285410404, -183.84055003523827, -173.8211519420147, -179.11471580713987, -176.4861895442009], "episode_lengths": [100, 100, 33, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1934070637671388, "mean_inference_ms": 2.404424186458223, "mean_action_processing_ms": 0.22896348977112724, "mean_env_wait_ms": 2.9971746488040996, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 39078, "num_agent_steps_trained": 2481408, "num_env_steps_sampled": 39078, "num_env_steps_trained": 2481408, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 39078, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 39078, "timers": {"training_iteration_time_ms": 189.773, "load_time_ms": 0.339, "load_throughput": 754721.181, "learn_time_ms": 28.043, "learn_throughput": 9128.765, "synch_weights_time_ms": 5.995}, "counters": {"num_env_steps_sampled": 39078, "num_env_steps_trained": 2481408, "num_agent_steps_sampled": 39078, "num_agent_steps_trained": 2481408, "last_target_update_ts": 39078, "num_target_updates": 9693}, "done": false, "episodes_total": 400, "training_iteration": 39, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-01-14", "timestamp": 1675951274, "time_this_iter_s": 52.93822193145752, "time_total_s": 1581.4667999744415, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2df0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1581.4667999744415, "timesteps_since_restore": 0, "iterations_since_restore": 39, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.670833333333334, "ram_util_percent": 87.56944444444444}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.395040035247803, "actor_loss": 35.2781982421875, "critic_loss": 0.36083918809890747, "alpha_loss": -22.028289794921875, "alpha_value": 0.05085420608520508, "log_alpha_value": -2.978792428970337, "target_entropy": -5.0, "policy_t": -0.17199791967868805, "mean_q": -35.445194244384766, "max_q": -30.909507751464844, "min_q": -38.356658935546875}, "td_error": [1.0724048614501953, 0.4304065704345703, 0.4795646667480469, 0.21640968322753906, 0.09708213806152344, 0.5866012573242188, 0.5721473693847656, 33.449283599853516, 0.4099864959716797, 0.4530506134033203, 279.696044921875, 0.4909400939941406, 0.4162788391113281, 0.2035541534423828, 0.36655426025390625, 0.5906734466552734, 0.5576229095458984, 34.613216400146484, 0.3368206024169922, 0.10413742065429688, 0.5324687957763672, 0.4462013244628906, 0.2170886993408203, 0.4061126708984375, 0.13102149963378906, 0.5810680389404297, 0.6037540435791016, 0.1872386932373047, 0.48316383361816406, 0.3821086883544922, 0.6373271942138672, 0.3951282501220703, 0.10689353942871094, 0.9395084381103516, 0.18015480041503906, 0.5647716522216797, 0.5931911468505859, 0.7282485961914062, 0.3154888153076172, 34.948020935058594, 0.02838134765625, 0.125091552734375, 0.7413387298583984, 32.09769821166992, 0.3266277313232422, 0.35466575622558594, 0.5532798767089844, 0.11450386047363281, 0.5949211120605469, 0.06382179260253906, 0.27552032470703125, 0.49587440490722656, 0.301788330078125, 33.924842834472656, 34.980621337890625, 0.7075958251953125, 0.19293975830078125, 0.37259674072265625, 0.5564250946044922, 35.54710388183594, 0.8389492034912109, 31.54311752319336, 0.15821266174316406, 0.7171306610107422, 0.9543437957763672, 0.6603870391845703, 0.07149314880371094, 0.6032848358154297, 0.6797332763671875, 0.23850059509277344, 0.4845008850097656, 34.70067596435547, 0.0752105712890625, 0.17609405517578125, 0.6911125183105469, 0.8792228698730469, 35.897666931152344, 0.5674705505371094, 0.16642379760742188, 0.8805351257324219, 0.6235599517822266, 0.4496040344238281, 0.385833740234375, 0.8639373779296875, 0.6572589874267578, 0.16484832763671875, 0.10680007934570312, 34.70067596435547, 0.5501251220703125, 0.33167266845703125, 0.1981334686279297, 0.6453742980957031, 0.22199440002441406, 0.5550251007080078, 0.4757404327392578, 0.9848384857177734, 0.2756843566894531, 0.7745075225830078, 0.6945171356201172, 0.4345073699951172, 0.31366539001464844, 0.36302757263183594, 0.21713829040527344, 0.32843017578125, 0.29288482666015625, 0.25346946716308594, 0.7115459442138672, 0.5379276275634766, 0.27895355224609375, 0.8282680511474609, 0.6753749847412109, 0.4234962463378906, 0.25049400329589844, 1.063751220703125, 0.48431968688964844, 0.27779197692871094, 0.2230243682861328, 0.3928108215332031, 1.1652412414550781, 0.06203651428222656, 34.54487609863281, 0.32390403747558594, 0.4578685760498047, 0.4643821716308594, 0.4333782196044922, 0.33625030517578125, 0.6699733734130859, 0.3324604034423828, 33.846168518066406, 35.890220642089844, 0.5710525512695312, 0.7156524658203125, 0.5043010711669922, 0.43170928955078125, 31.666215896606445, 0.5947284698486328, 0.07028007507324219, 0.3376045227050781, 0.441192626953125, 0.2647571563720703, 0.18668365478515625, 0.6052799224853516, 0.5967788696289062, 0.2990455627441406, 0.2721271514892578, 0.24692153930664062, 0.4524192810058594, 0.5113277435302734, 30.892696380615234, 0.3750419616699219, 0.35269737243652344, 0.1656208038330078, 0.6580581665039062, 33.77204132080078, 0.10227012634277344, 0.11738777160644531, 36.09619903564453, 0.19133377075195312, 0.7151546478271484, 34.154029846191406, 0.3004570007324219, 0.28159141540527344, 0.1363201141357422, 0.12055778503417969, 0.7610282897949219, 0.20786666870117188, 0.6535739898681641, 0.5719261169433594, 0.6834983825683594, 0.33839988708496094, 0.35749053955078125, 0.45541954040527344, 0.5069122314453125, 0.3960456848144531, 0.11545753479003906, 0.6879806518554688, 0.3856163024902344, 0.4218158721923828, 33.09505081176758, 0.5237350463867188, 0.03154945373535156, 0.7558479309082031, 0.4988880157470703, 0.05701255798339844, 0.47906494140625, 0.49664306640625, 0.13275146484375, 0.23427581787109375, 0.13993263244628906, 0.8891315460205078, 0.5786075592041016, 0.7292423248291016, 0.023675918579101562, 0.4430274963378906, 0.5511531829833984, 0.4682903289794922, 0.06107902526855469, 0.5743808746337891, 1.1210060119628906, 0.8540287017822266, 0.2809886932373047, 0.6093482971191406, 0.6570949554443359, 31.958393096923828, 0.11742401123046875, 0.5655899047851562, 0.18987274169921875, 0.5872287750244141, 33.279808044433594, 0.1576862335205078, 34.509132385253906, 0.852569580078125, 0.5722179412841797, 0.270294189453125, 0.3246002197265625, 284.06024169921875, 0.30857276916503906, 0.5655479431152344, 0.5806951522827148, 0.40764617919921875, 0.5445022583007812, 0.7270412445068359, 0.5176277160644531, 32.202484130859375, 0.7050075531005859, 0.5158824920654297, 0.5693588256835938, 0.07232475280761719, 0.25925636291503906, 0.44687461853027344, 0.7298717498779297, 0.15954208374023438, 0.261474609375, 0.3737964630126953, 0.34767913818359375, 35.805274963378906, 32.425453186035156, 0.5570869445800781, 0.1363658905029297, 0.9547958374023438, 0.4490184783935547, 0.6677322387695312, 35.19574737548828, 0.5232772827148438, 0.31080055236816406, 35.19574737548828, 0.7554931640625, 0.6342391967773438, 0.5726509094238281, 0.15125465393066406, 0.39495277404785156, 0.2802104949951172, 0.5187549591064453, 0.6282215118408203, 0.1429271697998047, 0.5961437225341797], "mean_td_error": 6.308843612670898, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 10027.0, "diff_num_grad_updates_vs_sampler_policy": 10026.0}}, "num_env_steps_sampled": 40080, "num_env_steps_trained": 2566912, "num_agent_steps_sampled": 40080, "num_agent_steps_trained": 2566912, "last_target_update_ts": 40080, "num_target_updates": 10027}, "sampler_results": {"episode_reward_max": -168.3656321167946, "episode_reward_min": -184.26397243887186, "episode_reward_mean": -177.43997548686133, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.22941114008427, -182.0724149569869, -174.7681783437729, -168.3656321167946, -180.22953482717276, -171.86355243623257, -174.27145668119192, -179.89562644064426, -184.26397243887186], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1817531201682596, "mean_inference_ms": 2.389162917891725, "mean_action_processing_ms": 0.22715000449232636, "mean_env_wait_ms": 2.9810903921927463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -168.3656321167946, "episode_reward_min": -184.26397243887186, "episode_reward_mean": -177.43997548686133, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-181.22941114008427, -182.0724149569869, -174.7681783437729, -168.3656321167946, -180.22953482717276, -171.86355243623257, -174.27145668119192, -179.89562644064426, -184.26397243887186], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1817531201682596, "mean_inference_ms": 2.389162917891725, "mean_action_processing_ms": 0.22715000449232636, "mean_env_wait_ms": 2.9810903921927463, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 40080, "num_agent_steps_trained": 2566912, "num_env_steps_sampled": 40080, "num_env_steps_trained": 2566912, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 40080, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 40080, "timers": {"training_iteration_time_ms": 156.589, "load_time_ms": 0.292, "load_throughput": 876810.243, "learn_time_ms": 25.563, "learn_throughput": 10014.315, "synch_weights_time_ms": 5.373}, "counters": {"num_env_steps_sampled": 40080, "num_env_steps_trained": 2566912, "num_agent_steps_sampled": 40080, "num_agent_steps_trained": 2566912, "last_target_update_ts": 40080, "num_target_updates": 10027}, "done": false, "episodes_total": 409, "training_iteration": 40, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-02-07", "timestamp": 1675951327, "time_this_iter_s": 53.56896924972534, "time_total_s": 1635.0357692241669, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105804c0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a94c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1635.0357692241669, "timesteps_since_restore": 0, "iterations_since_restore": 40, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.58243243243243, "ram_util_percent": 87.7445945945946}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.30413818359375, "actor_loss": 37.687068939208984, "critic_loss": 0.45127594470977783, "alpha_loss": -22.46035385131836, "alpha_value": 0.04618881270289421, "log_alpha_value": -3.0750176906585693, "target_entropy": -5.0, "policy_t": -0.1779249608516693, "mean_q": -37.806175231933594, "max_q": -33.972938537597656, "min_q": -40.62430953979492}, "td_error": [0.2545337677001953, 0.4282951354980469, 35.44929885864258, 0.23957443237304688, 0.5330963134765625, 0.3423748016357422, 35.79069137573242, 0.08000946044921875, 0.8243236541748047, 0.4461688995361328, 0.24110031127929688, 37.290245056152344, 0.5998001098632812, 0.1390552520751953, 0.029844284057617188, 0.38474082946777344, 0.17645835876464844, 0.38791656494140625, 0.5948638916015625, 0.21553993225097656, 0.3877449035644531, 285.04803466796875, 0.3151054382324219, 36.20494079589844, 0.3819141387939453, 0.2113361358642578, 0.6449604034423828, 0.339996337890625, 0.5249099731445312, 0.1647624969482422, 33.81693649291992, 0.08634376525878906, 0.32596588134765625, 35.51317596435547, 0.3429145812988281, 35.00503921508789, 0.178680419921875, 36.15885925292969, 0.5387306213378906, 0.4516010284423828, 36.75578689575195, 0.606475830078125, 0.25690269470214844, 0.4147014617919922, 0.39032554626464844, 0.2606239318847656, 35.67350769042969, 0.41925811767578125, 0.429931640625, 0.14901351928710938, 0.7448863983154297, 34.189674377441406, 0.48339271545410156, 0.8609275817871094, 285.44451904296875, 0.4391651153564453, 0.10721206665039062, 0.5159530639648438, 0.36736297607421875, 0.30655670166015625, 0.4912586212158203, 0.18467140197753906, 0.4329509735107422, 0.6356849670410156, 0.3154449462890625, 0.35420799255371094, 0.2778453826904297, 0.13585281372070312, 0.6757278442382812, 0.3649711608886719, 35.85224151611328, 36.91570281982422, 0.6497974395751953, 0.12644004821777344, 34.189674377441406, 0.4914722442626953, 0.2813434600830078, 0.24699783325195312, 0.4295310974121094, 0.318634033203125, 0.16391372680664062, 0.31831932067871094, 0.4328727722167969, 37.47772979736328, 0.2012481689453125, 0.8186073303222656, 0.5646076202392578, 36.70362854003906, 0.4719066619873047, 0.35787391662597656, 0.6290206909179688, 0.1658935546875, 0.6084156036376953, 0.08833122253417969, 37.896263122558594, 0.7283535003662109, 0.7918434143066406, 0.14115524291992188, 0.5196304321289062, 0.5630664825439453, 0.28614044189453125, 0.17803955078125, 0.16347122192382812, 0.08940887451171875, 0.42705535888671875, 0.33422088623046875, 0.40824317932128906, 32.986358642578125, 0.7230644226074219, 0.3260040283203125, 0.3557014465332031, 0.4113006591796875, 0.31777000427246094, 35.48230743408203, 0.4268474578857422, 0.4618263244628906, 0.2061634063720703, 0.4804573059082031, 33.4925537109375, 0.5651397705078125, 35.123268127441406, 0.6088409423828125, 0.34523773193359375, 0.5386009216308594, 35.88978958129883, 0.08698844909667969, 0.18715858459472656, 0.47827911376953125, 0.4315376281738281, 0.5041770935058594, 0.04916954040527344, 0.17330169677734375, 0.2722759246826172, 0.41246795654296875, 0.06952285766601562, 0.3850975036621094, 0.3528327941894531, 0.6292552947998047, 0.1671466827392578, 0.18695831298828125, 0.44376182556152344, 36.10779571533203, 0.42299842834472656, 0.2724761962890625, 0.15726280212402344, 0.6215152740478516, 0.5844211578369141, 0.6037845611572266, 1.2051200866699219, 35.169158935546875, 0.3096446990966797, 36.43911361694336, 0.3102607727050781, 0.5985698699951172, 0.6802120208740234, 0.3865680694580078, 0.3302574157714844, 0.6035938262939453, 0.50115966796875, 0.4836864471435547, 0.46780967712402344, 0.37136268615722656, 0.5964202880859375, 32.716705322265625, 37.3280143737793, 0.4058856964111328, 0.4840202331542969, 0.07688713073730469, 0.4163494110107422, 0.5657978057861328, 0.22839736938476562, 0.33426666259765625, 0.5182456970214844, 0.49318885803222656, 0.31688499450683594, 0.3956642150878906, 35.45507049560547, 0.3831462860107422, 0.4084930419921875, 0.36988258361816406, 0.1759967803955078, 37.83998107910156, 0.40627098083496094, 0.21440696716308594, 0.8129596710205078, 0.0648956298828125, 0.2260417938232422, 0.4319648742675781, 0.5626583099365234, 0.5033473968505859, 0.08289337158203125, 0.19224929809570312, 0.4197063446044922, 0.5851020812988281, 0.354644775390625, 0.49591636657714844, 0.3749275207519531, 0.337493896484375, 0.44866943359375, 0.8715095520019531, 0.3625984191894531, 0.4259681701660156, 0.5010013580322266, 0.3754768371582031, 0.6990070343017578, 0.2071552276611328, 37.995750427246094, 0.7602691650390625, 36.497989654541016, 0.5372047424316406, 0.19198036193847656, 0.3161277770996094, 34.816627502441406, 0.2492961883544922, 0.33794403076171875, 0.17441749572753906, 0.3607349395751953, 37.80785369873047, 0.5193405151367188, 0.5735206604003906, 0.14807701110839844, 0.473663330078125, 0.6169853210449219, 0.08260345458984375, 0.2827949523925781, 0.41665077209472656, 0.4481201171875, 0.5244598388671875, 0.42154693603515625, 0.056362152099609375, 0.03185272216796875, 36.51954650878906, 0.2649955749511719, 0.5640583038330078, 0.47843360900878906, 0.6497573852539062, 0.3900260925292969, 0.2138385772705078, 0.16468429565429688, 0.3942756652832031, 0.09568977355957031, 0.3552265167236328, 0.4421844482421875, 36.81729507446289, 0.11456298828125, 0.39273643493652344, 0.42559242248535156, 0.11341094970703125, 0.8848838806152344, 0.046268463134765625, 0.3174152374267578, 0.3770408630371094, 0.07407569885253906, 37.47772979736328, 37.51104736328125, 0.42099761962890625], "mean_td_error": 7.752413749694824, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 10361.0, "diff_num_grad_updates_vs_sampler_policy": 10360.0}}, "num_env_steps_sampled": 41082, "num_env_steps_trained": 2652416, "num_agent_steps_sampled": 41082, "num_agent_steps_trained": 2652416, "last_target_update_ts": 41082, "num_target_updates": 10361}, "sampler_results": {"episode_reward_max": -163.83987384289503, "episode_reward_min": -187.10371681302786, "episode_reward_mean": -178.45808702955642, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-178.34522638469934, -183.75319823622704, -185.9970791861415, -177.59257932007313, -187.10371681302786, -185.4290682822466, -182.764564730227, -173.81865569204092, -179.22336603701115, -168.72168152034283, -163.83987384289503, -174.90803430974483], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.180918489158828, "mean_inference_ms": 2.3901687191251395, "mean_action_processing_ms": 0.22722392588821191, "mean_env_wait_ms": 2.9826144805365966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -163.83987384289503, "episode_reward_min": -187.10371681302786, "episode_reward_mean": -178.45808702955642, "episode_len_mean": 100.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-178.34522638469934, -183.75319823622704, -185.9970791861415, -177.59257932007313, -187.10371681302786, -185.4290682822466, -182.764564730227, -173.81865569204092, -179.22336603701115, -168.72168152034283, -163.83987384289503, -174.90803430974483], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.180918489158828, "mean_inference_ms": 2.3901687191251395, "mean_action_processing_ms": 0.22722392588821191, "mean_env_wait_ms": 2.9826144805365966, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 41082, "num_agent_steps_trained": 2652416, "num_env_steps_sampled": 41082, "num_env_steps_trained": 2652416, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 41082, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 41082, "timers": {"training_iteration_time_ms": 177.233, "load_time_ms": 0.336, "load_throughput": 761789.162, "learn_time_ms": 27.545, "learn_throughput": 9293.843, "synch_weights_time_ms": 6.892}, "counters": {"num_env_steps_sampled": 41082, "num_env_steps_trained": 2652416, "num_agent_steps_sampled": 41082, "num_agent_steps_trained": 2652416, "last_target_update_ts": 41082, "num_target_updates": 10361}, "done": false, "episodes_total": 421, "training_iteration": 41, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-03-01", "timestamp": 1675951381, "time_this_iter_s": 53.288047552108765, "time_total_s": 1688.3238167762756, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093be0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a91f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1688.3238167762756, "timesteps_since_restore": 0, "iterations_since_restore": 41, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.98918918918919, "ram_util_percent": 88.09864864864863}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 7.111858367919922, "actor_loss": 39.30339050292969, "critic_loss": 0.8070809245109558, "alpha_loss": -22.550003051757812, "alpha_value": 0.041971661150455475, "log_alpha_value": -3.1707606315612793, "target_entropy": -5.0, "policy_t": -0.1860651671886444, "mean_q": -39.400367736816406, "max_q": -34.85597610473633, "min_q": -42.22355270385742}, "td_error": [38.616783142089844, 0.8600654602050781, 0.2639751434326172, 0.43552398681640625, 36.781272888183594, 0.390411376953125, 36.64750671386719, 0.4881725311279297, 36.018775939941406, 0.2257862091064453, 0.16774559020996094, 0.42433929443359375, 0.3503875732421875, 0.2902336120605469, 39.16228103637695, 0.5539169311523438, 0.4880104064941406, 0.3669719696044922, 0.2229290008544922, 37.983306884765625, 38.616783142089844, 0.3512992858886719, 0.6111660003662109, 0.5312213897705078, 0.7832126617431641, 0.17981719970703125, 40.6487922668457, 0.404296875, 0.3149375915527344, 0.6545219421386719, 0.6077461242675781, 0.4889984130859375, 0.4869956970214844, 0.9290142059326172, 0.7267818450927734, 0.3810997009277344, 0.4803485870361328, 0.4157447814941406, 0.5130958557128906, 0.6012496948242188, 0.6215724945068359, 36.784645080566406, 36.39723205566406, 0.2724132537841797, 0.7419033050537109, 0.09591293334960938, 0.11871719360351562, 39.38042449951172, 0.5904808044433594, 0.187896728515625, 39.16228103637695, 0.36884117126464844, 37.70201873779297, 0.04339599609375, 0.2585735321044922, 0.11277389526367188, 0.7488727569580078, 0.47740745544433594, 0.37365150451660156, 0.07088088989257812, 38.854583740234375, 0.8072319030761719, 0.23102188110351562, 0.4495201110839844, 0.4910240173339844, 0.6073741912841797, 39.87749481201172, 0.5075454711914062, 0.5957660675048828, 288.239013671875, 0.13648033142089844, 0.38439369201660156, 38.82838439941406, 0.43137550354003906, 0.337799072265625, 0.4162254333496094, 0.1342620849609375, 0.5326404571533203, 34.75924301147461, 0.12879180908203125, 0.06065559387207031, 0.4764671325683594, 0.5968723297119141, 37.2962760925293, 0.21370315551757812, 0.6496181488037109, 0.205047607421875, 0.1297168731689453, 0.5515289306640625, 0.15215110778808594, 0.09474945068359375, 0.36279296875, 0.9535675048828125, 0.08291244506835938, 0.46434783935546875, 0.5152053833007812, 34.68276596069336, 0.4616050720214844, 0.2220897674560547, 0.08685684204101562, 0.4637603759765625, 0.5093765258789062, 0.22806358337402344, 0.4910125732421875, 0.5875759124755859, 0.5858573913574219, 38.86609649658203, 39.636383056640625, 288.97467041015625, 0.6606769561767578, 0.4329204559326172, 0.4038658142089844, 0.08510971069335938, 283.650390625, 35.04999542236328, 0.47588157653808594, 0.39006805419921875, 0.3578453063964844, 0.3586597442626953, 0.2137775421142578, 38.81689453125, 0.5832023620605469, 0.2775382995605469, 0.25788116455078125, 37.63802719116211, 39.339332580566406, 0.6892204284667969, 0.33536338806152344, 0.6617431640625, 39.15821075439453, 0.31020355224609375, 0.4609870910644531, 38.720054626464844, 38.01153564453125, 0.10025787353515625, 285.83673095703125, 0.6059284210205078, 0.6659317016601562, 0.06441879272460938, 0.4823951721191406, 0.061248779296875, 0.2786998748779297, 0.6830253601074219, 0.9500045776367188, 35.13412857055664, 0.15361595153808594, 36.451026916503906, 0.1950244903564453, 0.6863231658935547, 0.4639167785644531, 0.15324783325195312, 0.9523754119873047, 0.3480548858642578, 39.042762756347656, 0.6988487243652344, 39.382850646972656, 0.34570884704589844, 0.5056343078613281, 0.18682098388671875, 0.6847038269042969, 0.5128612518310547, 0.7473354339599609, 0.07701492309570312, 0.6328983306884766, 0.5360546112060547, 0.24234962463378906, 35.226829528808594, 37.6025390625, 0.29094505310058594, 0.4503803253173828, 0.5490341186523438, 38.86457443237305, 0.04289054870605469, 0.773162841796875, 0.35307884216308594, 0.2844734191894531, 0.3158683776855469, 0.30584716796875, 0.5071773529052734, 0.3878669738769531, 0.36905670166015625, 287.10546875, 1.1074295043945312, 0.7563953399658203, 0.5938606262207031, 0.3891773223876953, 0.5668811798095703, 0.5284919738769531, 0.32552337646484375, 0.48076629638671875, 0.6727180480957031, 0.47251129150390625, 0.5923061370849609, 0.5096435546875, 0.5938072204589844, 0.7018146514892578, 0.13469886779785156, 0.6180877685546875, 0.2779197692871094, 0.15874481201171875, 38.034542083740234, 0.252471923828125, 0.7592220306396484, 0.2350635528564453, 0.5957260131835938, 0.3692588806152344, 0.7400283813476562, 0.7877731323242188, 0.2105083465576172, 0.6158161163330078, 38.35283279418945, 0.4665088653564453, 35.13412857055664, 0.41027259826660156, 34.115509033203125, 0.32738494873046875, 0.7357769012451172, 0.29612159729003906, 37.424503326416016, 0.22032546997070312, 0.09751319885253906, 0.27288818359375, 0.35985565185546875, 39.058380126953125, 34.50729751586914, 0.13227272033691406, 0.5791702270507812, 0.4225730895996094, 0.5487518310546875, 0.09317588806152344, 0.47936058044433594, 0.5184669494628906, 0.191802978515625, 0.6199359893798828, 0.3040618896484375, 287.6824951171875, 0.6483173370361328, 0.37830352783203125, 0.09320831298828125, 0.2987194061279297, 35.31959915161133, 0.833709716796875, 0.5259170532226562, 0.9919509887695312, 286.791015625, 0.6866416931152344, 0.023496627807617188, 0.3568382263183594, 286.791015625, 38.89405822753906, 0.21494293212890625, 0.3354930877685547, 0.8620357513427734, 0.3626728057861328, 0.3904533386230469, 0.3417835235595703], "mean_td_error": 15.775511741638184, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 10695.0, "diff_num_grad_updates_vs_sampler_policy": 10694.0}}, "num_env_steps_sampled": 42084, "num_env_steps_trained": 2737920, "num_agent_steps_sampled": 42084, "num_agent_steps_trained": 2737920, "last_target_update_ts": 42084, "num_target_updates": 10695}, "sampler_results": {"episode_reward_max": 180.91379027813673, "episode_reward_min": -187.11290511488914, "episode_reward_mean": -116.10810863152146, "episode_len_mean": 93.2, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-180.63632839918137, 180.91379027813673, -182.74909734725952, -186.68236726522446, -166.189367569983, -184.58452029526234, 96.62216354161501, -178.2939925789833, -172.36846156418324, -187.11290511488914], "episode_lengths": [100, 41, 100, 100, 100, 100, 91, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.191112938895264, "mean_inference_ms": 2.4060518762511136, "mean_action_processing_ms": 0.22949094620746185, "mean_env_wait_ms": 2.999420322026927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 180.91379027813673, "episode_reward_min": -187.11290511488914, "episode_reward_mean": -116.10810863152146, "episode_len_mean": 93.2, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-180.63632839918137, 180.91379027813673, -182.74909734725952, -186.68236726522446, -166.189367569983, -184.58452029526234, 96.62216354161501, -178.2939925789833, -172.36846156418324, -187.11290511488914], "episode_lengths": [100, 41, 100, 100, 100, 100, 91, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.191112938895264, "mean_inference_ms": 2.4060518762511136, "mean_action_processing_ms": 0.22949094620746185, "mean_env_wait_ms": 2.999420322026927, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 42084, "num_agent_steps_trained": 2737920, "num_env_steps_sampled": 42084, "num_env_steps_trained": 2737920, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 42084, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 42084, "timers": {"training_iteration_time_ms": 156.819, "load_time_ms": 0.297, "load_throughput": 862720.411, "learn_time_ms": 25.618, "learn_throughput": 9993.037, "synch_weights_time_ms": 5.867}, "counters": {"num_env_steps_sampled": 42084, "num_env_steps_trained": 2737920, "num_agent_steps_sampled": 42084, "num_agent_steps_trained": 2737920, "last_target_update_ts": 42084, "num_target_updates": 10695}, "done": false, "episodes_total": 431, "training_iteration": 42, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-03-54", "timestamp": 1675951434, "time_this_iter_s": 53.3751220703125, "time_total_s": 1741.6989388465881, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a2e0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef4c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1741.6989388465881, "timesteps_since_restore": 0, "iterations_since_restore": 42, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.37534246575343, "ram_util_percent": 88.15890410958905}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.679849624633789, "actor_loss": 41.478271484375, "critic_loss": 0.6610358953475952, "alpha_loss": -21.80742645263672, "alpha_value": 0.038209982216358185, "log_alpha_value": -3.2646584510803223, "target_entropy": -5.0, "policy_t": -0.19459569454193115, "mean_q": -41.569908142089844, "max_q": -37.261329650878906, "min_q": -44.647430419921875}, "td_error": [0.8331661224365234, 0.29334068298339844, 1.1130657196044922, 0.2368793487548828, 0.6719570159912109, 0.2057342529296875, 0.5994586944580078, 0.02744293212890625, 0.7233047485351562, 0.09349441528320312, 1.0248222351074219, 0.6765232086181641, 0.5289459228515625, 0.7302684783935547, 0.6561012268066406, 0.2803783416748047, 0.1352062225341797, 0.11095237731933594, 0.11496925354003906, 0.1448993682861328, 0.8723716735839844, 0.44916725158691406, 0.3643951416015625, 0.06522750854492188, 0.3927726745605469, 0.4375038146972656, 0.03519248962402344, 0.11520004272460938, 0.2528820037841797, 0.3464813232421875, 39.95182418823242, 0.3476715087890625, 0.3426780700683594, 0.12570953369140625, 40.841392517089844, 0.4645824432373047, 0.6371059417724609, 0.16074752807617188, 0.5995273590087891, 0.3048095703125, 38.981178283691406, 0.6668148040771484, 0.5169506072998047, 40.93304443359375, 0.5173320770263672, 0.2205638885498047, 0.38125038146972656, 37.673892974853516, 0.3430042266845703, 0.9328746795654297, 0.2709503173828125, 0.6007137298583984, 0.29193878173828125, 0.7747631072998047, 0.5563945770263672, 0.6112289428710938, 0.26422119140625, 0.38140106201171875, 0.4028301239013672, 0.15320205688476562, 0.15523529052734375, 0.5775566101074219, 0.9707126617431641, 0.20210838317871094, 0.11623764038085938, 0.5018386840820312, 38.62702560424805, 0.6472873687744141, 0.22977256774902344, 0.15171432495117188, 289.6005859375, 0.35471153259277344, 0.49320411682128906, 0.5892753601074219, 0.2800922393798828, 39.81447219848633, 39.7315673828125, 0.09859848022460938, 0.5955562591552734, 39.331729888916016, 36.75581359863281, 0.5707798004150391, 0.2071247100830078, 0.4716987609863281, 0.31620216369628906, 35.47382736206055, 0.6494541168212891, 39.82072067260742, 0.4430217742919922, 0.5913200378417969, 0.2829551696777344, 0.1457691192626953, 0.4540519714355469, 0.28418540954589844, 0.08622169494628906, 0.43084144592285156, 0.5994396209716797, 0.2401885986328125, 0.11960029602050781, 0.48645782470703125, 289.0848388671875, 0.5600643157958984, 0.17320632934570312, 0.7496223449707031, 0.41088294982910156, 36.541831970214844, 39.1093635559082, 0.5300483703613281, 0.4397430419921875, 0.41419029235839844, 0.19222450256347656, 0.3285846710205078, 0.10953140258789062, 0.05943870544433594, 0.6486034393310547, 40.90923309326172, 0.4963092803955078, 1.1925888061523438, 0.5729942321777344, 0.3961925506591797, 0.34673500061035156, 0.41048622131347656, 0.5113410949707031, 0.6314620971679688, 0.4685192108154297, 0.4963703155517578, 0.5663127899169922, 0.765716552734375, 0.4379310607910156, 0.5776729583740234, 0.5639991760253906, 38.205322265625, 0.7990989685058594, 41.9715576171875, 36.835655212402344, 0.42572021484375, 290.20587158203125, 40.625144958496094, 38.31687927246094, 0.5255393981933594, 0.26842308044433594, 36.17897033691406, 40.7891845703125, 0.5202846527099609, 0.06763648986816406, 0.6097183227539062, 0.6332187652587891, 0.2367115020751953, 40.46315002441406, 0.9704418182373047, 0.46050071716308594, 0.3484363555908203, 40.0908088684082, 0.26197242736816406, 39.105560302734375, 0.2670764923095703, 0.38233184814453125, 0.33194732666015625, 0.18834686279296875, 41.03522491455078, 0.5115184783935547, 42.36676025390625, 1.0427799224853516, 0.24749755859375, 0.2861785888671875, 0.3367500305175781, 0.3047904968261719, 0.5112285614013672, 0.24747657775878906, 0.39904212951660156, 0.15236854553222656, 0.3109416961669922, 0.6315689086914062, 0.6355361938476562, 0.5056324005126953, 0.15205955505371094, 0.6608905792236328, 0.43823814392089844, 0.9565868377685547, 0.22440719604492188, 0.577545166015625, 0.5808048248291016, 0.5714950561523438, 0.3533306121826172, 0.5349712371826172, 0.7095394134521484, 0.3747882843017578, 0.27892112731933594, 41.16428756713867, 0.10718727111816406, 0.2469329833984375, 0.2432727813720703, 0.2132549285888672, 289.3779602050781, 0.4044761657714844, 0.8345260620117188, 0.3637371063232422, 0.33582496643066406, 0.6677932739257812, 0.06615829467773438, 0.20698928833007812, 0.17505455017089844, 0.6123714447021484, 0.4690284729003906, 0.11910438537597656, 39.229637145996094, 290.95501708984375, 0.8975734710693359, 0.2079181671142578, 0.3806743621826172, 0.047817230224609375, 0.2710895538330078, 288.76959228515625, 0.276763916015625, 40.78297424316406, 0.11326026916503906, 0.5598392486572266, 0.327423095703125, 0.76947021484375, 0.6610145568847656, 0.5700664520263672, 0.40051841735839844, 0.42832374572753906, 39.339561462402344, 0.3242015838623047, 0.5529346466064453, 0.29828453063964844, 0.20402145385742188, 0.7126979827880859, 0.6083030700683594, 40.0908088684082, 0.3466663360595703, 0.6414833068847656, 0.3273143768310547, 287.75457763671875, 0.4859809875488281, 0.9521350860595703, 0.13354110717773438, 0.06621932983398438, 0.5030994415283203, 0.6120967864990234, 0.7729263305664062, 0.010488510131835938, 0.5999279022216797, 0.5372676849365234, 0.05061531066894531, 0.3324909210205078, 0.18138504028320312, 0.4668388366699219, 1.079080581665039, 0.3424224853515625, 0.4728851318359375, 0.6297359466552734, 1.1293163299560547, 0.4804210662841797, 0.3061199188232422], "mean_td_error": 13.205488204956055, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 11029.0, "diff_num_grad_updates_vs_sampler_policy": 11028.0}}, "num_env_steps_sampled": 43086, "num_env_steps_trained": 2823424, "num_agent_steps_sampled": 43086, "num_agent_steps_trained": 2823424, "last_target_update_ts": 43086, "num_target_updates": 11029}, "sampler_results": {"episode_reward_max": -168.88876070827246, "episode_reward_min": -187.7259635925293, "episode_reward_mean": -177.95538324366012, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-172.41410469263792, -187.7259635925293, -185.0848912000656, -169.18732691556215, -178.81310380995274, -178.75061001628637, -181.12918283045292, -179.60450542718172, -168.88876070827246], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1787363645656328, "mean_inference_ms": 2.3891664867670697, "mean_action_processing_ms": 0.2274294961239977, "mean_env_wait_ms": 2.9815346242579803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -168.88876070827246, "episode_reward_min": -187.7259635925293, "episode_reward_mean": -177.95538324366012, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-172.41410469263792, -187.7259635925293, -185.0848912000656, -169.18732691556215, -178.81310380995274, -178.75061001628637, -181.12918283045292, -179.60450542718172, -168.88876070827246], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1787363645656328, "mean_inference_ms": 2.3891664867670697, "mean_action_processing_ms": 0.2274294961239977, "mean_env_wait_ms": 2.9815346242579803, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 43086, "num_agent_steps_trained": 2823424, "num_env_steps_sampled": 43086, "num_env_steps_trained": 2823424, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 43086, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 43086, "timers": {"training_iteration_time_ms": 158.221, "load_time_ms": 0.294, "load_throughput": 869849.177, "learn_time_ms": 25.543, "learn_throughput": 10022.344, "synch_weights_time_ms": 7.087}, "counters": {"num_env_steps_sampled": 43086, "num_env_steps_trained": 2823424, "num_agent_steps_sampled": 43086, "num_agent_steps_trained": 2823424, "last_target_update_ts": 43086, "num_target_updates": 11029}, "done": false, "episodes_total": 440, "training_iteration": 43, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-04-47", "timestamp": 1675951487, "time_this_iter_s": 52.78848600387573, "time_total_s": 1794.4874248504639, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be58ac0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a9160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1794.4874248504639, "timesteps_since_restore": 0, "iterations_since_restore": 43, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.00000000000001, "ram_util_percent": 88.40684931506848}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.404277801513672, "actor_loss": 43.59561538696289, "critic_loss": 0.7264860272407532, "alpha_loss": -21.50908851623535, "alpha_value": 0.03478565067052841, "log_alpha_value": -3.3585503101348877, "target_entropy": -5.0, "policy_t": -0.21457460522651672, "mean_q": -43.7049674987793, "max_q": -39.64472961425781, "min_q": -46.26543045043945}, "td_error": [0.1428852081298828, 0.5631065368652344, 0.3098869323730469, 0.16379547119140625, 0.29334068298339844, 0.5629749298095703, 0.33867835998535156, 0.5318984985351562, 0.4128379821777344, 0.1404438018798828, 0.24869155883789062, 0.33498573303222656, 0.3831367492675781, 0.6912460327148438, 0.15459060668945312, 0.5522785186767578, 0.19323348999023438, 0.2442779541015625, 0.5039081573486328, 0.3652324676513672, 0.6113338470458984, 42.128849029541016, 0.57958984375, 0.6624164581298828, 0.6928291320800781, 0.40773963928222656, 0.6679058074951172, 42.57966613769531, 0.5626811981201172, 0.71820068359375, 0.43228912353515625, 290.846923828125, 0.12260055541992188, 0.0491790771484375, 43.817142486572266, 0.27663421630859375, 0.5054836273193359, 0.12361526489257812, 42.62224578857422, 0.47612953186035156, 0.2668895721435547, 0.5448818206787109, 44.69085693359375, 0.2566184997558594, 0.22072792053222656, 0.43570709228515625, 0.3760662078857422, 43.135215759277344, 0.4722099304199219, 0.2752723693847656, 0.15756607055664062, 0.4185676574707031, 44.410621643066406, 0.6704330444335938, 43.414329528808594, 0.1647491455078125, 0.2274303436279297, 0.45090484619140625, 0.5669937133789062, 0.4908180236816406, 0.25121116638183594, 0.6434688568115234, 0.8181476593017578, 0.5501136779785156, 1.1273689270019531, 0.29000282287597656, 39.058834075927734, 42.56810760498047, 0.7184715270996094, 42.815345764160156, 0.17489051818847656, 0.19034767150878906, 0.12428665161132812, 40.89715576171875, 0.1295337677001953, 0.8067092895507812, 0.2677726745605469, 0.3390769958496094, 0.18757057189941406, 42.68164825439453, 0.10468292236328125, 0.4193096160888672, 0.11190223693847656, 41.56812286376953, 0.4581737518310547, 0.28680992126464844, 42.67413330078125, 0.6055831909179688, 0.6977901458740234, 0.30454254150390625, 0.3749046325683594, 0.3481121063232422, 0.4134635925292969, 0.13948440551757812, 44.142433166503906, 1.0036334991455078, 0.7056503295898438, 42.31763458251953, 0.6075992584228516, 0.1980743408203125, 41.703086853027344, 0.6372623443603516, 0.4723186492919922, 0.5136299133300781, 43.8057975769043, 0.2470684051513672, 0.5390796661376953, 0.35302162170410156, 0.6698760986328125, 0.3609180450439453, 0.33152198791503906, 43.04019546508789, 0.5188560485839844, 0.5846691131591797, 0.8745174407958984, 291.34552001953125, 0.16866683959960938, 0.17327499389648438, 0.4435462951660156, 42.891876220703125, 0.3873863220214844, 0.06378364562988281, 41.49786376953125, 43.90435028076172, 291.62738037109375, 0.19899368286132812, 0.09181594848632812, 0.2180309295654297, 0.1536712646484375, 0.8544712066650391, 0.4836082458496094, 0.2941703796386719, 42.56810760498047, 0.2846221923828125, 41.1199836730957, 0.4741935729980469, 0.7175827026367188, 0.07300376892089844, 44.410621643066406, 0.2864036560058594, 0.17810440063476562, 0.7115077972412109, 0.39051246643066406, 0.20375823974609375, 0.4885578155517578, 0.42513084411621094, 0.8172264099121094, 41.85808563232422, 0.3887214660644531, 39.82442855834961, 39.913368225097656, 0.4608135223388672, 0.08718681335449219, 0.3109931945800781, 0.23876571655273438, 0.4074993133544922, 41.67424011230469, 0.14804840087890625, 0.23189544677734375, 40.44984436035156, 0.5339031219482422, 0.5255947113037109, 39.93159484863281, 0.27869224548339844, 0.2925281524658203, 42.14750289916992, 0.6774463653564453, 0.4016704559326172, 0.04608345031738281, 0.05773735046386719, 0.5805816650390625, 0.7602005004882812, 0.28708839416503906, 43.43266677856445, 0.5876598358154297, 0.35253334045410156, 40.86054229736328, 0.36658287048339844, 290.846923828125, 0.1588153839111328, 0.7562408447265625, 0.6624355316162109, 0.632415771484375, 0.3660469055175781, 0.6697120666503906, 0.2101306915283203, 0.3272571563720703, 0.4052391052246094, 38.37335205078125, 0.3636512756347656, 0.6114311218261719, 0.43500518798828125, 0.08854484558105469, 0.78497314453125, 42.72150421142578, 0.5200634002685547, 0.19486236572265625, 0.9051723480224609, 42.647857666015625, 0.7179355621337891, 0.7608814239501953, 0.1955089569091797, 0.42466163635253906, 0.3668231964111328, 0.2457561492919922, 40.55615997314453, 0.5434818267822266, 0.36794471740722656, 0.3175010681152344, 42.79294204711914, 0.0197296142578125, 41.50629806518555, 0.4789409637451172, 0.45691490173339844, 0.26529884338378906, 0.3989372253417969, 43.29454040527344, 44.69085693359375, 0.45461463928222656, 39.35035705566406, 0.036834716796875, 0.2327861785888672, 0.023942947387695312, 0.194610595703125, 42.4029541015625, 0.22863197326660156, 0.5145301818847656, 0.14122962951660156, 1.051858901977539, 0.5518321990966797, 0.4485301971435547, 0.4517364501953125, 0.24686050415039062, 0.43617820739746094, 41.63722229003906, 0.6543140411376953, 0.3740520477294922, 0.3559837341308594, 37.52851867675781, 0.205230712890625, 0.42321014404296875, 0.5491580963134766, 0.4502525329589844, 0.3392753601074219, 0.407623291015625, 0.299560546875, 43.292579650878906, 0.5723705291748047, 0.11956596374511719, 0.08829498291015625, 43.550376892089844, 0.15957069396972656, 43.43266677856445, 0.353271484375, 0.2949066162109375, 0.41947364807128906], "mean_td_error": 13.100997924804688, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 11363.0, "diff_num_grad_updates_vs_sampler_policy": 11362.0}}, "num_env_steps_sampled": 44088, "num_env_steps_trained": 2908928, "num_agent_steps_sampled": 44088, "num_agent_steps_trained": 2908928, "last_target_update_ts": 44088, "num_target_updates": 11363}, "sampler_results": {"episode_reward_max": 246.4839284569025, "episode_reward_min": -184.4967777505517, "episode_reward_mean": -114.73694654554129, "episode_len_mean": 89.08333333333333, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-167.30752436816692, -176.83662459999323, -184.4967777505517, -178.40541774779558, -173.2690906599164, -172.38881369680166, 140.20121035724878, -169.0239269733429, -181.60337759554386, -182.68479396402836, -177.5121500045061, 246.4839284569025], "episode_lengths": [100, 100, 100, 100, 100, 100, 67, 100, 100, 100, 100, 2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1598800450799327, "mean_inference_ms": 2.363374713911461, "mean_action_processing_ms": 0.22409406793798592, "mean_env_wait_ms": 2.9512557957767265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 246.4839284569025, "episode_reward_min": -184.4967777505517, "episode_reward_mean": -114.73694654554129, "episode_len_mean": 89.08333333333333, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-167.30752436816692, -176.83662459999323, -184.4967777505517, -178.40541774779558, -173.2690906599164, -172.38881369680166, 140.20121035724878, -169.0239269733429, -181.60337759554386, -182.68479396402836, -177.5121500045061, 246.4839284569025], "episode_lengths": [100, 100, 100, 100, 100, 100, 67, 100, 100, 100, 100, 2]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1598800450799327, "mean_inference_ms": 2.363374713911461, "mean_action_processing_ms": 0.22409406793798592, "mean_env_wait_ms": 2.9512557957767265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 44088, "num_agent_steps_trained": 2908928, "num_env_steps_sampled": 44088, "num_env_steps_trained": 2908928, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 44088, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 44088, "timers": {"training_iteration_time_ms": 156.148, "load_time_ms": 0.292, "load_throughput": 875666.143, "learn_time_ms": 24.652, "learn_throughput": 10384.481, "synch_weights_time_ms": 6.166}, "counters": {"num_env_steps_sampled": 44088, "num_env_steps_trained": 2908928, "num_agent_steps_sampled": 44088, "num_agent_steps_trained": 2908928, "last_target_update_ts": 44088, "num_target_updates": 11363}, "done": false, "episodes_total": 452, "training_iteration": 44, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-05-39", "timestamp": 1675951539, "time_this_iter_s": 51.63157558441162, "time_total_s": 1846.1190004348755, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2af0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ddca0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1846.1190004348755, "timesteps_since_restore": 0, "iterations_since_restore": 44, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.8549295774648, "ram_util_percent": 88.67464788732394}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 6.095778942108154, "actor_loss": 45.54407501220703, "critic_loss": 0.4098662734031677, "alpha_loss": -21.024795532226562, "alpha_value": 0.03177503123879433, "log_alpha_value": -3.4490745067596436, "target_entropy": -5.0, "policy_t": -0.30024057626724243, "mean_q": -45.66254806518555, "max_q": -41.48340606689453, "min_q": -48.75438690185547}, "td_error": [45.25380325317383, 0.21082115173339844, 0.30207252502441406, 0.24470901489257812, 0.6217632293701172, 0.3727912902832031, 0.7220706939697266, 0.6285114288330078, 0.2734260559082031, 0.5177783966064453, 0.3527660369873047, 0.17844581604003906, 0.3315849304199219, 0.26896095275878906, 42.32421112060547, 0.20880508422851562, 0.2138843536376953, 0.28883934020996094, 0.5937747955322266, 41.579246520996094, 0.11075401306152344, 0.4908943176269531, 293.1499938964844, 0.4554119110107422, 0.5261898040771484, 0.2128009796142578, 0.5219593048095703, 0.7574195861816406, 0.24506568908691406, 0.23075485229492188, 42.988555908203125, 0.4628772735595703, 0.1689891815185547, 0.28902626037597656, 0.3312816619873047, 0.4864387512207031, 0.3092384338378906, 45.61332321166992, 0.35300254821777344, 45.69029998779297, 0.3240184783935547, 0.3485260009765625, 0.4365978240966797, 44.24123764038086, 0.7392539978027344, 0.6760349273681641, 40.41973114013672, 0.7894687652587891, 0.46340370178222656, 0.5572299957275391, 42.14270782470703, 0.4495124816894531, 0.4322185516357422, 0.436004638671875, 0.07799530029296875, 0.3144817352294922, 0.038909912109375, 0.5651760101318359, 0.1732616424560547, 45.09180450439453, 0.37052154541015625, 0.4305553436279297, 0.7300434112548828, 0.07828140258789062, 0.46761131286621094, 0.5640506744384766, 0.5599174499511719, 0.8675098419189453, 0.4358177185058594, 0.10866355895996094, 0.704681396484375, 0.18862342834472656, 0.5264472961425781, 45.25873947143555, 0.47469520568847656, 0.407379150390625, 0.25819969177246094, 0.5825557708740234, 46.09889221191406, 0.8182621002197266, 0.6781177520751953, 0.3610706329345703, 0.948883056640625, 0.48918914794921875, 0.5140361785888672, 0.5186634063720703, 0.17559814453125, 45.153472900390625, 44.58868408203125, 0.1378936767578125, 0.3654804229736328, 0.2067241668701172, 0.5388946533203125, 0.10473251342773438, 292.64532470703125, 0.4435272216796875, 0.4311065673828125, 0.07691383361816406, 0.47394752502441406, 0.36330604553222656, 0.5490341186523438, 0.25168800354003906, 0.80804443359375, 0.3716239929199219, 0.3528423309326172, 0.875457763671875, 0.48058319091796875, 0.36579322814941406, 0.4662189483642578, 0.1807270050048828, 0.2896747589111328, 0.14204788208007812, 0.22625350952148438, 0.40674591064453125, 0.2589912414550781, 0.31036376953125, 42.67303466796875, 0.4351062774658203, 42.499549865722656, 0.11747550964355469, 0.7962265014648438, 0.15888404846191406, 42.567047119140625, 0.3991241455078125, 0.21055984497070312, 0.331268310546875, 0.058307647705078125, 0.5398597717285156, 40.163063049316406, 0.27855491638183594, 0.5241680145263672, 0.2291431427001953, 0.23122596740722656, 0.23425865173339844, 293.1499938964844, 40.776397705078125, 43.640689849853516, 0.4385185241699219, 0.20801734924316406, 0.2632331848144531, 0.40868568420410156, 0.5737533569335938, 0.41890525817871094, 0.6570568084716797, 0.4799346923828125, 0.5018272399902344, 0.37615966796875, 0.4858283996582031, 0.7632846832275391, 0.5765094757080078, 42.23799133300781, 40.89034652709961, 0.1319580078125, 0.10003280639648438, 0.6812953948974609, 0.5205764770507812, 0.5114364624023438, 0.39917945861816406, 0.5751724243164062, 0.4213733673095703, 42.67303466796875, 0.03515815734863281, 43.23994445800781, 0.23575401306152344, 0.8318214416503906, 0.5006217956542969, 0.18693161010742188, 0.19153594970703125, 0.9029369354248047, 0.7644920349121094, 44.181427001953125, 0.13227272033691406, 0.47936248779296875, 0.7025737762451172, 40.163063049316406, 0.5088253021240234, 0.5081291198730469, 0.5338764190673828, 0.12733078002929688, 0.6130886077880859, 0.1830272674560547, 43.142913818359375, 45.319740295410156, 44.86149215698242, 0.4382896423339844, 0.17982101440429688, 0.33046531677246094, 1.0284061431884766, 0.1536388397216797, 0.16965103149414062, 0.1893749237060547, 1.1552410125732422, 0.09083938598632812, 0.2525463104248047, 0.10363197326660156, 0.25055694580078125, 0.4204082489013672, 0.35711097717285156, 0.13845443725585938, 0.7497386932373047, 0.5201530456542969, 0.8138504028320312, 0.6055259704589844, 0.56463623046875, 0.6322002410888672, 0.37958717346191406, 0.5056896209716797, 0.5791416168212891, 0.3726539611816406, 0.8864650726318359, 0.2451648712158203, 0.5975704193115234, 40.776397705078125, 0.48094749450683594, 0.3862037658691406, 0.5831794738769531, 0.45265769958496094, 0.22062110900878906, 0.4557971954345703, 44.5444221496582, 0.3110313415527344, 0.06132698059082031, 40.6234130859375, 44.181427001953125, 0.5841884613037109, 0.4834918975830078, 0.7987117767333984, 0.261932373046875, 0.6346054077148438, 0.5349197387695312, 0.34809303283691406, 0.3541698455810547, 45.223052978515625, 0.3461036682128906, 0.274078369140625, 0.14972305297851562, 0.27678680419921875, 0.852569580078125, 0.5015239715576172, 0.16980743408203125, 0.08519935607910156, 0.10829544067382812, 0.4878120422363281, 0.6081771850585938, 0.125274658203125, 0.24686622619628906, 0.38594627380371094, 0.1622142791748047, 0.6151905059814453, 40.76953125, 0.5902767181396484, 0.499847412109375, 45.713294982910156, 0.32600975036621094, 0.2674579620361328, 44.705108642578125], "mean_td_error": 10.039125442504883, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 11697.0, "diff_num_grad_updates_vs_sampler_policy": 11696.0}}, "num_env_steps_sampled": 45090, "num_env_steps_trained": 2994432, "num_agent_steps_sampled": 45090, "num_agent_steps_trained": 2994432, "last_target_update_ts": 45090, "num_target_updates": 11697}, "sampler_results": {"episode_reward_max": -164.93139814585447, "episode_reward_min": -184.66212997585535, "episode_reward_mean": -173.97430018931627, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-175.16701660305262, -171.22391971945763, -180.22801702469587, -164.93139814585447, -175.00142758339643, -174.2958224490285, -174.6481312662363, -173.2648135572672, -184.66212997585535, -166.32032556831837], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.187749493027723, "mean_inference_ms": 2.403977553166043, "mean_action_processing_ms": 0.229260214201015, "mean_env_wait_ms": 2.998773847525011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -164.93139814585447, "episode_reward_min": -184.66212997585535, "episode_reward_mean": -173.97430018931627, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-175.16701660305262, -171.22391971945763, -180.22801702469587, -164.93139814585447, -175.00142758339643, -174.2958224490285, -174.6481312662363, -173.2648135572672, -184.66212997585535, -166.32032556831837], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.187749493027723, "mean_inference_ms": 2.403977553166043, "mean_action_processing_ms": 0.229260214201015, "mean_env_wait_ms": 2.998773847525011, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 45090, "num_agent_steps_trained": 2994432, "num_env_steps_sampled": 45090, "num_env_steps_trained": 2994432, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 45090, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 45090, "timers": {"training_iteration_time_ms": 152.399, "load_time_ms": 0.279, "load_throughput": 916552.987, "learn_time_ms": 24.511, "learn_throughput": 10444.136, "synch_weights_time_ms": 6.3}, "counters": {"num_env_steps_sampled": 45090, "num_env_steps_trained": 2994432, "num_agent_steps_sampled": 45090, "num_agent_steps_trained": 2994432, "last_target_update_ts": 45090, "num_target_updates": 11697}, "done": false, "episodes_total": 462, "training_iteration": 45, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-06-31", "timestamp": 1675951591, "time_this_iter_s": 52.04433584213257, "time_total_s": 1898.163336277008, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb970>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a0d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1898.163336277008, "timesteps_since_restore": 0, "iterations_since_restore": 45, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.16197183098592, "ram_util_percent": 89.17464788732397}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.81618595123291, "actor_loss": 47.8076286315918, "critic_loss": 0.35018056631088257, "alpha_loss": -17.007516860961914, "alpha_value": 0.02926611714065075, "log_alpha_value": -3.531324863433838, "target_entropy": -5.0, "policy_t": -0.40487056970596313, "mean_q": -47.816925048828125, "max_q": -43.401676177978516, "min_q": -50.481929779052734}, "td_error": [0.6332187652587891, 0.41905975341796875, 0.06148719787597656, 0.50640869140625, 45.926483154296875, 0.14138031005859375, 0.5312099456787109, 0.2769737243652344, 0.26084136962890625, 0.43492889404296875, 0.05044364929199219, 0.42298126220703125, 0.8369941711425781, 47.750038146972656, 0.26347923278808594, 0.43371009826660156, 0.07871055603027344, 0.40712738037109375, 0.5122776031494141, 0.5439491271972656, 47.110679626464844, 0.09484481811523438, 0.6721382141113281, 0.39812660217285156, 0.5613632202148438, 0.37142181396484375, 0.4124641418457031, 0.2133464813232422, 0.3907947540283203, 0.7647228240966797, 0.2117748260498047, 0.24236488342285156, 44.07025146484375, 0.10191917419433594, 0.6481113433837891, 0.6944599151611328, 0.8686141967773438, 0.3095817565917969, 0.05869293212890625, 0.8634605407714844, 0.4379291534423828, 0.13824844360351562, 47.527313232421875, 0.11328315734863281, 0.3467578887939453, 47.48606872558594, 0.6097507476806641, 0.19783401489257812, 0.18010520935058594, 0.4313621520996094, 0.5426025390625, 0.2529010772705078, 0.7827396392822266, 0.6180267333984375, 0.3881702423095703, 0.13129425048828125, 0.8098602294921875, 0.3860931396484375, 0.13718795776367188, 0.06485366821289062, 0.3325042724609375, 47.5943603515625, 0.5406265258789062, 0.47102928161621094, 0.5497226715087891, 46.906578063964844, 0.2698535919189453, 0.47652626037597656, 0.6958942413330078, 0.6099929809570312, 0.12273788452148438, 0.08516502380371094, 0.33345985412597656, 47.410091400146484, 0.5276279449462891, 0.4588432312011719, 0.098602294921875, 48.203453063964844, 0.23445892333984375, 0.5477199554443359, 0.04630470275878906, 0.3558349609375, 0.5438270568847656, 0.34292030334472656, 0.7074966430664062, 0.9039878845214844, 0.5459861755371094, 0.079254150390625, 47.181880950927734, 0.2846851348876953, 0.5694236755371094, 48.213096618652344, 0.38558006286621094, 45.661163330078125, 47.45209884643555, 0.46724510192871094, 0.9117927551269531, 0.37836265563964844, 0.14289283752441406, 48.40765380859375, 0.21247482299804688, 0.29456329345703125, 42.53756332397461, 0.3658027648925781, 0.15634536743164062, 0.15870094299316406, 0.31191062927246094, 0.45467567443847656, 0.64202880859375, 0.4280242919921875, 0.7621402740478516, 0.44908905029296875, 0.4056396484375, 0.13227462768554688, 0.29477882385253906, 0.2808971405029297, 0.02904510498046875, 0.332244873046875, 0.05949211120605469, 0.14432716369628906, 0.4195117950439453, 0.3492088317871094, 0.5855503082275391, 0.48780250549316406, 0.21309852600097656, 0.22280502319335938, 0.34192466735839844, 0.31554222106933594, 0.44403648376464844, 0.6269111633300781, 46.333866119384766, 0.3659687042236328, 0.6100673675537109, 0.026788711547851562, 0.035076141357421875, 294.55908203125, 0.2265644073486328, 0.7862949371337891, 0.31060218811035156, 0.08938789367675781, 0.5788211822509766, 0.12143135070800781, 0.31735992431640625, 0.4452381134033203, 0.15564346313476562, 47.750038146972656, 0.3499431610107422, 0.8388805389404297, 0.8888721466064453, 42.89350128173828, 0.18439865112304688, 0.6708755493164062, 0.6939163208007812, 0.1665210723876953, 0.2762794494628906, 45.524200439453125, 0.5035419464111328, 0.6174240112304688, 47.928138732910156, 0.21665000915527344, 41.71519088745117, 0.06691360473632812, 0.3245086669921875, 0.3028888702392578, 1.0868415832519531, 0.08860206604003906, 0.41040992736816406, 46.89215087890625, 0.43189239501953125, 0.5437946319580078, 0.5890007019042969, 0.36014556884765625, 0.7031192779541016, 0.09893035888671875, 46.42814254760742, 45.274513244628906, 0.12975311279296875, 0.39396095275878906, 0.3770008087158203, 0.13411521911621094, 0.10181236267089844, 0.12311744689941406, 0.5685863494873047, 0.5583610534667969, 0.4347496032714844, 0.49555397033691406, 0.5282630920410156, 0.36391448974609375, 43.425254821777344, 0.5222034454345703, 44.93461608886719, 0.3532085418701172, 0.6979236602783203, 0.6230354309082031, 47.59193420410156, 0.4383583068847656, 0.3295402526855469, 0.23584365844726562, 0.8017463684082031, 0.5526676177978516, 0.3857841491699219, 0.5990848541259766, 0.07878303527832031, 0.41339111328125, 293.51495361328125, 0.5689907073974609, 0.3516387939453125, 0.7262077331542969, 0.03801918029785156, 0.4903392791748047, 0.08361625671386719, 0.32584190368652344, 44.42779541015625, 0.48328208923339844, 0.6064586639404297, 0.7977809906005859, 0.383453369140625, 46.42814254760742, 0.47608375549316406, 0.0538330078125, 0.48142051696777344, 0.6125507354736328, 0.16660690307617188, 0.9706478118896484, 0.15154457092285156, 0.38372039794921875, 0.7277908325195312, 0.61749267578125, 1.0398674011230469, 0.42800331115722656, 0.0712890625, 47.827152252197266, 0.3450145721435547, 0.6142444610595703, 0.8842391967773438, 0.36661529541015625, 47.59961700439453, 0.1714935302734375, 0.4884166717529297, 0.48620033264160156, 0.8090038299560547, 0.31105995178222656, 0.13927268981933594, 0.512298583984375, 0.8672466278076172, 0.23546791076660156, 0.3851470947265625, 0.4811897277832031, 0.11479949951171875, 0.28469276428222656, 0.5487098693847656, 0.4104633331298828, 0.27641868591308594, 0.20220947265625, 0.8020229339599609, 0.41088294982910156], "mean_td_error": 8.439838409423828, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 12031.0, "diff_num_grad_updates_vs_sampler_policy": 12030.0}}, "num_env_steps_sampled": 46092, "num_env_steps_trained": 3079936, "num_agent_steps_sampled": 46092, "num_agent_steps_trained": 3079936, "last_target_update_ts": 46092, "num_target_updates": 12031}, "sampler_results": {"episode_reward_max": -159.62204612791538, "episode_reward_min": -188.7975147664547, "episode_reward_mean": -173.51912591867148, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-184.3933058977127, -159.85871002078056, -182.05973440408707, -174.52376528084278, -177.9114715717733, -188.7975147664547, -177.67379681766033, -163.71339911222458, -166.6375151872635, -159.62204612791538], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1734883792230448, "mean_inference_ms": 2.3844269188614957, "mean_action_processing_ms": 0.22661155727993498, "mean_env_wait_ms": 2.977860643465667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -159.62204612791538, "episode_reward_min": -188.7975147664547, "episode_reward_mean": -173.51912591867148, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-184.3933058977127, -159.85871002078056, -182.05973440408707, -174.52376528084278, -177.9114715717733, -188.7975147664547, -177.67379681766033, -163.71339911222458, -166.6375151872635, -159.62204612791538], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1734883792230448, "mean_inference_ms": 2.3844269188614957, "mean_action_processing_ms": 0.22661155727993498, "mean_env_wait_ms": 2.977860643465667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 46092, "num_agent_steps_trained": 3079936, "num_env_steps_sampled": 46092, "num_env_steps_trained": 3079936, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 46092, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 46092, "timers": {"training_iteration_time_ms": 154.273, "load_time_ms": 0.286, "load_throughput": 894635.747, "learn_time_ms": 25.473, "learn_throughput": 10049.773, "synch_weights_time_ms": 6.889}, "counters": {"num_env_steps_sampled": 46092, "num_env_steps_trained": 3079936, "num_agent_steps_sampled": 46092, "num_agent_steps_trained": 3079936, "last_target_update_ts": 46092, "num_target_updates": 12031}, "done": false, "episodes_total": 472, "training_iteration": 46, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-07-22", "timestamp": 1675951642, "time_this_iter_s": 51.68443274497986, "time_total_s": 1949.847769021988, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e3f10>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ec4c0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 1949.847769021988, "timesteps_since_restore": 0, "iterations_since_restore": 46, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.12857142857142, "ram_util_percent": 89.73714285714283}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.826326370239258, "actor_loss": 49.585487365722656, "critic_loss": 0.4745522737503052, "alpha_loss": -17.413110733032227, "alpha_value": 0.027107561007142067, "log_alpha_value": -3.607942581176758, "target_entropy": -5.0, "policy_t": -0.37485775351524353, "mean_q": -49.60845184326172, "max_q": -45.16228103637695, "min_q": -52.56848907470703}, "td_error": [0.20067787170410156, 0.2363300323486328, 48.44215393066406, 0.04754638671875, 0.37992095947265625, 0.5406475067138672, 0.0618438720703125, 0.4639911651611328, 0.14372634887695312, 0.4387054443359375, 0.3765850067138672, 0.4739665985107422, 0.26760292053222656, 0.4293537139892578, 0.6276130676269531, 50.240665435791016, 0.3533782958984375, 0.6267452239990234, 0.8498897552490234, 0.4212322235107422, 0.3604907989501953, 0.10525703430175781, 0.2813568115234375, 0.9252262115478516, 0.5579757690429688, 0.3397178649902344, 0.3001289367675781, 45.493247985839844, 0.6663532257080078, 0.07880973815917969, 0.3722820281982422, 0.03293609619140625, 49.031394958496094, 0.42241668701171875, 0.019437789916992188, 0.16831398010253906, 46.04447555541992, 0.061450958251953125, 0.2884845733642578, 0.3975543975830078, 0.6570148468017578, 50.26874542236328, 0.2883434295654297, 0.40468788146972656, 0.2069568634033203, 47.29499053955078, 48.1859130859375, 0.7356395721435547, 0.2661628723144531, 0.4932823181152344, 0.23725509643554688, 0.3025245666503906, 0.7252254486083984, 0.4607677459716797, 0.5538082122802734, 48.99052047729492, 0.16587257385253906, 0.4899158477783203, 0.39151573181152344, 44.493080139160156, 0.11014556884765625, 0.46298789978027344, 0.3653888702392578, 0.3687305450439453, 0.5752067565917969, 0.7226581573486328, 0.0279083251953125, 43.70436477661133, 0.4469127655029297, 0.4259471893310547, 50.26039505004883, 49.401275634765625, 46.254302978515625, 0.05941581726074219, 0.5006999969482422, 48.58154296875, 0.4380474090576172, 0.10080146789550781, 0.764312744140625, 48.954368591308594, 0.6129016876220703, 0.3572502136230469, 49.01808547973633, 0.5398445129394531, 44.77654266357422, 0.33577919006347656, 0.34461021423339844, 0.24692153930664062, 0.42556190490722656, 0.2797088623046875, 0.312286376953125, 0.38794517517089844, 0.4399394989013672, 46.245216369628906, 0.1331958770751953, 0.1898212432861328, 0.18434715270996094, 0.6323451995849609, 0.6586647033691406, 0.6078968048095703, 297.0185241699219, 0.47101402282714844, 0.7300300598144531, 43.879981994628906, 48.74707794189453, 49.00579071044922, 0.32671356201171875, 0.10903358459472656, 0.4030170440673828, 47.67217254638672, 0.06240272521972656, 0.4368133544921875, 0.6469516754150391, 0.3829212188720703, 0.5992698669433594, 0.22919273376464844, 0.51409912109375, 0.34915924072265625, 0.5632572174072266, 0.5482521057128906, 49.31378173828125, 0.3758220672607422, 44.7294807434082, 0.7536754608154297, 0.6466922760009766, 46.2222900390625, 0.33950042724609375, 0.3307666778564453, 0.8116168975830078, 0.2052936553955078, 0.7309856414794922, 0.2744255065917969, 0.7748222351074219, 0.47084808349609375, 0.1655712127685547, 46.311458587646484, 0.20958328247070312, 0.3918781280517578, 48.09242630004883, 0.40932273864746094, 0.3687629699707031, 295.353515625, 0.57061767578125, 0.4242382049560547, 0.6099224090576172, 0.37479591369628906, 0.6301956176757812, 0.4642620086669922, 47.1085205078125, 0.5037307739257812, 0.05495262145996094, 0.47148704528808594, 0.6335735321044922, 0.10399436950683594, 49.71912384033203, 0.47492218017578125, 0.06267356872558594, 0.2348480224609375, 0.41834259033203125, 45.56098937988281, 0.2738838195800781, 48.574520111083984, 0.15716171264648438, 0.6035385131835938, 46.9803466796875, 0.8229312896728516, 0.2833728790283203, 0.4936790466308594, 0.2740745544433594, 47.465614318847656, 47.38221740722656, 0.5203762054443359, 0.4713096618652344, 0.5807437896728516, 0.096160888671875, 0.11034584045410156, 0.14021873474121094, 0.3615589141845703, 0.5165672302246094, 0.2229766845703125, 0.155029296875, 0.06932640075683594, 0.7133998870849609, 0.1878509521484375, 0.1582355499267578, 0.6509494781494141, 0.3998432159423828, 0.1789379119873047, 47.18331527709961, 0.7628459930419922, 0.8043785095214844, 0.1878204345703125, 0.14875411987304688, 49.31378173828125, 0.7282543182373047, 0.2071208953857422, 49.52908706665039, 50.364349365234375, 48.65895080566406, 48.00447082519531, 0.6911125183105469, 0.37157249450683594, 0.03980445861816406, 0.4876708984375, 0.5792675018310547, 0.2846393585205078, 0.31655120849609375, 0.12153244018554688, 0.21178436279296875, 0.5955257415771484, 1.35968017578125, 0.05911827087402344, 48.877227783203125, 0.0024204254150390625, 0.5824337005615234, 0.7419719696044922, 45.76795959472656, 0.4443817138671875, 0.7010898590087891, 0.2381610870361328, 0.1391429901123047, 0.30959320068359375, 0.15122032165527344, 0.7423934936523438, 0.2235431671142578, 0.44022178649902344, 46.22574234008789, 0.3832283020019531, 0.04944801330566406, 0.7730865478515625, 0.5663471221923828, 0.024953842163085938, 0.8911705017089844, 0.39754295349121094, 0.3298797607421875, 0.1536846160888672, 0.47967529296875, 0.8266925811767578, 0.6050453186035156, 0.0534515380859375, 0.5668754577636719, 0.3763713836669922, 0.09568214416503906, 0.40973472595214844, 47.586971282958984, 47.41584396362305, 0.7089481353759766, 0.2631568908691406, 0.7296581268310547, 0.3375110626220703, 0.31596946716308594, 0.4756755828857422, 0.42131614685058594, 0.16807937622070312, 0.05014228820800781, 0.5161037445068359], "mean_td_error": 11.196297645568848, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 12365.0, "diff_num_grad_updates_vs_sampler_policy": 12364.0}}, "num_env_steps_sampled": 47094, "num_env_steps_trained": 3165440, "num_agent_steps_sampled": 47094, "num_agent_steps_trained": 3165440, "last_target_update_ts": 47094, "num_target_updates": 12365}, "sampler_results": {"episode_reward_max": -156.76976097002625, "episode_reward_min": -182.86714262515306, "episode_reward_mean": -168.8070443738252, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-160.15382880717516, -166.3982791826129, -180.81407899409533, -182.86714262515306, -156.76976097002625, -163.0765529051423, -168.91380199044943, -167.2463010251522, -170.40086115896702, -171.42983607947826], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1631953912947963, "mean_inference_ms": 2.3701897122478917, "mean_action_processing_ms": 0.22504626128983213, "mean_env_wait_ms": 2.9598141044589, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.76976097002625, "episode_reward_min": -182.86714262515306, "episode_reward_mean": -168.8070443738252, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-160.15382880717516, -166.3982791826129, -180.81407899409533, -182.86714262515306, -156.76976097002625, -163.0765529051423, -168.91380199044943, -167.2463010251522, -170.40086115896702, -171.42983607947826], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1631953912947963, "mean_inference_ms": 2.3701897122478917, "mean_action_processing_ms": 0.22504626128983213, "mean_env_wait_ms": 2.9598141044589, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 47094, "num_agent_steps_trained": 3165440, "num_env_steps_sampled": 47094, "num_env_steps_trained": 3165440, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 47094, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 47094, "timers": {"training_iteration_time_ms": 156.113, "load_time_ms": 0.296, "load_throughput": 866060.513, "learn_time_ms": 24.688, "learn_throughput": 10369.268, "synch_weights_time_ms": 6.903}, "counters": {"num_env_steps_sampled": 47094, "num_env_steps_trained": 3165440, "num_agent_steps_sampled": 47094, "num_agent_steps_trained": 3165440, "last_target_update_ts": 47094, "num_target_updates": 12365}, "done": false, "episodes_total": 482, "training_iteration": 47, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-08-15", "timestamp": 1675951695, "time_this_iter_s": 52.2833309173584, "time_total_s": 2002.1310999393463, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105884f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ec160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2002.1310999393463, "timesteps_since_restore": 0, "iterations_since_restore": 47, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.10277777777778, "ram_util_percent": 89.8138888888889}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.113633632659912, "actor_loss": 51.277069091796875, "critic_loss": 0.5725752711296082, "alpha_loss": -15.172660827636719, "alpha_value": 0.025012386962771416, "log_alpha_value": -3.6883840560913086, "target_entropy": -5.0, "policy_t": -0.40664178133010864, "mean_q": -51.362430572509766, "max_q": -46.790531158447266, "min_q": -54.65789794921875}, "td_error": [0.4698219299316406, 0.15938186645507812, 46.47480010986328, 298.3553771972656, 0.4008903503417969, 46.236328125, 49.43733596801758, 0.07677078247070312, 0.1265544891357422, 0.3695487976074219, 0.034572601318359375, 0.046962738037109375, 0.10832405090332031, 46.32549285888672, 0.47850799560546875, 0.44320106506347656, 0.5878734588623047, 0.2948722839355469, 0.28778839111328125, 0.4546928405761719, 50.748313903808594, 0.16974639892578125, 0.4899749755859375, 0.3218555450439453, 1.0663127899169922, 0.5235595703125, 0.41606903076171875, 0.22600936889648438, 45.76729965209961, 0.8297386169433594, 0.5317440032958984, 0.5069732666015625, 0.48418235778808594, 51.566856384277344, 0.24944686889648438, 0.5877838134765625, 0.30774688720703125, 0.09897041320800781, 0.36127662658691406, 0.7571811676025391, 0.12408828735351562, 0.6705551147460938, 0.42192840576171875, 0.1674957275390625, 0.203582763671875, 0.17041587829589844, 0.9422187805175781, 0.5278816223144531, 0.5231418609619141, 0.453948974609375, 0.4788379669189453, 0.16643905639648438, 0.12438583374023438, 0.34459495544433594, 0.24966049194335938, 0.40497398376464844, 0.24698257446289062, 0.3096179962158203, 0.14986038208007812, 0.7172069549560547, 46.056095123291016, 0.20122909545898438, 300.064208984375, 0.660888671875, 0.7734832763671875, 51.65748596191406, 0.5379543304443359, 0.23225975036621094, 0.501800537109375, 0.1318798065185547, 0.3137016296386719, 0.21941757202148438, 47.198089599609375, 0.5342731475830078, 49.974754333496094, 0.5678558349609375, 0.5933761596679688, 0.5841293334960938, 0.3320770263671875, 0.42157936096191406, 0.22607803344726562, 0.2223186492919922, 0.3951072692871094, 0.7033119201660156, 0.3598899841308594, 0.6332645416259766, 0.109130859375, 0.2501659393310547, 0.4099693298339844, 0.6049766540527344, 0.10222244262695312, 0.5882472991943359, 51.0964241027832, 0.06323051452636719, 0.5380611419677734, 0.278228759765625, 0.14771270751953125, 50.9559326171875, 0.6570014953613281, 0.2929840087890625, 0.3363056182861328, 0.2526664733886719, 0.14735984802246094, 0.24552536010742188, 0.2022418975830078, 0.16628074645996094, 0.15417098999023438, 49.99929428100586, 0.6632061004638672, 0.7453384399414062, 0.07954788208007812, 0.5801734924316406, 0.37827491760253906, 52.364158630371094, 1.1548786163330078, 0.5300941467285156, 0.16716575622558594, 0.17264747619628906, 0.6454010009765625, 0.04507637023925781, 0.37419700622558594, 0.5054492950439453, 0.14824867248535156, 0.19327926635742188, 0.3909015655517578, 0.6464443206787109, 0.13671875, 49.97080993652344, 0.42923927307128906, 0.5525493621826172, 0.2691383361816406, 0.4083442687988281, 0.08629608154296875, 0.9460334777832031, 0.5643348693847656, 0.5997676849365234, 0.21454429626464844, 51.61207580566406, 0.28214454650878906, 0.23086929321289062, 0.3405876159667969, 298.7294616699219, 0.18135833740234375, 0.3230133056640625, 0.4783744812011719, 0.4403648376464844, 0.1288623809814453, 0.2762775421142578, 295.53302001953125, 0.8935184478759766, 0.42106056213378906, 0.21710968017578125, 0.221710205078125, 0.2960014343261719, 0.5686511993408203, 0.43230628967285156, 0.8051280975341797, 0.4410572052001953, 0.03403663635253906, 0.3600425720214844, 0.4911327362060547, 0.1767444610595703, 0.7017364501953125, 299.0634765625, 49.52976989746094, 0.3794231414794922, 0.43817710876464844, 0.27370262145996094, 0.2625083923339844, 0.24918746948242188, 0.5070991516113281, 295.53302001953125, 50.52458953857422, 46.51728820800781, 0.8478069305419922, 51.35957717895508, 0.6903800964355469, 0.26813507080078125, 0.4118213653564453, 0.46008872985839844, 0.877471923828125, 0.42394447326660156, 0.16367721557617188, 0.4750194549560547, 47.382789611816406, 0.5378856658935547, 0.8377780914306641, 0.5827674865722656, 0.17574501037597656, 0.09004402160644531, 0.1761627197265625, 0.6914634704589844, 0.39459800720214844, 52.14877700805664, 52.12570571899414, 0.20400619506835938, 0.36150360107421875, 0.4207763671875, 0.5770797729492188, 0.7519168853759766, 48.37138366699219, 0.5614147186279297, 0.03301429748535156, 0.4217643737792969, 1.1219558715820312, 0.22102737426757812, 0.2599925994873047, 0.12337493896484375, 0.3722705841064453, 50.69591522216797, 299.0634765625, 0.6054534912109375, 0.21181488037109375, 0.6074256896972656, 46.01875686645508, 51.17010498046875, 0.3356513977050781, 48.78718566894531, 0.3506813049316406, 0.6709346771240234, 0.5417098999023438, 0.3498706817626953, 0.3502349853515625, 0.24774551391601562, 0.4459648132324219, 0.3114356994628906, 49.964927673339844, 0.08354759216308594, 0.039104461669921875, 50.668212890625, 0.3199462890625, 0.5319290161132812, 0.018301010131835938, 0.5886650085449219, 0.5066642761230469, 0.45090293884277344, 0.5032978057861328, 0.4521312713623047, 0.19781875610351562, 0.7014904022216797, 297.41766357421875, 0.4844532012939453, 0.6076335906982422, 0.6617527008056641, 51.80818176269531, 0.2689704895019531, 0.33904266357421875, 0.6904830932617188, 0.3463020324707031, 0.3267669677734375, 0.046909332275390625, 0.33368682861328125, 0.5442008972167969, 0.33656883239746094, 0.20816421508789062, 0.36518287658691406], "mean_td_error": 15.834491729736328, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 12699.0, "diff_num_grad_updates_vs_sampler_policy": 12698.0}}, "num_env_steps_sampled": 48096, "num_env_steps_trained": 3250944, "num_agent_steps_sampled": 48096, "num_agent_steps_trained": 3250944, "last_target_update_ts": 48096, "num_target_updates": 12699}, "sampler_results": {"episode_reward_max": 134.60009190440178, "episode_reward_min": -187.80273082852364, "episode_reward_mean": -146.0879253826358, "episode_len_mean": 97.63636363636364, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-156.90459544211626, -172.33873042464256, -177.08846881985664, -174.41388424485922, -166.60171175003052, -168.72993633896112, 134.60009190440178, -187.80273082852364, -179.12906210124493, -171.90995248407125, -186.64819867908955], "episode_lengths": [100, 100, 100, 100, 100, 100, 74, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.181873496777882, "mean_inference_ms": 2.3961599049570044, "mean_action_processing_ms": 0.2283518083855446, "mean_env_wait_ms": 2.9955742633765268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 134.60009190440178, "episode_reward_min": -187.80273082852364, "episode_reward_mean": -146.0879253826358, "episode_len_mean": 97.63636363636364, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-156.90459544211626, -172.33873042464256, -177.08846881985664, -174.41388424485922, -166.60171175003052, -168.72993633896112, 134.60009190440178, -187.80273082852364, -179.12906210124493, -171.90995248407125, -186.64819867908955], "episode_lengths": [100, 100, 100, 100, 100, 100, 74, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.181873496777882, "mean_inference_ms": 2.3961599049570044, "mean_action_processing_ms": 0.2283518083855446, "mean_env_wait_ms": 2.9955742633765268, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 48096, "num_agent_steps_trained": 3250944, "num_env_steps_sampled": 48096, "num_env_steps_trained": 3250944, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 48096, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 48096, "timers": {"training_iteration_time_ms": 152.22, "load_time_ms": 0.266, "load_throughput": 962651.806, "learn_time_ms": 24.534, "learn_throughput": 10434.363, "synch_weights_time_ms": 5.802}, "counters": {"num_env_steps_sampled": 48096, "num_env_steps_trained": 3250944, "num_agent_steps_sampled": 48096, "num_agent_steps_trained": 3250944, "last_target_update_ts": 48096, "num_target_updates": 12699}, "done": false, "episodes_total": 493, "training_iteration": 48, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-09-07", "timestamp": 1675951747, "time_this_iter_s": 52.59737300872803, "time_total_s": 2054.7284729480743, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105885e0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a91f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2054.7284729480743, "timesteps_since_restore": 0, "iterations_since_restore": 48, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.9986111111111, "ram_util_percent": 89.19166666666666}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6947832107543945, "actor_loss": 53.09146499633789, "critic_loss": 0.5243028402328491, "alpha_loss": -13.925455093383789, "alpha_value": 0.02307627536356449, "log_alpha_value": -3.7689502239227295, "target_entropy": -5.0, "policy_t": -0.44182953238487244, "mean_q": -53.24835968017578, "max_q": -48.546138763427734, "min_q": -56.76914596557617}, "td_error": [0.5364742279052734, 0.4472789764404297, 0.4204559326171875, 0.8234615325927734, 51.608497619628906, 47.974143981933594, 0.528594970703125, 0.15996551513671875, 52.54063415527344, 0.08405876159667969, 0.22665023803710938, 1.2633934020996094, 0.47318458557128906, 0.7942371368408203, 0.16403770446777344, 0.316375732421875, 0.644287109375, 0.3999309539794922, 0.2335033416748047, 0.6958484649658203, 0.7437114715576172, 0.2714862823486328, 52.168701171875, 0.2868175506591797, 0.23501014709472656, 0.4682178497314453, 53.29475021362305, 0.4824180603027344, 0.6700572967529297, 0.16911888122558594, 0.2787952423095703, 0.6519145965576172, 0.7178974151611328, 0.2957935333251953, 0.5224227905273438, 0.3312568664550781, 300.81793212890625, 48.691917419433594, 0.09446907043457031, 0.178192138671875, 0.2769489288330078, 0.14343643188476562, 0.09250259399414062, 0.2962188720703125, 0.23816871643066406, 0.41199684143066406, 0.5489253997802734, 0.144378662109375, 53.219947814941406, 0.1592388153076172, 0.2142486572265625, 0.3335113525390625, 0.2529621124267578, 0.41615867614746094, 0.23638343811035156, 0.7643203735351562, 0.1827068328857422, 0.6869316101074219, 51.435726165771484, 0.5713520050048828, 0.44952392578125, 0.07378387451171875, 0.5905666351318359, 0.26288414001464844, 0.25431060791015625, 0.2897987365722656, 0.39278221130371094, 0.2494373321533203, 0.3511638641357422, 0.38590049743652344, 0.24366188049316406, 0.37101173400878906, 0.5183639526367188, 0.6306419372558594, 53.2132568359375, 0.13458251953125, 51.939579010009766, 0.5260677337646484, 52.91149139404297, 0.043201446533203125, 0.3340911865234375, 50.028564453125, 48.71514129638672, 0.19400596618652344, 52.32672119140625, 51.146461486816406, 0.2740974426269531, 0.5017261505126953, 51.979278564453125, 0.7241020202636719, 0.43854331970214844, 0.026071548461914062, 0.28829002380371094, 0.6754188537597656, 0.36036109924316406, 0.9405708312988281, 0.4305438995361328, 0.27042579650878906, 53.349365234375, 0.5390968322753906, 0.2902812957763672, 0.40494728088378906, 0.1977519989013672, 0.15888214111328125, 52.58494567871094, 0.14253807067871094, 0.6748180389404297, 0.3661022186279297, 0.08915519714355469, 0.6668014526367188, 52.22698974609375, 0.3584575653076172, 0.1925182342529297, 299.8934326171875, 53.50838088989258, 0.04701805114746094, 0.8872699737548828, 52.8228759765625, 0.5114612579345703, 0.15900802612304688, 53.00537109375, 0.8920116424560547, 0.013872146606445312, 0.3609161376953125, 0.03359031677246094, 0.7448368072509766, 49.71513366699219, 0.2887611389160156, 53.24415588378906, 0.23734092712402344, 0.3462028503417969, 0.09813117980957031, 0.5075397491455078, 0.5493812561035156, 0.5086688995361328, 0.7505531311035156, 0.3124065399169922, 0.8792819976806641, 0.6873970031738281, 48.22952651977539, 0.32901954650878906, 52.39161682128906, 51.64996337890625, 0.1358623504638672, 0.06558418273925781, 0.5406436920166016, 0.47652244567871094, 0.3177661895751953, 0.15587425231933594, 0.22959518432617188, 0.5852088928222656, 0.6700305938720703, 0.5364303588867188, 0.5147609710693359, 0.20700836181640625, 53.922386169433594, 0.42617225646972656, 0.8787670135498047, 53.24415588378906, 0.14105606079101562, 0.26651573181152344, 0.3135242462158203, 0.2095813751220703, 54.017860412597656, 48.64887237548828, 51.629844665527344, 1.1428604125976562, 0.43874168395996094, 0.7237796783447266, 53.219947814941406, 0.5054244995117188, 0.3665332794189453, 0.1401519775390625, 0.3923206329345703, 0.4526195526123047, 49.403316497802734, 0.31154632568359375, 0.19029808044433594, 49.451805114746094, 0.7033901214599609, 0.1978130340576172, 0.08453941345214844, 0.8054180145263672, 0.35390281677246094, 0.07523536682128906, 0.4151878356933594, 52.39324188232422, 0.6859130859375, 0.2639751434326172, 0.451080322265625, 0.9672832489013672, 0.7623882293701172, 0.14397621154785156, 0.27398109436035156, 0.6947345733642578, 0.1471881866455078, 0.5755443572998047, 0.41518402099609375, 0.4425849914550781, 0.3049335479736328, 300.18634033203125, 0.6388797760009766, 0.2558631896972656, 0.2941303253173828, 0.4019889831542969, 49.205841064453125, 0.46964454650878906, 50.061431884765625, 0.7902126312255859, 0.11104583740234375, 0.49210166931152344, 0.9881076812744141, 0.21621131896972656, 0.08928489685058594, 0.18430709838867188, 0.2692699432373047, 0.40082740783691406, 0.5759258270263672, 0.8480167388916016, 0.5438709259033203, 1.001138687133789, 0.2105083465576172, 0.4832134246826172, 0.38483238220214844, 0.3909015655517578, 0.1795063018798828, 0.6719379425048828, 0.11232376098632812, 0.1868114471435547, 0.6789951324462891, 0.6177158355712891, 297.433837890625, 50.35206985473633, 0.43117713928222656, 0.5039730072021484, 0.19245338439941406, 0.3121318817138672, 0.7276515960693359, 0.3899974822998047, 0.5262241363525391, 0.13414382934570312, 0.4386329650878906, 0.3286399841308594, 48.60688781738281, 0.47931480407714844, 0.4311065673828125, 0.18853378295898438, 0.37373924255371094, 0.4389476776123047, 0.1047821044921875, 0.015333175659179688, 0.35594749450683594, 48.16516876220703, 0.32648277282714844, 0.1024627685546875, 0.12537765502929688], "mean_td_error": 13.246575355529785, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 13033.0, "diff_num_grad_updates_vs_sampler_policy": 13032.0}}, "num_env_steps_sampled": 49098, "num_env_steps_trained": 3336448, "num_agent_steps_sampled": 49098, "num_agent_steps_trained": 3336448, "last_target_update_ts": 49098, "num_target_updates": 13033}, "sampler_results": {"episode_reward_max": -157.72101052105427, "episode_reward_min": -187.16704893112183, "episode_reward_mean": -171.52214821014138, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-164.02385437488556, -165.1729513183236, -167.72791469842196, -169.36041093617678, -187.16704893112183, -166.19394103437662, -184.12222132086754, -157.72101052105427, -182.2099807560444], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.171389737271677, "mean_inference_ms": 2.382384325267802, "mean_action_processing_ms": 0.22673174717336908, "mean_env_wait_ms": 2.976710819517779, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -157.72101052105427, "episode_reward_min": -187.16704893112183, "episode_reward_mean": -171.52214821014138, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-164.02385437488556, -165.1729513183236, -167.72791469842196, -169.36041093617678, -187.16704893112183, -166.19394103437662, -184.12222132086754, -157.72101052105427, -182.2099807560444], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.171389737271677, "mean_inference_ms": 2.382384325267802, "mean_action_processing_ms": 0.22673174717336908, "mean_env_wait_ms": 2.976710819517779, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 49098, "num_agent_steps_trained": 3336448, "num_env_steps_sampled": 49098, "num_env_steps_trained": 3336448, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 49098, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 49098, "timers": {"training_iteration_time_ms": 163.143, "load_time_ms": 0.296, "load_throughput": 865781.184, "learn_time_ms": 27.682, "learn_throughput": 9247.96, "synch_weights_time_ms": 6.166}, "counters": {"num_env_steps_sampled": 49098, "num_env_steps_trained": 3336448, "num_agent_steps_sampled": 49098, "num_agent_steps_trained": 3336448, "last_target_update_ts": 49098, "num_target_updates": 13033}, "done": false, "episodes_total": 502, "training_iteration": 49, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-10-00", "timestamp": 1675951800, "time_this_iter_s": 52.084834814071655, "time_total_s": 2106.813307762146, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bba00>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ecd30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2106.813307762146, "timesteps_since_restore": 0, "iterations_since_restore": 49, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.35833333333333, "ram_util_percent": 89.12777777777778}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.9248414039611816, "actor_loss": 54.84054183959961, "critic_loss": 0.5813063383102417, "alpha_loss": -15.097679138183594, "alpha_value": 0.02135012298822403, "log_alpha_value": -3.8466978073120117, "target_entropy": -5.0, "policy_t": -0.40519922971725464, "mean_q": -54.92958450317383, "max_q": -50.260494232177734, "min_q": -58.11872100830078}, "td_error": [0.5210208892822266, 0.1074981689453125, 0.38108062744140625, 50.00604248046875, 0.2157878875732422, 0.20369529724121094, 0.48613548278808594, 0.5106182098388672, 0.6841182708740234, 0.4438896179199219, 0.6733779907226562, 0.3671550750732422, 0.4193763732910156, 0.6410961151123047, 0.6770572662353516, 0.06820487976074219, 56.31993103027344, 0.43952369689941406, 0.40157508850097656, 0.14391517639160156, 302.19061279296875, 0.3861408233642578, 0.036136627197265625, 0.6928558349609375, 0.6532535552978516, 0.037479400634765625, 304.5885314941406, 0.18736839294433594, 0.8623466491699219, 0.22419166564941406, 0.7794647216796875, 0.20294761657714844, 0.3289508819580078, 54.99568176269531, 0.6081581115722656, 0.6619110107421875, 0.14054107666015625, 0.1736316680908203, 55.59708023071289, 0.06854820251464844, 0.32471275329589844, 0.6880931854248047, 0.47634315490722656, 0.6763172149658203, 0.6091461181640625, 0.5062122344970703, 0.5859336853027344, 55.07573318481445, 0.248260498046875, 0.18621444702148438, 0.4716300964355469, 0.4216594696044922, 0.29458045959472656, 0.6300678253173828, 0.2871379852294922, 0.5641269683837891, 0.48813819885253906, 0.15015792846679688, 0.5126800537109375, 0.4243030548095703, 0.3658771514892578, 0.5342330932617188, 0.437103271484375, 0.30796051025390625, 0.4597644805908203, 0.16433143615722656, 54.30774688720703, 0.2338581085205078, 300.865234375, 0.5694351196289062, 0.5139408111572266, 0.41591644287109375, 0.11747550964355469, 53.461631774902344, 0.4811687469482422, 0.26580238342285156, 0.08965682983398438, 52.09696578979492, 0.4212474822998047, 0.7372474670410156, 0.5118618011474609, 0.3872509002685547, 52.343048095703125, 0.3591728210449219, 0.42745018005371094, 0.19945716857910156, 0.3779430389404297, 0.19059371948242188, 0.8826255798339844, 0.2841053009033203, 301.703125, 0.1564311981201172, 0.5937213897705078, 0.35293006896972656, 0.3923530578613281, 0.5740032196044922, 0.3167762756347656, 0.7079963684082031, 0.5290279388427734, 0.09277915954589844, 0.13587188720703125, 56.10877227783203, 0.40450477600097656, 0.1380615234375, 53.260963439941406, 0.5706386566162109, 0.7040138244628906, 0.30859947204589844, 0.3853168487548828, 52.038455963134766, 0.24209976196289062, 0.3111553192138672, 0.27597808837890625, 0.39907264709472656, 0.3350963592529297, 51.486366271972656, 0.8390617370605469, 0.7803096771240234, 0.5617809295654297, 0.20758056640625, 0.35144615173339844, 0.8716793060302734, 0.13282012939453125, 0.4528789520263672, 0.7376441955566406, 50.3431396484375, 0.06336402893066406, 0.49059104919433594, 0.6476764678955078, 0.3432426452636719, 0.5060062408447266, 55.049354553222656, 0.1337738037109375, 0.39800071716308594, 0.8412647247314453, 0.08305168151855469, 54.52415466308594, 0.23373985290527344, 0.47881126403808594, 0.11831474304199219, 0.5251007080078125, 0.6387081146240234, 0.4791603088378906, 0.6760482788085938, 0.9681758880615234, 0.06819725036621094, 0.7309341430664062, 55.71934509277344, 54.570213317871094, 52.1487922668457, 0.4924201965332031, 50.411521911621094, 0.44919776916503906, 0.7068996429443359, 53.40870666503906, 0.3553943634033203, 51.236907958984375, 52.61858367919922, 0.6416416168212891, 0.2387104034423828, 0.3925323486328125, 0.4356861114501953, 0.06136894226074219, 0.32456398010253906, 0.2159137725830078, 55.45439529418945, 0.7460384368896484, 55.55898666381836, 0.23511314392089844, 53.49317169189453, 0.8297290802001953, 0.45307159423828125, 0.6192989349365234, 0.31698036193847656, 0.4776477813720703, 0.5831947326660156, 0.30416297912597656, 0.5812740325927734, 0.2030658721923828, 53.767574310302734, 0.3414173126220703, 53.449119567871094, 55.15623474121094, 0.5981426239013672, 0.5971736907958984, 54.023311614990234, 55.49903869628906, 0.49587440490722656, 0.6373538970947266, 0.5698795318603516, 0.4800281524658203, 0.4339733123779297, 55.5062141418457, 0.34836769104003906, 0.09992408752441406, 51.00732421875, 0.185882568359375, 0.05110931396484375, 0.25110816955566406, 0.5459041595458984, 0.19829368591308594, 0.23188209533691406, 0.11985397338867188, 0.4049663543701172, 49.74627685546875, 53.34342956542969, 0.5291461944580078, 0.008777618408203125, 0.4319019317626953, 0.5831661224365234, 55.5062141418457, 0.3004436492919922, 0.47643089294433594, 0.3654670715332031, 0.18979835510253906, 50.67908477783203, 0.7278823852539062, 0.5724239349365234, 0.6531047821044922, 0.5500106811523438, 53.85719299316406, 0.5575542449951172, 0.8159160614013672, 0.22929000854492188, 0.5877437591552734, 0.3449573516845703, 0.4389972686767578, 0.4888763427734375, 0.2025909423828125, 0.24399185180664062, 0.4601173400878906, 55.09716033935547, 299.0993347167969, 0.7019004821777344, 55.32612609863281, 53.51823806762695, 0.18782424926757812, 0.24121856689453125, 0.7135295867919922, 0.10952377319335938, 0.3248577117919922, 0.5522842407226562, 0.5096321105957031, 0.7506675720214844, 0.41882896423339844, 0.16417884826660156, 0.7528419494628906, 50.95874786376953, 0.45165443420410156, 0.11730384826660156, 0.41138648986816406, 0.46840476989746094, 0.3497886657714844, 1.2080078125, 0.1299304962158203, 0.06139183044433594], "mean_td_error": 15.016244888305664, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 13367.0, "diff_num_grad_updates_vs_sampler_policy": 13366.0}}, "num_env_steps_sampled": 50100, "num_env_steps_trained": 3421952, "num_agent_steps_sampled": 50100, "num_agent_steps_trained": 3421952, "last_target_update_ts": 50100, "num_target_updates": 13367}, "sampler_results": {"episode_reward_max": -152.31337993592024, "episode_reward_min": -180.45381225645542, "episode_reward_mean": -167.01164238378405, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-166.2010705396533, -165.15286721289158, -177.13387587666512, -172.71380574256182, -180.45381225645542, -152.31337993592024, -169.01329336315393, -162.11746937781572, -170.08409921824932, -154.9327503144741], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1597138351683458, "mean_inference_ms": 2.3676077310685364, "mean_action_processing_ms": 0.22488010978207645, "mean_env_wait_ms": 2.959579776471321, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -152.31337993592024, "episode_reward_min": -180.45381225645542, "episode_reward_mean": -167.01164238378405, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-166.2010705396533, -165.15286721289158, -177.13387587666512, -172.71380574256182, -180.45381225645542, -152.31337993592024, -169.01329336315393, -162.11746937781572, -170.08409921824932, -154.9327503144741], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1597138351683458, "mean_inference_ms": 2.3676077310685364, "mean_action_processing_ms": 0.22488010978207645, "mean_env_wait_ms": 2.959579776471321, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 50100, "num_agent_steps_trained": 3421952, "num_env_steps_sampled": 50100, "num_env_steps_trained": 3421952, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 50100, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 50100, "timers": {"training_iteration_time_ms": 156.406, "load_time_ms": 0.288, "load_throughput": 887830.184, "learn_time_ms": 25.447, "learn_throughput": 10060.092, "synch_weights_time_ms": 5.837}, "counters": {"num_env_steps_sampled": 50100, "num_env_steps_trained": 3421952, "num_agent_steps_sampled": 50100, "num_agent_steps_trained": 3421952, "last_target_update_ts": 50100, "num_target_updates": 13367}, "done": false, "episodes_total": 512, "training_iteration": 50, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-10-52", "timestamp": 1675951852, "time_this_iter_s": 52.5621771812439, "time_total_s": 2159.37548494339, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb8b0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ece50>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2159.37548494339, "timesteps_since_restore": 0, "iterations_since_restore": 50, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.669444444444444, "ram_util_percent": 89.3736111111111}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 4.558913707733154, "actor_loss": 56.890830993652344, "critic_loss": 0.622977077960968, "alpha_loss": -17.916027069091797, "alpha_value": 0.019645843654870987, "log_alpha_value": -3.929889440536499, "target_entropy": -5.0, "policy_t": -0.3583984673023224, "mean_q": -56.8427734375, "max_q": -51.795440673828125, "min_q": -60.02763748168945}, "td_error": [57.109622955322266, 0.3543415069580078, 0.4438152313232422, 55.62726974487305, 0.33611297607421875, 0.5610904693603516, 0.5950603485107422, 55.27022171020508, 0.42029380798339844, 0.6332206726074219, 58.29810333251953, 0.1851806640625, 0.7812652587890625, 0.29523468017578125, 0.2406024932861328, 301.28631591796875, 0.40303611755371094, 0.03472709655761719, 0.05636024475097656, 0.5414257049560547, 305.5487060546875, 0.5392570495605469, 0.8877449035644531, 304.78216552734375, 0.4612998962402344, 0.36224937438964844, 52.158748626708984, 0.08366012573242188, 0.28125762939453125, 0.6459197998046875, 0.4635791778564453, 0.44606781005859375, 0.28005218505859375, 0.17705917358398438, 0.2732105255126953, 0.10597991943359375, 0.3892669677734375, 0.5206699371337891, 0.5335674285888672, 0.42075347900390625, 0.3938121795654297, 54.59008026123047, 0.7249336242675781, 0.03843498229980469, 0.3262939453125, 0.3918876647949219, 0.11482429504394531, 0.4070148468017578, 0.2760887145996094, 0.15356826782226562, 0.2842693328857422, 0.6253013610839844, 54.67680740356445, 53.75617218017578, 57.07141876220703, 303.56561279296875, 57.728492736816406, 0.30037879943847656, 0.2576446533203125, 0.35014915466308594, 0.5634937286376953, 0.2531700134277344, 0.835235595703125, 0.6126537322998047, 55.23191833496094, 57.261749267578125, 0.6132717132568359, 0.21660423278808594, 0.08126258850097656, 50.518028259277344, 0.41090965270996094, 0.6104984283447266, 54.67811584472656, 0.43720245361328125, 0.10490989685058594, 0.5419178009033203, 0.7474327087402344, 0.052520751953125, 0.10988807678222656, 0.5822124481201172, 0.2986488342285156, 0.37633705139160156, 0.6152496337890625, 0.3047676086425781, 0.4488658905029297, 0.7135143280029297, 57.43684387207031, 0.59814453125, 0.5789413452148438, 0.6664638519287109, 0.2193584442138672, 0.2420482635498047, 0.3458423614501953, 0.39107513427734375, 0.31995391845703125, 0.7220745086669922, 0.1662139892578125, 0.3459205627441406, 0.6260833740234375, 0.42765235900878906, 54.010799407958984, 0.2550334930419922, 0.1598052978515625, 0.2780494689941406, 0.5589237213134766, 303.33062744140625, 0.4964790344238281, 0.6294536590576172, 0.3666229248046875, 55.67350769042969, 56.737159729003906, 0.6860790252685547, 0.1573486328125, 0.5460605621337891, 0.7304134368896484, 57.861061096191406, 0.6690921783447266, 0.0520477294921875, 0.4579811096191406, 0.09312248229980469, 0.36691856384277344, 54.929908752441406, 50.696739196777344, 0.8614311218261719, 0.36960792541503906, 0.6784629821777344, 0.4816169738769531, 0.34908294677734375, 0.5005397796630859, 0.6492214202880859, 0.3412284851074219, 0.56011962890625, 0.4330921173095703, 0.06796836853027344, 0.48461151123046875, 0.18224143981933594, 0.6483097076416016, 0.22851943969726562, 0.05447196960449219, 0.5673770904541016, 0.5873031616210938, 0.14121627807617188, 0.022918701171875, 0.5774288177490234, 0.10356903076171875, 54.692848205566406, 0.4213294982910156, 0.5363922119140625, 0.3240184783935547, 53.330108642578125, 0.3679389953613281, 54.60836410522461, 0.42271995544433594, 0.4144134521484375, 0.11142921447753906, 0.11626815795898438, 0.23734092712402344, 0.42238807678222656, 52.158748626708984, 0.6953029632568359, 0.4140167236328125, 0.21954917907714844, 0.7375392913818359, 56.706993103027344, 56.62053680419922, 55.853126525878906, 0.5739479064941406, 0.08395576477050781, 0.467620849609375, 0.24892044067382812, 57.26911163330078, 0.6069469451904297, 0.236572265625, 0.6359958648681641, 54.09684753417969, 304.1152648925781, 0.14971160888671875, 0.31925010681152344, 0.4150066375732422, 0.8790225982666016, 0.5809764862060547, 0.3233528137207031, 0.4101715087890625, 0.2067699432373047, 0.2589530944824219, 0.7343292236328125, 0.13353347778320312, 0.08496475219726562, 0.24825477600097656, 56.067264556884766, 0.2470550537109375, 0.28318214416503906, 0.2543468475341797, 0.5381698608398438, 0.27558135986328125, 0.2208232879638672, 57.89546203613281, 0.42272186279296875, 0.5457649230957031, 0.11712646484375, 0.04811859130859375, 0.2267284393310547, 53.364784240722656, 0.24681472778320312, 0.5296726226806641, 52.49449157714844, 0.7554798126220703, 0.7680320739746094, 0.36739158630371094, 0.13901710510253906, 0.22919464111328125, 0.8709487915039062, 0.35508155822753906, 0.42758941650390625, 0.2989082336425781, 0.1383075714111328, 0.029247283935546875, 55.359703063964844, 0.64654541015625, 304.03363037109375, 0.1610546112060547, 0.8179855346679688, 0.14776992797851562, 0.2503852844238281, 0.3151741027832031, 0.8422298431396484, 0.5406951904296875, 0.27225303649902344, 0.3970909118652344, 0.1597766876220703, 0.43241119384765625, 0.44141578674316406, 0.5435009002685547, 57.48834991455078, 0.532958984375, 0.5820827484130859, 0.22263145446777344, 0.5103740692138672, 0.09406089782714844, 0.7174873352050781, 0.380157470703125, 53.798431396484375, 0.14931297302246094, 0.40483665466308594, 0.5789527893066406, 0.30390167236328125, 0.3556041717529297, 0.2715415954589844, 0.071136474609375, 0.8145732879638672, 0.05170440673828125, 57.03900146484375, 0.15237045288085938, 0.05872535705566406, 0.3584918975830078, 0.26407814025878906], "mean_td_error": 16.832103729248047, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 13701.0, "diff_num_grad_updates_vs_sampler_policy": 13700.0}}, "num_env_steps_sampled": 51102, "num_env_steps_trained": 3507456, "num_agent_steps_sampled": 51102, "num_agent_steps_trained": 3507456, "last_target_update_ts": 51102, "num_target_updates": 13701}, "sampler_results": {"episode_reward_max": -152.7232918664813, "episode_reward_min": -184.36629006266594, "episode_reward_mean": -171.7524909885092, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-177.88127502799034, -180.92025382816792, -176.51851931214333, -167.0416279733181, -174.85611286759377, -184.36629006266594, -164.09691985696554, -167.74666656553745, -152.7232918664813, -175.44189263135195, -167.6845508813858], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1784930727564988, "mean_inference_ms": 2.395031319027933, "mean_action_processing_ms": 0.22804207476988883, "mean_env_wait_ms": 2.99466412626673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -152.7232918664813, "episode_reward_min": -184.36629006266594, "episode_reward_mean": -171.7524909885092, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-177.88127502799034, -180.92025382816792, -176.51851931214333, -167.0416279733181, -174.85611286759377, -184.36629006266594, -164.09691985696554, -167.74666656553745, -152.7232918664813, -175.44189263135195, -167.6845508813858], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1784930727564988, "mean_inference_ms": 2.395031319027933, "mean_action_processing_ms": 0.22804207476988883, "mean_env_wait_ms": 2.99466412626673, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 51102, "num_agent_steps_trained": 3507456, "num_env_steps_sampled": 51102, "num_env_steps_trained": 3507456, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 51102, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 51102, "timers": {"training_iteration_time_ms": 154.129, "load_time_ms": 0.31, "load_throughput": 825130.119, "learn_time_ms": 25.893, "learn_throughput": 9886.925, "synch_weights_time_ms": 5.384}, "counters": {"num_env_steps_sampled": 51102, "num_env_steps_trained": 3507456, "num_agent_steps_sampled": 51102, "num_agent_steps_trained": 3507456, "last_target_update_ts": 51102, "num_target_updates": 13701}, "done": false, "episodes_total": 523, "training_iteration": 51, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-11-45", "timestamp": 1675951905, "time_this_iter_s": 52.303550243377686, "time_total_s": 2211.6790351867676, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef190>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2211.6790351867676, "timesteps_since_restore": 0, "iterations_since_restore": 51, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.91111111111112, "ram_util_percent": 89.57222222222222}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 3.6005947589874268, "actor_loss": 58.8569450378418, "critic_loss": 0.6942850351333618, "alpha_loss": -14.457460403442383, "alpha_value": 0.0180375799536705, "log_alpha_value": -4.015297889709473, "target_entropy": -5.0, "policy_t": -0.3796340525150299, "mean_q": -58.85035705566406, "max_q": -54.03670883178711, "min_q": -61.88453674316406}, "td_error": [0.14579200744628906, 58.34174346923828, 0.06899452209472656, 0.5708522796630859, 0.12118721008300781, 0.3951911926269531, 0.6159839630126953, 0.3701629638671875, 0.12474250793457031, 0.6894321441650391, 54.427894592285156, 0.16856002807617188, 0.5285682678222656, 58.530677795410156, 0.4728260040283203, 0.47986793518066406, 0.2312774658203125, 0.5704841613769531, 302.94970703125, 0.2030048370361328, 0.5937690734863281, 0.18066787719726562, 0.11095809936523438, 0.5353260040283203, 0.14203834533691406, 54.423561096191406, 0.25625038146972656, 0.5966587066650391, 0.5795001983642578, 59.873680114746094, 0.25217628479003906, 58.08648681640625, 0.26496315002441406, 0.6052780151367188, 0.2962493896484375, 53.949668884277344, 0.95806884765625, 0.48583984375, 0.3483314514160156, 0.4612617492675781, 0.35363006591796875, 0.1361217498779297, 0.4833564758300781, 0.6399993896484375, 0.29697608947753906, 57.204559326171875, 0.36685943603515625, 0.1683483123779297, 55.27602767944336, 0.5736522674560547, 0.13316726684570312, 0.127166748046875, 0.3670520782470703, 0.1378326416015625, 58.96806716918945, 0.1797618865966797, 0.3646526336669922, 0.1944255828857422, 56.507240295410156, 0.38088226318359375, 0.33502960205078125, 0.6926212310791016, 0.4025135040283203, 55.444427490234375, 0.09146881103515625, 0.5321731567382812, 0.3894329071044922, 0.5217170715332031, 0.9628257751464844, 0.5945587158203125, 0.4781646728515625, 0.5645694732666016, 0.8480415344238281, 0.7883205413818359, 0.29282569885253906, 0.05745697021484375, 0.5195636749267578, 0.17475509643554688, 0.6267261505126953, 0.3404426574707031, 0.14035606384277344, 0.6405086517333984, 0.4011669158935547, 58.387474060058594, 0.29065704345703125, 0.03340339660644531, 0.5547962188720703, 0.7941703796386719, 59.879173278808594, 0.20049285888671875, 0.040409088134765625, 0.02942657470703125, 0.41922950744628906, 0.2902412414550781, 0.49514198303222656, 0.1427936553955078, 0.4284343719482422, 0.3102455139160156, 0.41810035705566406, 53.5540885925293, 56.39815902709961, 0.4413928985595703, 0.22763633728027344, 0.43756103515625, 0.10531806945800781, 0.2666759490966797, 0.51287841796875, 0.7002811431884766, 58.06299591064453, 0.1606121063232422, 0.3578643798828125, 0.41655921936035156, 0.45398521423339844, 54.1525993347168, 0.14189720153808594, 56.789546966552734, 0.5264034271240234, 0.06595420837402344, 0.4793567657470703, 0.6438617706298828, 0.6544761657714844, 0.42315673828125, 0.6225452423095703, 0.08179664611816406, 0.1173858642578125, 0.4479217529296875, 0.29406166076660156, 0.12884902954101562, 55.666831970214844, 0.15373611450195312, 0.38228797912597656, 0.5673961639404297, 53.5540885925293, 0.4617748260498047, 56.507240295410156, 58.37995910644531, 0.30729103088378906, 57.24042892456055, 53.819698333740234, 0.6876735687255859, 0.5642223358154297, 0.424591064453125, 0.14829635620117188, 0.41887855529785156, 0.48929405212402344, 57.45487976074219, 0.7490863800048828, 0.11547660827636719, 0.6271266937255859, 0.05147552490234375, 55.187232971191406, 0.33682823181152344, 58.716888427734375, 0.12005805969238281, 0.5695247650146484, 0.5945262908935547, 0.9132003784179688, 0.5714797973632812, 53.11981964111328, 0.27024269104003906, 0.19313621520996094, 0.38149452209472656, 0.12902069091796875, 0.23192977905273438, 58.539161682128906, 0.8714084625244141, 306.37591552734375, 58.232566833496094, 0.5117435455322266, 0.6163330078125, 0.3744010925292969, 0.14209365844726562, 58.35304260253906, 59.23847961425781, 0.037586212158203125, 0.46402549743652344, 0.5719585418701172, 0.3571434020996094, 0.2010974884033203, 0.531951904296875, 0.45795249938964844, 0.46863365173339844, 0.08371543884277344, 0.4732513427734375, 0.2023792266845703, 306.31024169921875, 0.62298583984375, 0.6582603454589844, 0.2662677764892578, 0.11443901062011719, 0.12349891662597656, 0.13245010375976562, 0.2197551727294922, 0.6310043334960938, 58.93313980102539, 55.571739196777344, 0.36081886291503906, 0.16048240661621094, 0.3806591033935547, 58.73011779785156, 53.6685676574707, 0.20334243774414062, 0.6911983489990234, 0.3997955322265625, 0.2903251647949219, 0.5363216400146484, 0.4021282196044922, 0.48455047607421875, 0.3825206756591797, 0.4242820739746094, 53.949668884277344, 57.561302185058594, 0.5809097290039062, 0.17954063415527344, 0.3815593719482422, 58.24085235595703, 305.3302001953125, 0.8454875946044922, 0.24890899658203125, 59.82038879394531, 0.030576705932617188, 0.3442573547363281, 0.4239616394042969, 0.6077709197998047, 59.375606536865234, 0.4278297424316406, 0.6297874450683594, 0.5574989318847656, 58.615997314453125, 0.5077934265136719, 0.6788349151611328, 0.6809406280517578, 57.2009391784668, 0.362640380859375, 305.63897705078125, 0.42208099365234375, 0.5435123443603516, 0.5220298767089844, 0.08851242065429688, 302.94970703125, 0.5409221649169922, 0.32921409606933594, 54.71253204345703, 0.5672550201416016, 54.53571319580078, 0.18274307250976562, 0.2515678405761719, 0.1596202850341797, 0.5262908935546875, 0.7763252258300781, 59.19307327270508, 0.2776813507080078, 0.44277000427246094, 0.6247634887695312, 0.28484535217285156, 59.340492248535156], "mean_td_error": 18.126922607421875, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 14035.0, "diff_num_grad_updates_vs_sampler_policy": 14034.0}}, "num_env_steps_sampled": 52104, "num_env_steps_trained": 3592960, "num_agent_steps_sampled": 52104, "num_agent_steps_trained": 3592960, "last_target_update_ts": 52104, "num_target_updates": 14035}, "sampler_results": {"episode_reward_max": -158.65478856116533, "episode_reward_min": -187.4124725162983, "episode_reward_mean": -177.02790573984385, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-179.92599292099476, -170.8820983171463, -176.1663973480463, -183.63343332707882, -184.38870468735695, -178.17410226166248, -174.01316171884537, -158.65478856116533, -187.4124725162983], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1683279984762422, "mean_inference_ms": 2.3820202711216147, "mean_action_processing_ms": 0.22645537656995302, "mean_env_wait_ms": 2.980423446745467, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -158.65478856116533, "episode_reward_min": -187.4124725162983, "episode_reward_mean": -177.02790573984385, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-179.92599292099476, -170.8820983171463, -176.1663973480463, -183.63343332707882, -184.38870468735695, -178.17410226166248, -174.01316171884537, -158.65478856116533, -187.4124725162983], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1683279984762422, "mean_inference_ms": 2.3820202711216147, "mean_action_processing_ms": 0.22645537656995302, "mean_env_wait_ms": 2.980423446745467, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 52104, "num_agent_steps_trained": 3592960, "num_env_steps_sampled": 52104, "num_env_steps_trained": 3592960, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 52104, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 52104, "timers": {"training_iteration_time_ms": 153.388, "load_time_ms": 0.264, "load_throughput": 969168.539, "learn_time_ms": 24.985, "learn_throughput": 10246.117, "synch_weights_time_ms": 4.962}, "counters": {"num_env_steps_sampled": 52104, "num_env_steps_trained": 3592960, "num_agent_steps_sampled": 52104, "num_agent_steps_trained": 3592960, "last_target_update_ts": 52104, "num_target_updates": 14035}, "done": false, "episodes_total": 532, "training_iteration": 52, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-12-37", "timestamp": 1675951957, "time_this_iter_s": 52.606945514678955, "time_total_s": 2264.2859807014465, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbf40>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2264.2859807014465, "timesteps_since_restore": 0, "iterations_since_restore": 52, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.75694444444444, "ram_util_percent": 89.59166666666665}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 2.899827003479004, "actor_loss": 60.44023513793945, "critic_loss": 0.8240723609924316, "alpha_loss": -11.858055114746094, "alpha_value": 0.016752159222960472, "log_alpha_value": -4.08922815322876, "target_entropy": -5.0, "policy_t": -0.2252911627292633, "mean_q": -60.48311233520508, "max_q": -56.49126052856445, "min_q": -63.68833923339844}, "td_error": [0.3134479522705078, 58.54262161254883, 0.40537261962890625, 57.877906799316406, 0.9285354614257812, 0.31833648681640625, 0.18003463745117188, 0.2573070526123047, 0.7872695922851562, 0.167755126953125, 0.210540771484375, 0.4662933349609375, 54.4170036315918, 59.14588928222656, 59.509071350097656, 0.13474464416503906, 0.4577064514160156, 0.5480327606201172, 0.2019805908203125, 0.054790496826171875, 0.402679443359375, 61.19024658203125, 60.17154312133789, 306.58795166015625, 0.32082557678222656, 0.07968902587890625, 0.08858299255371094, 0.3231067657470703, 0.24033355712890625, 0.3891258239746094, 0.1813182830810547, 0.0602264404296875, 0.7706699371337891, 0.4510650634765625, 0.7791233062744141, 307.5420837402344, 0.3255805969238281, 309.439697265625, 60.48261260986328, 0.47548484802246094, 0.2253894805908203, 0.5307826995849609, 0.1886920928955078, 56.222129821777344, 60.822669982910156, 0.5480251312255859, 0.5621738433837891, 306.99896240234375, 0.8773765563964844, 60.00676727294922, 0.5295257568359375, 0.28526878356933594, 1.0210609436035156, 308.41192626953125, 0.02074432373046875, 0.39540863037109375, 0.6969470977783203, 60.16438293457031, 0.4324817657470703, 0.45680999755859375, 60.134765625, 0.37595367431640625, 60.1533088684082, 0.4618377685546875, 0.5845718383789062, 0.5938758850097656, 0.42583274841308594, 0.1924419403076172, 0.7287673950195312, 60.478355407714844, 0.48769187927246094, 0.5829715728759766, 0.1530132293701172, 0.26836204528808594, 0.08771705627441406, 0.1521167755126953, 0.6426811218261719, 0.42222023010253906, 0.3179054260253906, 0.045406341552734375, 0.08063507080078125, 0.18091583251953125, 0.1257801055908203, 0.6400394439697266, 0.4442863464355469, 0.04136085510253906, 0.07739830017089844, 0.0560150146484375, 58.883705139160156, 61.564453125, 60.560020446777344, 0.2236194610595703, 0.7254467010498047, 0.474151611328125, 0.18742752075195312, 0.5441379547119141, 0.23704910278320312, 0.6371517181396484, 0.4926109313964844, 59.41205596923828, 0.054576873779296875, 0.88824462890625, 0.7253761291503906, 0.4645118713378906, 0.6659088134765625, 55.70779037475586, 0.5737342834472656, 0.3518657684326172, 0.4069080352783203, 0.5568008422851562, 0.3305320739746094, 54.47449493408203, 0.16893959045410156, 0.5860748291015625, 56.786651611328125, 0.5963268280029297, 0.4746131896972656, 0.5998477935791016, 0.22162437438964844, 0.33072853088378906, 0.3111457824707031, 0.13420486450195312, 0.4355354309082031, 60.382259368896484, 0.2050342559814453, 0.31034278869628906, 0.24318313598632812, 0.5198268890380859, 0.4146308898925781, 0.5815792083740234, 60.493404388427734, 0.7427883148193359, 0.6439304351806641, 60.493553161621094, 0.8431682586669922, 0.2520637512207031, 0.07522964477539062, 0.36829376220703125, 58.1185302734375, 0.22851943969726562, 0.06878662109375, 58.88597106933594, 0.07998466491699219, 0.1960926055908203, 0.2943744659423828, 0.6517066955566406, 0.5155048370361328, 0.3287620544433594, 0.41928672790527344, 0.4810771942138672, 0.21833229064941406, 57.877906799316406, 55.810760498046875, 58.4954719543457, 0.15596389770507812, 0.4834117889404297, 56.37323760986328, 0.5632686614990234, 0.5075969696044922, 0.25226402282714844, 0.3861885070800781, 0.6010456085205078, 59.41205596923828, 308.41192626953125, 0.5303573608398438, 0.5245590209960938, 57.314849853515625, 0.4852466583251953, 0.6029052734375, 0.15261268615722656, 0.15996742248535156, 0.5043735504150391, 0.09762382507324219, 0.35079002380371094, 57.78407287597656, 307.4967041015625, 0.39422607421875, 0.5041370391845703, 0.9039077758789062, 0.37662506103515625, 0.6356372833251953, 0.09128379821777344, 60.804283142089844, 55.67615509033203, 0.30138206481933594, 60.227264404296875, 0.6955356597900391, 0.5219631195068359, 0.08034515380859375, 0.4535980224609375, 0.16881179809570312, 0.22555923461914062, 0.5279960632324219, 0.15693283081054688, 0.4031105041503906, 307.4967041015625, 0.19388771057128906, 0.7102241516113281, 0.33878517150878906, 0.2857093811035156, 0.3709144592285156, 0.41840171813964844, 0.3423881530761719, 0.2657203674316406, 59.69196319580078, 0.4337806701660156, 0.4409294128417969, 0.3379974365234375, 0.49993133544921875, 0.43731689453125, 0.2710151672363281, 60.37114334106445, 58.04987335205078, 0.5844612121582031, 0.40661048889160156, 0.3875865936279297, 0.7843761444091797, 0.233734130859375, 0.5798797607421875, 61.07353973388672, 0.22207069396972656, 0.45885276794433594, 0.4082145690917969, 58.4954719543457, 0.3431568145751953, 54.83632278442383, 0.19651412963867188, 0.24692916870117188, 0.5362968444824219, 0.06460189819335938, 58.350257873535156, 0.5984439849853516, 308.1263122558594, 0.5591049194335938, 0.19394493103027344, 58.28282165527344, 0.3244514465332031, 56.05864715576172, 0.8023757934570312, 0.6691703796386719, 0.5357933044433594, 0.5649909973144531, 0.177032470703125, 0.24176406860351562, 0.4574565887451172, 0.3853492736816406, 0.16277694702148438, 0.03874015808105469, 60.582489013671875, 0.5536174774169922, 0.5229015350341797, 60.0020866394043, 0.46210479736328125, 57.199520111083984, 0.4894542694091797, 0.21898269653320312], "mean_td_error": 22.368223190307617, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 14369.0, "diff_num_grad_updates_vs_sampler_policy": 14368.0}}, "num_env_steps_sampled": 53106, "num_env_steps_trained": 3678464, "num_agent_steps_sampled": 53106, "num_agent_steps_trained": 3678464, "last_target_update_ts": 53106, "num_target_updates": 14369}, "sampler_results": {"episode_reward_max": -162.54527327418327, "episode_reward_min": -180.6045781970024, "episode_reward_mean": -173.49289328232408, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.80859266221523, -162.54527327418327, -180.6045781970024, -168.33786635100842, -176.6122608780861, -178.73005056381226, -174.1295227855444, -171.88962145149708, -179.38428509235382, -171.88688156753778], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1573509450000015, "mean_inference_ms": 2.36857895904198, "mean_action_processing_ms": 0.22478369759320066, "mean_env_wait_ms": 2.961575403823857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -162.54527327418327, "episode_reward_min": -180.6045781970024, "episode_reward_mean": -173.49289328232408, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.80859266221523, -162.54527327418327, -180.6045781970024, -168.33786635100842, -176.6122608780861, -178.73005056381226, -174.1295227855444, -171.88962145149708, -179.38428509235382, -171.88688156753778], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1573509450000015, "mean_inference_ms": 2.36857895904198, "mean_action_processing_ms": 0.22478369759320066, "mean_env_wait_ms": 2.961575403823857, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 53106, "num_agent_steps_trained": 3678464, "num_env_steps_sampled": 53106, "num_env_steps_trained": 3678464, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 53106, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 53106, "timers": {"training_iteration_time_ms": 178.635, "load_time_ms": 0.311, "load_throughput": 822727.625, "learn_time_ms": 27.441, "learn_throughput": 9329.106, "synch_weights_time_ms": 7.622}, "counters": {"num_env_steps_sampled": 53106, "num_env_steps_trained": 3678464, "num_agent_steps_sampled": 53106, "num_agent_steps_trained": 3678464, "last_target_update_ts": 53106, "num_target_updates": 14369}, "done": false, "episodes_total": 542, "training_iteration": 53, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-13-30", "timestamp": 1675952010, "time_this_iter_s": 52.932852268218994, "time_total_s": 2317.2188329696655, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fbcd0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057bb80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2317.2188329696655, "timesteps_since_restore": 0, "iterations_since_restore": 53, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.131506849315066, "ram_util_percent": 89.5095890410959}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 1.3337559700012207, "actor_loss": 61.90546417236328, "critic_loss": 0.7591338157653809, "alpha_loss": -5.545193195343018, "alpha_value": 0.015645412728190422, "log_alpha_value": -4.1575775146484375, "target_entropy": -5.0, "policy_t": -0.29823797941207886, "mean_q": -62.05267333984375, "max_q": -57.278778076171875, "min_q": -65.0610580444336}, "td_error": [0.8616962432861328, 0.09133338928222656, 1.0342559814453125, 0.41289520263671875, 0.10116958618164062, 0.14415740966796875, 309.85968017578125, 61.01647186279297, 61.981536865234375, 0.3383140563964844, 0.3058185577392578, 0.5179939270019531, 0.2385082244873047, 0.2785606384277344, 62.87974548339844, 0.15198516845703125, 0.4085540771484375, 0.6805419921875, 0.3281993865966797, 0.12162971496582031, 0.4515419006347656, 0.7137107849121094, 0.17688369750976562, 0.276031494140625, 0.556976318359375, 61.472084045410156, 61.889183044433594, 0.5694408416748047, 0.1470813751220703, 61.997398376464844, 0.3199806213378906, 0.24983978271484375, 0.29355621337890625, 0.3266944885253906, 57.694374084472656, 61.90449523925781, 0.4216022491455078, 0.4501514434814453, 62.223785400390625, 0.22167205810546875, 0.4278564453125, 0.12193679809570312, 0.08716964721679688, 0.7221698760986328, 0.2894134521484375, 61.52044677734375, 1.0476341247558594, 0.5734996795654297, 61.07611083984375, 62.153717041015625, 56.09113693237305, 60.80962371826172, 0.37135887145996094, 56.03382110595703, 0.32171630859375, 61.47270584106445, 0.30821800231933594, 62.32865905761719, 0.4309539794921875, 0.6672687530517578, 0.3356952667236328, 0.24919509887695312, 0.4717674255371094, 0.04884529113769531, 0.3768177032470703, 0.3281974792480469, 0.9934520721435547, 0.48856544494628906, 0.5686626434326172, 0.38832664489746094, 0.5091056823730469, 0.48093414306640625, 0.08229446411132812, 0.4288311004638672, 0.6941547393798828, 0.11656570434570312, 57.0944709777832, 0.4722404479980469, 0.6363105773925781, 0.10964202880859375, 0.573944091796875, 0.4919013977050781, 0.5559158325195312, 57.944854736328125, 0.44274330139160156, 0.44875526428222656, 0.8038711547851562, 59.44721984863281, 0.42349815368652344, 0.5461826324462891, 58.47241973876953, 0.4876117706298828, 0.18079757690429688, 0.35173797607421875, 0.5571765899658203, 0.35474205017089844, 0.10146713256835938, 60.235801696777344, 0.5006065368652344, 0.19138145446777344, 0.4211006164550781, 61.44976043701172, 0.3770179748535156, 0.11186981201171875, 62.06256103515625, 0.4548664093017578, 0.036731719970703125, 0.3438873291015625, 0.4801063537597656, 0.4992866516113281, 0.3036231994628906, 0.2412109375, 0.3207073211669922, 0.6034488677978516, 61.909706115722656, 0.6229667663574219, 0.4480552673339844, 0.4029064178466797, 0.8371047973632812, 0.4959583282470703, 0.14474868774414062, 0.3080596923828125, 1.3381156921386719, 0.16548538208007812, 0.5701694488525391, 0.14641571044921875, 0.6244678497314453, 0.9785118103027344, 0.4657020568847656, 0.23297119140625, 60.487178802490234, 0.2804756164550781, 0.2599525451660156, 0.3458747863769531, 59.620670318603516, 0.26941871643066406, 0.33996009826660156, 0.3189525604248047, 0.18152809143066406, 0.2812843322753906, 0.23443984985351562, 61.695037841796875, 60.85887145996094, 60.88011932373047, 0.4323463439941406, 0.41848182678222656, 0.27408790588378906, 0.7375450134277344, 0.4093742370605469, 0.25837135314941406, 60.932106018066406, 0.2568702697753906, 0.2087860107421875, 0.5344333648681641, 0.5761871337890625, 306.91912841796875, 0.3682079315185547, 0.2980766296386719, 58.03860855102539, 62.073158264160156, 56.9541130065918, 0.6510200500488281, 0.5460414886474609, 0.17374038696289062, 0.4471874237060547, 0.7509994506835938, 58.19734191894531, 0.388458251953125, 0.25571250915527344, 308.77935791015625, 0.4203681945800781, 0.14748191833496094, 0.2511463165283203, 62.01720428466797, 0.3929290771484375, 0.1279449462890625, 62.25537872314453, 0.6897850036621094, 0.1751079559326172, 0.6543121337890625, 0.3495769500732422, 0.14665603637695312, 62.22943878173828, 0.47924041748046875, 1.0852527618408203, 0.048412322998046875, 0.35534095764160156, 0.6583137512207031, 0.4307117462158203, 0.6384162902832031, 60.324310302734375, 0.26569366455078125, 0.33841514587402344, 0.47060203552246094, 0.5111904144287109, 0.3051738739013672, 0.17568206787109375, 0.3176116943359375, 1.0285682678222656, 0.33521080017089844, 0.2875862121582031, 0.3406524658203125, 0.6183090209960938, 0.6495704650878906, 0.47083091735839844, 0.4982643127441406, 62.28358459472656, 0.32753562927246094, 61.64961242675781, 0.30823516845703125, 60.80962371826172, 0.5271568298339844, 0.33441925048828125, 0.6713523864746094, 0.5001640319824219, 0.04473686218261719, 0.1589374542236328, 0.4023323059082031, 59.72437286376953, 59.44721984863281, 0.3099937438964844, 57.269927978515625, 0.10846328735351562, 0.1802845001220703, 0.26959800720214844, 0.25048828125, 0.033905029296875, 0.35898590087890625, 58.73553466796875, 306.91912841796875, 62.315616607666016, 0.6499214172363281, 0.41924285888671875, 0.13891220092773438, 0.6218681335449219, 0.3892478942871094, 60.79081726074219, 58.86095428466797, 0.21266937255859375, 0.3901538848876953, 0.0986785888671875, 308.486572265625, 0.35639190673828125, 0.25679588317871094, 0.6652965545654297, 0.6601600646972656, 0.2897510528564453, 308.68701171875, 0.5345611572265625, 0.19052505493164062, 58.830467224121094, 62.027976989746094, 0.1295013427734375, 0.4136543273925781, 57.66595458984375, 0.31662940979003906], "mean_td_error": 19.799991607666016, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 14703.0, "diff_num_grad_updates_vs_sampler_policy": 14702.0}}, "num_env_steps_sampled": 54108, "num_env_steps_trained": 3763968, "num_agent_steps_sampled": 54108, "num_agent_steps_trained": 3763968, "last_target_update_ts": 54108, "num_target_updates": 14703}, "sampler_results": {"episode_reward_max": 172.17469937354326, "episode_reward_min": -178.04978723824024, "episode_reward_mean": -111.83921558206731, "episode_len_mean": 92.54545454545455, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-152.32089486718178, -168.6792200356722, 172.17469937354326, -174.37111976742744, -178.04978723824024, -161.35409639030695, -173.27450999617577, -175.17871895432472, -175.17226216197014, -168.80600002408028, 124.80053865909576], "episode_lengths": [100, 100, 45, 100, 100, 100, 100, 100, 100, 100, 73]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1781361143589992, "mean_inference_ms": 2.3995323424176904, "mean_action_processing_ms": 0.22811804378349382, "mean_env_wait_ms": 3.0050410073267106, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 172.17469937354326, "episode_reward_min": -178.04978723824024, "episode_reward_mean": -111.83921558206731, "episode_len_mean": 92.54545454545455, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-152.32089486718178, -168.6792200356722, 172.17469937354326, -174.37111976742744, -178.04978723824024, -161.35409639030695, -173.27450999617577, -175.17871895432472, -175.17226216197014, -168.80600002408028, 124.80053865909576], "episode_lengths": [100, 100, 45, 100, 100, 100, 100, 100, 100, 100, 73]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1781361143589992, "mean_inference_ms": 2.3995323424176904, "mean_action_processing_ms": 0.22811804378349382, "mean_env_wait_ms": 3.0050410073267106, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 54108, "num_agent_steps_trained": 3763968, "num_env_steps_sampled": 54108, "num_env_steps_trained": 3763968, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 54108, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 54108, "timers": {"training_iteration_time_ms": 172.22, "load_time_ms": 0.322, "load_throughput": 793835.446, "learn_time_ms": 34.221, "learn_throughput": 7480.78, "synch_weights_time_ms": 5.883}, "counters": {"num_env_steps_sampled": 54108, "num_env_steps_trained": 3763968, "num_agent_steps_sampled": 54108, "num_agent_steps_trained": 3763968, "last_target_update_ts": 54108, "num_target_updates": 14703}, "done": false, "episodes_total": 553, "training_iteration": 54, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-14-27", "timestamp": 1675952067, "time_this_iter_s": 56.83306169509888, "time_total_s": 2374.0518946647644, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb580>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10576430>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2374.0518946647644, "timesteps_since_restore": 0, "iterations_since_restore": 54, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 45.34358974358974, "ram_util_percent": 90.55128205128203}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.15761791169643402, "actor_loss": 63.56652069091797, "critic_loss": 0.611660361289978, "alpha_loss": 0.6567165851593018, "alpha_value": 0.015506288036704063, "log_alpha_value": -4.166509628295898, "target_entropy": -5.0, "policy_t": -0.28592029213905334, "mean_q": -63.663150787353516, "max_q": -59.64216232299805, "min_q": -66.5217056274414}, "td_error": [0.3693046569824219, 0.2569847106933594, 59.33385467529297, 0.12304306030273438, 0.5699062347412109, 0.6429862976074219, 0.22260284423828125, 0.13239669799804688, 0.5756244659423828, 0.19472503662109375, 63.37153625488281, 0.48529052734375, 61.862823486328125, 0.6503391265869141, 0.15869903564453125, 0.5205631256103516, 57.9787712097168, 0.4881458282470703, 0.44837188720703125, 0.5630912780761719, 0.1166839599609375, 0.14678573608398438, 57.2852783203125, 0.07262420654296875, 0.8629779815673828, 0.051105499267578125, 0.5090980529785156, 63.57686233520508, 0.5897712707519531, 0.7399711608886719, 0.16048049926757812, 0.5995330810546875, 62.35093307495117, 0.6289482116699219, 0.64337158203125, 0.2795906066894531, 0.19665145874023438, 62.927833557128906, 0.3477058410644531, 63.62664031982422, 0.7032852172851562, 57.983612060546875, 0.281463623046875, 0.4909820556640625, 0.6066722869873047, 0.3880043029785156, 0.24445343017578125, 0.3360023498535156, 0.20527076721191406, 0.6029472351074219, 0.18822479248046875, 312.2745361328125, 1.2474708557128906, 0.6326713562011719, 64.0133285522461, 0.18354034423828125, 0.770599365234375, 63.77090835571289, 62.73993682861328, 0.3952045440673828, 0.25324249267578125, 0.3310890197753906, 1.4439620971679688, 0.1912364959716797, 0.1335468292236328, 63.69556427001953, 0.6528282165527344, 0.4503440856933594, 0.4508857727050781, 0.8238372802734375, 0.2303447723388672, 0.40616607666015625, 0.44396209716796875, 1.109375, 0.5567550659179688, 0.11348152160644531, 61.47333526611328, 63.83973693847656, 0.281707763671875, 0.3749656677246094, 0.13225555419921875, 0.3860054016113281, 0.7005081176757812, 0.5326461791992188, 0.3115673065185547, 1.1346282958984375, 0.43457603454589844, 62.573238372802734, 0.4871101379394531, 0.5601425170898438, 0.40177154541015625, 0.07931327819824219, 0.5321636199951172, 0.6541595458984375, 0.28937530517578125, 0.5378379821777344, 0.6472206115722656, 0.4304237365722656, 0.11446762084960938, 0.7167186737060547, 61.369117736816406, 0.6297492980957031, 0.5936317443847656, 0.2910804748535156, 0.4764060974121094, 0.4241218566894531, 0.3068389892578125, 0.6484222412109375, 0.4257240295410156, 0.2995281219482422, 0.4207267761230469, 1.0063514709472656, 58.457366943359375, 0.3791694641113281, 58.863853454589844, 311.08843994140625, 0.17565155029296875, 0.28890228271484375, 0.0361175537109375, 0.07463836669921875, 0.22672271728515625, 62.494930267333984, 0.6435127258300781, 0.377593994140625, 0.5245552062988281, 0.38573455810546875, 0.7018280029296875, 0.4418067932128906, 61.36682891845703, 0.1736297607421875, 0.0827484130859375, 0.32514190673828125, 0.06951522827148438, 0.9111824035644531, 0.04776763916015625, 0.24224472045898438, 0.132476806640625, 309.98114013671875, 0.3421745300292969, 0.5707550048828125, 0.7021656036376953, 0.2154998779296875, 0.46607017517089844, 0.2516593933105469, 0.10082626342773438, 0.09395599365234375, 0.090301513671875, 0.5694961547851562, 0.3853797912597656, 311.4000244140625, 63.19164276123047, 0.5265159606933594, 0.2123565673828125, 0.3166007995605469, 0.2242412567138672, 59.25341796875, 0.6039352416992188, 0.7376670837402344, 0.6574630737304688, 0.32666969299316406, 0.6874771118164062, 311.03662109375, 0.16598892211914062, 0.5480575561523438, 0.54534912109375, 62.98938751220703, 0.5675621032714844, 0.0699005126953125, 1.0286445617675781, 0.4446582794189453, 0.46843719482421875, 0.1024169921875, 0.825836181640625, 0.5500526428222656, 0.19484710693359375, 0.4708404541015625, 0.5416278839111328, 59.550559997558594, 0.5768280029296875, 0.2573089599609375, 64.59317016601562, 0.5364151000976562, 0.8103523254394531, 0.6135368347167969, 0.13831329345703125, 0.12016105651855469, 62.691558837890625, 0.19673919677734375, 0.6766929626464844, 0.3807353973388672, 0.37862396240234375, 59.76396179199219, 0.7812004089355469, 63.83340072631836, 60.59181213378906, 0.18236923217773438, 0.4094371795654297, 0.06914329528808594, 0.22087860107421875, 0.6156005859375, 0.48907470703125, 0.057460784912109375, 0.5215988159179688, 64.45402526855469, 0.5095176696777344, 0.3362693786621094, 63.34235382080078, 0.4028282165527344, 61.224830627441406, 0.7336273193359375, 0.8166542053222656, 0.04328155517578125, 0.4427986145019531, 0.3273296356201172, 0.6426753997802734, 0.06484603881835938, 0.41112327575683594, 0.33010101318359375, 0.6112709045410156, 0.31713294982910156, 0.4203605651855469, 0.5948600769042969, 0.5006484985351562, 1.1236019134521484, 0.575469970703125, 0.6217765808105469, 0.4394702911376953, 0.3955707550048828, 0.3288230895996094, 0.16823959350585938, 0.10675048828125, 0.060703277587890625, 0.2739582061767578, 0.13576126098632812, 61.48636245727539, 0.6508216857910156, 63.39413070678711, 61.8763313293457, 0.6668205261230469, 0.5813236236572266, 0.38509368896484375, 0.5046348571777344, 0.7719631195068359, 63.85416793823242, 0.6829414367675781, 0.09708404541015625, 0.09660720825195312, 0.5681095123291016, 60.696739196777344, 0.35460662841796875, 0.6084442138671875, 0.5189228057861328, 0.3613777160644531, 61.63841247558594, 0.19187164306640625, 0.7714576721191406], "mean_td_error": 16.094013214111328, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 15037.0, "diff_num_grad_updates_vs_sampler_policy": 15036.0}}, "num_env_steps_sampled": 55110, "num_env_steps_trained": 3849472, "num_agent_steps_sampled": 55110, "num_agent_steps_trained": 3849472, "last_target_update_ts": 55110, "num_target_updates": 15037}, "sampler_results": {"episode_reward_max": -162.88143733888865, "episode_reward_min": -178.88590398430824, "episode_reward_mean": -173.37141248854724, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-178.19854023307562, -162.88143733888865, -177.13169145584106, -173.54518923163414, -178.88590398430824, -173.42413312196732, -174.1886915564537, -171.58526647090912, -175.8660365343094, -166.32416386902332, -175.05448357760906], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1695335327833603, "mean_inference_ms": 2.3877673399442436, "mean_action_processing_ms": 0.2269276792489708, "mean_env_wait_ms": 2.9990432795473727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -162.88143733888865, "episode_reward_min": -178.88590398430824, "episode_reward_mean": -173.37141248854724, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-178.19854023307562, -162.88143733888865, -177.13169145584106, -173.54518923163414, -178.88590398430824, -173.42413312196732, -174.1886915564537, -171.58526647090912, -175.8660365343094, -166.32416386902332, -175.05448357760906], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1695335327833603, "mean_inference_ms": 2.3877673399442436, "mean_action_processing_ms": 0.2269276792489708, "mean_env_wait_ms": 2.9990432795473727, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 55110, "num_agent_steps_trained": 3849472, "num_env_steps_sampled": 55110, "num_env_steps_trained": 3849472, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 55110, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 55110, "timers": {"training_iteration_time_ms": 165.069, "load_time_ms": 0.29, "load_throughput": 881489.06, "learn_time_ms": 25.891, "learn_throughput": 9887.444, "synch_weights_time_ms": 5.813}, "counters": {"num_env_steps_sampled": 55110, "num_env_steps_trained": 3849472, "num_agent_steps_sampled": 55110, "num_agent_steps_trained": 3849472, "last_target_update_ts": 55110, "num_target_updates": 15037}, "done": false, "episodes_total": 564, "training_iteration": 55, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-15-22", "timestamp": 1675952122, "time_this_iter_s": 54.77003026008606, "time_total_s": 2428.8219249248505, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb3d0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2428.8219249248505, "timesteps_since_restore": 0, "iterations_since_restore": 55, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 43.56891891891892, "ram_util_percent": 90.65270270270271}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.11838145554065704, "actor_loss": 65.24921417236328, "critic_loss": 0.6665303111076355, "alpha_loss": 0.4936535358428955, "alpha_value": 0.015451882965862751, "log_alpha_value": -4.170024394989014, "target_entropy": -5.0, "policy_t": -0.3245686888694763, "mean_q": -65.30184936523438, "max_q": -60.977622985839844, "min_q": -69.28939819335938}, "td_error": [0.4795799255371094, 0.5413341522216797, 0.16504669189453125, 0.6524581909179688, 0.24648284912109375, 0.2550544738769531, 0.6335525512695312, 0.43599510192871094, 0.2916450500488281, 0.14882278442382812, 0.6971378326416016, 0.44680023193359375, 0.07976913452148438, 0.21622467041015625, 0.167388916015625, 65.48757934570312, 0.6409702301025391, 0.11011886596679688, 65.05702209472656, 0.11751365661621094, 0.8403987884521484, 0.631683349609375, 0.578887939453125, 0.5041294097900391, 0.15514755249023438, 0.28163909912109375, 65.37696838378906, 0.6246433258056641, 0.7265052795410156, 0.12828445434570312, 65.30233001708984, 0.5552444458007812, 0.2580718994140625, 0.23175430297851562, 0.6721000671386719, 314.13177490234375, 65.21005249023438, 0.4992332458496094, 0.22643280029296875, 1.1312446594238281, 0.4388389587402344, 59.560462951660156, 0.269134521484375, 65.13816833496094, 0.2753334045410156, 0.36843109130859375, 0.24330902099609375, 0.19256973266601562, 65.35598754882812, 0.1013641357421875, 0.7034759521484375, 0.28261566162109375, 0.23981475830078125, 0.26226806640625, 0.22230148315429688, 61.492408752441406, 0.2561836242675781, 0.07448577880859375, 0.192626953125, 0.5236892700195312, 0.5202140808105469, 0.04806327819824219, 0.25225830078125, 0.3200225830078125, 0.6774826049804688, 64.59496307373047, 0.09965896606445312, 0.7785415649414062, 64.38412475585938, 0.7359199523925781, 0.21853256225585938, 60.670310974121094, 0.3840522766113281, 0.7247200012207031, 0.22245407104492188, 0.7529735565185547, 0.45236968994140625, 0.5109634399414062, 0.6489334106445312, 0.7585258483886719, 0.25566864013671875, 0.7914161682128906, 0.22205162048339844, 0.28112030029296875, 0.3524360656738281, 0.3921661376953125, 0.27121734619140625, 63.7140998840332, 0.20147323608398438, 0.3254432678222656, 0.5157279968261719, 0.5581836700439453, 63.11969757080078, 62.285125732421875, 0.6121292114257812, 0.8798828125, 59.80282974243164, 0.2534942626953125, 0.056209564208984375, 311.7798156738281, 0.45358848571777344, 0.2918281555175781, 0.21428680419921875, 65.6444320678711, 65.6444320678711, 63.161251068115234, 0.07704353332519531, 0.37268829345703125, 64.89080810546875, 0.3220329284667969, 0.08702468872070312, 0.40380859375, 65.24052429199219, 0.23217391967773438, 0.4122276306152344, 0.05846405029296875, 0.6151313781738281, 0.21463775634765625, 0.2679176330566406, 0.5493831634521484, 65.93449401855469, 0.11876678466796875, 0.5118446350097656, 0.4873523712158203, 0.6478538513183594, 312.1669921875, 0.5182571411132812, 0.5184364318847656, 1.0067996978759766, 0.4162788391113281, 0.6510581970214844, 0.12902069091796875, 0.294403076171875, 64.73729705810547, 0.11627578735351562, 0.3470039367675781, 58.603187561035156, 0.1996936798095703, 0.3962440490722656, 0.4797096252441406, 0.6472663879394531, 0.2075347900390625, 0.36936187744140625, 0.6632003784179688, 0.16533279418945312, 0.21425247192382812, 0.7437515258789062, 0.2543525695800781, 0.1781177520751953, 0.20644760131835938, 0.2515239715576172, 64.25694274902344, 0.13425827026367188, 0.43990135192871094, 0.6997451782226562, 0.5191669464111328, 0.1091461181640625, 0.09595870971679688, 0.46135520935058594, 312.12237548828125, 0.3025932312011719, 0.40627288818359375, 63.099449157714844, 0.059322357177734375, 0.4718818664550781, 312.03314208984375, 0.32649993896484375, 0.3995704650878906, 60.67486572265625, 0.1856689453125, 0.111480712890625, 0.341827392578125, 0.26560211181640625, 63.756134033203125, 0.5427761077880859, 0.5278415679931641, 62.26611328125, 62.008575439453125, 64.52047729492188, 0.4006195068359375, 0.10947799682617188, 0.38689422607421875, 0.6458511352539062, 0.36054229736328125, 0.22611618041992188, 0.5961341857910156, 0.35547828674316406, 0.038013458251953125, 0.6766815185546875, 0.5130119323730469, 0.45859527587890625, 0.5588665008544922, 0.3709850311279297, 0.265472412109375, 60.588348388671875, 0.0330047607421875, 62.506526947021484, 0.7057075500488281, 0.19333267211914062, 0.49619293212890625, 0.20484542846679688, 0.5902061462402344, 0.25168418884277344, 0.5243453979492188, 0.7252960205078125, 0.4045295715332031, 0.18411636352539062, 0.5490188598632812, 0.10584259033203125, 0.5672092437744141, 0.6209640502929688, 0.5839920043945312, 62.763587951660156, 0.3815593719482422, 0.5337505340576172, 0.7228431701660156, 0.9552154541015625, 61.10382080078125, 0.27060508728027344, 314.13177490234375, 0.4786415100097656, 0.36064910888671875, 0.5355224609375, 0.4290008544921875, 0.6868362426757812, 0.6472702026367188, 65.6610336303711, 0.7809181213378906, 65.41700744628906, 0.07398605346679688, 0.4805564880371094, 0.21942138671875, 0.3988761901855469, 0.795074462890625, 0.33660125732421875, 65.16575622558594, 0.8280830383300781, 0.8687515258789062, 0.8200302124023438, 0.031833648681640625, 0.3229255676269531, 0.18251800537109375, 0.5907859802246094, 0.32450103759765625, 63.78444290161133, 0.26104736328125, 0.2603187561035156, 0.8001289367675781, 63.996768951416016, 0.7307929992675781, 64.20951843261719, 0.7091426849365234, 0.056324005126953125, 0.1945343017578125, 0.4057464599609375, 0.8173294067382812], "mean_td_error": 17.84122657775879, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 15371.0, "diff_num_grad_updates_vs_sampler_policy": 15370.0}}, "num_env_steps_sampled": 56112, "num_env_steps_trained": 3934976, "num_agent_steps_sampled": 56112, "num_agent_steps_trained": 3934976, "last_target_update_ts": 56112, "num_target_updates": 15371}, "sampler_results": {"episode_reward_max": 145.30291169136763, "episode_reward_min": -177.46829970180988, "episode_reward_mean": -134.47186732706098, "episode_len_mean": 95.66666666666667, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-177.46829970180988, -172.56263116002083, -169.99527460336685, -168.33745901286602, -165.01786890625954, -175.25372545421124, -152.16031700372696, 145.30291169136763, -174.754141792655], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 61, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.168446624532885, "mean_inference_ms": 2.384881392037668, "mean_action_processing_ms": 0.2264207307852431, "mean_env_wait_ms": 3.0027140719595513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 145.30291169136763, "episode_reward_min": -177.46829970180988, "episode_reward_mean": -134.47186732706098, "episode_len_mean": 95.66666666666667, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-177.46829970180988, -172.56263116002083, -169.99527460336685, -168.33745901286602, -165.01786890625954, -175.25372545421124, -152.16031700372696, 145.30291169136763, -174.754141792655], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 61, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.168446624532885, "mean_inference_ms": 2.384881392037668, "mean_action_processing_ms": 0.2264207307852431, "mean_env_wait_ms": 3.0027140719595513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 56112, "num_agent_steps_trained": 3934976, "num_env_steps_sampled": 56112, "num_env_steps_trained": 3934976, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 56112, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 56112, "timers": {"training_iteration_time_ms": 155.194, "load_time_ms": 0.269, "load_throughput": 950298.101, "learn_time_ms": 24.196, "learn_throughput": 10580.311, "synch_weights_time_ms": 5.3}, "counters": {"num_env_steps_sampled": 56112, "num_env_steps_trained": 3934976, "num_agent_steps_sampled": 56112, "num_agent_steps_trained": 3934976, "last_target_update_ts": 56112, "num_target_updates": 15371}, "done": false, "episodes_total": 573, "training_iteration": 56, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-16-15", "timestamp": 1675952175, "time_this_iter_s": 52.84667134284973, "time_total_s": 2481.6685962677, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2a60>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ecd30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2481.6685962677, "timesteps_since_restore": 0, "iterations_since_restore": 56, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.38904109589041, "ram_util_percent": 90.55616438356165}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.029950562864542007, "actor_loss": 67.38470458984375, "critic_loss": 0.7805497646331787, "alpha_loss": -0.1250515729188919, "alpha_value": 0.015371105633676052, "log_alpha_value": -4.175265789031982, "target_entropy": -5.0, "policy_t": -0.26661252975463867, "mean_q": -67.42643737792969, "max_q": -62.28251647949219, "min_q": -70.2210464477539}, "td_error": [0.20964431762695312, 0.5548629760742188, 61.21284484863281, 66.29876708984375, 0.2854499816894531, 0.18737030029296875, 0.8066444396972656, 0.402557373046875, 0.6660537719726562, 0.4780921936035156, 0.7229347229003906, 0.639190673828125, 0.2607879638671875, 0.37955665588378906, 0.354217529296875, 67.95767211914062, 0.3218193054199219, 0.09518051147460938, 0.5994377136230469, 0.27579498291015625, 63.56802749633789, 0.4255218505859375, 0.490081787109375, 0.16839218139648438, 0.5149650573730469, 0.38558197021484375, 64.89714050292969, 0.17654800415039062, 63.93968963623047, 0.20512771606445312, 0.23945999145507812, 0.34095001220703125, 0.7125072479248047, 0.4511375427246094, 0.4219818115234375, 0.3081474304199219, 0.576934814453125, 0.4512367248535156, 0.31441688537597656, 0.17408370971679688, 0.13927459716796875, 64.55343627929688, 0.5006141662597656, 0.09447479248046875, 0.5199069976806641, 63.25801086425781, 0.46575355529785156, 0.3524971008300781, 64.814697265625, 0.388519287109375, 0.3855705261230469, 67.18949127197266, 0.7516059875488281, 0.4088401794433594, 0.03861236572265625, 67.55259704589844, 0.46689605712890625, 0.4532012939453125, 0.5696449279785156, 0.679931640625, 0.6884574890136719, 0.351226806640625, 0.4189262390136719, 62.5115852355957, 0.16565704345703125, 0.38803863525390625, 65.45364379882812, 0.3227996826171875, 0.3714408874511719, 62.191532135009766, 66.68995666503906, 0.6957740783691406, 65.71401977539062, 0.14118194580078125, 0.7289657592773438, 0.6321182250976562, 63.07483673095703, 0.2231292724609375, 0.21600341796875, 0.9448776245117188, 0.42943572998046875, 66.50320434570312, 67.06217956542969, 0.21154403686523438, 0.8856010437011719, 0.06543731689453125, 0.6128921508789062, 0.23878097534179688, 65.97496032714844, 0.4546546936035156, 67.04547119140625, 0.21721649169921875, 0.18194580078125, 65.69853210449219, 67.23918914794922, 0.0252838134765625, 0.11241531372070312, 0.12627410888671875, 0.3922576904296875, 67.17079162597656, 0.18924713134765625, 0.24164962768554688, 313.61090087890625, 0.06363677978515625, 0.40630149841308594, 0.4793853759765625, 0.07892417907714844, 0.6242866516113281, 0.1580657958984375, 0.5220375061035156, 66.91419982910156, 0.574310302734375, 0.36008453369140625, 0.1771984100341797, 64.55343627929688, 0.5449028015136719, 0.32740020751953125, 0.7736701965332031, 0.08788681030273438, 0.5866737365722656, 0.18041610717773438, 66.666748046875, 64.69612121582031, 64.52359008789062, 0.060108184814453125, 0.6085777282714844, 0.20825576782226562, 0.5162696838378906, 0.4408836364746094, 66.91865539550781, 0.293701171875, 0.3788795471191406, 64.436279296875, 0.15324020385742188, 67.44087219238281, 0.5224533081054688, 0.4586982727050781, 0.6047210693359375, 0.5244407653808594, 0.029205322265625, 0.3671684265136719, 67.15924835205078, 0.10148239135742188, 0.674896240234375, 64.36885070800781, 67.0892333984375, 65.20813751220703, 0.7613487243652344, 61.17906188964844, 0.36029815673828125, 0.8185157775878906, 0.7217826843261719, 0.3185005187988281, 0.5784111022949219, 66.55259704589844, 0.20357513427734375, 0.1662139892578125, 313.482421875, 0.4777412414550781, 0.10919570922851562, 0.36832427978515625, 67.14598083496094, 0.138580322265625, 315.78997802734375, 0.4946174621582031, 0.3279685974121094, 0.21469497680664062, 0.4754791259765625, 61.939605712890625, 67.23918914794922, 66.94532775878906, 0.10648727416992188, 0.3133049011230469, 0.2954368591308594, 0.08543777465820312, 0.6522216796875, 313.94659423828125, 0.24668121337890625, 67.75533294677734, 0.6551780700683594, 0.17954635620117188, 0.401275634765625, 0.3161125183105469, 1.0824775695800781, 0.3679618835449219, 0.4424171447753906, 0.3007354736328125, 65.97496032714844, 0.8058662414550781, 0.4141349792480469, 66.96867370605469, 0.365814208984375, 0.313323974609375, 0.3741722106933594, 0.18540573120117188, 65.73046875, 66.40120697021484, 0.2825202941894531, 0.7643775939941406, 0.284210205078125, 0.6007728576660156, 0.2936820983886719, 0.16771316528320312, 0.7078704833984375, 67.68622589111328, 62.94456100463867, 0.4241828918457031, 0.4261741638183594, 0.23816680908203125, 0.7996597290039062, 0.06769943237304688, 65.07383728027344, 67.54544067382812, 0.015956878662109375, 0.7854995727539062, 0.8365879058837891, 0.120391845703125, 0.4314994812011719, 0.38516998291015625, 0.5033416748046875, 0.4674720764160156, 0.34735107421875, 0.7504959106445312, 0.6167335510253906, 0.5346717834472656, 65.66886138916016, 0.41927337646484375, 66.90972900390625, 0.6392974853515625, 67.09453582763672, 0.19820404052734375, 67.95539855957031, 0.3693885803222656, 0.611968994140625, 0.5419578552246094, 0.5470695495605469, 1.0071868896484375, 66.99713897705078, 0.3042144775390625, 0.3676414489746094, 0.5451316833496094, 0.0885009765625, 0.40674781799316406, 0.4514617919921875, 0.1270751953125, 0.590240478515625, 0.3121147155761719, 0.7726974487304688, 0.6294403076171875, 0.3615455627441406, 0.4836387634277344, 0.3019676208496094, 0.6300697326660156, 65.36039733886719, 0.4136695861816406, 0.10696029663085938], "mean_td_error": 19.84507179260254, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 15705.0, "diff_num_grad_updates_vs_sampler_policy": 15704.0}}, "num_env_steps_sampled": 57114, "num_env_steps_trained": 4020480, "num_agent_steps_sampled": 57114, "num_agent_steps_trained": 4020480, "last_target_update_ts": 57114, "num_target_updates": 15705}, "sampler_results": {"episode_reward_max": 190.71583554148674, "episode_reward_min": -177.23308964073658, "episode_reward_mean": -135.2146406566555, "episode_len_mean": 94.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-174.89020885527134, -171.159431964159, -157.92751325666904, -159.18436642736197, 190.71583554148674, -172.40087322890759, -157.3429071456194, -162.45721162110567, -177.23308964073658, -172.98275361955166, -172.49852700531483], "episode_lengths": [100, 100, 100, 100, 34, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1567281180468754, "mean_inference_ms": 2.3690804976669826, "mean_action_processing_ms": 0.2244683446426464, "mean_env_wait_ms": 2.98578306030845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 190.71583554148674, "episode_reward_min": -177.23308964073658, "episode_reward_mean": -135.2146406566555, "episode_len_mean": 94.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-174.89020885527134, -171.159431964159, -157.92751325666904, -159.18436642736197, 190.71583554148674, -172.40087322890759, -157.3429071456194, -162.45721162110567, -177.23308964073658, -172.98275361955166, -172.49852700531483], "episode_lengths": [100, 100, 100, 100, 34, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1567281180468754, "mean_inference_ms": 2.3690804976669826, "mean_action_processing_ms": 0.2244683446426464, "mean_env_wait_ms": 2.98578306030845, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 57114, "num_agent_steps_trained": 4020480, "num_env_steps_sampled": 57114, "num_env_steps_trained": 4020480, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 57114, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 57114, "timers": {"training_iteration_time_ms": 153.721, "load_time_ms": 0.266, "load_throughput": 961961.856, "learn_time_ms": 24.674, "learn_throughput": 10375.249, "synch_weights_time_ms": 4.924}, "counters": {"num_env_steps_sampled": 57114, "num_env_steps_trained": 4020480, "num_agent_steps_sampled": 57114, "num_agent_steps_trained": 4020480, "last_target_update_ts": 57114, "num_target_updates": 15705}, "done": false, "episodes_total": 584, "training_iteration": 57, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-17-06", "timestamp": 1675952226, "time_this_iter_s": 51.583651542663574, "time_total_s": 2533.2522478103638, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb940>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb3a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2533.2522478103638, "timesteps_since_restore": 0, "iterations_since_restore": 57, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.728169014084514, "ram_util_percent": 90.64929577464792}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3018943965435028, "actor_loss": 68.89152526855469, "critic_loss": 0.6015766859054565, "alpha_loss": -1.2630696296691895, "alpha_value": 0.01524028368294239, "log_alpha_value": -4.183813095092773, "target_entropy": -5.0, "policy_t": -0.2953658401966095, "mean_q": -68.86299133300781, "max_q": -63.98253631591797, "min_q": -71.96566009521484}, "td_error": [0.3446388244628906, 68.9594497680664, 0.6604118347167969, 0.07786941528320312, 0.5968208312988281, 0.21350860595703125, 68.81764221191406, 0.17410659790039062, 0.004680633544921875, 0.28310394287109375, 0.20780181884765625, 0.48459625244140625, 68.52613830566406, 0.43302154541015625, 66.29042053222656, 0.4466896057128906, 68.706787109375, 0.12188339233398438, 0.11725234985351562, 0.3476715087890625, 0.3194923400878906, 0.6338272094726562, 0.7330741882324219, 0.7987136840820312, 0.3781280517578125, 0.15092849731445312, 0.45548248291015625, 0.5809593200683594, 0.8082695007324219, 66.37434387207031, 0.12650299072265625, 0.5273361206054688, 0.4668693542480469, 66.314208984375, 0.06330490112304688, 0.5582733154296875, 0.3901863098144531, 0.3574676513671875, 0.454925537109375, 0.6176261901855469, 0.4717140197753906, 0.4411048889160156, 0.2614173889160156, 0.5920486450195312, 0.4803810119628906, 0.1422271728515625, 0.47582244873046875, 0.044864654541015625, 0.7203483581542969, 0.3867912292480469, 0.19315719604492188, 0.29718780517578125, 0.6313514709472656, 0.21453094482421875, 0.39725494384765625, 0.4448089599609375, 316.16156005859375, 0.5588912963867188, 67.2557373046875, 0.15081787109375, 0.8048896789550781, 0.3983001708984375, 64.87861633300781, 0.455108642578125, 0.17174911499023438, 0.042057037353515625, 0.2848320007324219, 0.3950538635253906, 68.0335693359375, 0.11307144165039062, 0.28214263916015625, 0.5464019775390625, 68.89075469970703, 0.7122611999511719, 0.540191650390625, 0.6314888000488281, 65.1073226928711, 0.835479736328125, 0.18404006958007812, 63.52914810180664, 68.33377075195312, 0.2545623779296875, 0.09888839721679688, 0.2003173828125, 0.3171577453613281, 67.98768615722656, 0.7435111999511719, 66.07902526855469, 0.6711654663085938, 0.4348106384277344, 64.33561706542969, 0.7601089477539062, 0.5024032592773438, 0.6303672790527344, 0.58642578125, 0.6508216857910156, 0.4470024108886719, 67.41059875488281, 68.68841552734375, 68.85624694824219, 69.01678466796875, 0.40404510498046875, 0.22014999389648438, 66.28445434570312, 0.3498649597167969, 0.29550933837890625, 0.2859535217285156, 0.4688873291015625, 66.92863464355469, 62.75989532470703, 0.9037513732910156, 0.660186767578125, 0.37920379638671875, 0.2866096496582031, 0.3663902282714844, 0.5367012023925781, 0.6775054931640625, 0.2411956787109375, 0.1604156494140625, 0.7083168029785156, 0.46697998046875, 0.5361137390136719, 0.3687705993652344, 62.75566482543945, 64.60005187988281, 0.20122146606445312, 0.8852691650390625, 66.29042053222656, 0.7751235961914062, 0.06576156616210938, 0.8225898742675781, 67.04432678222656, 0.19652175903320312, 0.5465927124023438, 68.96640014648438, 0.24454498291015625, 0.7004547119140625, 0.3381309509277344, 0.193511962890625, 0.3676338195800781, 0.4763603210449219, 0.18238067626953125, 0.1581268310546875, 0.25247955322265625, 0.4297218322753906, 67.7403793334961, 0.6268043518066406, 0.3030509948730469, 0.4862937927246094, 0.71820068359375, 0.41363525390625, 0.13411331176757812, 0.6469917297363281, 0.3644599914550781, 0.19526290893554688, 0.6411170959472656, 0.4377784729003906, 0.7050285339355469, 0.24774932861328125, 0.3995933532714844, 0.04448699951171875, 67.2208251953125, 0.3328208923339844, 65.40199279785156, 0.2988548278808594, 68.51565551757812, 0.4504737854003906, 64.14936828613281, 0.17596435546875, 0.1575775146484375, 68.30785369873047, 0.430328369140625, 0.7044601440429688, 0.3111572265625, 63.414772033691406, 0.15990829467773438, 0.5183372497558594, 0.6001014709472656, 0.8404579162597656, 0.19923019409179688, 0.4619178771972656, 64.46549987792969, 0.058620452880859375, 0.18980026245117188, 64.48503875732422, 0.2819709777832031, 65.4250717163086, 67.98583984375, 0.294677734375, 0.21570587158203125, 0.20116043090820312, 0.3083076477050781, 67.47601318359375, 0.4292488098144531, 62.348262786865234, 0.3247947692871094, 0.9318351745605469, 0.5006141662597656, 67.6654281616211, 0.5641555786132812, 0.5432929992675781, 0.6972885131835938, 0.3526649475097656, 0.27259063720703125, 0.2782745361328125, 0.19938278198242188, 0.348358154296875, 0.11996841430664062, 0.9833412170410156, 0.08201217651367188, 0.6270256042480469, 0.19940948486328125, 0.6003189086914062, 0.41579437255859375, 68.22454071044922, 0.4239463806152344, 0.2966766357421875, 0.037822723388671875, 0.43915557861328125, 0.3787117004394531, 0.3651237487792969, 63.926727294921875, 0.3921966552734375, 0.07960128784179688, 0.522674560546875, 0.15952682495117188, 0.16338729858398438, 0.6790084838867188, 0.15070343017578125, 0.6389045715332031, 0.3044242858886719, 0.7638740539550781, 0.10918426513671875, 0.5453758239746094, 0.6868057250976562, 0.31278228759765625, 63.24911880493164, 0.6071701049804688, 0.47158050537109375, 0.21468734741210938, 67.91510009765625, 0.623809814453125, 0.495941162109375, 0.18999862670898438, 68.70314025878906, 66.55874633789062, 0.20681381225585938, 0.22693634033203125, 68.12301635742188, 0.2720489501953125, 0.2799034118652344, 0.8950881958007812, 0.2908973693847656, 0.49925994873046875, 0.20146560668945312, 0.4423255920410156], "mean_td_error": 14.56472110748291, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 16039.0, "diff_num_grad_updates_vs_sampler_policy": 16038.0}}, "num_env_steps_sampled": 58116, "num_env_steps_trained": 4105984, "num_agent_steps_sampled": 58116, "num_agent_steps_trained": 4105984, "last_target_update_ts": 58116, "num_target_updates": 16039}, "sampler_results": {"episode_reward_max": 235.2074180394411, "episode_reward_min": -181.51839230954647, "episode_reward_mean": -107.81507757926981, "episode_len_mean": 86.75, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-169.1734808459878, -165.13312735408545, -181.51839230954647, 195.56617008149624, 235.2074180394411, -170.57011537253857, -176.20819710195065, -180.06366753578186, -176.26358722895384, -167.89460321515799, -171.07733319699764, -166.65201491117477], "episode_lengths": [100, 100, 100, 31, 10, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.184853309958937, "mean_inference_ms": 2.409731862418623, "mean_action_processing_ms": 0.22906245486115503, "mean_env_wait_ms": 3.0413982721293067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 235.2074180394411, "episode_reward_min": -181.51839230954647, "episode_reward_mean": -107.81507757926981, "episode_len_mean": 86.75, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-169.1734808459878, -165.13312735408545, -181.51839230954647, 195.56617008149624, 235.2074180394411, -170.57011537253857, -176.20819710195065, -180.06366753578186, -176.26358722895384, -167.89460321515799, -171.07733319699764, -166.65201491117477], "episode_lengths": [100, 100, 100, 31, 10, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.184853309958937, "mean_inference_ms": 2.409731862418623, "mean_action_processing_ms": 0.22906245486115503, "mean_env_wait_ms": 3.0413982721293067, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 58116, "num_agent_steps_trained": 4105984, "num_env_steps_sampled": 58116, "num_env_steps_trained": 4105984, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 58116, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 58116, "timers": {"training_iteration_time_ms": 149.844, "load_time_ms": 0.256, "load_throughput": 1000691.355, "learn_time_ms": 24.615, "learn_throughput": 10400.011, "synch_weights_time_ms": 4.994}, "counters": {"num_env_steps_sampled": 58116, "num_env_steps_trained": 4105984, "num_agent_steps_sampled": 58116, "num_agent_steps_trained": 4105984, "last_target_update_ts": 58116, "num_target_updates": 16039}, "done": false, "episodes_total": 596, "training_iteration": 58, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-17-58", "timestamp": 1675952278, "time_this_iter_s": 51.68439030647278, "time_total_s": 2584.9366381168365, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb790>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2584.9366381168365, "timesteps_since_restore": 0, "iterations_since_restore": 58, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.939436619718315, "ram_util_percent": 90.74084507042252}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6017497777938843, "actor_loss": 70.27995300292969, "critic_loss": 0.9894709587097168, "alpha_loss": -2.536435604095459, "alpha_value": 0.014770840294659138, "log_alpha_value": -4.215100288391113, "target_entropy": -5.0, "policy_t": -0.36978229880332947, "mean_q": -70.22700500488281, "max_q": -65.55696868896484, "min_q": -73.52262115478516}, "td_error": [70.29550170898438, 69.84306335449219, 0.06389617919921875, 0.06795883178710938, 0.2563629150390625, 0.449371337890625, 70.36421966552734, 0.3409423828125, 0.16821670532226562, 65.37950134277344, 0.47693634033203125, 0.4455070495605469, 0.34519195556640625, 0.03780364990234375, 0.26567840576171875, 64.95465850830078, 64.94041442871094, 68.39627838134766, 0.6081390380859375, 0.07400131225585938, 0.80792236328125, 70.79035186767578, 0.3515777587890625, 0.1666107177734375, 0.7696685791015625, 68.77782440185547, 66.77308654785156, 0.3365440368652344, 0.799896240234375, 0.24266433715820312, 71.24885559082031, 0.8072395324707031, 0.8946533203125, 0.43575286865234375, 0.6917991638183594, 0.21216201782226562, 314.9435729980469, 0.5692520141601562, 0.23198318481445312, 70.062255859375, 0.48895263671875, 68.098388671875, 0.19378280639648438, 0.24853897094726562, 0.18741607666015625, 0.16986846923828125, 0.2503814697265625, 0.4049263000488281, 0.2348175048828125, 0.1631622314453125, 316.3138732910156, 68.78694152832031, 316.4706726074219, 1.063812255859375, 0.7329940795898438, 69.47767639160156, 0.3532295227050781, 0.0497283935546875, 0.62176513671875, 0.5368843078613281, 0.552703857421875, 65.9501953125, 0.3238372802734375, 0.4341888427734375, 0.1582183837890625, 0.3315544128417969, 66.42665100097656, 0.38762664794921875, 0.33821868896484375, 0.14027786254882812, 0.5114097595214844, 0.18718338012695312, 0.6131515502929688, 0.3203773498535156, 0.3033332824707031, 71.39376068115234, 0.4904937744140625, 0.3155632019042969, 0.33245086669921875, 0.435577392578125, 0.16218185424804688, 0.2007598876953125, 67.22715759277344, 0.5801658630371094, 0.2719535827636719, 0.4626312255859375, 68.20867919921875, 0.8235511779785156, 0.5620765686035156, 0.3588294982910156, 0.3959236145019531, 68.82322692871094, 0.5381622314453125, 0.18964004516601562, 67.7313461303711, 0.38889312744140625, 0.41143035888671875, 0.3221473693847656, 0.4397125244140625, 0.5762138366699219, 0.48389434814453125, 0.8034744262695312, 0.405731201171875, 0.5621376037597656, 0.5022163391113281, 69.98561096191406, 66.09506225585938, 66.42034912109375, 0.3501739501953125, 317.1036071777344, 70.34840393066406, 71.26563262939453, 0.17334747314453125, 0.3172149658203125, 0.331787109375, 70.31779479980469, 0.12066268920898438, 70.4085464477539, 67.4620590209961, 0.410491943359375, 0.044677734375, 0.14853668212890625, 0.7864761352539062, 69.56098937988281, 0.7926139831542969, 68.85261535644531, 0.6526603698730469, 0.16623306274414062, 0.3729248046875, 0.211273193359375, 0.5973587036132812, 0.375091552734375, 0.4034423828125, 69.85969543457031, 317.15826416015625, 68.99833679199219, 0.1261749267578125, 0.09693145751953125, 0.4597053527832031, 0.44326019287109375, 0.36536407470703125, 0.4449424743652344, 0.29034423828125, 0.256927490234375, 0.15468215942382812, 0.316436767578125, 0.4131622314453125, 69.73767852783203, 0.06842041015625, 0.43773651123046875, 0.5033798217773438, 0.45221710205078125, 64.43256378173828, 0.6595382690429688, 0.5598297119140625, 65.587158203125, 64.69888305664062, 0.5401382446289062, 0.10803985595703125, 0.7979621887207031, 0.25054931640625, 0.3980712890625, 0.60009765625, 0.6708297729492188, 69.63397979736328, 69.67366027832031, 0.5449943542480469, 0.0264434814453125, 0.4257240295410156, 0.5195960998535156, 67.32763671875, 0.10555267333984375, 318.7093200683594, 0.0650177001953125, 314.61700439453125, 0.40622711181640625, 70.38064575195312, 69.763427734375, 71.25399780273438, 0.39756011962890625, 0.7163352966308594, 70.79035186767578, 63.86158752441406, 66.0212631225586, 0.7124137878417969, 0.7069435119628906, 0.14688491821289062, 0.3314971923828125, 0.09132766723632812, 0.5068740844726562, 0.3151817321777344, 0.38478851318359375, 0.6212387084960938, 67.2571029663086, 66.3958969116211, 0.2884483337402344, 0.46562957763671875, 0.37061309814453125, 0.124786376953125, 0.6018333435058594, 0.24829864501953125, 0.7539710998535156, 0.536956787109375, 0.6113510131835938, 0.48418426513671875, 0.08849716186523438, 0.5215873718261719, 0.5078239440917969, 0.28534698486328125, 0.7064628601074219, 69.02603149414062, 0.09281539916992188, 0.4761505126953125, 0.3594779968261719, 0.3545989990234375, 66.58084106445312, 0.584503173828125, 65.9501953125, 0.16504669189453125, 314.4359130859375, 0.39579010009765625, 0.3433837890625, 1.3164749145507812, 70.98957824707031, 0.039958953857421875, 0.3642997741699219, 0.5567054748535156, 0.4674949645996094, 70.30780029296875, 0.2605934143066406, 0.08071136474609375, 0.2711906433105469, 0.0509033203125, 0.20263671875, 65.66450500488281, 0.6011123657226562, 0.17087936401367188, 0.6984825134277344, 70.68162536621094, 67.34382629394531, 0.3759651184082031, 67.22715759277344, 70.03705596923828, 0.49361419677734375, 0.3106651306152344, 0.09386825561523438, 0.42588043212890625, 0.5716667175292969, 0.3942604064941406, 0.18997955322265625, 0.36598968505859375, 0.31659698486328125, 66.0816650390625, 66.431396484375, 0.4955596923828125, 0.0979156494140625], "mean_td_error": 26.445022583007812, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 16373.0, "diff_num_grad_updates_vs_sampler_policy": 16372.0}}, "num_env_steps_sampled": 59118, "num_env_steps_trained": 4191488, "num_agent_steps_sampled": 59118, "num_agent_steps_trained": 4191488, "last_target_update_ts": 59118, "num_target_updates": 16373}, "sampler_results": {"episode_reward_max": -163.9477882012725, "episode_reward_min": -182.78319193422794, "episode_reward_mean": -171.1263469800353, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.76183578372002, -182.78319193422794, -163.9477882012725, -172.7225134074688, -169.8990863710642, -174.10112477838993, -167.67432311177254, -167.00066530704498, -172.57840389758348, -171.79453700780869], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.177199225499035, "mean_inference_ms": 2.399099586325378, "mean_action_processing_ms": 0.22786457849406644, "mean_env_wait_ms": 3.0333925552937258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -163.9477882012725, "episode_reward_min": -182.78319193422794, "episode_reward_mean": -171.1263469800353, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-168.76183578372002, -182.78319193422794, -163.9477882012725, -172.7225134074688, -169.8990863710642, -174.10112477838993, -167.67432311177254, -167.00066530704498, -172.57840389758348, -171.79453700780869], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.177199225499035, "mean_inference_ms": 2.399099586325378, "mean_action_processing_ms": 0.22786457849406644, "mean_env_wait_ms": 3.0333925552937258, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 59118, "num_agent_steps_trained": 4191488, "num_env_steps_sampled": 59118, "num_env_steps_trained": 4191488, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 59118, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 59118, "timers": {"training_iteration_time_ms": 155.741, "load_time_ms": 0.282, "load_throughput": 906646.816, "learn_time_ms": 25.293, "learn_throughput": 10121.361, "synch_weights_time_ms": 5.296}, "counters": {"num_env_steps_sampled": 59118, "num_env_steps_trained": 4191488, "num_agent_steps_sampled": 59118, "num_agent_steps_trained": 4191488, "last_target_update_ts": 59118, "num_target_updates": 16373}, "done": false, "episodes_total": 606, "training_iteration": 59, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-18-50", "timestamp": 1675952330, "time_this_iter_s": 51.56728720664978, "time_total_s": 2636.5039253234863, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380abaf0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb790>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2636.5039253234863, "timesteps_since_restore": 0, "iterations_since_restore": 59, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.85211267605633, "ram_util_percent": 90.81408450704222}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.49701112508773804, "actor_loss": 71.79824829101562, "critic_loss": 0.8666204214096069, "alpha_loss": -2.113943099975586, "alpha_value": 0.014217067509889603, "log_alpha_value": -4.253312110900879, "target_entropy": -5.0, "policy_t": -0.39003443717956543, "mean_q": -71.7850341796875, "max_q": -66.75133514404297, "min_q": -74.84465789794922}, "td_error": [0.4808998107910156, 0.09522628784179688, 0.15554428100585938, 0.20806121826171875, 318.6121826171875, 0.2977867126464844, 0.4326667785644531, 67.89547729492188, 0.6074676513671875, 69.22417449951172, 69.38351440429688, 0.28025054931640625, 0.4387931823730469, 0.49080657958984375, 0.6816749572753906, 0.5652351379394531, 72.61729431152344, 68.79846954345703, 0.4088935852050781, 0.4585304260253906, 0.380126953125, 0.10456466674804688, 0.2543907165527344, 0.294464111328125, 0.13519668579101562, 0.3331794738769531, 0.6152267456054688, 66.10757446289062, 0.14034652709960938, 0.1763458251953125, 0.6555366516113281, 0.6774520874023438, 0.06407546997070312, 0.5170974731445312, 0.21730804443359375, 0.6818695068359375, 0.053760528564453125, 0.5082969665527344, 0.15721893310546875, 0.6507682800292969, 72.08362579345703, 0.21174240112304688, 0.5602798461914062, 66.37933349609375, 0.6842536926269531, 0.2786674499511719, 0.5445747375488281, 0.2799415588378906, 0.20486831665039062, 0.17641448974609375, 0.6361808776855469, 0.5449104309082031, 0.25225067138671875, 318.7287902832031, 0.5412483215332031, 0.7382583618164062, 0.3724403381347656, 0.15388870239257812, 70.36752319335938, 69.69219970703125, 0.12829971313476562, 0.680938720703125, 0.7021675109863281, 71.2201156616211, 0.7744789123535156, 0.2536048889160156, 0.4427032470703125, 0.5771331787109375, 0.22330856323242188, 67.41200256347656, 0.3534965515136719, 0.4971580505371094, 0.44115447998046875, 0.26717376708984375, 0.7913703918457031, 0.3934364318847656, 0.4499397277832031, 0.414031982421875, 0.22751998901367188, 70.91250610351562, 0.3967323303222656, 0.6353416442871094, 71.70590209960938, 0.5335197448730469, 71.94081115722656, 0.5138015747070312, 70.16212463378906, 0.2538032531738281, 0.38824462890625, 0.32260894775390625, 0.23967361450195312, 0.17618179321289062, 0.33856201171875, 0.200347900390625, 0.3995513916015625, 64.46575164794922, 0.6454353332519531, 0.3045463562011719, 0.4250221252441406, 0.24407958984375, 70.31722259521484, 0.5245018005371094, 316.9727783203125, 0.5136489868164062, 70.77035522460938, 0.6982536315917969, 0.5359077453613281, 0.3161354064941406, 0.14902114868164062, 70.61836242675781, 0.3248748779296875, 69.94496154785156, 0.5206794738769531, 0.4203910827636719, 0.16960906982421875, 0.201446533203125, 0.191131591796875, 0.21606826782226562, 0.17836761474609375, 71.05206298828125, 72.31476593017578, 0.13171005249023438, 0.3286323547363281, 0.2087249755859375, 0.5530891418457031, 69.13275146484375, 0.17901229858398438, 0.4563102722167969, 0.14749908447265625, 0.6901702880859375, 0.017139434814453125, 73.41691589355469, 0.6725349426269531, 0.4664306640625, 0.3812980651855469, 0.7108345031738281, 0.2761993408203125, 0.5016822814941406, 0.049404144287109375, 0.23518753051757812, 0.4896888732910156, 0.2812538146972656, 65.53817749023438, 0.1370086669921875, 318.9999694824219, 0.23219680786132812, 0.4070892333984375, 0.5658226013183594, 0.5229263305664062, 0.12980270385742188, 71.49755859375, 0.5397796630859375, 0.8159294128417969, 0.8335990905761719, 0.3863410949707031, 0.28105926513671875, 0.70013427734375, 318.5308837890625, 0.4373817443847656, 0.49810791015625, 0.3862800598144531, 0.020843505859375, 0.3982048034667969, 0.345428466796875, 0.6046714782714844, 0.7512931823730469, 70.63104248046875, 0.3756256103515625, 0.41078948974609375, 0.4494972229003906, 68.1836929321289, 0.31075286865234375, 0.050304412841796875, 0.24528121948242188, 71.13859558105469, 72.16494750976562, 0.0467071533203125, 0.3246574401855469, 0.4050178527832031, 71.97662353515625, 0.5332527160644531, 0.04550933837890625, 0.4007530212402344, 67.48764038085938, 0.1416473388671875, 0.4187583923339844, 0.032306671142578125, 0.21007156372070312, 0.3932228088378906, 69.69219970703125, 0.13825607299804688, 0.8130073547363281, 0.09704208374023438, 0.07622528076171875, 0.19428634643554688, 0.11073684692382812, 0.3593940734863281, 71.6036376953125, 0.3262176513671875, 71.7964859008789, 0.377105712890625, 0.05865478515625, 319.22735595703125, 0.7737846374511719, 69.83512878417969, 69.37867736816406, 0.6667633056640625, 0.33245849609375, 66.25402069091797, 0.07052993774414062, 0.2778167724609375, 71.404296875, 0.0765380859375, 0.4569511413574219, 318.14532470703125, 0.690582275390625, 0.7822036743164062, 0.25376129150390625, 72.13021850585938, 0.6735496520996094, 0.7774772644042969, 0.8566474914550781, 0.235198974609375, 0.5899925231933594, 0.537353515625, 0.9252281188964844, 69.49859619140625, 69.35861206054688, 0.17404556274414062, 0.26715087890625, 0.4176750183105469, 0.546966552734375, 0.5840377807617188, 0.49694061279296875, 0.45720672607421875, 0.9450416564941406, 0.4971160888671875, 0.8564949035644531, 0.39227294921875, 69.13017272949219, 67.89547729492188, 0.084625244140625, 71.59420776367188, 71.7964859008789, 0.3870582580566406, 0.4696540832519531, 70.65789794921875, 69.22417449951172, 0.07567977905273438, 0.3189849853515625, 0.4636116027832031, 0.2557830810546875, 0.2670555114746094, 0.31072998046875, 0.4130973815917969, 319.22735595703125], "mean_td_error": 23.64850425720215, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 16707.0, "diff_num_grad_updates_vs_sampler_policy": 16706.0}}, "num_env_steps_sampled": 60120, "num_env_steps_trained": 4276992, "num_agent_steps_sampled": 60120, "num_agent_steps_trained": 4276992, "last_target_update_ts": 60120, "num_target_updates": 16707}, "sampler_results": {"episode_reward_max": -149.96378096938133, "episode_reward_min": -184.42970390617847, "episode_reward_mean": -170.0797163911164, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-172.28781836479902, -149.96378096938133, -176.29950307309628, -183.52996740490198, -184.42970390617847, -168.78611098229885, -170.16987989842892, -166.8136347681284, -157.78914754092693, -170.72761700302362], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1547097593038822, "mean_inference_ms": 2.3676612694685426, "mean_action_processing_ms": 0.22422665875386674, "mean_env_wait_ms": 2.9974517419686677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -149.96378096938133, "episode_reward_min": -184.42970390617847, "episode_reward_mean": -170.0797163911164, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-172.28781836479902, -149.96378096938133, -176.29950307309628, -183.52996740490198, -184.42970390617847, -168.78611098229885, -170.16987989842892, -166.8136347681284, -157.78914754092693, -170.72761700302362], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1547097593038822, "mean_inference_ms": 2.3676612694685426, "mean_action_processing_ms": 0.22422665875386674, "mean_env_wait_ms": 2.9974517419686677, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 60120, "num_agent_steps_trained": 4276992, "num_env_steps_sampled": 60120, "num_env_steps_trained": 4276992, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 60120, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 60120, "timers": {"training_iteration_time_ms": 150.598, "load_time_ms": 0.261, "load_throughput": 980854.868, "learn_time_ms": 24.077, "learn_throughput": 10632.771, "synch_weights_time_ms": 5.794}, "counters": {"num_env_steps_sampled": 60120, "num_env_steps_trained": 4276992, "num_agent_steps_sampled": 60120, "num_agent_steps_trained": 4276992, "last_target_update_ts": 60120, "num_target_updates": 16707}, "done": false, "episodes_total": 616, "training_iteration": 60, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-19-42", "timestamp": 1675952382, "time_this_iter_s": 52.56097674369812, "time_total_s": 2689.0649020671844, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef700>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cbb80>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2689.0649020671844, "timesteps_since_restore": 0, "iterations_since_restore": 60, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.18472222222223, "ram_util_percent": 90.86944444444445}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7520429491996765, "actor_loss": 73.59013366699219, "critic_loss": 0.9074606895446777, "alpha_loss": -3.2247469425201416, "alpha_value": 0.013732603751122952, "log_alpha_value": -4.28798246383667, "target_entropy": -5.0, "policy_t": -0.3779509663581848, "mean_q": -73.57282257080078, "max_q": -68.88961029052734, "min_q": -76.5862808227539}, "td_error": [0.9117813110351562, 0.4684791564941406, 0.5079231262207031, 70.16694641113281, 0.2591285705566406, 0.12603759765625, 0.6744003295898438, 0.22559356689453125, 0.49333953857421875, 67.99457550048828, 71.61155700683594, 71.3770523071289, 69.05208587646484, 0.16474151611328125, 0.032619476318359375, 0.5534706115722656, 0.2580528259277344, 0.13733291625976562, 0.19504165649414062, 0.29682159423828125, 73.4130630493164, 0.4647674560546875, 0.3309135437011719, 0.18742752075195312, 0.3707275390625, 0.43267822265625, 0.0826873779296875, 0.3746337890625, 72.50664520263672, 0.4716758728027344, 0.5558280944824219, 73.25653076171875, 0.3716239929199219, 68.45816802978516, 0.6037635803222656, 0.6929130554199219, 0.14976882934570312, 0.4964256286621094, 0.562164306640625, 0.1812896728515625, 73.52704620361328, 71.10015869140625, 0.0802154541015625, 68.94572448730469, 0.8186454772949219, 0.12183380126953125, 0.4241981506347656, 0.14070510864257812, 0.4242095947265625, 0.7803459167480469, 1.233551025390625, 0.7610092163085938, 73.14816284179688, 0.6750259399414062, 0.3223724365234375, 0.5163192749023438, 0.09581756591796875, 73.53672790527344, 69.20985412597656, 0.6721420288085938, 0.23123931884765625, 0.465850830078125, 0.4488716125488281, 0.09965896606445312, 0.16124725341796875, 0.41712188720703125, 0.6357879638671875, 0.5788192749023438, 71.6358642578125, 0.28588104248046875, 0.09051895141601562, 0.6470680236816406, 0.1772308349609375, 0.3306999206542969, 320.72418212890625, 74.24569702148438, 0.4897651672363281, 72.04141235351562, 0.6513748168945312, 0.5886917114257812, 0.7427902221679688, 69.20639038085938, 0.2595977783203125, 0.6185073852539062, 0.7840995788574219, 0.574432373046875, 0.19041061401367188, 0.07513427734375, 0.3856544494628906, 0.4270896911621094, 0.8299636840820312, 0.30410003662109375, 0.2640495300292969, 0.3146858215332031, 0.41216278076171875, 0.16961288452148438, 73.5047378540039, 0.3477363586425781, 0.7299766540527344, 70.67347717285156, 0.5798912048339844, 0.1295318603515625, 0.4678459167480469, 0.2706451416015625, 0.10782241821289062, 0.4523811340332031, 0.3476715087890625, 0.19680023193359375, 0.3219947814941406, 0.21004486083984375, 0.3326377868652344, 0.6199874877929688, 0.351165771484375, 0.4864387512207031, 0.4760169982910156, 320.1419677734375, 0.10868072509765625, 0.06836700439453125, 66.70816040039062, 0.5303497314453125, 0.16849517822265625, 0.3962860107421875, 0.3659324645996094, 0.5129280090332031, 0.2061767578125, 72.61857604980469, 0.4334678649902344, 0.3441734313964844, 0.6207160949707031, 0.9476776123046875, 0.4750862121582031, 0.33277130126953125, 0.3746376037597656, 69.17070770263672, 0.6098098754882812, 0.378509521484375, 319.80914306640625, 0.164825439453125, 0.4677162170410156, 0.16481781005859375, 0.463104248046875, 0.5153923034667969, 0.6095848083496094, 0.7236442565917969, 70.97391510009766, 0.30072021484375, 0.4066810607910156, 72.3199462890625, 0.23943710327148438, 71.78243255615234, 73.26628875732422, 74.53067016601562, 0.30142974853515625, 0.26517486572265625, 72.02133178710938, 0.4666709899902344, 0.6966400146484375, 73.6943359375, 0.2722663879394531, 69.36898040771484, 0.5696334838867188, 0.09653472900390625, 0.5219001770019531, 72.76467895507812, 0.31012725830078125, 0.3726806640625, 0.5593605041503906, 0.4626922607421875, 0.018749237060546875, 73.68284606933594, 72.94224548339844, 0.5163154602050781, 67.87837219238281, 72.09906005859375, 0.3609733581542969, 68.34626007080078, 0.7698631286621094, 0.3438377380371094, 0.2371978759765625, 0.5186347961425781, 0.07727432250976562, 0.7549896240234375, 68.237548828125, 0.7249031066894531, 69.30862426757812, 0.15228271484375, 318.8846130371094, 0.5729293823242188, 0.46538543701171875, 0.4802703857421875, 0.47487640380859375, 0.3752937316894531, 0.27459716796875, 0.38068389892578125, 0.2260894775390625, 0.2799491882324219, 71.43507385253906, 0.37924957275390625, 0.9152297973632812, 0.6108360290527344, 0.15550613403320312, 0.4031219482421875, 74.73573303222656, 0.2347259521484375, 0.453277587890625, 72.94224548339844, 69.75221252441406, 0.7599105834960938, 72.76504516601562, 72.1495361328125, 0.5860404968261719, 71.02828979492188, 0.20550918579101562, 0.5832481384277344, 67.94706726074219, 0.15689468383789062, 0.37795257568359375, 0.5109786987304688, 0.3116645812988281, 71.01078033447266, 0.655059814453125, 0.5957069396972656, 0.3723564147949219, 0.6875381469726562, 0.2826271057128906, 0.4587860107421875, 73.74432373046875, 0.3377952575683594, 0.058696746826171875, 0.39893341064453125, 0.9870414733886719, 67.6512451171875, 0.7559967041015625, 0.5856857299804688, 0.3378105163574219, 72.7494888305664, 71.0133285522461, 0.3624763488769531, 0.502777099609375, 0.692169189453125, 73.60247039794922, 320.58349609375, 0.3407249450683594, 73.6555404663086, 73.13282775878906, 71.6358642578125, 73.46102905273438, 0.2649040222167969, 0.12737655639648438, 0.6980247497558594, 73.31381225585938, 70.16389465332031, 68.98138427734375, 0.20389556884765625, 0.4669952392578125, 0.44806671142578125], "mean_td_error": 23.578977584838867, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 17041.0, "diff_num_grad_updates_vs_sampler_policy": 17040.0}}, "num_env_steps_sampled": 61122, "num_env_steps_trained": 4362496, "num_agent_steps_sampled": 61122, "num_agent_steps_trained": 4362496, "last_target_update_ts": 61122, "num_target_updates": 17041}, "sampler_results": {"episode_reward_max": 183.24299144744873, "episode_reward_min": -175.62199070304632, "episode_reward_mean": -135.15221174332228, "episode_len_mean": 94.72727272727273, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-152.1386574730277, -172.1268064752221, 183.24299144744873, -167.3796276524663, -168.53416009247303, -175.62199070304632, -157.11144542694092, -171.20542296767235, -171.28015413880348, -167.0303348749876, -167.48872081935406], "episode_lengths": [100, 100, 42, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1737715077014588, "mean_inference_ms": 2.394903638279112, "mean_action_processing_ms": 0.22766215829163106, "mean_env_wait_ms": 3.0354324836539486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 183.24299144744873, "episode_reward_min": -175.62199070304632, "episode_reward_mean": -135.15221174332228, "episode_len_mean": 94.72727272727273, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-152.1386574730277, -172.1268064752221, 183.24299144744873, -167.3796276524663, -168.53416009247303, -175.62199070304632, -157.11144542694092, -171.20542296767235, -171.28015413880348, -167.0303348749876, -167.48872081935406], "episode_lengths": [100, 100, 42, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1737715077014588, "mean_inference_ms": 2.394903638279112, "mean_action_processing_ms": 0.22766215829163106, "mean_env_wait_ms": 3.0354324836539486, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 61122, "num_agent_steps_trained": 4362496, "num_env_steps_sampled": 61122, "num_env_steps_trained": 4362496, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 61122, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 61122, "timers": {"training_iteration_time_ms": 149.664, "load_time_ms": 0.267, "load_throughput": 958355.787, "learn_time_ms": 24.639, "learn_throughput": 10389.937, "synch_weights_time_ms": 5.948}, "counters": {"num_env_steps_sampled": 61122, "num_env_steps_trained": 4362496, "num_agent_steps_sampled": 61122, "num_agent_steps_trained": 4362496, "last_target_update_ts": 61122, "num_target_updates": 17041}, "done": false, "episodes_total": 627, "training_iteration": 61, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-20-34", "timestamp": 1675952434, "time_this_iter_s": 52.008280992507935, "time_total_s": 2741.0731830596924, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c21f0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cbdc0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2741.0731830596924, "timesteps_since_restore": 0, "iterations_since_restore": 61, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.582857142857144, "ram_util_percent": 91.12999999999998}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.056652605533599854, "actor_loss": 75.06427764892578, "critic_loss": 1.007399559020996, "alpha_loss": 0.24419525265693665, "alpha_value": 0.013428222388029099, "log_alpha_value": -4.310396671295166, "target_entropy": -5.0, "policy_t": -0.35493233799934387, "mean_q": -75.0690689086914, "max_q": -69.91065216064453, "min_q": -78.3011703491211}, "td_error": [0.2708282470703125, 0.47496795654296875, 0.3125724792480469, 0.5599098205566406, 0.302764892578125, 68.86915588378906, 72.04579162597656, 75.21578216552734, 0.3802528381347656, 0.15473175048828125, 0.08671188354492188, 0.07968521118164062, 68.68334197998047, 0.2980194091796875, 0.6810569763183594, 0.46492767333984375, 0.19327545166015625, 75.29391479492188, 0.19310379028320312, 0.34490203857421875, 0.169708251953125, 0.22223663330078125, 0.17808151245117188, 0.54150390625, 75.92769622802734, 0.4457130432128906, 72.85150909423828, 0.610809326171875, 0.22249603271484375, 0.7521514892578125, 0.7260971069335938, 73.86088562011719, 0.3056488037109375, 73.08087158203125, 0.28610992431640625, 0.013065338134765625, 0.8268623352050781, 75.39871215820312, 0.5671005249023438, 0.15095901489257812, 74.94015502929688, 0.3911285400390625, 0.16300201416015625, 0.2644615173339844, 70.92350006103516, 0.5518531799316406, 75.05492401123047, 0.3837318420410156, 0.1236114501953125, 68.58322143554688, 0.00730133056640625, 0.9172897338867188, 0.6064682006835938, 0.5166587829589844, 0.06897735595703125, 0.3241004943847656, 0.2784996032714844, 74.80603790283203, 0.25615692138671875, 0.24288177490234375, 319.96124267578125, 73.45002746582031, 318.82012939453125, 72.8934326171875, 0.44420623779296875, 0.2254486083984375, 0.28539276123046875, 0.6181869506835938, 74.66844177246094, 0.16277694702148438, 74.68461608886719, 321.2054138183594, 72.45683288574219, 70.96121215820312, 73.42196655273438, 0.6324882507324219, 0.29340362548828125, 0.6973075866699219, 0.06810379028320312, 0.42584991455078125, 0.5770950317382812, 0.37799835205078125, 0.429229736328125, 74.34950256347656, 0.069061279296875, 0.26657867431640625, 0.6523818969726562, 70.7551040649414, 0.3284339904785156, 0.5112342834472656, 0.7437362670898438, 0.5102310180664062, 323.42462158203125, 0.13930511474609375, 0.28610992431640625, 76.13577270507812, 0.7494964599609375, 0.39569854736328125, 0.11032867431640625, 0.3777198791503906, 72.83979797363281, 0.12320327758789062, 0.18267822265625, 0.4133720397949219, 72.96847534179688, 0.932525634765625, 74.86060333251953, 0.26448822021484375, 0.7356071472167969, 0.14567947387695312, 69.53939056396484, 0.5605659484863281, 0.5363006591796875, 0.5088424682617188, 0.47675323486328125, 0.391693115234375, 0.32445526123046875, 0.8600845336914062, 0.48354339599609375, 0.1476287841796875, 0.3913421630859375, 0.08298492431640625, 73.48072814941406, 0.39630126953125, 0.06439208984375, 0.4241790771484375, 0.0861358642578125, 0.5895195007324219, 0.49755859375, 0.3021087646484375, 0.32147979736328125, 0.26222991943359375, 0.14359664916992188, 0.49169158935546875, 0.040470123291015625, 73.58882141113281, 0.4647178649902344, 0.516357421875, 0.6383476257324219, 0.2647590637207031, 72.8545913696289, 0.3306884765625, 0.610260009765625, 0.16142654418945312, 0.5340728759765625, 321.69287109375, 0.16977691650390625, 0.5667381286621094, 0.3453521728515625, 0.3319129943847656, 0.9524765014648438, 0.20080184936523438, 75.36971282958984, 0.5327720642089844, 0.1724090576171875, 0.49964141845703125, 0.13653945922851562, 75.04837036132812, 73.9427490234375, 0.13392257690429688, 75.31649780273438, 322.4769287109375, 0.7706069946289062, 0.34398651123046875, 0.40032196044921875, 0.2990760803222656, 0.20230484008789062, 0.4899711608886719, 0.32977294921875, 70.23282623291016, 0.2253265380859375, 0.046321868896484375, 0.28827667236328125, 0.5279159545898438, 75.11892700195312, 0.4763336181640625, 71.32201385498047, 0.2909889221191406, 0.5621299743652344, 0.4974479675292969, 321.0933532714844, 0.4621925354003906, 0.32311248779296875, 0.693878173828125, 70.55464935302734, 72.82571411132812, 73.6209487915039, 0.44446563720703125, 0.6095123291015625, 0.24061203002929688, 0.16056060791015625, 0.30336761474609375, 0.27753448486328125, 0.46210479736328125, 0.7454376220703125, 320.8997802734375, 75.48213195800781, 74.4925308227539, 75.13359069824219, 0.4740447998046875, 0.5197257995605469, 0.0797882080078125, 68.86532592773438, 0.1582489013671875, 0.4378852844238281, 75.35037994384766, 0.60552978515625, 0.3624763488769531, 0.03650665283203125, 0.5004806518554688, 0.6604652404785156, 0.4593315124511719, 0.5346603393554688, 0.47641754150390625, 0.22258377075195312, 0.274932861328125, 75.11626434326172, 0.5236396789550781, 0.15428543090820312, 319.349365234375, 73.17233276367188, 73.03831481933594, 0.4997444152832031, 1.0821037292480469, 0.84149169921875, 0.72393798828125, 0.14959716796875, 0.463897705078125, 69.86674499511719, 0.6138916015625, 0.4716300964355469, 0.10296630859375, 0.26639556884765625, 72.74562072753906, 70.6218490600586, 0.5871086120605469, 0.2884635925292969, 0.11785125732421875, 75.40562438964844, 0.3434257507324219, 0.20906448364257812, 0.3445854187011719, 0.1793365478515625, 0.3896636962890625, 0.460113525390625, 0.142974853515625, 73.61536407470703, 0.3318634033203125, 0.44872283935546875, 69.98623657226562, 0.3063087463378906, 0.6789703369140625, 0.2396240234375, 0.6140594482421875, 0.22632980346679688, 0.20710372924804688], "mean_td_error": 27.570053100585938, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 17375.0, "diff_num_grad_updates_vs_sampler_policy": 17374.0}}, "num_env_steps_sampled": 62124, "num_env_steps_trained": 4448000, "num_agent_steps_sampled": 62124, "num_agent_steps_trained": 4448000, "last_target_update_ts": 62124, "num_target_updates": 17375}, "sampler_results": {"episode_reward_max": 239.73450852930546, "episode_reward_min": -185.16179871559143, "episode_reward_mean": -67.65054373849522, "episode_len_mean": 79.81818181818181, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-166.44169382750988, -163.61962708085775, -165.41450536251068, 164.16573779284954, -156.2493090108037, -184.68035705387592, 239.73450852930546, -176.2363166809082, 211.67640355974436, -185.16179871559143, -161.9290232732892], "episode_lengths": [100, 100, 100, 50, 100, 100, 6, 100, 22, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1522581986748532, "mean_inference_ms": 2.365065178609856, "mean_action_processing_ms": 0.22422213681630165, "mean_env_wait_ms": 3.000933015446322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 239.73450852930546, "episode_reward_min": -185.16179871559143, "episode_reward_mean": -67.65054373849522, "episode_len_mean": 79.81818181818181, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-166.44169382750988, -163.61962708085775, -165.41450536251068, 164.16573779284954, -156.2493090108037, -184.68035705387592, 239.73450852930546, -176.2363166809082, 211.67640355974436, -185.16179871559143, -161.9290232732892], "episode_lengths": [100, 100, 100, 50, 100, 100, 6, 100, 22, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1522581986748532, "mean_inference_ms": 2.365065178609856, "mean_action_processing_ms": 0.22422213681630165, "mean_env_wait_ms": 3.000933015446322, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 62124, "num_agent_steps_trained": 4448000, "num_env_steps_sampled": 62124, "num_env_steps_trained": 4448000, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 62124, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 62124, "timers": {"training_iteration_time_ms": 150.051, "load_time_ms": 0.27, "load_throughput": 948618.98, "learn_time_ms": 23.942, "learn_throughput": 10692.595, "synch_weights_time_ms": 4.618}, "counters": {"num_env_steps_sampled": 62124, "num_env_steps_trained": 4448000, "num_agent_steps_sampled": 62124, "num_agent_steps_trained": 4448000, "last_target_update_ts": 62124, "num_target_updates": 17375}, "done": false, "episodes_total": 638, "training_iteration": 62, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-21-26", "timestamp": 1675952486, "time_this_iter_s": 51.265044927597046, "time_total_s": 2792.3382279872894, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093940>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105761f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2792.3382279872894, "timesteps_since_restore": 0, "iterations_since_restore": 62, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.511267605633805, "ram_util_percent": 91.45492957746481}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.05446416512131691, "actor_loss": 76.25946044921875, "critic_loss": 0.9490589499473572, "alpha_loss": -0.23494774103164673, "alpha_value": 0.01338253729045391, "log_alpha_value": -4.313804626464844, "target_entropy": -5.0, "policy_t": -0.35983332991600037, "mean_q": -76.21299743652344, "max_q": -70.89612579345703, "min_q": -79.94763946533203}, "td_error": [0.8709335327148438, 77.09028625488281, 0.323394775390625, 0.8544654846191406, 0.7966690063476562, 0.49555206298828125, 0.15348052978515625, 0.3980369567871094, 0.4503631591796875, 0.05588531494140625, 0.5803985595703125, 0.5316848754882812, 0.5506324768066406, 76.46220397949219, 71.10909271240234, 0.2780189514160156, 0.32350921630859375, 319.9111328125, 0.7414398193359375, 0.2860908508300781, 0.3655815124511719, 0.22326278686523438, 72.29205322265625, 0.3449859619140625, 323.2466125488281, 0.8727607727050781, 0.30735015869140625, 0.5892524719238281, 0.28924560546875, 0.44528961181640625, 0.38611602783203125, 0.4953727722167969, 0.11762237548828125, 0.9029731750488281, 72.541015625, 0.14797210693359375, 0.6084671020507812, 0.2899932861328125, 0.30138397216796875, 0.46303558349609375, 0.5499305725097656, 0.12468338012695312, 0.3994102478027344, 323.45294189453125, 0.6491546630859375, 0.24389266967773438, 0.4225006103515625, 0.4515533447265625, 76.14134216308594, 0.15535736083984375, 73.71183776855469, 0.3535003662109375, 76.07102966308594, 1.0894241333007812, 0.930511474609375, 0.6565284729003906, 0.15456008911132812, 0.37133026123046875, 0.7559852600097656, 0.3668785095214844, 0.22702789306640625, 74.3968734741211, 320.5341796875, 0.6250572204589844, 77.77206420898438, 76.4764175415039, 74.82283020019531, 0.5739288330078125, 1.0547866821289062, 0.7395820617675781, 0.4767723083496094, 0.29290008544921875, 0.09571456909179688, 0.4594688415527344, 0.744354248046875, 76.74947357177734, 0.61993408203125, 0.5335655212402344, 76.60281372070312, 75.96882629394531, 0.3373374938964844, 0.6051216125488281, 0.790679931640625, 0.6384696960449219, 0.5491676330566406, 0.3456306457519531, 0.47210693359375, 0.7926864624023438, 0.39019775390625, 0.4976997375488281, 0.1927947998046875, 73.98242950439453, 73.08866882324219, 0.4134521484375, 0.3638496398925781, 0.8741226196289062, 0.696380615234375, 0.5357551574707031, 0.7002601623535156, 0.6581268310546875, 76.83207702636719, 76.2116928100586, 0.9426460266113281, 0.8247299194335938, 0.4655876159667969, 0.07880401611328125, 0.059146881103515625, 0.8012809753417969, 0.6110649108886719, 0.713958740234375, 77.54766845703125, 0.3887672424316406, 0.09351348876953125, 0.17702102661132812, 0.5109367370605469, 0.4801216125488281, 74.6583023071289, 0.20449066162109375, 0.4831047058105469, 0.481597900390625, 72.44233703613281, 0.19441604614257812, 0.6702804565429688, 0.2962799072265625, 0.6906356811523438, 0.24832916259765625, 76.48086547851562, 0.036075592041015625, 0.045886993408203125, 73.63870239257812, 76.71266174316406, 74.18873596191406, 0.0683135986328125, 0.42519378662109375, 0.23973846435546875, 0.6159324645996094, 320.88836669921875, 0.7317123413085938, 75.56144714355469, 0.3036537170410156, 0.22701644897460938, 325.4902648925781, 0.18899917602539062, 0.09981918334960938, 0.6001701354980469, 0.2749595642089844, 0.4042701721191406, 75.86766052246094, 0.27095794677734375, 0.420745849609375, 0.42572784423828125, 0.6672248840332031, 71.32826232910156, 76.5510025024414, 0.1291656494140625, 0.9256515502929688, 76.3499984741211, 0.34880828857421875, 76.91722106933594, 73.85829162597656, 0.34304046630859375, 76.91283416748047, 0.5508041381835938, 0.5105743408203125, 0.306976318359375, 0.14197921752929688, 322.8107604980469, 0.6731491088867188, 0.13647079467773438, 0.22513580322265625, 0.233856201171875, 0.6672554016113281, 69.98617553710938, 0.7645454406738281, 0.3700828552246094, 76.2906265258789, 0.4559974670410156, 0.5776901245117188, 0.4952507019042969, 74.30648803710938, 0.1290130615234375, 74.20137786865234, 0.10118865966796875, 0.22269439697265625, 0.630340576171875, 0.9430160522460938, 71.91120910644531, 0.0831756591796875, 0.3556022644042969, 0.3911399841308594, 0.5801124572753906, 0.4199256896972656, 76.90435791015625, 0.4726676940917969, 0.1249237060546875, 0.535736083984375, 71.859130859375, 0.4567108154296875, 76.54100036621094, 0.3836669921875, 75.60629272460938, 0.12602996826171875, 1.3483695983886719, 0.7120513916015625, 0.5036468505859375, 1.0130538940429688, 0.2663726806640625, 0.6445236206054688, 0.3839683532714844, 0.31341552734375, 0.450347900390625, 71.72625732421875, 73.6541748046875, 0.9855079650878906, 75.25689697265625, 71.06158447265625, 0.435791015625, 76.73529815673828, 1.492218017578125, 71.27729797363281, 0.43317413330078125, 0.6360092163085938, 0.11517333984375, 0.13222503662109375, 71.77603912353516, 0.1837158203125, 0.4188804626464844, 0.6917648315429688, 0.5550193786621094, 0.5311431884765625, 0.14424896240234375, 0.5808334350585938, 75.49856567382812, 71.34986877441406, 0.191131591796875, 77.19764709472656, 0.5797309875488281, 73.15116119384766, 75.32286071777344, 0.3077545166015625, 0.8550872802734375, 0.5271644592285156, 0.7987823486328125, 0.6001663208007812, 0.4122200012207031, 0.542694091796875, 0.7033538818359375, 0.2605781555175781, 70.76025390625, 0.452239990234375, 0.38219451904296875, 0.47704315185546875, 0.3137359619140625, 0.40582275390625, 0.8021087646484375, 1.028533935546875], "mean_td_error": 25.4951114654541, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 17709.0, "diff_num_grad_updates_vs_sampler_policy": 17708.0}}, "num_env_steps_sampled": 63126, "num_env_steps_trained": 4533504, "num_agent_steps_sampled": 63126, "num_agent_steps_trained": 4533504, "last_target_update_ts": 63126, "num_target_updates": 17709}, "sampler_results": {"episode_reward_max": -164.83878053724766, "episode_reward_min": -184.31719098985195, "episode_reward_mean": -172.19335282345614, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-173.22791515290737, -166.02916425466537, -184.31719098985195, -164.90399967879057, -167.61980755627155, -172.49408177286386, -181.30813418328762, -164.83878053724766, -167.37792050093412, -175.67796140164137, -165.0356966406107, -183.4895812124014], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.161695348102149, "mean_inference_ms": 2.3783665558109326, "mean_action_processing_ms": 0.2257217219056826, "mean_env_wait_ms": 3.018582295305679, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -164.83878053724766, "episode_reward_min": -184.31719098985195, "episode_reward_mean": -172.19335282345614, "episode_len_mean": 100.0, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-173.22791515290737, -166.02916425466537, -184.31719098985195, -164.90399967879057, -167.61980755627155, -172.49408177286386, -181.30813418328762, -164.83878053724766, -167.37792050093412, -175.67796140164137, -165.0356966406107, -183.4895812124014], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.161695348102149, "mean_inference_ms": 2.3783665558109326, "mean_action_processing_ms": 0.2257217219056826, "mean_env_wait_ms": 3.018582295305679, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 63126, "num_agent_steps_trained": 4533504, "num_env_steps_sampled": 63126, "num_env_steps_trained": 4533504, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 63126, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 63126, "timers": {"training_iteration_time_ms": 149.157, "load_time_ms": 0.275, "load_throughput": 930774.813, "learn_time_ms": 24.949, "learn_throughput": 10260.873, "synch_weights_time_ms": 5.077}, "counters": {"num_env_steps_sampled": 63126, "num_env_steps_trained": 4533504, "num_agent_steps_sampled": 63126, "num_agent_steps_trained": 4533504, "last_target_update_ts": 63126, "num_target_updates": 17709}, "done": false, "episodes_total": 650, "training_iteration": 63, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-22-17", "timestamp": 1675952537, "time_this_iter_s": 50.72093605995178, "time_total_s": 2843.059164047241, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588880>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10576040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2843.059164047241, "timesteps_since_restore": 0, "iterations_since_restore": 63, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 37.994202898550725, "ram_util_percent": 91.45072463768112}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.19426460564136505, "actor_loss": 78.0165023803711, "critic_loss": 1.008075475692749, "alpha_loss": 0.8364347815513611, "alpha_value": 0.01349216140806675, "log_alpha_value": -4.3056464195251465, "target_entropy": -5.0, "policy_t": -0.3287544846534729, "mean_q": -77.97445678710938, "max_q": -72.05387115478516, "min_q": -81.27588653564453}, "td_error": [78.74942779541016, 78.69392395019531, 0.4806785583496094, 75.7325439453125, 0.0518341064453125, 0.2808647155761719, 0.6811180114746094, 0.5938148498535156, 0.26848602294921875, 0.19427871704101562, 0.450531005859375, 73.96714782714844, 0.243316650390625, 0.8336563110351562, 0.30715179443359375, 0.12896728515625, 0.1768798828125, 0.067413330078125, 0.7367401123046875, 0.4445381164550781, 0.6124038696289062, 0.13936996459960938, 327.1879577636719, 0.041339874267578125, 0.5020332336425781, 0.6149177551269531, 0.20478439331054688, 0.10838699340820312, 0.3557243347167969, 0.3002662658691406, 0.7042808532714844, 73.17074584960938, 79.05320739746094, 1.1858482360839844, 0.5187873840332031, 0.4725914001464844, 77.44896697998047, 78.06703186035156, 0.2805900573730469, 324.89117431640625, 75.49272918701172, 0.051540374755859375, 0.7116127014160156, 73.80183410644531, 0.23545074462890625, 0.8082427978515625, 71.45527648925781, 0.18326950073242188, 0.27141571044921875, 76.35266876220703, 0.5502243041992188, 0.224822998046875, 0.3028907775878906, 0.48426055908203125, 0.49648284912109375, 78.11256408691406, 0.21804428100585938, 0.23728561401367188, 0.3888816833496094, 76.58079528808594, 77.30128479003906, 75.89419555664062, 0.5363655090332031, 0.3651618957519531, 0.18193817138671875, 0.7106590270996094, 0.023647308349609375, 0.2730216979980469, 0.2885284423828125, 0.15983963012695312, 0.5533027648925781, 0.336669921875, 0.8108291625976562, 0.7075004577636719, 0.8301582336425781, 0.455169677734375, 74.94967651367188, 78.29088592529297, 0.5157203674316406, 76.61671447753906, 0.18493270874023438, 76.54798889160156, 0.5596771240234375, 0.41009521484375, 74.78987121582031, 75.92632293701172, 0.49452972412109375, 0.8847541809082031, 0.3438262939453125, 72.72650146484375, 0.20088577270507812, 78.07627868652344, 0.18239212036132812, 0.048381805419921875, 0.3789253234863281, 78.77605438232422, 0.3274192810058594, 0.2161712646484375, 324.32183837890625, 0.42694091796875, 0.7364463806152344, 0.5457954406738281, 327.1879577636719, 0.16167068481445312, 0.54669189453125, 0.4435005187988281, 0.6499671936035156, 0.7472648620605469, 0.4147911071777344, 0.35167694091796875, 0.16259002685546875, 0.1118927001953125, 0.3686256408691406, 0.09164047241210938, 0.4092369079589844, 79.45497131347656, 0.23496246337890625, 0.6626930236816406, 0.2564125061035156, 73.04257202148438, 0.5969963073730469, 0.5480461120605469, 0.7600479125976562, 0.2501983642578125, 0.2980499267578125, 0.22463607788085938, 0.2714653015136719, 0.1985626220703125, 73.37970733642578, 0.10797500610351562, 0.6599197387695312, 0.8685264587402344, 75.94590759277344, 79.33795166015625, 0.350067138671875, 0.59344482421875, 76.77523803710938, 0.21605682373046875, 0.48754119873046875, 0.5489349365234375, 0.3689918518066406, 0.2957267761230469, 75.26472473144531, 0.6380882263183594, 0.0907440185546875, 0.27813720703125, 0.32494354248046875, 0.20112991333007812, 0.2963294982910156, 0.12442398071289062, 326.1348876953125, 77.67190551757812, 78.91741180419922, 324.39947509765625, 0.8928871154785156, 0.35924530029296875, 74.37422180175781, 0.5204582214355469, 1.3873558044433594, 0.6099090576171875, 0.2830924987792969, 0.5303993225097656, 0.10982131958007812, 0.215972900390625, 0.5138931274414062, 324.8143310546875, 0.5287704467773438, 0.4113006591796875, 0.6555900573730469, 0.4745674133300781, 0.2717399597167969, 0.29364776611328125, 0.036632537841796875, 0.5389137268066406, 0.6952629089355469, 0.17872238159179688, 0.2937889099121094, 0.3345794677734375, 77.34115600585938, 0.25737762451171875, 0.2923088073730469, 73.5619125366211, 0.3762779235839844, 77.59236145019531, 0.16311264038085938, 0.4829444885253906, 0.4880409240722656, 327.56549072265625, 0.08141708374023438, 0.0914306640625, 0.0460662841796875, 78.06703186035156, 77.82093811035156, 71.84028625488281, 0.29227447509765625, 0.45656585693359375, 77.63323974609375, 0.2386016845703125, 0.1536865234375, 0.21537399291992188, 0.5646324157714844, 76.67390441894531, 76.38673400878906, 72.35548400878906, 0.63311767578125, 0.2915992736816406, 0.4729804992675781, 0.6091957092285156, 75.09672546386719, 0.15322494506835938, 0.7889938354492188, 75.080810546875, 76.61058044433594, 0.6010856628417969, 0.5773353576660156, 0.331878662109375, 0.6160736083984375, 78.73939514160156, 0.12625503540039062, 72.6531982421875, 0.16498947143554688, 0.9687576293945312, 78.73451232910156, 75.58805847167969, 0.12831497192382812, 0.4684028625488281, 75.96987915039062, 0.41028594970703125, 0.6477241516113281, 77.59272766113281, 72.93141174316406, 0.9693832397460938, 78.10920715332031, 0.3126716613769531, 0.70611572265625, 0.17006301879882812, 0.6674461364746094, 0.5276565551757812, 0.15533065795898438, 0.062427520751953125, 0.40474700927734375, 0.21336746215820312, 0.23253631591796875, 0.2729454040527344, 0.21814346313476562, 0.36336517333984375, 0.3021278381347656, 0.3848381042480469, 0.3928680419921875, 0.2612419128417969, 0.5289688110351562, 0.3470344543457031, 76.78616333007812, 0.511993408203125, 0.2928352355957031, 0.5376358032226562], "mean_td_error": 27.44773292541504, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 18043.0, "diff_num_grad_updates_vs_sampler_policy": 18042.0}}, "num_env_steps_sampled": 64128, "num_env_steps_trained": 4619008, "num_agent_steps_sampled": 64128, "num_agent_steps_trained": 4619008, "last_target_update_ts": 64128, "num_target_updates": 18043}, "sampler_results": {"episode_reward_max": 155.9317017197609, "episode_reward_min": -178.00977374613285, "episode_reward_mean": -131.80782703227467, "episode_len_mean": 95.55555555555556, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-161.44142983853817, -168.61906314641237, -178.00977374613285, -177.75505349040031, -159.45529536157846, -171.50798258930445, -161.90505647659302, -163.5084903612733, 155.9317017197609], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 60]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1606687460805056, "mean_inference_ms": 2.3775513035971017, "mean_action_processing_ms": 0.22564693327857632, "mean_env_wait_ms": 3.0192040532362205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 155.9317017197609, "episode_reward_min": -178.00977374613285, "episode_reward_mean": -131.80782703227467, "episode_len_mean": 95.55555555555556, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-161.44142983853817, -168.61906314641237, -178.00977374613285, -177.75505349040031, -159.45529536157846, -171.50798258930445, -161.90505647659302, -163.5084903612733, 155.9317017197609], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 60]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1606687460805056, "mean_inference_ms": 2.3775513035971017, "mean_action_processing_ms": 0.22564693327857632, "mean_env_wait_ms": 3.0192040532362205, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 64128, "num_agent_steps_trained": 4619008, "num_env_steps_sampled": 64128, "num_env_steps_trained": 4619008, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 64128, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 64128, "timers": {"training_iteration_time_ms": 147.258, "load_time_ms": 0.28, "load_throughput": 915146.871, "learn_time_ms": 23.921, "learn_throughput": 10701.707, "synch_weights_time_ms": 5.602}, "counters": {"num_env_steps_sampled": 64128, "num_env_steps_trained": 4619008, "num_agent_steps_sampled": 64128, "num_agent_steps_trained": 4619008, "last_target_update_ts": 64128, "num_target_updates": 18043}, "done": false, "episodes_total": 659, "training_iteration": 64, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-23-08", "timestamp": 1675952588, "time_this_iter_s": 51.817686319351196, "time_total_s": 2894.8768503665924, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde38163070>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb550>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2894.8768503665924, "timesteps_since_restore": 0, "iterations_since_restore": 64, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.774647887323944, "ram_util_percent": 92.03098591549295}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3556196987628937, "actor_loss": 79.59092712402344, "critic_loss": 1.1047813892364502, "alpha_loss": 1.5236032009124756, "alpha_value": 0.013782421126961708, "log_alpha_value": -4.284361362457275, "target_entropy": -5.0, "policy_t": -0.31917881965637207, "mean_q": -79.53946685791016, "max_q": -74.55268859863281, "min_q": -82.95907592773438}, "td_error": [0.22083282470703125, 0.21976470947265625, 0.5225639343261719, 0.4713020324707031, 74.28075408935547, 0.23876190185546875, 0.615631103515625, 0.4268379211425781, 0.11529541015625, 79.36041259765625, 0.35292816162109375, 0.6466102600097656, 0.8133964538574219, 324.9215087890625, 0.2729835510253906, 0.5390892028808594, 0.6028366088867188, 79.83137512207031, 76.86495971679688, 0.4106712341308594, 0.3333473205566406, 0.41522979736328125, 0.16390609741210938, 79.01638793945312, 0.10271072387695312, 0.4244575500488281, 0.24653244018554688, 80.30168151855469, 325.964111328125, 80.17282104492188, 75.75784301757812, 0.3952674865722656, 0.22946929931640625, 78.54327392578125, 0.3970146179199219, 0.43131256103515625, 0.5985832214355469, 0.21248245239257812, 0.43111419677734375, 0.6376914978027344, 0.6368026733398438, 0.7229118347167969, 76.14047241210938, 0.4839591979980469, 0.20893478393554688, 0.6656074523925781, 0.4914588928222656, 0.3174400329589844, 0.6063690185546875, 79.0947494506836, 74.58232116699219, 0.267547607421875, 0.36890411376953125, 1.2474632263183594, 0.21802902221679688, 74.87989807128906, 0.14801406860351562, 79.86683654785156, 0.022594451904296875, 77.45909118652344, 0.6091957092285156, 0.21203994750976562, 80.17365264892578, 0.6674461364746094, 0.3154869079589844, 78.866455078125, 0.262054443359375, 0.171539306640625, 0.4923973083496094, 80.76519775390625, 0.20439529418945312, 76.51087951660156, 81.20563507080078, 0.5009956359863281, 73.41563415527344, 0.1620025634765625, 72.50296783447266, 0.41745758056640625, 74.5822525024414, 0.612884521484375, 0.2905845642089844, 0.6697959899902344, 79.00456237792969, 0.12829208374023438, 78.50624084472656, 325.2257385253906, 74.58232116699219, 80.14631652832031, 0.9357376098632812, 0.15412521362304688, 0.7484931945800781, 0.4247589111328125, 0.2923622131347656, 75.49919128417969, 326.5985412597656, 0.16170120239257812, 0.5671882629394531, 0.3561439514160156, 0.8081588745117188, 0.26741790771484375, 0.7188682556152344, 77.24519348144531, 0.6924171447753906, 78.16625213623047, 0.6216468811035156, 79.90220642089844, 77.85762023925781, 0.18605422973632812, 0.921539306640625, 74.0865478515625, 0.6301116943359375, 0.4372749328613281, 0.3614616394042969, 0.4943656921386719, 0.2574729919433594, 0.129180908203125, 0.29611968994140625, 0.12248611450195312, 0.02286529541015625, 0.6299705505371094, 0.3972282409667969, 79.04536437988281, 0.16704940795898438, 0.4651679992675781, 0.24354171752929688, 0.2568473815917969, 0.17598724365234375, 0.16092300415039062, 80.82017517089844, 0.30284881591796875, 79.9084243774414, 79.59281921386719, 0.6639823913574219, 0.08272933959960938, 0.4148445129394531, 0.4855613708496094, 79.01551055908203, 0.5651931762695312, 0.22812271118164062, 0.29247283935546875, 0.19411087036132812, 0.370452880859375, 0.20366287231445312, 76.61659240722656, 0.21295928955078125, 79.5621337890625, 0.18963623046875, 0.11700820922851562, 0.3402137756347656, 0.38080596923828125, 74.34530639648438, 79.36739349365234, 0.3862419128417969, 80.15847778320312, 0.24425888061523438, 77.028076171875, 0.6498146057128906, 0.08974075317382812, 79.0396728515625, 0.6243858337402344, 0.5830726623535156, 0.07724380493164062, 76.217041015625, 0.12279891967773438, 0.08726119995117188, 78.9232177734375, 72.81035614013672, 77.66157531738281, 0.3824348449707031, 76.82286071777344, 0.22129058837890625, 326.3481140136719, 0.139984130859375, 328.0425109863281, 0.3934974670410156, 0.4494667053222656, 73.909423828125, 0.3199119567871094, 79.57148742675781, 0.34593963623046875, 0.02947998046875, 0.06838607788085938, 0.19374465942382812, 74.979248046875, 0.15896224975585938, 0.4397087097167969, 0.8635597229003906, 0.07555007934570312, 0.142181396484375, 0.3431587219238281, 0.2866973876953125, 0.19052505493164062, 0.16947174072265625, 0.031558990478515625, 0.8214912414550781, 326.3481140136719, 0.5974998474121094, 0.2842063903808594, 0.4100379943847656, 0.6970863342285156, 0.2700080871582031, 0.4375114440917969, 0.3278312683105469, 78.96436309814453, 0.5056495666503906, 0.7636337280273438, 0.15478134155273438, 0.08118057250976562, 77.33015441894531, 0.7328338623046875, 0.5202217102050781, 0.3725738525390625, 0.1971588134765625, 0.0711517333984375, 0.10516738891601562, 77.18186950683594, 0.8898544311523438, 73.18775939941406, 0.4964103698730469, 79.97393035888672, 0.2070159912109375, 0.06290054321289062, 0.3038482666015625, 0.7636528015136719, 0.01910400390625, 77.0574951171875, 0.342193603515625, 0.019012451171875, 0.4853019714355469, 0.4150199890136719, 0.7459259033203125, 0.540771484375, 0.3967018127441406, 0.3984107971191406, 79.01795959472656, 0.2678565979003906, 78.80020141601562, 0.6646041870117188, 75.41136932373047, 0.3675727844238281, 79.7676010131836, 0.4247856140136719, 0.036411285400390625, 79.30738830566406, 0.10955429077148438, 76.70024108886719, 80.81539916992188, 0.225250244140625, 78.96803283691406, 0.14681243896484375, 0.3921012878417969, 0.12014389038085938, 0.039813995361328125, 0.161376953125, 0.5125846862792969, 0.2649803161621094], "mean_td_error": 29.52164077758789, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 18377.0, "diff_num_grad_updates_vs_sampler_policy": 18376.0}}, "num_env_steps_sampled": 65130, "num_env_steps_trained": 4704512, "num_agent_steps_sampled": 65130, "num_agent_steps_trained": 4704512, "last_target_update_ts": 65130, "num_target_updates": 18377}, "sampler_results": {"episode_reward_max": 183.30390575528145, "episode_reward_min": -179.6067262738943, "episode_reward_mean": -138.66359566835067, "episode_len_mean": 94.91666666666667, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.30390575528145, -171.12455678731203, -155.62387500703335, -173.1842506080866, -158.1185237467289, -164.1399745941162, -168.26139509677887, -171.55332411825657, -179.6067262738943, -172.7773946300149, -167.53122694790363, -165.34580596536398], "episode_lengths": [39, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.159725753217009, "mean_inference_ms": 2.375829445487214, "mean_action_processing_ms": 0.2255228950784308, "mean_env_wait_ms": 3.0170383087027477, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 183.30390575528145, "episode_reward_min": -179.6067262738943, "episode_reward_mean": -138.66359566835067, "episode_len_mean": 94.91666666666667, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [183.30390575528145, -171.12455678731203, -155.62387500703335, -173.1842506080866, -158.1185237467289, -164.1399745941162, -168.26139509677887, -171.55332411825657, -179.6067262738943, -172.7773946300149, -167.53122694790363, -165.34580596536398], "episode_lengths": [39, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.159725753217009, "mean_inference_ms": 2.375829445487214, "mean_action_processing_ms": 0.2255228950784308, "mean_env_wait_ms": 3.0170383087027477, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 65130, "num_agent_steps_trained": 4704512, "num_env_steps_sampled": 65130, "num_env_steps_trained": 4704512, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 65130, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 65130, "timers": {"training_iteration_time_ms": 150.034, "load_time_ms": 0.27, "load_throughput": 949373.85, "learn_time_ms": 24.054, "learn_throughput": 10642.54, "synch_weights_time_ms": 5.747}, "counters": {"num_env_steps_sampled": 65130, "num_env_steps_trained": 4704512, "num_agent_steps_sampled": 65130, "num_agent_steps_trained": 4704512, "last_target_update_ts": 65130, "num_target_updates": 18377}, "done": false, "episodes_total": 671, "training_iteration": 65, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-23-59", "timestamp": 1675952639, "time_this_iter_s": 50.45256757736206, "time_total_s": 2945.3294179439545, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580fd0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10558160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2945.3294179439545, "timesteps_since_restore": 0, "iterations_since_restore": 65, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 37.38260869565218, "ram_util_percent": 92.10579710144927}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5008028149604797, "actor_loss": 81.12873077392578, "critic_loss": 0.8090665340423584, "alpha_loss": 2.1233022212982178, "alpha_value": 0.01441052183508873, "log_alpha_value": -4.2397966384887695, "target_entropy": -5.0, "policy_t": -0.35124513506889343, "mean_q": -81.07975006103516, "max_q": -75.76871490478516, "min_q": -84.90445709228516}, "td_error": [80.68123626708984, 82.20143127441406, 0.2689323425292969, 0.6004486083984375, 80.27993774414062, 0.8396186828613281, 0.119415283203125, 0.06566619873046875, 0.23829269409179688, 0.057506561279296875, 0.2024993896484375, 0.405303955078125, 0.5214042663574219, 0.39874267578125, 0.19104385375976562, 0.7019844055175781, 0.5227279663085938, 81.4066162109375, 0.1218109130859375, 80.2364273071289, 0.4862518310546875, 81.74208068847656, 0.14272308349609375, 77.15587615966797, 0.7242431640625, 0.11629104614257812, 80.987060546875, 0.8696212768554688, 0.9754791259765625, 0.715087890625, 0.38759613037109375, 0.249267578125, 0.7565269470214844, 81.81328582763672, 0.9462928771972656, 0.1155853271484375, 0.334564208984375, 0.5953445434570312, 0.9084281921386719, 0.3563499450683594, 82.82388305664062, 0.16582107543945312, 0.3887748718261719, 0.14330291748046875, 0.2482147216796875, 0.2533111572265625, 0.47765350341796875, 0.39337921142578125, 80.98912048339844, 0.23868560791015625, 75.31648254394531, 0.9340438842773438, 81.72476196289062, 79.5255355834961, 0.35301971435546875, 0.43024444580078125, 0.2992210388183594, 0.19098663330078125, 329.9241943359375, 0.08742904663085938, 0.15289306640625, 0.4413719177246094, 0.4114189147949219, 76.48138427734375, 82.14118957519531, 0.4989509582519531, 0.29402923583984375, 0.2475738525390625, 0.31420135498046875, 0.4045448303222656, 0.009471893310546875, 0.101470947265625, 0.08859634399414062, 0.4650764465332031, 0.38120269775390625, 81.41613006591797, 0.07110595703125, 0.6106071472167969, 0.3346099853515625, 0.0327911376953125, 0.07169342041015625, 80.6879653930664, 0.5669593811035156, 0.6444015502929688, 0.7189407348632812, 0.9056282043457031, 0.42047882080078125, 81.75601196289062, 0.4718971252441406, 0.10771942138671875, 0.5475387573242188, 0.15422821044921875, 76.28262329101562, 0.8061904907226562, 0.6312713623046875, 0.6438369750976562, 0.16953277587890625, 0.48760223388671875, 0.2388916015625, 0.715240478515625, 0.31171417236328125, 0.2946815490722656, 0.8447608947753906, 0.4179229736328125, 0.14406204223632812, 0.4597320556640625, 0.8086624145507812, 0.1381072998046875, 79.10511016845703, 0.2672271728515625, 0.18703079223632812, 0.2200164794921875, 76.38691711425781, 0.11048507690429688, 0.13000106811523438, 0.2630462646484375, 79.04710388183594, 79.58451843261719, 0.17560577392578125, 1.041778564453125, 0.48767852783203125, 80.12805938720703, 0.5521965026855469, 0.4818878173828125, 0.3426094055175781, 0.12653350830078125, 0.6254081726074219, 0.3454856872558594, 0.6148872375488281, 0.5207328796386719, 0.09860992431640625, 0.061893463134765625, 0.8050155639648438, 0.09302902221679688, 80.61956787109375, 0.09312820434570312, 0.37100982666015625, 0.0188751220703125, 0.5317230224609375, 81.71055603027344, 0.4802513122558594, 0.2764015197753906, 0.3252143859863281, 0.13301849365234375, 0.4733085632324219, 0.18567276000976562, 0.6675453186035156, 0.11161422729492188, 0.5667076110839844, 0.6196327209472656, 0.2994041442871094, 0.7316207885742188, 0.1820526123046875, 0.21731948852539062, 0.2605476379394531, 0.07574844360351562, 0.13341522216796875, 0.32865142822265625, 0.3545494079589844, 0.3729515075683594, 0.2967262268066406, 328.58245849609375, 0.21575546264648438, 0.5868453979492188, 0.813323974609375, 81.81727600097656, 0.12853240966796875, 0.14789199829101562, 0.18022918701171875, 0.5831832885742188, 0.799896240234375, 74.74668884277344, 0.12112808227539062, 76.59162902832031, 0.6517791748046875, 0.7754173278808594, 0.042629241943359375, 0.02645111083984375, 0.16928863525390625, 0.7719764709472656, 327.4278869628906, 0.22613906860351562, 0.7628974914550781, 0.42252349853515625, 0.33991241455078125, 0.033634185791015625, 81.67721557617188, 0.0433197021484375, 0.04834747314453125, 0.7008895874023438, 0.6945228576660156, 78.3403549194336, 79.13618469238281, 80.9093017578125, 0.05139923095703125, 328.278076171875, 0.4560127258300781, 76.46440124511719, 0.21251678466796875, 0.3509979248046875, 0.7348861694335938, 77.79121398925781, 0.6312179565429688, 0.4032325744628906, 0.7662506103515625, 0.1470794677734375, 0.35991668701171875, 76.46440124511719, 0.12803268432617188, 80.49195861816406, 74.93030548095703, 0.26145172119140625, 0.1832122802734375, 0.6617698669433594, 0.11833953857421875, 0.5563201904296875, 77.40270233154297, 0.6228713989257812, 0.07993316650390625, 0.0402984619140625, 0.06319427490234375, 0.07514190673828125, 0.6094436645507812, 78.6072006225586, 80.78959655761719, 0.12013626098632812, 0.5529403686523438, 81.16056060791016, 0.24906539916992188, 0.8078956604003906, 0.1491241455078125, 0.639678955078125, 0.5608558654785156, 81.65370178222656, 0.1135101318359375, 0.3717765808105469, 0.8162078857421875, 0.5631103515625, 81.50382995605469, 0.3780059814453125, 0.00861358642578125, 0.31081390380859375, 0.3019599914550781, 81.53408813476562, 81.87728881835938, 0.07305526733398438, 80.04322814941406, 0.22422409057617188, 0.693328857421875, 75.02005004882812, 0.6505508422851562, 77.92365264892578, 0.8057746887207031, 0.29274749755859375, 80.5923080444336, 0.069183349609375], "mean_td_error": 21.290016174316406, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 18711.0, "diff_num_grad_updates_vs_sampler_policy": 18710.0}}, "num_env_steps_sampled": 66132, "num_env_steps_trained": 4790016, "num_agent_steps_sampled": 66132, "num_agent_steps_trained": 4790016, "last_target_update_ts": 66132, "num_target_updates": 18711}, "sampler_results": {"episode_reward_max": 198.18074981868267, "episode_reward_min": -188.14086382091045, "episode_reward_mean": -74.54947767271237, "episode_len_mean": 83.81818181818181, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-157.19410021603107, -188.14086382091045, -169.11975614726543, -170.2193198800087, 171.1429763957858, 179.46075742691755, 198.18074981868267, -160.25839917361736, -170.5428620427847, -167.42007557302713, -185.93336118757725], "episode_lengths": [100, 100, 100, 100, 47, 43, 32, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.156295746163601, "mean_inference_ms": 2.370544130692677, "mean_action_processing_ms": 0.22472781337053033, "mean_env_wait_ms": 3.0111810920602227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 198.18074981868267, "episode_reward_min": -188.14086382091045, "episode_reward_mean": -74.54947767271237, "episode_len_mean": 83.81818181818181, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-157.19410021603107, -188.14086382091045, -169.11975614726543, -170.2193198800087, 171.1429763957858, 179.46075742691755, 198.18074981868267, -160.25839917361736, -170.5428620427847, -167.42007557302713, -185.93336118757725], "episode_lengths": [100, 100, 100, 100, 47, 43, 32, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.156295746163601, "mean_inference_ms": 2.370544130692677, "mean_action_processing_ms": 0.22472781337053033, "mean_env_wait_ms": 3.0111810920602227, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 66132, "num_agent_steps_trained": 4790016, "num_env_steps_sampled": 66132, "num_env_steps_trained": 4790016, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 66132, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 66132, "timers": {"training_iteration_time_ms": 152.797, "load_time_ms": 0.329, "load_throughput": 777961.038, "learn_time_ms": 24.497, "learn_throughput": 10450.195, "synch_weights_time_ms": 4.974}, "counters": {"num_env_steps_sampled": 66132, "num_env_steps_trained": 4790016, "num_agent_steps_sampled": 66132, "num_agent_steps_trained": 4790016, "last_target_update_ts": 66132, "num_target_updates": 18711}, "done": false, "episodes_total": 682, "training_iteration": 66, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-24-50", "timestamp": 1675952690, "time_this_iter_s": 50.996140241622925, "time_total_s": 2996.3255581855774, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588c10>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cba60>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 2996.3255581855774, "timesteps_since_restore": 0, "iterations_since_restore": 66, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.16285714285714, "ram_util_percent": 92.06714285714285}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.4894280433654785, "actor_loss": 82.51847839355469, "critic_loss": 1.1814199686050415, "alpha_loss": 2.053804874420166, "alpha_value": 0.015050617046654224, "log_alpha_value": -4.196336269378662, "target_entropy": -5.0, "policy_t": -0.31680136919021606, "mean_q": -82.36874389648438, "max_q": -76.69085693359375, "min_q": -85.89157104492188}, "td_error": [0.4678077697753906, 0.01938629150390625, 0.10869979858398438, 0.4576225280761719, 0.18602371215820312, 0.5138015747070312, 0.8153266906738281, 0.47852325439453125, 82.89038848876953, 0.1079559326171875, 0.3291168212890625, 82.71923828125, 0.16753005981445312, 327.974365234375, 0.07183837890625, 81.0819091796875, 82.7589111328125, 0.2865562438964844, 1.0233116149902344, 0.317718505859375, 83.32516479492188, 0.15212631225585938, 0.6699180603027344, 0.3619842529296875, 82.39759063720703, 0.11791610717773438, 0.8984718322753906, 82.48237609863281, 0.3809356689453125, 83.20306396484375, 0.13303756713867188, 0.047176361083984375, 80.98880004882812, 0.0860137939453125, 0.3502044677734375, 0.2845458984375, 0.2740898132324219, 0.6410255432128906, 0.6551170349121094, 0.045166015625, 77.42481994628906, 81.74162292480469, 0.18123626708984375, 0.16763687133789062, 0.2010040283203125, 0.16263961791992188, 0.12064743041992188, 82.2569580078125, 0.2645835876464844, 0.26467132568359375, 0.6782379150390625, 83.18063354492188, 0.3524208068847656, 0.4313697814941406, 0.2984466552734375, 80.82384490966797, 82.71853637695312, 0.8102455139160156, 83.35484313964844, 0.173614501953125, 0.4782371520996094, 0.3713645935058594, 82.88420104980469, 80.0765380859375, 0.22835540771484375, 0.14874649047851562, 83.26609802246094, 0.2718009948730469, 0.8184661865234375, 83.4070053100586, 0.0228729248046875, 0.3470344543457031, 0.3272247314453125, 83.34571838378906, 329.0504150390625, 83.27604675292969, 0.3303642272949219, 0.6390266418457031, 0.8332290649414062, 0.41253662109375, 0.2684669494628906, 0.3950347900390625, 0.3177680969238281, 325.96221923828125, 79.76859283447266, 0.7432441711425781, 0.08994674682617188, 0.196136474609375, 0.4270896911621094, 0.17293930053710938, 80.41505432128906, 0.13312911987304688, 0.14126205444335938, 0.27716064453125, 0.19542694091796875, 0.22079849243164062, 0.8402671813964844, 79.03211975097656, 0.55401611328125, 0.8497314453125, 82.52883911132812, 80.76629638671875, 82.83418273925781, 79.03211975097656, 82.6785659790039, 83.4070053100586, 0.2831840515136719, 0.7531089782714844, 0.1136474609375, 0.8035659790039062, 0.32979583740234375, 82.54891204833984, 0.23436355590820312, 0.47211456298828125, 0.4597930908203125, 0.17882919311523438, 82.85638427734375, 77.02034759521484, 0.39249420166015625, 76.72769165039062, 83.01626586914062, 0.30350494384765625, 0.18324661254882812, 0.7202606201171875, 329.86663818359375, 329.1512756347656, 0.3815040588378906, 0.6616554260253906, 0.14783096313476562, 82.75191497802734, 81.06901550292969, 0.17828750610351562, 0.44045257568359375, 0.6061363220214844, 82.14193725585938, 0.06118011474609375, 0.3330268859863281, 0.33269500732421875, 79.69563293457031, 0.5366401672363281, 0.7904548645019531, 0.24094772338867188, 0.05222320556640625, 0.14683914184570312, 0.2934226989746094, 0.194122314453125, 0.45609283447265625, 0.5579986572265625, 0.1336822509765625, 0.4849395751953125, 0.3610877990722656, 0.3567695617675781, 77.78277587890625, 82.1690444946289, 329.40533447265625, 80.94178771972656, 0.14609527587890625, 0.3458595275878906, 0.119781494140625, 1.0790138244628906, 0.610748291015625, 0.29439544677734375, 0.4071006774902344, 0.09830093383789062, 0.39362335205078125, 77.42481994628906, 326.46380615234375, 78.43855285644531, 0.6762542724609375, 0.5961570739746094, 0.5598373413085938, 0.155181884765625, 0.13591766357421875, 0.3947792053222656, 79.95426940917969, 326.46380615234375, 0.26358795166015625, 83.10970306396484, 83.36727905273438, 0.32611083984375, 0.46445465087890625, 83.34571838378906, 0.24187088012695312, 0.13513946533203125, 0.24192047119140625, 83.65266418457031, 0.8456954956054688, 0.11798858642578125, 0.2759246826171875, 0.3337135314941406, 79.76783752441406, 78.835693359375, 0.3777618408203125, 82.33641815185547, 0.1593017578125, 0.6453056335449219, 0.5787582397460938, 0.2421417236328125, 0.23403167724609375, 0.08780288696289062, 0.33209228515625, 0.7772674560546875, 0.46735382080078125, 77.03556060791016, 0.3014068603515625, 0.400360107421875, 0.387298583984375, 0.5523681640625, 0.5762557983398438, 0.232421875, 0.373748779296875, 0.4748687744140625, 0.5684127807617188, 0.6327743530273438, 0.23892593383789062, 0.09923934936523438, 78.03273010253906, 327.83746337890625, 0.2733650207519531, 80.2183837890625, 327.2072448730469, 325.653076171875, 0.2941856384277344, 0.5392379760742188, 0.5869178771972656, 0.35889434814453125, 0.3065643310546875, 0.9151153564453125, 0.04918670654296875, 0.3097991943359375, 81.08905792236328, 0.5886459350585938, 0.19802093505859375, 0.7241249084472656, 0.2546272277832031, 0.8253860473632812, 0.0649566650390625, 0.3770942687988281, 0.5582809448242188, 83.26609802246094, 0.31502532958984375, 0.4380378723144531, 0.1060333251953125, 0.6646156311035156, 0.17708587646484375, 0.32189178466796875, 0.28112030029296875, 0.3281898498535156, 0.05712127685546875, 0.3616142272949219, 0.24742507934570312, 0.4919586181640625, 0.4745521545410156, 0.3060798645019531, 77.12337493896484, 0.2212066650390625], "mean_td_error": 33.083675384521484, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 19045.0, "diff_num_grad_updates_vs_sampler_policy": 19044.0}}, "num_env_steps_sampled": 67134, "num_env_steps_trained": 4875520, "num_agent_steps_sampled": 67134, "num_agent_steps_trained": 4875520, "last_target_update_ts": 67134, "num_target_updates": 19045}, "sampler_results": {"episode_reward_max": -167.23506778478622, "episode_reward_min": -194.75925220549107, "episode_reward_mean": -176.44510723650455, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-194.75925220549107, -167.45148000121117, -173.71280989050865, -183.20505180954933, -167.3187713623047, -167.23506778478622, -172.46199409663677, -187.53810274600983, -176.63034914433956, -174.13819332420826], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1692303371970652, "mean_inference_ms": 2.38934916249069, "mean_action_processing_ms": 0.2271182778171509, "mean_env_wait_ms": 3.0354050711250755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -167.23506778478622, "episode_reward_min": -194.75925220549107, "episode_reward_mean": -176.44510723650455, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-194.75925220549107, -167.45148000121117, -173.71280989050865, -183.20505180954933, -167.3187713623047, -167.23506778478622, -172.46199409663677, -187.53810274600983, -176.63034914433956, -174.13819332420826], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1692303371970652, "mean_inference_ms": 2.38934916249069, "mean_action_processing_ms": 0.2271182778171509, "mean_env_wait_ms": 3.0354050711250755, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 67134, "num_agent_steps_trained": 4875520, "num_env_steps_sampled": 67134, "num_env_steps_trained": 4875520, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 67134, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 67134, "timers": {"training_iteration_time_ms": 153.466, "load_time_ms": 0.271, "load_throughput": 943202.586, "learn_time_ms": 24.378, "learn_throughput": 10501.307, "synch_weights_time_ms": 5.186}, "counters": {"num_env_steps_sampled": 67134, "num_env_steps_trained": 4875520, "num_agent_steps_sampled": 67134, "num_agent_steps_trained": 4875520, "last_target_update_ts": 67134, "num_target_updates": 19045}, "done": false, "episodes_total": 692, "training_iteration": 67, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-25-40", "timestamp": 1675952740, "time_this_iter_s": 50.382936000823975, "time_total_s": 3046.7084941864014, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb430>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105761f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3046.7084941864014, "timesteps_since_restore": 0, "iterations_since_restore": 67, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 37.724999999999994, "ram_util_percent": 92.01617647058823}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.15237806737422943, "actor_loss": 83.83667755126953, "critic_loss": 0.8358434438705444, "alpha_loss": 0.6316894888877869, "alpha_value": 0.01583487167954445, "log_alpha_value": -4.145540714263916, "target_entropy": -5.0, "policy_t": -0.3011484444141388, "mean_q": -83.90608978271484, "max_q": -77.57401275634766, "min_q": -87.76445770263672}, "td_error": [0.24214935302734375, 0.46729278564453125, 80.20101165771484, 0.8623199462890625, 0.44158935546875, 0.06795501708984375, 329.9668884277344, 0.5881996154785156, 0.523773193359375, 82.69986724853516, 0.1796875, 0.3783531188964844, 0.2534637451171875, 333.232177734375, 0.15070343017578125, 81.74415588378906, 0.25226593017578125, 84.46992492675781, 0.1061859130859375, 0.5366744995117188, 0.4594573974609375, 0.6598167419433594, 0.3511466979980469, 81.41838073730469, 84.66221618652344, 0.44918060302734375, 83.86138916015625, 0.2191925048828125, 0.23880767822265625, 0.12894439697265625, 0.7292327880859375, 0.11348724365234375, 0.7661819458007812, 0.100921630859375, 0.4505157470703125, 0.2833442687988281, 82.4432373046875, 0.06742095947265625, 0.8698158264160156, 83.38720703125, 0.5151901245117188, 0.33582305908203125, 0.10527420043945312, 0.2625083923339844, 81.49523162841797, 0.4610443115234375, 0.49060821533203125, 81.22696685791016, 0.45899200439453125, 84.9256362915039, 0.39092254638671875, 0.0758514404296875, 0.03891754150390625, 0.239105224609375, 0.8889312744140625, 0.33351898193359375, 82.50273132324219, 78.71900939941406, 0.5364990234375, 84.6262435913086, 0.14455032348632812, 0.8103523254394531, 0.7275466918945312, 0.29352569580078125, 83.95327758789062, 78.02082061767578, 0.3481178283691406, 0.5825347900390625, 0.0552520751953125, 81.77783203125, 0.4158287048339844, 0.03916168212890625, 0.4694671630859375, 0.3942413330078125, 0.4993629455566406, 326.40362548828125, 0.3868980407714844, 84.1133804321289, 0.04137420654296875, 84.49214935302734, 0.24393844604492188, 0.5396842956542969, 0.10656356811523438, 0.4077491760253906, 82.46937561035156, 0.7707443237304688, 0.6636810302734375, 0.08621597290039062, 0.11293792724609375, 84.37103271484375, 0.44654083251953125, 0.23926162719726562, 82.26502990722656, 0.4316520690917969, 83.50640106201172, 0.15234375, 0.2805519104003906, 0.5464439392089844, 0.2671165466308594, 0.38886260986328125, 0.5567817687988281, 0.18828201293945312, 0.11437225341796875, 0.4933128356933594, 0.18501663208007812, 0.4862022399902344, 0.5003280639648438, 81.03919219970703, 0.3027153015136719, 84.1133804321289, 0.000988006591796875, 0.6867294311523438, 79.02947998046875, 83.61021423339844, 0.24195480346679688, 0.12631607055664062, 0.39641571044921875, 84.5587387084961, 0.3586616516113281, 0.5038986206054688, 0.564483642578125, 84.77372741699219, 0.22719573974609375, 0.3072242736816406, 82.02687072753906, 0.3314208984375, 77.1165771484375, 0.4273567199707031, 0.7183265686035156, 78.27851867675781, 0.5160064697265625, 0.3786659240722656, 0.08321380615234375, 0.29050445556640625, 0.1203155517578125, 0.06035614013671875, 0.570465087890625, 0.4575614929199219, 0.4576759338378906, 0.19968795776367188, 0.197509765625, 0.20867919921875, 0.5671615600585938, 0.4468498229980469, 0.4409141540527344, 0.7739791870117188, 0.7909126281738281, 0.2592620849609375, 0.7936477661132812, 0.44507598876953125, 0.32750701904296875, 0.4775733947753906, 0.4248695373535156, 0.4391937255859375, 0.6801795959472656, 0.105743408203125, 0.19462966918945312, 0.3303680419921875, 0.15395355224609375, 0.584503173828125, 0.0808258056640625, 0.06759262084960938, 0.20232772827148438, 0.21620559692382812, 83.73114776611328, 0.9115829467773438, 0.27526092529296875, 331.75567626953125, 0.4122505187988281, 0.42343902587890625, 0.5163726806640625, 330.75811767578125, 0.2662506103515625, 80.05017852783203, 0.29145050048828125, 0.36222076416015625, 0.16574478149414062, 83.03410339355469, 0.23813629150390625, 0.07549667358398438, 80.10824584960938, 0.4374427795410156, 0.23694229125976562, 0.6889305114746094, 0.5761146545410156, 0.26917266845703125, 0.24279022216796875, 0.7035865783691406, 0.4392204284667969, 81.90963745117188, 83.57112121582031, 79.99017333984375, 0.3353767395019531, 0.7417716979980469, 0.3506736755371094, 0.5484733581542969, 0.4739494323730469, 0.24200820922851562, 0.3418846130371094, 0.741973876953125, 0.19879913330078125, 0.3738250732421875, 0.7792205810546875, 0.2849235534667969, 0.19921112060546875, 84.091064453125, 0.21833038330078125, 0.5772247314453125, 0.7451553344726562, 0.09893798828125, 80.57789611816406, 0.48404693603515625, 0.3935089111328125, 0.4114532470703125, 82.92045593261719, 0.31378936767578125, 0.046680450439453125, 0.6953315734863281, 0.10348892211914062, 0.2591285705566406, 0.3341560363769531, 0.71136474609375, 0.5116424560546875, 0.03179931640625, 83.16827392578125, 0.32154083251953125, 0.0335540771484375, 0.36725616455078125, 0.4513092041015625, 0.5334587097167969, 0.22076797485351562, 0.19512557983398438, 0.20541763305664062, 0.2377471923828125, 0.5696525573730469, 0.4210205078125, 0.305328369140625, 78.15203857421875, 81.90963745117188, 0.73358154296875, 0.146636962890625, 0.5176010131835938, 0.5517196655273438, 84.26315307617188, 0.4295501708984375, 0.27426910400390625, 0.5023651123046875, 0.561370849609375, 0.4409065246582031, 80.57656860351562, 0.3850746154785156, 84.12841796875, 0.24788284301757812, 0.2948570251464844, 0.1743316650390625, 0.412017822265625], "mean_td_error": 22.49155616760254, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 19379.0, "diff_num_grad_updates_vs_sampler_policy": 19378.0}}, "num_env_steps_sampled": 68136, "num_env_steps_trained": 4961024, "num_agent_steps_sampled": 68136, "num_agent_steps_trained": 4961024, "last_target_update_ts": 68136, "num_target_updates": 19379}, "sampler_results": {"episode_reward_max": 199.47801526635885, "episode_reward_min": -185.48150983452797, "episode_reward_mean": -137.65783218362114, "episode_len_mean": 93.54545454545455, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-178.56572143733501, -167.55778631567955, -166.04872252047062, 199.47801526635885, -169.49843569099903, -169.19959335029125, -162.0254235714674, -167.34990080446005, -171.22927805781364, -185.48150983452797, -176.75779770314693], "episode_lengths": [100, 100, 100, 29, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1574515099040548, "mean_inference_ms": 2.372989675802231, "mean_action_processing_ms": 0.22532611039577824, "mean_env_wait_ms": 3.0180462109730666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 199.47801526635885, "episode_reward_min": -185.48150983452797, "episode_reward_mean": -137.65783218362114, "episode_len_mean": 93.54545454545455, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-178.56572143733501, -167.55778631567955, -166.04872252047062, 199.47801526635885, -169.49843569099903, -169.19959335029125, -162.0254235714674, -167.34990080446005, -171.22927805781364, -185.48150983452797, -176.75779770314693], "episode_lengths": [100, 100, 100, 29, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1574515099040548, "mean_inference_ms": 2.372989675802231, "mean_action_processing_ms": 0.22532611039577824, "mean_env_wait_ms": 3.0180462109730666, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 68136, "num_agent_steps_trained": 4961024, "num_env_steps_sampled": 68136, "num_env_steps_trained": 4961024, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 68136, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 68136, "timers": {"training_iteration_time_ms": 156.16, "load_time_ms": 0.268, "load_throughput": 955201.338, "learn_time_ms": 24.844, "learn_throughput": 10304.357, "synch_weights_time_ms": 6.559}, "counters": {"num_env_steps_sampled": 68136, "num_env_steps_trained": 4961024, "num_agent_steps_sampled": 68136, "num_agent_steps_trained": 4961024, "last_target_update_ts": 68136, "num_target_updates": 19379}, "done": false, "episodes_total": 703, "training_iteration": 68, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-26-32", "timestamp": 1675952792, "time_this_iter_s": 51.47679924964905, "time_total_s": 3098.1852934360504, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a490>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3098.1852934360504, "timesteps_since_restore": 0, "iterations_since_restore": 68, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.94788732394366, "ram_util_percent": 92.24788732394362}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.23368693888187408, "actor_loss": 85.24129486083984, "critic_loss": 1.0499526262283325, "alpha_loss": 0.9553093910217285, "alpha_value": 0.016772940754890442, "log_alpha_value": -4.087988376617432, "target_entropy": -5.0, "policy_t": -0.3291897475719452, "mean_q": -85.18939208984375, "max_q": -79.53237915039062, "min_q": -89.44457244873047}, "td_error": [0.39041900634765625, 82.18878936767578, 0.795806884765625, 0.17921066284179688, 0.14352035522460938, 0.3783149719238281, 0.42006683349609375, 0.6024398803710938, 0.08206939697265625, 0.12406539916992188, 84.06930541992188, 0.6481361389160156, 0.5583877563476562, 78.50931549072266, 0.4820365905761719, 78.45330047607422, 0.17790603637695312, 82.64861297607422, 85.37864685058594, 0.4485206604003906, 0.10875320434570312, 83.82562255859375, 0.5002098083496094, 334.8840637207031, 0.544525146484375, 0.35424041748046875, 0.5990867614746094, 0.49152374267578125, 0.41088104248046875, 0.2126007080078125, 0.32956695556640625, 0.3690528869628906, 0.167510986328125, 81.47209167480469, 83.49468994140625, 0.06728363037109375, 0.7132186889648438, 0.3256950378417969, 0.054901123046875, 0.16825103759765625, 0.18212127685546875, 0.10386276245117188, 0.274627685546875, 0.6421585083007812, 0.049591064453125, 1.1319351196289062, 0.13771820068359375, 0.4334297180175781, 83.6033935546875, 0.8604278564453125, 0.1787567138671875, 0.422271728515625, 0.885772705078125, 0.29094696044921875, 0.41912078857421875, 0.07987594604492188, 83.03564453125, 85.41572570800781, 0.49188995361328125, 0.4411659240722656, 0.199554443359375, 0.5664291381835938, 0.3142585754394531, 78.90646362304688, 0.10446929931640625, 0.21361923217773438, 0.5074119567871094, 0.4424781799316406, 0.5451583862304688, 81.99644470214844, 86.49835205078125, 0.2862129211425781, 0.30511474609375, 0.085235595703125, 0.11181640625, 0.6477890014648438, 0.5659980773925781, 0.5146827697753906, 84.2239990234375, 0.15573501586914062, 0.26561737060546875, 333.09259033203125, 0.819549560546875, 0.17487335205078125, 0.44365692138671875, 0.4217681884765625, 0.3170166015625, 84.8656234741211, 0.1123809814453125, 1.0305404663085938, 0.038761138916015625, 0.33419036865234375, 0.30682373046875, 0.431396484375, 85.694091796875, 87.00370788574219, 86.45072174072266, 0.5211601257324219, 85.91378021240234, 0.6022987365722656, 0.16475677490234375, 0.35338592529296875, 83.38628387451172, 0.34576416015625, 0.05831146240234375, 0.5360832214355469, 0.4317131042480469, 0.2637138366699219, 0.6779708862304688, 0.22896575927734375, 0.6692886352539062, 78.42848205566406, 0.5831718444824219, 81.53970336914062, 86.32676696777344, 0.3215293884277344, 0.10015869140625, 0.5760955810546875, 82.58495330810547, 0.31575775146484375, 0.4373588562011719, 0.0605010986328125, 82.02081298828125, 85.37864685058594, 0.2573127746582031, 82.4294662475586, 0.449005126953125, 0.2277069091796875, 81.5859603881836, 78.14276123046875, 0.0740509033203125, 0.4855461120605469, 79.73027038574219, 0.18059921264648438, 85.89256286621094, 0.7229499816894531, 84.94721221923828, 86.42418670654297, 0.2345733642578125, 0.3685455322265625, 0.184234619140625, 0.30600738525390625, 85.55170440673828, 81.91287231445312, 0.4768829345703125, 0.0517730712890625, 0.0928497314453125, 0.24901199340820312, 0.2547798156738281, 0.10326004028320312, 83.81185150146484, 0.22399520874023438, 0.7224464416503906, 0.53515625, 0.17383193969726562, 0.11423873901367188, 0.041027069091796875, 0.11454391479492188, 0.17876434326171875, 0.3050575256347656, 0.4754180908203125, 0.6989402770996094, 0.7076950073242188, 0.3655509948730469, 82.41729736328125, 0.2232818603515625, 0.5341949462890625, 85.43441772460938, 0.2025909423828125, 83.04670715332031, 83.50527954101562, 0.255950927734375, 0.11487197875976562, 0.1521759033203125, 0.02564239501953125, 85.81327819824219, 0.21080398559570312, 78.41276550292969, 84.46163940429688, 0.10752105712890625, 0.27272796630859375, 80.38186645507812, 0.5449943542480469, 78.12085723876953, 79.9319839477539, 0.497589111328125, 0.3795280456542969, 0.5830307006835938, 0.4368133544921875, 78.45663452148438, 0.3733100891113281, 0.5130386352539062, 0.20343399047851562, 0.48249053955078125, 0.47640228271484375, 0.32054901123046875, 0.6911773681640625, 85.5569839477539, 0.550537109375, 0.09384918212890625, 0.6793746948242188, 0.3031730651855469, 0.22082901000976562, 0.08393096923828125, 0.8072586059570312, 330.205078125, 331.85430908203125, 0.4640541076660156, 0.0836334228515625, 85.41572570800781, 0.3569679260253906, 0.3320198059082031, 0.5819282531738281, 0.3472938537597656, 0.2117767333984375, 0.17626953125, 86.79688262939453, 0.121795654296875, 79.49738311767578, 85.41104125976562, 83.58589935302734, 0.10343170166015625, 0.7469215393066406, 0.0486297607421875, 84.44026947021484, 0.23287582397460938, 0.472381591796875, 0.4551658630371094, 0.030033111572265625, 0.19621658325195312, 0.5108757019042969, 0.6458053588867188, 0.120941162109375, 0.18641281127929688, 0.11759185791015625, 0.132720947265625, 0.5441627502441406, 0.3302459716796875, 84.96904754638672, 86.20372009277344, 0.7136802673339844, 80.46639251708984, 82.31097412109375, 0.4105682373046875, 0.2678031921386719, 83.38641357421875, 0.209869384765625, 0.7252998352050781, 333.3430480957031, 79.0414047241211, 0.0542144775390625, 0.5706024169921875, 82.82854461669922, 0.183380126953125, 81.00720977783203, 84.4361572265625], "mean_td_error": 27.844709396362305, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 19713.0, "diff_num_grad_updates_vs_sampler_policy": 19712.0}}, "num_env_steps_sampled": 69138, "num_env_steps_trained": 5046528, "num_agent_steps_sampled": 69138, "num_agent_steps_trained": 5046528, "last_target_update_ts": 69138, "num_target_updates": 19713}, "sampler_results": {"episode_reward_max": 110.41143734753132, "episode_reward_min": -182.64592268317938, "episode_reward_mean": -143.69641439914705, "episode_len_mean": 97.9, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.87691847980022, -171.50100470334291, -166.9094069674611, -170.9276044666767, -182.64592268317938, -176.23206087201834, -166.06158356368542, -171.75342164933681, -170.46765795350075, 110.41143734753132], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 79]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1538557444145536, "mean_inference_ms": 2.368648111077976, "mean_action_processing_ms": 0.224642295943334, "mean_env_wait_ms": 3.019898236845302, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 110.41143734753132, "episode_reward_min": -182.64592268317938, "episode_reward_mean": -143.69641439914705, "episode_len_mean": 97.9, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.87691847980022, -171.50100470334291, -166.9094069674611, -170.9276044666767, -182.64592268317938, -176.23206087201834, -166.06158356368542, -171.75342164933681, -170.46765795350075, 110.41143734753132], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 79]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1538557444145536, "mean_inference_ms": 2.368648111077976, "mean_action_processing_ms": 0.224642295943334, "mean_env_wait_ms": 3.019898236845302, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 69138, "num_agent_steps_trained": 5046528, "num_env_steps_sampled": 69138, "num_env_steps_trained": 5046528, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 69138, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 69138, "timers": {"training_iteration_time_ms": 155.399, "load_time_ms": 0.298, "load_throughput": 860163.281, "learn_time_ms": 24.873, "learn_throughput": 10292.208, "synch_weights_time_ms": 5.988}, "counters": {"num_env_steps_sampled": 69138, "num_env_steps_trained": 5046528, "num_agent_steps_sampled": 69138, "num_agent_steps_trained": 5046528, "last_target_update_ts": 69138, "num_target_updates": 19713}, "done": false, "episodes_total": 713, "training_iteration": 69, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-27-23", "timestamp": 1675952843, "time_this_iter_s": 51.41184735298157, "time_total_s": 3149.597140789032, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb0a0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ba60>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3149.597140789032, "timesteps_since_restore": 0, "iterations_since_restore": 69, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.508571428571436, "ram_util_percent": 92.4457142857143}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.08973204344511032, "actor_loss": 86.33537292480469, "critic_loss": 1.2276619672775269, "alpha_loss": 0.3645753562450409, "alpha_value": 0.01719846948981285, "log_alpha_value": -4.062934875488281, "target_entropy": -5.0, "policy_t": -0.354002445936203, "mean_q": -86.28176879882812, "max_q": -80.09086608886719, "min_q": -90.65145874023438}, "td_error": [0.6005859375, 83.82333374023438, 0.09463882446289062, 0.3889312744140625, 86.44270324707031, 0.26473236083984375, 0.8289756774902344, 84.92155456542969, 0.3407630920410156, 0.252227783203125, 0.7676315307617188, 332.9561767578125, 0.23918914794921875, 84.39558410644531, 0.6843223571777344, 0.48206329345703125, 0.44094085693359375, 0.23044204711914062, 0.6291465759277344, 0.831573486328125, 0.221405029296875, 84.25367736816406, 0.2113037109375, 86.81756591796875, 85.93392944335938, 80.45262145996094, 336.09698486328125, 0.3528938293457031, 87.41455078125, 0.6277809143066406, 86.84550476074219, 82.46076965332031, 0.37200927734375, 0.49163055419921875, 333.4735107421875, 0.12918853759765625, 87.42577362060547, 84.19932556152344, 0.551361083984375, 82.19239807128906, 85.9507827758789, 0.20173263549804688, 0.17111968994140625, 0.7027359008789062, 0.31250762939453125, 0.20367431640625, 0.8230514526367188, 0.5294570922851562, 0.2743415832519531, 0.33216094970703125, 0.7126579284667969, 0.19694900512695312, 85.011474609375, 0.0444183349609375, 0.4354438781738281, 0.4863929748535156, 0.23371505737304688, 0.13468551635742188, 0.4845466613769531, 0.805267333984375, 0.28316497802734375, 332.7918701171875, 80.93592834472656, 0.23325729370117188, 0.22695541381835938, 0.1219024658203125, 0.5737228393554688, 0.6412315368652344, 85.53887939453125, 0.4213676452636719, 0.40474700927734375, 0.5128822326660156, 83.21763610839844, 0.5046234130859375, 0.5927238464355469, 0.4080657958984375, 0.4544525146484375, 0.37242889404296875, 87.61825561523438, 0.3196144104003906, 0.26909637451171875, 0.5494499206542969, 0.3637809753417969, 0.48686981201171875, 0.19022750854492188, 0.2813224792480469, 0.3654441833496094, 0.2923393249511719, 0.29256439208984375, 83.76195526123047, 0.7553863525390625, 0.2797698974609375, 1.0351943969726562, 0.59649658203125, 0.07765579223632812, 0.4477996826171875, 87.54344940185547, 0.42586517333984375, 0.6322708129882812, 0.4101905822753906, 88.41410827636719, 0.16266632080078125, 0.6095809936523438, 0.3577728271484375, 0.7038002014160156, 0.19876861572265625, 0.24751663208007812, 0.4197044372558594, 0.2846565246582031, 0.21583938598632812, 87.62985229492188, 86.96568298339844, 0.03566741943359375, 84.35814666748047, 87.63711547851562, 85.86431884765625, 0.11876678466796875, 87.34335327148438, 0.6161346435546875, 0.1121673583984375, 0.059600830078125, 0.43532562255859375, 86.82594299316406, 0.09907913208007812, 334.426513671875, 0.36226654052734375, 0.15961837768554688, 0.1096649169921875, 87.7524185180664, 0.30831146240234375, 0.3850135803222656, 87.07057189941406, 0.12397384643554688, 87.14825439453125, 86.98975372314453, 0.11653518676757812, 0.3660430908203125, 79.2916259765625, 0.60784912109375, 0.7004508972167969, 88.63481140136719, 0.02143096923828125, 0.060638427734375, 0.6335945129394531, 0.0984649658203125, 0.6338653564453125, 84.56069946289062, 0.041900634765625, 0.3376121520996094, 0.26692962646484375, 0.3092842102050781, 82.65020751953125, 87.54344940185547, 0.3074188232421875, 0.17877960205078125, 0.1240997314453125, 0.37831878662109375, 0.28849029541015625, 0.41475677490234375, 0.8923301696777344, 86.52182006835938, 0.04634857177734375, 80.51023864746094, 0.7585563659667969, 0.21793746948242188, 0.7413177490234375, 0.058315277099609375, 87.4789047241211, 0.21381378173828125, 0.647125244140625, 0.5471611022949219, 0.81072998046875, 0.07275009155273438, 0.22185897827148438, 0.5738716125488281, 0.3937225341796875, 0.3264007568359375, 0.22557449340820312, 0.5211448669433594, 0.692047119140625, 87.32357788085938, 0.582122802734375, 87.08209228515625, 0.0683441162109375, 0.468170166015625, 0.5252685546875, 0.5235939025878906, 88.17356872558594, 0.37999725341796875, 0.32220458984375, 0.10829544067382812, 0.13430404663085938, 0.614105224609375, 79.6026611328125, 0.045078277587890625, 0.12820816040039062, 0.2700462341308594, 0.185150146484375, 82.7220458984375, 0.5485610961914062, 0.2735137939453125, 0.3511695861816406, 87.02071380615234, 0.6633377075195312, 0.4122657775878906, 0.3363800048828125, 84.94005584716797, 84.03148651123047, 332.8955078125, 329.0960693359375, 81.54421997070312, 83.3332748413086, 0.10253143310546875, 85.78974151611328, 0.25397491455078125, 84.90191650390625, 0.6259727478027344, 0.22135162353515625, 0.198760986328125, 0.16621017456054688, 330.13287353515625, 0.4414520263671875, 0.03835296630859375, 0.21174240112304688, 0.2765541076660156, 0.8402786254882812, 0.2016754150390625, 85.05223846435547, 0.2790985107421875, 86.1140365600586, 0.29027557373046875, 0.5871086120605469, 0.5596466064453125, 0.6136322021484375, 331.7418212890625, 0.16320037841796875, 0.17333221435546875, 0.5230865478515625, 0.18265533447265625, 0.6208763122558594, 330.13287353515625, 0.6953048706054688, 0.8410224914550781, 0.35485076904296875, 0.7661514282226562, 0.40743255615234375, 0.3964385986328125, 0.9635467529296875, 81.8351058959961, 333.08624267578125, 85.75363159179688, 86.26903533935547, 0.13397216796875, 0.19350814819335938, 0.12649154663085938, 86.78467559814453], "mean_td_error": 34.545936584472656, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 20047.0, "diff_num_grad_updates_vs_sampler_policy": 20046.0}}, "num_env_steps_sampled": 70140, "num_env_steps_trained": 5132032, "num_agent_steps_sampled": 70140, "num_agent_steps_trained": 5132032, "last_target_update_ts": 70140, "num_target_updates": 20047}, "sampler_results": {"episode_reward_max": 119.72416963428259, "episode_reward_min": -178.23986833542585, "episode_reward_mean": -109.35119683519005, "episode_len_mean": 95.2, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-169.28218329697847, 116.13884158432484, -170.0493287369609, -178.23986833542585, -157.2627425789833, -156.08764888346195, -171.0137109681964, -160.89349257946014, 119.72416963428259, -166.546004191041], "episode_lengths": [100, 77, 100, 100, 100, 100, 100, 100, 75, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1433648928508524, "mean_inference_ms": 2.355041298332556, "mean_action_processing_ms": 0.22310589322541716, "mean_env_wait_ms": 3.0036732575467266, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 119.72416963428259, "episode_reward_min": -178.23986833542585, "episode_reward_mean": -109.35119683519005, "episode_len_mean": 95.2, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-169.28218329697847, 116.13884158432484, -170.0493287369609, -178.23986833542585, -157.2627425789833, -156.08764888346195, -171.0137109681964, -160.89349257946014, 119.72416963428259, -166.546004191041], "episode_lengths": [100, 77, 100, 100, 100, 100, 100, 100, 75, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1433648928508524, "mean_inference_ms": 2.355041298332556, "mean_action_processing_ms": 0.22310589322541716, "mean_env_wait_ms": 3.0036732575467266, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 70140, "num_agent_steps_trained": 5132032, "num_env_steps_sampled": 70140, "num_env_steps_trained": 5132032, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 70140, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 70140, "timers": {"training_iteration_time_ms": 151.217, "load_time_ms": 0.287, "load_throughput": 891812.146, "learn_time_ms": 24.198, "learn_throughput": 10579.394, "synch_weights_time_ms": 6.622}, "counters": {"num_env_steps_sampled": 70140, "num_env_steps_trained": 5132032, "num_agent_steps_sampled": 70140, "num_agent_steps_trained": 5132032, "last_target_update_ts": 70140, "num_target_updates": 20047}, "done": false, "episodes_total": 723, "training_iteration": 70, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-28-14", "timestamp": 1675952894, "time_this_iter_s": 50.57467818260193, "time_total_s": 3200.171818971634, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2d90>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c820>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3200.171818971634, "timesteps_since_restore": 0, "iterations_since_restore": 70, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.649275362318846, "ram_util_percent": 91.87101449275363}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.5090949535369873, "actor_loss": 88.13954162597656, "critic_loss": 1.0070393085479736, "alpha_loss": 2.0474984645843506, "alpha_value": 0.017919959500432014, "log_alpha_value": -4.0218400955200195, "target_entropy": -5.0, "policy_t": -0.3395386040210724, "mean_q": -88.06439971923828, "max_q": -81.57752227783203, "min_q": -92.07586669921875}, "td_error": [0.2904777526855469, 0.1676025390625, 0.5340423583984375, 0.031158447265625, 0.2920570373535156, 0.50836181640625, 0.700714111328125, 86.63189697265625, 0.649627685546875, 0.9760971069335938, 88.72369384765625, 81.09252166748047, 0.5319862365722656, 89.94210815429688, 0.7937889099121094, 85.46881103515625, 0.9178352355957031, 0.9123497009277344, 0.28424835205078125, 0.1230621337890625, 0.6326942443847656, 0.08246612548828125, 0.02950286865234375, 0.5456771850585938, 0.5150032043457031, 0.6045799255371094, 0.2876472473144531, 82.62564086914062, 0.6650009155273438, 0.26074981689453125, 87.73404693603516, 0.456512451171875, 0.3267822265625, 0.6577415466308594, 0.36858367919921875, 0.40137481689453125, 0.35887908935546875, 0.675567626953125, 0.34145355224609375, 0.11319732666015625, 0.1425323486328125, 89.09255981445312, 0.2292938232421875, 1.0031547546386719, 87.26241302490234, 82.23551940917969, 0.3661613464355469, 0.18659210205078125, 0.3937225341796875, 0.2994384765625, 88.28987884521484, 88.28987884521484, 0.4413032531738281, 0.91259765625, 89.13522338867188, 83.71914672851562, 0.14661788940429688, 0.26434326171875, 0.493316650390625, 334.99005126953125, 88.71385192871094, 0.107421875, 0.6264801025390625, 0.13288497924804688, 84.31547546386719, 0.31093597412109375, 0.2436676025390625, 84.47691345214844, 0.5029945373535156, 0.4484100341796875, 84.68756103515625, 0.5415420532226562, 0.621673583984375, 89.13522338867188, 0.10657501220703125, 0.07070541381835938, 0.3190116882324219, 0.09235763549804688, 87.75399780273438, 0.3474578857421875, 85.28254699707031, 87.92506408691406, 88.73021697998047, 0.22382736206054688, 0.44892120361328125, 83.94308471679688, 0.24252700805664062, 0.2854957580566406, 0.230010986328125, 86.23121643066406, 0.3079986572265625, 82.26505279541016, 82.75508117675781, 0.2735595703125, 0.3359336853027344, 0.6631050109863281, 0.049930572509765625, 0.5588150024414062, 0.298492431640625, 0.25524139404296875, 0.5533866882324219, 89.81259155273438, 0.5775527954101562, 0.3815269470214844, 0.1497344970703125, 0.40547943115234375, 0.6868629455566406, 0.26790618896484375, 0.42633056640625, 0.5035820007324219, 0.6821479797363281, 0.21428680419921875, 0.7097320556640625, 0.11502838134765625, 0.1284332275390625, 0.0868988037109375, 0.14434051513671875, 0.05741119384765625, 0.15314483642578125, 0.16473388671875, 0.2669677734375, 0.34871673583984375, 0.07836151123046875, 0.16427230834960938, 0.500457763671875, 0.26377105712890625, 0.519073486328125, 0.22052383422851562, 334.341064453125, 0.5485954284667969, 0.4322471618652344, 0.205963134765625, 0.5780448913574219, 330.5565490722656, 80.7059097290039, 0.3492774963378906, 86.32212829589844, 0.61834716796875, 85.30699157714844, 0.696075439453125, 0.1610870361328125, 90.25747680664062, 87.31851196289062, 0.49471282958984375, 0.09100341796875, 0.21808242797851562, 0.34850311279296875, 0.5407218933105469, 0.229522705078125, 0.2934684753417969, 90.23185729980469, 0.35308837890625, 0.1637115478515625, 0.45587158203125, 0.7684288024902344, 0.16086959838867188, 0.19423294067382812, 0.27886962890625, 0.1043243408203125, 0.255584716796875, 87.73922729492188, 87.06708526611328, 0.07514190673828125, 0.24898529052734375, 0.3946189880371094, 0.2815971374511719, 83.87908935546875, 0.8603477478027344, 0.07410049438476562, 0.49382781982421875, 0.247650146484375, 0.5595512390136719, 0.3021240234375, 332.66033935546875, 0.41625213623046875, 0.29766082763671875, 82.68659973144531, 0.3319587707519531, 0.2830047607421875, 0.619384765625, 0.7974739074707031, 0.24622344970703125, 0.7782936096191406, 0.62481689453125, 88.99012756347656, 0.28099822998046875, 0.5637435913085938, 0.31635284423828125, 0.643157958984375, 0.19429779052734375, 0.6636085510253906, 0.2542877197265625, 0.2866401672363281, 0.13628005981445312, 89.31600189208984, 0.7284317016601562, 0.35028076171875, 0.2630805969238281, 0.2690887451171875, 0.2407684326171875, 0.22524261474609375, 83.12884521484375, 0.7168197631835938, 0.07177734375, 0.1895904541015625, 0.45488739013671875, 0.06535720825195312, 0.2789306640625, 0.6337852478027344, 88.34616088867188, 0.5544662475585938, 0.6090164184570312, 0.2311248779296875, 0.5062179565429688, 84.97090911865234, 0.3526115417480469, 87.21497344970703, 84.75128936767578, 80.40029907226562, 0.6188316345214844, 0.2765350341796875, 0.2559623718261719, 0.078399658203125, 82.44491577148438, 0.4866752624511719, 86.23041534423828, 87.73977661132812, 0.6198043823242188, 0.3998756408691406, 0.49138641357421875, 0.3940849304199219, 0.260009765625, 85.65504455566406, 88.99005126953125, 89.65451049804688, 0.2288970947265625, 0.3296623229980469, 0.3839759826660156, 84.68943786621094, 0.38298797607421875, 85.90808868408203, 89.49463653564453, 0.08139801025390625, 0.5853347778320312, 334.7000732421875, 89.49463653564453, 0.16106033325195312, 332.27130126953125, 0.48932647705078125, 0.6010169982910156, 0.38605499267578125, 86.70960998535156, 0.5541915893554688, 0.04825592041015625, 0.3213539123535156, 0.4374961853027344], "mean_td_error": 27.321075439453125, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 20381.0, "diff_num_grad_updates_vs_sampler_policy": 20380.0}}, "num_env_steps_sampled": 71142, "num_env_steps_trained": 5217536, "num_agent_steps_sampled": 71142, "num_agent_steps_trained": 5217536, "last_target_update_ts": 71142, "num_target_updates": 20381}, "sampler_results": {"episode_reward_max": -159.49032779037952, "episode_reward_min": -175.48708271980286, "episode_reward_mean": -165.0475115455687, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-165.38771004229784, -165.03332306444645, -161.53718860447407, -159.81730138510466, -172.05934658646584, -159.49032779037952, -164.55455171316862, -175.48708271980286, -165.7156725153327, -161.3926110342145], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.165176470420945, "mean_inference_ms": 2.3855955008085132, "mean_action_processing_ms": 0.2266659787906113, "mean_env_wait_ms": 3.0395015030502393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -159.49032779037952, "episode_reward_min": -175.48708271980286, "episode_reward_mean": -165.0475115455687, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-165.38771004229784, -165.03332306444645, -161.53718860447407, -159.81730138510466, -172.05934658646584, -159.49032779037952, -164.55455171316862, -175.48708271980286, -165.7156725153327, -161.3926110342145], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.165176470420945, "mean_inference_ms": 2.3855955008085132, "mean_action_processing_ms": 0.2266659787906113, "mean_env_wait_ms": 3.0395015030502393, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 71142, "num_agent_steps_trained": 5217536, "num_env_steps_sampled": 71142, "num_env_steps_trained": 5217536, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 71142, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 71142, "timers": {"training_iteration_time_ms": 149.864, "load_time_ms": 0.263, "load_throughput": 974622.696, "learn_time_ms": 24.139, "learn_throughput": 10605.046, "synch_weights_time_ms": 5.613}, "counters": {"num_env_steps_sampled": 71142, "num_env_steps_trained": 5217536, "num_agent_steps_sampled": 71142, "num_agent_steps_trained": 5217536, "last_target_update_ts": 71142, "num_target_updates": 20381}, "done": false, "episodes_total": 733, "training_iteration": 71, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-29-05", "timestamp": 1675952945, "time_this_iter_s": 51.007408618927, "time_total_s": 3251.179227590561, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2dc0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3251.179227590561, "timesteps_since_restore": 0, "iterations_since_restore": 71, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.505714285714284, "ram_util_percent": 91.11000000000001}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.00788333173841238, "actor_loss": 89.40756225585938, "critic_loss": 0.8403581380844116, "alpha_loss": -0.03135475516319275, "alpha_value": 0.01873531937599182, "log_alpha_value": -3.9773447513580322, "target_entropy": -5.0, "policy_t": -0.30752578377723694, "mean_q": -89.31521606445312, "max_q": -82.93258666992188, "min_q": -93.63999938964844}, "td_error": [0.314117431640625, 88.18052673339844, 0.43851470947265625, 0.602020263671875, 0.2545280456542969, 0.5754013061523438, 0.8133354187011719, 0.028308868408203125, 0.54022216796875, 0.123382568359375, 0.33751678466796875, 0.528350830078125, 0.2313995361328125, 0.4586982727050781, 88.05725860595703, 0.3139190673828125, 0.4442863464355469, 0.13433456420898438, 337.3211669921875, 0.35811614990234375, 0.6729888916015625, 84.48748779296875, 0.09061431884765625, 87.15855407714844, 0.1234893798828125, 0.13532638549804688, 90.52059173583984, 0.19227981567382812, 0.23558807373046875, 0.31804656982421875, 0.4219474792480469, 0.4296302795410156, 0.7628250122070312, 0.08368301391601562, 0.2937583923339844, 0.22788238525390625, 0.14243316650390625, 0.7006721496582031, 0.5091133117675781, 0.23895645141601562, 0.5021324157714844, 87.97152709960938, 0.75384521484375, 0.11307907104492188, 0.6304473876953125, 0.17559814453125, 0.13165664672851562, 0.4804840087890625, 0.2830543518066406, 0.7669181823730469, 0.5977821350097656, 90.1059799194336, 0.3571434020996094, 0.39386749267578125, 0.29051971435546875, 90.25341796875, 0.0058441162109375, 337.05767822265625, 0.6178245544433594, 84.75944519042969, 0.0406341552734375, 0.0220794677734375, 0.4439277648925781, 0.5458831787109375, 88.35994720458984, 89.52799987792969, 0.16498565673828125, 332.06829833984375, 0.12326431274414062, 0.6511917114257812, 90.37921142578125, 0.3579063415527344, 0.057239532470703125, 0.5897102355957031, 88.49991607666016, 0.3223876953125, 0.39737701416015625, 0.468994140625, 0.2198944091796875, 0.3210906982421875, 0.6153831481933594, 0.6304473876953125, 0.5538177490234375, 0.5537452697753906, 0.46868896484375, 0.35495758056640625, 0.5855941772460938, 0.32489013671875, 89.84129333496094, 0.5330429077148438, 0.052448272705078125, 0.050670623779296875, 0.11144638061523438, 0.19652938842773438, 0.451385498046875, 0.567718505859375, 89.03329467773438, 87.62345886230469, 89.79530334472656, 0.544586181640625, 0.2435302734375, 0.18581008911132812, 0.12129974365234375, 0.5296859741210938, 0.3055381774902344, 0.14640045166015625, 0.5845069885253906, 0.5050315856933594, 88.84420013427734, 0.14203643798828125, 0.3159065246582031, 0.6185226440429688, 0.3525505065917969, 0.5366249084472656, 0.46804046630859375, 0.6268844604492188, 0.6736526489257812, 0.8217926025390625, 0.08050918579101562, 0.36031341552734375, 0.40457916259765625, 0.09252548217773438, 0.1883697509765625, 0.11850738525390625, 0.8248367309570312, 0.1905517578125, 0.0247039794921875, 87.02792358398438, 333.656494140625, 0.6796302795410156, 0.18450164794921875, 86.91024780273438, 0.1119537353515625, 0.07953262329101562, 0.21978378295898438, 0.5636329650878906, 0.23407745361328125, 84.01197052001953, 0.6102447509765625, 0.24880599975585938, 0.273590087890625, 0.557861328125, 0.6036186218261719, 0.184234619140625, 0.49993896484375, 84.702392578125, 0.036075592041015625, 86.19137573242188, 0.5787467956542969, 0.32346343994140625, 0.4776153564453125, 0.6742897033691406, 0.24767303466796875, 0.6221275329589844, 0.15200042724609375, 0.5301856994628906, 0.3211822509765625, 0.07396316528320312, 0.4361114501953125, 88.35581970214844, 0.5407867431640625, 0.6727294921875, 0.22703933715820312, 0.5282173156738281, 0.35263824462890625, 0.236907958984375, 0.4045372009277344, 0.7105941772460938, 0.6256446838378906, 335.63116455078125, 0.26871490478515625, 0.4820213317871094, 0.1787261962890625, 0.11241531372070312, 0.4173851013183594, 0.27645111083984375, 0.30279541015625, 0.34070587158203125, 0.52886962890625, 0.5703620910644531, 90.23563385009766, 85.3168716430664, 0.27814483642578125, 0.35260009765625, 88.72209930419922, 0.19979095458984375, 0.3558235168457031, 87.59629821777344, 83.74653625488281, 0.279052734375, 0.5447845458984375, 83.45893096923828, 0.3541374206542969, 0.1996307373046875, 0.7443389892578125, 0.2985725402832031, 0.8126335144042969, 0.6199188232421875, 87.59150695800781, 0.2967262268066406, 0.1353759765625, 0.2378997802734375, 0.1942901611328125, 0.4591636657714844, 0.34429931640625, 0.33675384521484375, 83.92364501953125, 83.40461730957031, 0.33390045166015625, 0.5574684143066406, 0.2546272277832031, 0.06296539306640625, 83.1619644165039, 0.12109375, 0.539764404296875, 0.35003662109375, 0.49523162841796875, 0.14019775390625, 0.5233993530273438, 0.5826492309570312, 88.35581970214844, 0.140899658203125, 0.18541336059570312, 0.6735725402832031, 0.14635467529296875, 0.8019828796386719, 0.5527381896972656, 90.59308624267578, 83.43856811523438, 0.6270828247070312, 0.4440879821777344, 0.31336212158203125, 0.5245552062988281, 0.3300323486328125, 0.3081512451171875, 0.419891357421875, 87.62496948242188, 90.10038757324219, 83.69371795654297, 0.425872802734375, 0.21480941772460938, 0.1903228759765625, 0.314910888671875, 89.92420196533203, 81.75807189941406, 0.5178604125976562, 89.21393585205078, 0.5690193176269531, 91.03990173339844, 83.343505859375, 0.22890853881835938, 0.23149871826171875, 0.232391357421875, 85.93106079101562, 0.4415092468261719, 89.79530334472656], "mean_td_error": 22.86878204345703, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 20715.0, "diff_num_grad_updates_vs_sampler_policy": 20714.0}}, "num_env_steps_sampled": 72144, "num_env_steps_trained": 5303040, "num_agent_steps_sampled": 72144, "num_agent_steps_trained": 5303040, "last_target_update_ts": 72144, "num_target_updates": 20715}, "sampler_results": {"episode_reward_max": 148.31048257648945, "episode_reward_min": -185.2264585196972, "episode_reward_mean": -143.34482212613025, "episode_len_mean": 96.83333333333333, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-171.61356304585934, -185.2264585196972, 148.31048257648945, -166.364186309278, -161.1578652113676, -166.60447953641415, -177.44498451054096, -165.76431642472744, -161.29296194761992, -175.79897065460682, -168.94946272671223, -168.23109920322895], "episode_lengths": [100, 100, 62, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1524487637560776, "mean_inference_ms": 2.3680322193092507, "mean_action_processing_ms": 0.22460716169622386, "mean_env_wait_ms": 3.018858441130469, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 148.31048257648945, "episode_reward_min": -185.2264585196972, "episode_reward_mean": -143.34482212613025, "episode_len_mean": 96.83333333333333, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-171.61356304585934, -185.2264585196972, 148.31048257648945, -166.364186309278, -161.1578652113676, -166.60447953641415, -177.44498451054096, -165.76431642472744, -161.29296194761992, -175.79897065460682, -168.94946272671223, -168.23109920322895], "episode_lengths": [100, 100, 62, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1524487637560776, "mean_inference_ms": 2.3680322193092507, "mean_action_processing_ms": 0.22460716169622386, "mean_env_wait_ms": 3.018858441130469, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 72144, "num_agent_steps_trained": 5303040, "num_env_steps_sampled": 72144, "num_env_steps_trained": 5303040, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 72144, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 72144, "timers": {"training_iteration_time_ms": 167.624, "load_time_ms": 0.276, "load_throughput": 928440.834, "learn_time_ms": 28.432, "learn_throughput": 9004.094, "synch_weights_time_ms": 6.066}, "counters": {"num_env_steps_sampled": 72144, "num_env_steps_trained": 5303040, "num_agent_steps_sampled": 72144, "num_agent_steps_trained": 5303040, "last_target_update_ts": 72144, "num_target_updates": 20715}, "done": false, "episodes_total": 745, "training_iteration": 72, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-29-57", "timestamp": 1675952997, "time_this_iter_s": 51.67850995063782, "time_total_s": 3302.8577375411987, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb520>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c1f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3302.8577375411987, "timesteps_since_restore": 0, "iterations_since_restore": 72, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.270422535211274, "ram_util_percent": 91.16056338028169}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.008733272552490234, "actor_loss": 90.63200378417969, "critic_loss": 1.2766268253326416, "alpha_loss": -0.034524135291576385, "alpha_value": 0.019193919375538826, "log_alpha_value": -3.9531617164611816, "target_entropy": -5.0, "policy_t": -0.36304160952568054, "mean_q": -90.59332275390625, "max_q": -83.798583984375, "min_q": -94.44348907470703}, "td_error": [0.44635009765625, 0.13912200927734375, 339.6766357421875, 0.4379463195800781, 0.4444465637207031, 86.35306549072266, 0.23037338256835938, 0.4400291442871094, 84.57537841796875, 0.6883430480957031, 0.33946990966796875, 0.6145896911621094, 0.3145332336425781, 88.80210876464844, 0.57586669921875, 0.48128509521484375, 86.18506622314453, 89.6978759765625, 91.00717163085938, 0.6013221740722656, 0.20322418212890625, 1.1556015014648438, 0.7479782104492188, 0.07692718505859375, 0.6739845275878906, 0.4568595886230469, 0.31819915771484375, 0.9293632507324219, 0.0766754150390625, 87.73429870605469, 89.36349487304688, 0.7070655822753906, 337.98297119140625, 0.27155303955078125, 0.7820281982421875, 335.4161682128906, 0.5192680358886719, 0.3935394287109375, 92.95654296875, 0.7459640502929688, 0.229461669921875, 90.03250122070312, 0.5486946105957031, 0.02970123291015625, 0.5434722900390625, 91.29603576660156, 90.91881561279297, 92.07276153564453, 0.4131011962890625, 0.38153076171875, 91.8122329711914, 0.5798492431640625, 0.6018524169921875, 92.66439056396484, 0.47829437255859375, 0.329071044921875, 0.5426864624023438, 88.06249237060547, 0.07133865356445312, 0.4528007507324219, 0.373748779296875, 90.12960815429688, 0.27352142333984375, 0.13440704345703125, 0.8351631164550781, 83.81089782714844, 0.5008316040039062, 89.34720611572266, 0.4007072448730469, 0.22733688354492188, 90.72035217285156, 0.5212020874023438, 0.31934356689453125, 0.8650856018066406, 0.583984375, 0.2145843505859375, 0.16474533081054688, 0.5676803588867188, 0.6384315490722656, 0.5323677062988281, 91.44868469238281, 0.31784820556640625, 0.6299858093261719, 87.38154602050781, 87.95503234863281, 0.5938034057617188, 88.79348754882812, 335.1282653808594, 91.96232604980469, 0.3895111083984375, 0.16153335571289062, 0.11026763916015625, 0.06795883178710938, 0.241851806640625, 92.27369689941406, 0.7340202331542969, 336.5128479003906, 0.6726341247558594, 0.2390594482421875, 0.6149139404296875, 0.5062789916992188, 0.4187126159667969, 0.5348320007324219, 0.5610198974609375, 92.57621765136719, 0.6162605285644531, 91.03964233398438, 0.28557586669921875, 0.2989959716796875, 0.31884002685546875, 92.23893737792969, 92.02416229248047, 0.5694847106933594, 336.4427490234375, 0.5996856689453125, 0.14612579345703125, 0.3942832946777344, 0.47527313232421875, 91.78997802734375, 0.49869537353515625, 0.20653152465820312, 0.6849594116210938, 0.5397529602050781, 0.13167190551757812, 340.10089111328125, 91.33718872070312, 89.12428283691406, 0.3392524719238281, 0.3712654113769531, 0.7443313598632812, 0.241943359375, 0.5849037170410156, 0.41959381103515625, 0.4372406005859375, 0.6116561889648438, 0.25919342041015625, 91.22831726074219, 332.67218017578125, 92.51936340332031, 83.6569595336914, 0.44725799560546875, 0.38674163818359375, 0.19378662109375, 84.36195373535156, 0.3649406433105469, 91.17451477050781, 0.26354217529296875, 0.25612640380859375, 86.24263000488281, 0.11724472045898438, 335.13623046875, 0.22066497802734375, 0.4568977355957031, 0.5879859924316406, 0.30425262451171875, 0.052001953125, 0.193695068359375, 0.9079399108886719, 0.7667808532714844, 0.528472900390625, 0.2359619140625, 0.31517791748046875, 0.5011100769042969, 0.08771133422851562, 0.05992889404296875, 0.0552520751953125, 0.12689590454101562, 0.1326141357421875, 0.5194816589355469, 0.2905235290527344, 88.53076171875, 0.857757568359375, 0.39034271240234375, 88.00830841064453, 0.5407028198242188, 0.43410491943359375, 0.1878814697265625, 0.616302490234375, 90.73200988769531, 86.27162170410156, 337.2098388671875, 0.08811569213867188, 0.63861083984375, 0.42363739013671875, 0.9136962890625, 0.5112190246582031, 90.5345458984375, 0.4690208435058594, 0.8460960388183594, 90.16789245605469, 88.70641326904297, 0.5362548828125, 89.00506591796875, 90.1704330444336, 0.4851799011230469, 0.6475906372070312, 0.4398765563964844, 90.40994262695312, 90.70526123046875, 0.9577598571777344, 0.28070831298828125, 89.9969482421875, 0.060459136962890625, 0.6208000183105469, 0.31609344482421875, 0.6936492919921875, 91.35873413085938, 0.22969818115234375, 0.28873443603515625, 0.14205169677734375, 84.9468765258789, 91.54786682128906, 85.50432586669922, 0.5113983154296875, 90.0767822265625, 0.04441070556640625, 0.6588935852050781, 0.11031341552734375, 0.130615234375, 0.4274406433105469, 0.22679901123046875, 87.38412475585938, 0.5927314758300781, 0.2570381164550781, 0.15259552001953125, 0.126251220703125, 0.217803955078125, 88.47311401367188, 0.4201622009277344, 334.1702880859375, 0.4963188171386719, 0.36456298828125, 0.6207733154296875, 0.5498695373535156, 0.31632232666015625, 0.161865234375, 89.59153747558594, 0.17971420288085938, 0.128753662109375, 0.1573028564453125, 0.2981605529785156, 0.09573745727539062, 0.41168975830078125, 0.2888526916503906, 0.22249984741210938, 0.17718124389648438, 0.6236305236816406, 0.1949462890625, 89.99089050292969, 0.5735702514648438, 89.58992767333984, 0.21014404296875, 0.47434234619140625, 0.408905029296875, 0.4765167236328125, 0.5179443359375], "mean_td_error": 36.071781158447266, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 21049.0, "diff_num_grad_updates_vs_sampler_policy": 21048.0}}, "num_env_steps_sampled": 73146, "num_env_steps_trained": 5388544, "num_agent_steps_sampled": 73146, "num_agent_steps_trained": 5388544, "last_target_update_ts": 73146, "num_target_updates": 21049}, "sampler_results": {"episode_reward_max": -143.17557802051306, "episode_reward_min": -172.038729429245, "episode_reward_mean": -161.87674024452767, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-172.038729429245, -143.17557802051306, -168.86351500451565, -159.019325658679, -156.78222466260195, -160.2406881302595, -171.39745411276817, -165.27322578430176, -160.09992139786482], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1529814176975732, "mean_inference_ms": 2.368934296390233, "mean_action_processing_ms": 0.22488786435361607, "mean_env_wait_ms": 3.018615387568453, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -143.17557802051306, "episode_reward_min": -172.038729429245, "episode_reward_mean": -161.87674024452767, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-172.038729429245, -143.17557802051306, -168.86351500451565, -159.019325658679, -156.78222466260195, -160.2406881302595, -171.39745411276817, -165.27322578430176, -160.09992139786482], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1529814176975732, "mean_inference_ms": 2.368934296390233, "mean_action_processing_ms": 0.22488786435361607, "mean_env_wait_ms": 3.018615387568453, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 73146, "num_agent_steps_trained": 5388544, "num_env_steps_sampled": 73146, "num_env_steps_trained": 5388544, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 73146, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 73146, "timers": {"training_iteration_time_ms": 157.749, "load_time_ms": 0.281, "load_throughput": 911340.879, "learn_time_ms": 25.577, "learn_throughput": 10008.956, "synch_weights_time_ms": 5.688}, "counters": {"num_env_steps_sampled": 73146, "num_env_steps_trained": 5388544, "num_agent_steps_sampled": 73146, "num_agent_steps_trained": 5388544, "last_target_update_ts": 73146, "num_target_updates": 21049}, "done": false, "episodes_total": 754, "training_iteration": 73, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-30-52", "timestamp": 1675953052, "time_this_iter_s": 54.81452250480652, "time_total_s": 3357.6722600460052, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588ac0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c8b0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3357.6722600460052, "timesteps_since_restore": 0, "iterations_since_restore": 73, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 43.33866666666667, "ram_util_percent": 91.6786666666667}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.11421801149845123, "actor_loss": 91.67402648925781, "critic_loss": 1.2446141242980957, "alpha_loss": -0.45008546113967896, "alpha_value": 0.01943688467144966, "log_alpha_value": -3.940582752227783, "target_entropy": -5.0, "policy_t": -0.35278674960136414, "mean_q": -91.54541015625, "max_q": -84.85543060302734, "min_q": -95.78936767578125}, "td_error": [0.31705474853515625, 0.7316856384277344, 0.44313812255859375, 88.37571716308594, 1.133392333984375, 0.4303627014160156, 0.25533294677734375, 90.29844665527344, 0.6185646057128906, 0.3675498962402344, 0.2869720458984375, 93.20138549804688, 0.23182296752929688, 0.3180694580078125, 0.5306510925292969, 0.23632431030273438, 0.32224273681640625, 336.84698486328125, 0.4832344055175781, 333.8537292480469, 91.5933837890625, 0.6029434204101562, 92.64442443847656, 86.00411987304688, 0.173858642578125, 0.6363105773925781, 93.13667297363281, 0.09088897705078125, 0.16846084594726562, 0.20251083374023438, 0.18841552734375, 91.76380920410156, 0.16724395751953125, 0.6385536193847656, 0.025264739990234375, 0.2406463623046875, 91.47682189941406, 0.2868499755859375, 337.8921203613281, 0.18339920043945312, 0.6200752258300781, 0.15383148193359375, 0.5652580261230469, 90.13726806640625, 89.35991668701172, 0.7335662841796875, 90.33523559570312, 0.07886505126953125, 0.6411285400390625, 0.25157928466796875, 89.52830505371094, 0.17786407470703125, 0.27105712890625, 0.032344818115234375, 0.1396484375, 0.297576904296875, 0.6685523986816406, 89.22383880615234, 0.13991928100585938, 0.1463775634765625, 0.15205764770507812, 0.24767684936523438, 0.39365386962890625, 0.8653717041015625, 0.3177146911621094, 0.6511459350585938, 0.053699493408203125, 0.16669845581054688, 0.30138397216796875, 337.9776611328125, 0.4888572692871094, 0.3842315673828125, 0.6023521423339844, 89.46045684814453, 90.91763305664062, 337.61065673828125, 0.42266845703125, 0.6538352966308594, 87.76829528808594, 0.6909904479980469, 0.7479095458984375, 1.0613327026367188, 338.7726135253906, 0.8624343872070312, 0.08246231079101562, 0.08775711059570312, 0.4025611877441406, 93.27055358886719, 0.08734893798828125, 0.40718841552734375, 0.24058914184570312, 0.46681976318359375, 0.6280517578125, 89.47954559326172, 0.5978126525878906, 85.71575164794922, 0.227325439453125, 0.27767181396484375, 0.6128883361816406, 0.3269996643066406, 0.1973419189453125, 0.4108543395996094, 0.19573974609375, 0.3179168701171875, 0.11553573608398438, 0.16485214233398438, 0.36806488037109375, 0.6895942687988281, 0.4413719177246094, 0.36927032470703125, 338.3084716796875, 0.5143013000488281, 337.8921203613281, 0.7514724731445312, 0.41657257080078125, 0.40316009521484375, 93.16627502441406, 92.50758361816406, 0.6624565124511719, 94.26709747314453, 0.413360595703125, 0.5913162231445312, 0.125732421875, 85.59722137451172, 0.046375274658203125, 0.15423583984375, 0.4139976501464844, 0.08026504516601562, 0.2667350769042969, 0.4521446228027344, 0.20794677734375, 0.9793853759765625, 0.3720588684082031, 0.5262374877929688, 89.54466247558594, 0.09289932250976562, 0.5136566162109375, 0.21858978271484375, 91.62134552001953, 0.17456817626953125, 90.94407653808594, 0.240325927734375, 0.29395294189453125, 0.428192138671875, 92.40399169921875, 0.46978759765625, 0.7151374816894531, 0.2950248718261719, 90.57806396484375, 0.4883155822753906, 0.1933441162109375, 0.17464447021484375, 0.2580833435058594, 335.75421142578125, 0.7411155700683594, 0.3844146728515625, 0.21436309814453125, 0.6150245666503906, 0.2844657897949219, 87.347412109375, 0.1544952392578125, 0.8425064086914062, 0.09189605712890625, 90.57806396484375, 0.212921142578125, 92.10139465332031, 0.29407501220703125, 0.378448486328125, 91.89553833007812, 0.15091323852539062, 0.4535675048828125, 0.5245323181152344, 89.485595703125, 93.44168090820312, 0.07477188110351562, 0.17821502685546875, 0.27898406982421875, 0.3494720458984375, 338.3084716796875, 0.3332099914550781, 0.4173126220703125, 0.18140411376953125, 0.17547607421875, 86.11241149902344, 0.7250213623046875, 91.26889038085938, 86.52874755859375, 0.2214202880859375, 0.2579803466796875, 0.7123641967773438, 0.049938201904296875, 338.3084716796875, 0.23095703125, 0.10264205932617188, 93.41716766357422, 0.7038078308105469, 92.59983825683594, 0.5758132934570312, 0.17547607421875, 0.6163291931152344, 0.1304779052734375, 0.5098381042480469, 0.27793121337890625, 0.017589569091796875, 90.13906860351562, 0.3679924011230469, 91.59226989746094, 0.47451019287109375, 0.6408767700195312, 0.17969512939453125, 0.5822639465332031, 0.4490852355957031, 0.1408538818359375, 338.01239013671875, 0.6355171203613281, 0.3070182800292969, 0.32506561279296875, 0.38793182373046875, 0.46262359619140625, 0.46025848388671875, 0.4690895080566406, 0.5080070495605469, 0.16350555419921875, 0.3127403259277344, 0.13769149780273438, 0.5777511596679688, 0.08964920043945312, 91.48433685302734, 0.30182647705078125, 335.41717529296875, 0.5615501403808594, 0.38285064697265625, 0.5446624755859375, 0.5234947204589844, 0.2471160888671875, 89.00128173828125, 90.55755615234375, 0.12667465209960938, 93.47297668457031, 0.7264671325683594, 0.3077735900878906, 92.88157653808594, 0.1129913330078125, 0.110321044921875, 0.5419883728027344, 0.32801055908203125, 92.20146942138672, 0.5627632141113281, 0.063232421875, 0.47924041748046875, 0.4052391052246094, 341.32720947265625, 86.4160385131836, 0.12685775756835938, 86.35072326660156, 0.166229248046875], "mean_td_error": 36.407623291015625, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 21383.0, "diff_num_grad_updates_vs_sampler_policy": 21382.0}}, "num_env_steps_sampled": 74148, "num_env_steps_trained": 5474048, "num_agent_steps_sampled": 74148, "num_agent_steps_trained": 5474048, "last_target_update_ts": 74148, "num_target_updates": 21383}, "sampler_results": {"episode_reward_max": 191.80275205522776, "episode_reward_min": -173.12717425823212, "episode_reward_mean": -128.55730764120818, "episode_len_mean": 93.6, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-172.25843781232834, -171.56783711910248, -154.89343477785587, -165.64450925588608, -154.28777254372835, -146.19070403277874, -173.0055277645588, -166.4004309028387, -173.12717425823212, 191.80275205522776], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 36]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1425050200008482, "mean_inference_ms": 2.3547043165458557, "mean_action_processing_ms": 0.22346309971769837, "mean_env_wait_ms": 2.9981971235584326, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 191.80275205522776, "episode_reward_min": -173.12717425823212, "episode_reward_mean": -128.55730764120818, "episode_len_mean": 93.6, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-172.25843781232834, -171.56783711910248, -154.89343477785587, -165.64450925588608, -154.28777254372835, -146.19070403277874, -173.0055277645588, -166.4004309028387, -173.12717425823212, 191.80275205522776], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 36]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1425050200008482, "mean_inference_ms": 2.3547043165458557, "mean_action_processing_ms": 0.22346309971769837, "mean_env_wait_ms": 2.9981971235584326, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 74148, "num_agent_steps_trained": 5474048, "num_env_steps_sampled": 74148, "num_env_steps_trained": 5474048, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 74148, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 74148, "timers": {"training_iteration_time_ms": 173.058, "load_time_ms": 0.311, "load_throughput": 822853.724, "learn_time_ms": 27.224, "learn_throughput": 9403.454, "synch_weights_time_ms": 5.795}, "counters": {"num_env_steps_sampled": 74148, "num_env_steps_trained": 5474048, "num_agent_steps_sampled": 74148, "num_agent_steps_trained": 5474048, "last_target_update_ts": 74148, "num_target_updates": 21383}, "done": false, "episodes_total": 764, "training_iteration": 74, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-31-46", "timestamp": 1675953106, "time_this_iter_s": 54.20589566230774, "time_total_s": 3411.878155708313, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380abee0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f71f0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3411.878155708313, "timesteps_since_restore": 0, "iterations_since_restore": 74, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.764, "ram_util_percent": 91.61466666666666}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.09214271605014801, "actor_loss": 92.91163635253906, "critic_loss": 1.0780906677246094, "alpha_loss": 0.3647041320800781, "alpha_value": 0.01910061575472355, "log_alpha_value": -3.9580347537994385, "target_entropy": -5.0, "policy_t": -0.3730393052101135, "mean_q": -92.845458984375, "max_q": -86.70433044433594, "min_q": -96.9544448852539}, "td_error": [0.2542572021484375, 91.9512710571289, 0.5121040344238281, 0.5451889038085938, 94.28158569335938, 0.4177894592285156, 0.2521209716796875, 0.17642593383789062, 93.55545043945312, 0.7091827392578125, 0.17183685302734375, 0.5204238891601562, 0.3658561706542969, 86.10877990722656, 0.06577682495117188, 0.13647842407226562, 0.3465156555175781, 0.27025604248046875, 91.23783874511719, 0.44232940673828125, 91.49952697753906, 91.92849731445312, 0.8902015686035156, 0.3720703125, 0.2726249694824219, 0.083587646484375, 0.8739166259765625, 93.68817138671875, 0.358489990234375, 338.7572937011719, 0.49819183349609375, 0.6080551147460938, 0.0376129150390625, 91.20268249511719, 0.5927581787109375, 88.0359878540039, 0.30055999755859375, 0.09540176391601562, 0.4825439453125, 93.32825469970703, 0.4941291809082031, 0.195556640625, 92.405029296875, 0.4201316833496094, 0.22684478759765625, 0.5933799743652344, 0.0536956787109375, 0.418304443359375, 92.84754180908203, 0.5612335205078125, 0.42987060546875, 0.1582183837890625, 0.235015869140625, 0.9196548461914062, 0.41753387451171875, 0.0400390625, 0.9362411499023438, 0.41828155517578125, 0.143524169921875, 0.5470848083496094, 88.077392578125, 0.5230751037597656, 94.3913345336914, 0.5613288879394531, 0.582366943359375, 0.4784736633300781, 0.5891151428222656, 0.190948486328125, 0.5297508239746094, 0.5359306335449219, 0.5157127380371094, 0.04241180419921875, 0.16938018798828125, 0.2771148681640625, 94.35628509521484, 92.58087158203125, 0.5787544250488281, 92.97689819335938, 0.633270263671875, 0.8147010803222656, 0.21427154541015625, 0.30999755859375, 89.0542221069336, 0.7929191589355469, 0.5333328247070312, 0.59710693359375, 0.6249542236328125, 92.7689437866211, 338.9680480957031, 0.283538818359375, 0.4369163513183594, 91.35029602050781, 90.46107482910156, 0.8394317626953125, 0.4948997497558594, 0.3795280456542969, 91.2982177734375, 86.53424072265625, 0.35977935791015625, 86.57012939453125, 0.4198265075683594, 0.16799163818359375, 0.22232818603515625, 0.4882392883300781, 0.038120269775390625, 0.10766983032226562, 0.34001922607421875, 0.49982452392578125, 94.34481048583984, 0.2042999267578125, 0.7852096557617188, 0.4551239013671875, 0.241546630859375, 85.94743347167969, 0.16588592529296875, 0.3442420959472656, 0.4843597412109375, 93.50552368164062, 92.02976989746094, 93.50822448730469, 0.744110107421875, 0.20395660400390625, 0.23485946655273438, 94.28858184814453, 0.53338623046875, 0.46183013916015625, 339.33056640625, 93.0973129272461, 0.38712310791015625, 0.34647369384765625, 0.26180267333984375, 93.9418716430664, 1.0661201477050781, 0.46559906005859375, 0.5935173034667969, 0.7614555358886719, 0.4786109924316406, 93.9981918334961, 0.17795181274414062, 0.1150665283203125, 0.46053314208984375, 0.09587860107421875, 0.5092811584472656, 93.19232177734375, 0.15354537963867188, 0.25235748291015625, 0.21283721923828125, 0.4434547424316406, 0.4597816467285156, 90.32124328613281, 0.4675025939941406, 0.7502937316894531, 89.56367492675781, 88.19219207763672, 0.5264968872070312, 0.34949493408203125, 89.15158081054688, 87.9390869140625, 0.5524635314941406, 87.84284210205078, 0.7799835205078125, 0.6357612609863281, 0.30713653564453125, 89.34854125976562, 90.91523742675781, 0.53350830078125, 0.5406036376953125, 0.2822113037109375, 0.6412086486816406, 0.40692901611328125, 0.11466217041015625, 0.6947097778320312, 0.41016387939453125, 88.26731872558594, 0.62347412109375, 0.56500244140625, 0.36086273193359375, 93.7768325805664, 0.44195556640625, 0.21183013916015625, 0.9209747314453125, 0.348052978515625, 0.14559173583984375, 0.15983963012695312, 0.4675750732421875, 0.5275802612304688, 0.2819671630859375, 91.96907043457031, 0.2922096252441406, 0.10918045043945312, 0.6027946472167969, 0.666595458984375, 0.10814285278320312, 0.349365234375, 0.6700630187988281, 0.41002655029296875, 92.47662353515625, 0.5693550109863281, 92.79507446289062, 0.5021133422851562, 0.5126838684082031, 0.6186447143554688, 0.6384391784667969, 92.97262573242188, 0.7374267578125, 93.19261169433594, 0.3096809387207031, 0.3848457336425781, 0.4090423583984375, 339.99981689453125, 0.5419654846191406, 0.7800102233886719, 0.6505661010742188, 0.4761772155761719, 0.6291236877441406, 89.87332916259766, 0.7060813903808594, 0.35504150390625, 0.1243743896484375, 89.03546142578125, 0.64764404296875, 0.518218994140625, 0.44793701171875, 93.49473571777344, 0.12995147705078125, 89.70626068115234, 0.6630287170410156, 93.97731018066406, 0.281005859375, 0.49234771728515625, 0.18053436279296875, 90.507080078125, 0.16975021362304688, 337.8441162109375, 0.4363212585449219, 90.9551010131836, 0.21698379516601562, 0.7424659729003906, 0.5668792724609375, 0.4030570983886719, 0.59710693359375, 0.26250457763671875, 0.4589042663574219, 0.34877777099609375, 0.5144882202148438, 0.69378662109375, 94.01589965820312, 95.58064270019531, 0.10910797119140625, 0.5373725891113281, 0.16950225830078125, 92.86699676513672, 86.19781494140625, 91.37092590332031, 0.08340072631835938, 0.6013526916503906], "mean_td_error": 29.07093620300293, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 21717.0, "diff_num_grad_updates_vs_sampler_policy": 21716.0}}, "num_env_steps_sampled": 75150, "num_env_steps_trained": 5559552, "num_agent_steps_sampled": 75150, "num_agent_steps_trained": 5559552, "last_target_update_ts": 75150, "num_target_updates": 21717}, "sampler_results": {"episode_reward_max": 124.93473886698484, "episode_reward_min": -172.29703122377396, "episode_reward_mean": -135.55750901590693, "episode_len_mean": 98.9090909090909, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [124.93473886698484, -163.0180952101946, -161.28063073009253, -167.00439904630184, -151.3675112053752, -160.56970743089914, -158.76533725112677, -161.2794821932912, -172.29703122377396, -161.53198893368244, -158.95315481722355], "episode_lengths": [88, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1636558597515732, "mean_inference_ms": 2.3856886428337463, "mean_action_processing_ms": 0.22670400744381095, "mean_env_wait_ms": 3.035813006661667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 124.93473886698484, "episode_reward_min": -172.29703122377396, "episode_reward_mean": -135.55750901590693, "episode_len_mean": 98.9090909090909, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [124.93473886698484, -163.0180952101946, -161.28063073009253, -167.00439904630184, -151.3675112053752, -160.56970743089914, -158.76533725112677, -161.2794821932912, -172.29703122377396, -161.53198893368244, -158.95315481722355], "episode_lengths": [88, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1636558597515732, "mean_inference_ms": 2.3856886428337463, "mean_action_processing_ms": 0.22670400744381095, "mean_env_wait_ms": 3.035813006661667, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 75150, "num_agent_steps_trained": 5559552, "num_env_steps_sampled": 75150, "num_env_steps_trained": 5559552, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 75150, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 75150, "timers": {"training_iteration_time_ms": 175.662, "load_time_ms": 0.331, "load_throughput": 772642.89, "learn_time_ms": 27.407, "learn_throughput": 9340.8, "synch_weights_time_ms": 5.817}, "counters": {"num_env_steps_sampled": 75150, "num_env_steps_trained": 5559552, "num_agent_steps_sampled": 75150, "num_agent_steps_trained": 5559552, "last_target_update_ts": 75150, "num_target_updates": 21717}, "done": false, "episodes_total": 775, "training_iteration": 75, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-32-43", "timestamp": 1675953163, "time_this_iter_s": 56.431779861450195, "time_total_s": 3468.309935569763, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a3d0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3468.309935569763, "timesteps_since_restore": 0, "iterations_since_restore": 75, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 44.26538461538461, "ram_util_percent": 92.00384615384613}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.26577937602996826, "actor_loss": 94.1208267211914, "critic_loss": 1.284174919128418, "alpha_loss": 1.0401973724365234, "alpha_value": 0.019965235143899918, "log_alpha_value": -3.9137628078460693, "target_entropy": -5.0, "policy_t": -0.3701443076133728, "mean_q": -93.99894714355469, "max_q": -87.35562896728516, "min_q": -98.20873260498047}, "td_error": [0.4252777099609375, 0.41400909423828125, 91.58267211914062, 95.30604553222656, 95.89215850830078, 0.4444465637207031, 336.9557189941406, 0.30757904052734375, 0.4544029235839844, 90.08866882324219, 95.47611999511719, 0.4681739807128906, 93.5606918334961, 0.3471946716308594, 90.4094009399414, 91.87046813964844, 94.54582214355469, 0.6292648315429688, 0.11567306518554688, 95.32485961914062, 0.7256202697753906, 0.24255752563476562, 0.2105560302734375, 0.8258399963378906, 0.24205780029296875, 0.3498878479003906, 0.30889129638671875, 86.44247436523438, 0.17113113403320312, 0.7221298217773438, 95.35183715820312, 92.41786193847656, 0.5086555480957031, 93.51480865478516, 0.20305633544921875, 0.24938201904296875, 94.44725799560547, 95.93152618408203, 91.33370208740234, 0.7300338745117188, 88.64686584472656, 338.60552978515625, 0.46277618408203125, 0.21685409545898438, 339.67608642578125, 0.17135238647460938, 0.17391586303710938, 0.451263427734375, 0.5714950561523438, 0.6091461181640625, 0.4131660461425781, 0.421478271484375, 0.09454345703125, 338.60552978515625, 88.089599609375, 0.9940757751464844, 0.5490188598632812, 0.8284149169921875, 92.8039321899414, 0.2155303955078125, 1.0446395874023438, 0.40032958984375, 91.46746826171875, 0.5904006958007812, 0.24431610107421875, 0.40293121337890625, 0.09847259521484375, 0.6411895751953125, 94.20462036132812, 0.242767333984375, 0.12471389770507812, 0.8655014038085938, 0.38526153564453125, 0.12251663208007812, 94.63226318359375, 0.31951904296875, 0.6138267517089844, 0.23645401000976562, 0.4343109130859375, 0.318817138671875, 0.5998497009277344, 0.5408515930175781, 0.3674812316894531, 0.7935829162597656, 0.35591888427734375, 92.36890411376953, 0.29729461669921875, 0.14623641967773438, 0.10419464111328125, 0.43627166748046875, 0.270660400390625, 0.13818359375, 0.23384857177734375, 0.040615081787109375, 89.65899658203125, 0.6922950744628906, 0.4787559509277344, 0.5595283508300781, 94.75971984863281, 1.0578079223632812, 93.35015869140625, 89.84542846679688, 0.4188079833984375, 91.87046813964844, 0.1447906494140625, 0.5681076049804688, 0.3681907653808594, 0.4457969665527344, 0.12382888793945312, 0.12578964233398438, 0.20035171508789062, 0.3276519775390625, 0.11576080322265625, 338.60552978515625, 339.8813781738281, 94.79266357421875, 0.650726318359375, 0.20803070068359375, 0.19666290283203125, 0.2457275390625, 0.6394081115722656, 0.867401123046875, 0.513763427734375, 0.3127708435058594, 0.3815460205078125, 0.3596649169921875, 0.5567703247070312, 0.2600059509277344, 0.3457374572753906, 88.28524780273438, 0.5642013549804688, 0.3390998840332031, 0.22440338134765625, 93.35015869140625, 1.0045547485351562, 0.9905815124511719, 95.31396484375, 0.5921173095703125, 0.2656059265136719, 341.8963623046875, 0.1902618408203125, 0.5147018432617188, 0.4081153869628906, 0.55908203125, 88.898193359375, 88.52311706542969, 0.6227378845214844, 0.5099105834960938, 0.6608123779296875, 0.5143203735351562, 95.86769104003906, 0.05826568603515625, 0.46926116943359375, 0.2918701171875, 339.05963134765625, 0.7882575988769531, 0.015106201171875, 0.4579010009765625, 93.41256713867188, 94.96160888671875, 0.7975234985351562, 0.1573638916015625, 92.76463317871094, 1.0453987121582031, 0.08877182006835938, 0.3220329284667969, 0.8467330932617188, 0.7394638061523438, 0.274017333984375, 0.31854248046875, 93.94266510009766, 339.8813781738281, 342.3982849121094, 0.40840911865234375, 0.17496490478515625, 94.86862182617188, 0.5059165954589844, 0.23139572143554688, 0.38775634765625, 0.7383041381835938, 0.6952323913574219, 94.3727798461914, 0.5887336730957031, 86.61735534667969, 0.6260719299316406, 93.2191162109375, 0.19823455810546875, 0.06256103515625, 0.4396247863769531, 0.3142662048339844, 0.28964996337890625, 0.2513999938964844, 0.2793426513671875, 0.16875839233398438, 0.106658935546875, 0.29766845703125, 0.5755729675292969, 94.76373291015625, 0.22128677368164062, 0.04918670654296875, 0.6673583984375, 0.0162353515625, 1.1142654418945312, 94.12078857421875, 0.2531852722167969, 0.46968841552734375, 0.3118934631347656, 0.4032020568847656, 94.86128234863281, 0.187347412109375, 0.10715484619140625, 0.3325767517089844, 0.2904014587402344, 0.5042190551757812, 0.8519020080566406, 0.649322509765625, 0.1915740966796875, 0.4917869567871094, 0.050579071044921875, 0.15734481811523438, 0.5346870422363281, 0.16217422485351562, 0.109375, 86.4703369140625, 91.98190307617188, 0.4912452697753906, 0.7637367248535156, 0.8615341186523438, 0.744354248046875, 0.3002052307128906, 90.74468231201172, 0.3773040771484375, 93.037109375, 89.27644348144531, 0.16511154174804688, 0.4161262512207031, 1.0105247497558594, 90.84740447998047, 0.075347900390625, 94.48759460449219, 0.376007080078125, 338.78656005859375, 0.37699127197265625, 0.7513351440429688, 0.2841796875, 0.0706939697265625, 0.0917205810546875, 0.4931793212890625, 0.5030746459960938, 0.7008323669433594, 0.43181610107421875, 0.33498382568359375, 339.05963134765625, 95.30604553222656, 90.97891998291016, 95.73810577392578], "mean_td_error": 36.82802963256836, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 22051.0, "diff_num_grad_updates_vs_sampler_policy": 22050.0}}, "num_env_steps_sampled": 76152, "num_env_steps_trained": 5645056, "num_agent_steps_sampled": 76152, "num_agent_steps_trained": 5645056, "last_target_update_ts": 76152, "num_target_updates": 22051}, "sampler_results": {"episode_reward_max": 169.6803795993328, "episode_reward_min": -182.34440790116787, "episode_reward_mean": -131.51495799273252, "episode_len_mean": 95.2, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [169.6803795993328, -161.44799581170082, -159.49181184917688, -164.70041462033987, -163.04296263307333, -171.42047108709812, -163.48527751863003, -182.34440790116787, -153.71747366338968, -165.17914444208145], "episode_lengths": [52, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.143030667600844, "mean_inference_ms": 2.3581014065519903, "mean_action_processing_ms": 0.22341121292640218, "mean_env_wait_ms": 2.999100585563318, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 169.6803795993328, "episode_reward_min": -182.34440790116787, "episode_reward_mean": -131.51495799273252, "episode_len_mean": 95.2, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [169.6803795993328, -161.44799581170082, -159.49181184917688, -164.70041462033987, -163.04296263307333, -171.42047108709812, -163.48527751863003, -182.34440790116787, -153.71747366338968, -165.17914444208145], "episode_lengths": [52, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.143030667600844, "mean_inference_ms": 2.3581014065519903, "mean_action_processing_ms": 0.22341121292640218, "mean_env_wait_ms": 2.999100585563318, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 76152, "num_agent_steps_trained": 5645056, "num_env_steps_sampled": 76152, "num_env_steps_trained": 5645056, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 76152, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 76152, "timers": {"training_iteration_time_ms": 150.224, "load_time_ms": 0.309, "load_throughput": 829336.39, "learn_time_ms": 24.523, "learn_throughput": 10439.293, "synch_weights_time_ms": 5.553}, "counters": {"num_env_steps_sampled": 76152, "num_env_steps_trained": 5645056, "num_agent_steps_sampled": 76152, "num_agent_steps_trained": 5645056, "last_target_update_ts": 76152, "num_target_updates": 22051}, "done": false, "episodes_total": 785, "training_iteration": 76, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-33-36", "timestamp": 1675953216, "time_this_iter_s": 53.583471059799194, "time_total_s": 3521.8934066295624, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380efc70>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3521.8934066295624, "timesteps_since_restore": 0, "iterations_since_restore": 76, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 41.509459459459464, "ram_util_percent": 91.6527027027027}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.04123365134000778, "actor_loss": 95.42279052734375, "critic_loss": 1.2633136510849, "alpha_loss": -0.15820640325546265, "alpha_value": 0.021561913192272186, "log_alpha_value": -3.836826801300049, "target_entropy": -5.0, "policy_t": -0.3771326541900635, "mean_q": -95.38306427001953, "max_q": -89.02662658691406, "min_q": -100.76753997802734}, "td_error": [0.19571304321289062, 0.04006195068359375, 0.4650115966796875, 0.509063720703125, 0.516754150390625, 0.43471527099609375, 0.4479866027832031, 0.435760498046875, 0.461334228515625, 345.25469970703125, 0.007770538330078125, 94.50837707519531, 0.6788101196289062, 337.8888854980469, 0.17981719970703125, 0.4081611633300781, 0.5724563598632812, 0.08533859252929688, 0.493438720703125, 0.3798561096191406, 0.17773056030273438, 92.62847900390625, 0.3260498046875, 0.4712028503417969, 0.4214363098144531, 0.086151123046875, 92.11715698242188, 0.14711380004882812, 0.3509063720703125, 96.7960205078125, 0.05873870849609375, 0.4053077697753906, 95.19424438476562, 0.21700286865234375, 96.51840209960938, 0.3499412536621094, 0.4149932861328125, 91.08766174316406, 96.18895721435547, 0.1724700927734375, 90.19259643554688, 0.22451019287109375, 0.24738311767578125, 0.37683868408203125, 0.11029052734375, 0.5355339050292969, 95.5519027709961, 0.3346214294433594, 90.92269897460938, 0.699615478515625, 0.8079414367675781, 96.17152404785156, 0.32335662841796875, 0.23577499389648438, 0.40552520751953125, 0.21955108642578125, 338.18145751953125, 0.6994857788085938, 0.9603843688964844, 0.037364959716796875, 0.3704681396484375, 97.27134704589844, 0.15464019775390625, 0.3971061706542969, 96.26008605957031, 0.7339286804199219, 0.41124725341796875, 0.285430908203125, 0.4617729187011719, 0.2757415771484375, 0.134063720703125, 93.44723510742188, 342.9892883300781, 0.4711875915527344, 0.09439468383789062, 0.4936332702636719, 0.40657806396484375, 0.21329116821289062, 0.36890411376953125, 0.5549240112304688, 97.18244934082031, 0.10477066040039062, 0.3642463684082031, 95.226318359375, 0.4035758972167969, 0.4754066467285156, 0.14572525024414062, 0.5483627319335938, 340.4765625, 0.5758247375488281, 0.6347694396972656, 92.61686706542969, 95.43083953857422, 0.3480873107910156, 0.5053291320800781, 343.63311767578125, 0.3773651123046875, 0.14955902099609375, 92.83013916015625, 0.5416946411132812, 0.33190155029296875, 92.83013916015625, 0.09216690063476562, 96.45756530761719, 0.4663810729980469, 0.23077011108398438, 93.04206848144531, 0.5746498107910156, 0.6498069763183594, 0.41533660888671875, 0.6268157958984375, 92.79510498046875, 0.11774444580078125, 96.26008605957031, 0.33394622802734375, 0.17040252685546875, 0.6196098327636719, 95.5519027709961, 0.5709800720214844, 0.11603546142578125, 0.13009262084960938, 96.86458587646484, 0.5099258422851562, 0.62103271484375, 0.342498779296875, 0.37554168701171875, 0.16663742065429688, 0.23421096801757812, 0.15575408935546875, 0.6699943542480469, 95.4715576171875, 0.9342689514160156, 0.4757347106933594, 0.29067230224609375, 0.20318984985351562, 95.09205627441406, 94.677978515625, 94.63467407226562, 0.3294219970703125, 0.4159088134765625, 94.35167694091797, 0.2517127990722656, 92.41537475585938, 0.5789718627929688, 92.61686706542969, 0.08973312377929688, 0.281951904296875, 338.9618225097656, 96.64408874511719, 0.2974281311035156, 0.4652442932128906, 0.3188629150390625, 0.14730072021484375, 0.5982780456542969, 96.44059753417969, 0.7627334594726562, 0.5618095397949219, 0.3725242614746094, 0.4745368957519531, 96.52395629882812, 0.11626815795898438, 0.16146469116210938, 0.7782974243164062, 0.3213157653808594, 88.70085906982422, 0.0274505615234375, 0.45969390869140625, 0.7788810729980469, 0.44254302978515625, 0.5275230407714844, 89.75718688964844, 0.2805061340332031, 0.2635917663574219, 0.1018829345703125, 0.4295234680175781, 90.07261657714844, 0.6875877380371094, 0.421844482421875, 0.061603546142578125, 91.24575805664062, 0.13700485229492188, 88.15870666503906, 0.749481201171875, 89.70695495605469, 0.5307044982910156, 89.973388671875, 0.3194122314453125, 0.2552375793457031, 1.1796493530273438, 0.3405647277832031, 95.85884857177734, 95.88262176513672, 0.41326141357421875, 96.29266357421875, 0.1975860595703125, 0.5878486633300781, 87.90040588378906, 96.0018310546875, 0.29205322265625, 95.26287841796875, 91.37944793701172, 0.2774085998535156, 92.83013916015625, 0.5046882629394531, 91.73701477050781, 0.8700294494628906, 96.88055419921875, 0.7868690490722656, 0.5416831970214844, 0.43329620361328125, 0.5560340881347656, 0.32721710205078125, 340.462890625, 0.050563812255859375, 0.463836669921875, 96.26008605957031, 93.15788269042969, 95.68692016601562, 0.36302947998046875, 0.3908576965332031, 0.4548912048339844, 0.08633804321289062, 0.060466766357421875, 0.7074127197265625, 0.20807266235351562, 0.16512298583984375, 0.267547607421875, 0.1627960205078125, 0.3173332214355469, 0.48766326904296875, 0.5050277709960938, 95.07769775390625, 0.5901603698730469, 0.4661064147949219, 0.135223388671875, 0.32949066162109375, 0.45729827880859375, 94.80140686035156, 0.0911407470703125, 87.22451782226562, 0.42156982421875, 0.3701972961425781, 0.12596893310546875, 0.7829971313476562, 0.2797698974609375, 342.05908203125, 0.39034271240234375, 95.28416442871094, 0.05621337890625, 0.34037017822265625, 0.25551605224609375, 0.7149848937988281, 95.2752685546875, 0.4023399353027344, 0.12043380737304688, 94.98515319824219], "mean_td_error": 35.37422561645508, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 22385.0, "diff_num_grad_updates_vs_sampler_policy": 22384.0}}, "num_env_steps_sampled": 77154, "num_env_steps_trained": 5730560, "num_agent_steps_sampled": 77154, "num_agent_steps_trained": 5730560, "last_target_update_ts": 77154, "num_target_updates": 22385}, "sampler_results": {"episode_reward_max": -152.8951591551304, "episode_reward_min": -181.0063157826662, "episode_reward_mean": -163.9134340003133, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-167.2451076209545, -167.8662877753377, -156.23243982344866, -159.70816734433174, -157.71184766292572, -181.0063157826662, -164.72998490184546, -152.8951591551304, -165.67885532975197, -166.06017460674047], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.16559326604679, "mean_inference_ms": 2.390617717827612, "mean_action_processing_ms": 0.22710014953459026, "mean_env_wait_ms": 3.0347617196556547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -152.8951591551304, "episode_reward_min": -181.0063157826662, "episode_reward_mean": -163.9134340003133, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-167.2451076209545, -167.8662877753377, -156.23243982344866, -159.70816734433174, -157.71184766292572, -181.0063157826662, -164.72998490184546, -152.8951591551304, -165.67885532975197, -166.06017460674047], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.16559326604679, "mean_inference_ms": 2.390617717827612, "mean_action_processing_ms": 0.22710014953459026, "mean_env_wait_ms": 3.0347617196556547, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 77154, "num_agent_steps_trained": 5730560, "num_env_steps_sampled": 77154, "num_env_steps_trained": 5730560, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 77154, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 77154, "timers": {"training_iteration_time_ms": 156.099, "load_time_ms": 0.261, "load_throughput": 980049.127, "learn_time_ms": 26.352, "learn_throughput": 9714.747, "synch_weights_time_ms": 6.395}, "counters": {"num_env_steps_sampled": 77154, "num_env_steps_trained": 5730560, "num_agent_steps_sampled": 77154, "num_agent_steps_trained": 5730560, "last_target_update_ts": 77154, "num_target_updates": 22385}, "done": false, "episodes_total": 795, "training_iteration": 77, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-34-28", "timestamp": 1675953268, "time_this_iter_s": 51.772043228149414, "time_total_s": 3573.665449857712, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a730>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508160>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3573.665449857712, "timesteps_since_restore": 0, "iterations_since_restore": 77, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.29859154929578, "ram_util_percent": 91.60422535211268}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.0007296120747923851, "actor_loss": 96.52136993408203, "critic_loss": 1.092558741569519, "alpha_loss": -0.0027846135199069977, "alpha_value": 0.02200610563158989, "log_alpha_value": -3.8164353370666504, "target_entropy": -5.0, "policy_t": -0.36814260482788086, "mean_q": -96.48612976074219, "max_q": -90.15156555175781, "min_q": -101.07707977294922}, "td_error": [0.5452766418457031, 0.6603622436523438, 93.99198913574219, 0.6442527770996094, 96.05602264404297, 0.9118423461914062, 0.32749176025390625, 0.2903785705566406, 0.36847686767578125, 0.40001678466796875, 90.73776245117188, 0.20008087158203125, 0.7704391479492188, 0.650054931640625, 0.6858558654785156, 0.47212982177734375, 0.20807266235351562, 0.0763702392578125, 97.23762512207031, 0.15371322631835938, 0.4995574951171875, 0.3644752502441406, 0.4811515808105469, 0.7440910339355469, 0.42760467529296875, 97.22101593017578, 0.06795883178710938, 0.8269081115722656, 0.29253387451171875, 0.5276527404785156, 95.53498077392578, 0.4367790222167969, 96.93726348876953, 0.9995880126953125, 0.16756439208984375, 0.5292892456054688, 0.7100753784179688, 0.2838478088378906, 97.23762512207031, 0.24725341796875, 0.055118560791015625, 94.75820922851562, 0.2861747741699219, 0.9702911376953125, 0.4181251525878906, 0.19421768188476562, 92.90753173828125, 94.30569458007812, 0.5998992919921875, 97.30374145507812, 0.15672683715820312, 97.15412139892578, 0.1179962158203125, 98.37828826904297, 0.2205810546875, 0.14119720458984375, 0.34157562255859375, 0.7166748046875, 0.159576416015625, 0.25022125244140625, 97.86074829101562, 97.75431823730469, 0.22067642211914062, 0.30161285400390625, 0.3451728820800781, 0.6482086181640625, 88.93618774414062, 0.5979232788085938, 340.34637451171875, 343.27960205078125, 95.9950180053711, 0.260101318359375, 0.2705802917480469, 0.13690567016601562, 0.5595588684082031, 0.2927360534667969, 0.29447174072265625, 0.5178184509277344, 0.18452835083007812, 97.95263671875, 0.6019363403320312, 0.2111968994140625, 0.074920654296875, 0.6939468383789062, 0.03398895263671875, 0.16370010375976562, 0.353271484375, 0.38297271728515625, 97.34203338623047, 0.2811241149902344, 346.22625732421875, 0.4135246276855469, 0.0088958740234375, 0.4803352355957031, 0.5600433349609375, 0.1036529541015625, 91.2261962890625, 0.47663116455078125, 0.36395263671875, 98.0544662475586, 0.13455963134765625, 0.5295143127441406, 0.170623779296875, 0.7131805419921875, 0.17775726318359375, 0.4229736328125, 0.5558662414550781, 98.53279113769531, 0.8509445190429688, 0.8505935668945312, 91.03717041015625, 0.4769783020019531, 0.6652984619140625, 0.15996551513671875, 0.3646125793457031, 91.79917907714844, 0.6555404663085938, 93.3052978515625, 0.375823974609375, 0.2543182373046875, 92.70636749267578, 0.44319915771484375, 88.44293975830078, 96.28959655761719, 0.6427345275878906, 97.69308471679688, 94.88375854492188, 0.3434410095214844, 0.7791366577148438, 0.44594573974609375, 0.6642608642578125, 94.78202056884766, 0.3337821960449219, 91.38050842285156, 0.45499420166015625, 342.79852294921875, 0.9522056579589844, 0.3302268981933594, 0.973968505859375, 0.6261711120605469, 0.08284759521484375, 0.5919532775878906, 0.4972724914550781, 0.6746139526367188, 0.12590789794921875, 93.64533996582031, 0.6922988891601562, 0.2972450256347656, 92.80174255371094, 0.2152252197265625, 0.6596870422363281, 0.455291748046875, 0.129150390625, 94.66375732421875, 0.3097190856933594, 0.7557487487792969, 0.40015411376953125, 93.978515625, 91.31452941894531, 0.2515754699707031, 0.46192169189453125, 0.18707275390625, 0.6956253051757812, 0.5044212341308594, 0.4134178161621094, 99.346923828125, 0.3197135925292969, 0.56097412109375, 0.7426261901855469, 90.0302505493164, 94.562255859375, 0.17627716064453125, 0.40448760986328125, 0.4193458557128906, 0.3298835754394531, 94.21524810791016, 89.86253356933594, 0.05139923095703125, 88.97845458984375, 0.17625808715820312, 0.5915069580078125, 0.13628387451171875, 0.29207611083984375, 0.5953140258789062, 0.429901123046875, 0.14943313598632812, 0.2024688720703125, 0.156524658203125, 0.9589157104492188, 93.35282897949219, 93.23401641845703, 0.2838478088378906, 90.42381286621094, 92.56989288330078, 0.053562164306640625, 0.32221221923828125, 0.18574905395507812, 1.0036506652832031, 97.3369140625, 0.3298797607421875, 0.4707298278808594, 0.33574676513671875, 0.11756134033203125, 93.64533996582031, 0.3373069763183594, 0.31854248046875, 97.74427795410156, 0.1412811279296875, 0.65350341796875, 0.23740005493164062, 0.4008445739746094, 0.443145751953125, 0.225677490234375, 90.54136657714844, 0.18817901611328125, 0.05492401123046875, 0.18967437744140625, 98.07211303710938, 96.431396484375, 90.78294372558594, 0.6346359252929688, 0.23430252075195312, 0.8092117309570312, 0.5965652465820312, 0.11765670776367188, 97.610595703125, 96.2789077758789, 0.0798187255859375, 0.4007759094238281, 0.806488037109375, 95.2915267944336, 0.11143112182617188, 0.276275634765625, 0.6215248107910156, 93.2132568359375, 0.3848419189453125, 89.35537719726562, 0.1746826171875, 0.2975616455078125, 0.6372604370117188, 0.6499710083007812, 0.580413818359375, 0.4100532531738281, 0.2528419494628906, 94.88375854492188, 0.4243621826171875, 0.5164299011230469, 1.1335678100585938, 0.12527847290039062, 0.6834640502929688, 0.4201469421386719, 0.414520263671875, 97.93890380859375, 0.3354949951171875, 96.48674011230469, 93.64533996582031], "mean_td_error": 29.288774490356445, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 22719.0, "diff_num_grad_updates_vs_sampler_policy": 22718.0}}, "num_env_steps_sampled": 78156, "num_env_steps_trained": 5816064, "num_agent_steps_sampled": 78156, "num_agent_steps_trained": 5816064, "last_target_update_ts": 78156, "num_target_updates": 22719}, "sampler_results": {"episode_reward_max": 218.4875881522894, "episode_reward_min": -170.17647764086723, "episode_reward_mean": -104.9829066991806, "episode_len_mean": 89.41666666666667, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.60555607825518, -156.57682275772095, 167.93389448523521, -169.0568140000105, -162.2520575746894, -165.49506570398808, -170.17647764086723, -162.3308557420969, -161.8372429832816, 218.4875881522894, -164.90873232483864, -169.97673822194338], "episode_lengths": [100, 100, 54, 100, 100, 100, 100, 100, 100, 19, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.152931325341899, "mean_inference_ms": 2.3722291811777336, "mean_action_processing_ms": 0.2249989798580283, "mean_env_wait_ms": 3.00977597008278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 218.4875881522894, "episode_reward_min": -170.17647764086723, "episode_reward_mean": -104.9829066991806, "episode_len_mean": 89.41666666666667, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-163.60555607825518, -156.57682275772095, 167.93389448523521, -169.0568140000105, -162.2520575746894, -165.49506570398808, -170.17647764086723, -162.3308557420969, -161.8372429832816, 218.4875881522894, -164.90873232483864, -169.97673822194338], "episode_lengths": [100, 100, 54, 100, 100, 100, 100, 100, 100, 19, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.152931325341899, "mean_inference_ms": 2.3722291811777336, "mean_action_processing_ms": 0.2249989798580283, "mean_env_wait_ms": 3.00977597008278, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 78156, "num_agent_steps_trained": 5816064, "num_env_steps_sampled": 78156, "num_env_steps_trained": 5816064, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 78156, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 78156, "timers": {"training_iteration_time_ms": 151.968, "load_time_ms": 0.262, "load_throughput": 977817.889, "learn_time_ms": 24.66, "learn_throughput": 10381.107, "synch_weights_time_ms": 4.957}, "counters": {"num_env_steps_sampled": 78156, "num_env_steps_trained": 5816064, "num_agent_steps_sampled": 78156, "num_agent_steps_trained": 5816064, "last_target_update_ts": 78156, "num_target_updates": 22719}, "done": false, "episodes_total": 807, "training_iteration": 78, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-35-20", "timestamp": 1675953320, "time_this_iter_s": 52.28432488441467, "time_total_s": 3625.9497747421265, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a670>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7a60>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3625.9497747421265, "timesteps_since_restore": 0, "iterations_since_restore": 78, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.680281690140845, "ram_util_percent": 91.58309859154932}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.44777923822402954, "actor_loss": 98.47936248779297, "critic_loss": 1.2056889533996582, "alpha_loss": 1.6964234113693237, "alpha_value": 0.022628920152783394, "log_alpha_value": -3.7885265350341797, "target_entropy": -5.0, "policy_t": -0.37933048605918884, "mean_q": -98.42659759521484, "max_q": -91.68278503417969, "min_q": -102.14861297607422}, "td_error": [96.53260803222656, 0.1884307861328125, 0.4749412536621094, 0.36389923095703125, 0.6966400146484375, 0.48329925537109375, 0.08445358276367188, 0.292938232421875, 345.318359375, 95.65971374511719, 0.6099166870117188, 0.2465667724609375, 0.06504058837890625, 0.037479400634765625, 0.36643218994140625, 0.7245521545410156, 0.9040374755859375, 96.56904602050781, 0.3771171569824219, 0.41213226318359375, 0.5444679260253906, 0.2938728332519531, 0.8302688598632812, 93.92896270751953, 0.14693450927734375, 0.1494598388671875, 0.3057060241699219, 97.55758666992188, 99.388427734375, 0.5158767700195312, 0.530914306640625, 97.07160949707031, 0.22058868408203125, 0.4959907531738281, 0.45774078369140625, 0.11684417724609375, 0.14138031005859375, 98.99189758300781, 0.06719589233398438, 100.23391723632812, 0.16628265380859375, 91.44233703613281, 0.46405792236328125, 98.46582794189453, 0.5827598571777344, 0.07281112670898438, 0.21010589599609375, 0.12184524536132812, 0.2886314392089844, 344.14306640625, 0.0940399169921875, 0.0520477294921875, 0.5904121398925781, 0.28504180908203125, 0.23484039306640625, 0.38836669921875, 0.5231857299804688, 99.06060028076172, 99.28190612792969, 0.5641632080078125, 0.43415069580078125, 0.40969085693359375, 99.85554504394531, 0.5171661376953125, 0.18350601196289062, 0.09581375122070312, 99.1972427368164, 99.84062194824219, 0.1556243896484375, 0.46408843994140625, 0.09708786010742188, 0.14558029174804688, 0.1403961181640625, 0.16472244262695312, 96.80064392089844, 94.64535522460938, 0.370513916015625, 0.22322845458984375, 0.4322662353515625, 0.13084793090820312, 0.6361160278320312, 0.7839927673339844, 95.8167724609375, 0.7082633972167969, 344.1527099609375, 99.4132080078125, 0.16007614135742188, 0.14960098266601562, 0.1741485595703125, 0.35584259033203125, 0.4460601806640625, 0.5647315979003906, 0.28672027587890625, 0.20162582397460938, 0.36661529541015625, 96.47369384765625, 0.469024658203125, 99.77347564697266, 0.3681640625, 95.89737701416016, 0.23173904418945312, 0.32588958740234375, 0.5601730346679688, 0.11631011962890625, 347.4295349121094, 0.09705734252929688, 97.1788330078125, 0.4388847351074219, 0.5506820678710938, 0.5388069152832031, 0.6164665222167969, 0.2694854736328125, 0.5569534301757812, 94.27171325683594, 0.18947601318359375, 0.6963272094726562, 0.5890769958496094, 0.17511749267578125, 0.265472412109375, 0.8633041381835938, 90.66395568847656, 0.041900634765625, 0.23765182495117188, 93.60757446289062, 95.5759506225586, 0.7830848693847656, 99.37895202636719, 0.5839462280273438, 92.11900329589844, 0.209747314453125, 0.17358779907226562, 95.27056121826172, 0.10778045654296875, 0.5596847534179688, 0.8127593994140625, 0.20986175537109375, 99.24276733398438, 97.87942504882812, 92.15637969970703, 0.495391845703125, 90.85989379882812, 0.1016845703125, 0.5920181274414062, 344.03326416015625, 96.65850830078125, 0.24123001098632812, 95.8226089477539, 0.4193878173828125, 0.4083518981933594, 0.14397048950195312, 96.5978012084961, 94.71044158935547, 0.08901214599609375, 0.8331565856933594, 0.55023193359375, 347.9191589355469, 0.27251434326171875, 97.96346282958984, 96.0691909790039, 0.6259651184082031, 0.5641098022460938, 92.58406066894531, 0.17589569091796875, 0.42464447021484375, 0.3362083435058594, 99.08636474609375, 0.8485870361328125, 0.300994873046875, 0.3431396484375, 0.1995697021484375, 0.3578338623046875, 0.3868522644042969, 0.23020553588867188, 0.5815696716308594, 0.11611557006835938, 0.123687744140625, 0.36775970458984375, 0.468719482421875, 0.0564117431640625, 100.24134826660156, 0.6694183349609375, 0.22002029418945312, 97.95500183105469, 0.3265380859375, 94.71556091308594, 0.7625274658203125, 344.5567626953125, 0.47771453857421875, 0.29824066162109375, 0.29486846923828125, 0.2649040222167969, 0.3776588439941406, 0.45172882080078125, 0.37334442138671875, 0.8945121765136719, 96.91739654541016, 0.6416473388671875, 0.8666305541992188, 95.60408020019531, 98.86050415039062, 0.5552787780761719, 99.36184692382812, 1.3048210144042969, 0.6671485900878906, 0.47599029541015625, 0.4165496826171875, 1.0100173950195312, 98.56883239746094, 0.27109527587890625, 96.49212646484375, 0.3444480895996094, 0.29402923583984375, 0.16818618774414062, 0.3685569763183594, 0.27944183349609375, 0.5035057067871094, 0.1457366943359375, 0.33812713623046875, 0.5685844421386719, 0.23987960815429688, 0.45844268798828125, 0.5933647155761719, 0.4909019470214844, 0.4054412841796875, 1.0044631958007812, 0.19415664672851562, 0.24280548095703125, 96.72712707519531, 0.7407455444335938, 98.39717102050781, 0.32970428466796875, 99.41714477539062, 0.43154144287109375, 100.28180694580078, 93.92896270751953, 0.4394378662109375, 98.09263610839844, 344.3267822265625, 0.7413978576660156, 0.5294647216796875, 99.05198669433594, 0.2790184020996094, 0.6834754943847656, 0.5513839721679688, 0.37377166748046875, 0.23026657104492188, 90.83760833740234, 0.4974861145019531, 0.4261322021484375, 0.3427085876464844, 0.6477317810058594, 0.29460906982421875, 0.5698051452636719, 0.4210243225097656, 0.11896896362304688, 0.15073394775390625], "mean_td_error": 33.75336837768555, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 23053.0, "diff_num_grad_updates_vs_sampler_policy": 23052.0}}, "num_env_steps_sampled": 79158, "num_env_steps_trained": 5901568, "num_agent_steps_sampled": 79158, "num_agent_steps_trained": 5901568, "last_target_update_ts": 79158, "num_target_updates": 23053}, "sampler_results": {"episode_reward_max": 236.46240736544132, "episode_reward_min": -167.6678908020258, "episode_reward_mean": -119.44905663728714, "episode_len_mean": 90.8, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-155.22694990038872, -148.03948517143726, -167.6678908020258, -155.15678357332945, -165.17036618292332, -160.64602085202932, -150.88469261676073, -160.58221770077944, 236.46240736544132, -167.5785669386387], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 8, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1416198350112192, "mean_inference_ms": 2.3564032897142537, "mean_action_processing_ms": 0.22313536539423637, "mean_env_wait_ms": 2.986136513552914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 236.46240736544132, "episode_reward_min": -167.6678908020258, "episode_reward_mean": -119.44905663728714, "episode_len_mean": 90.8, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-155.22694990038872, -148.03948517143726, -167.6678908020258, -155.15678357332945, -165.17036618292332, -160.64602085202932, -150.88469261676073, -160.58221770077944, 236.46240736544132, -167.5785669386387], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 8, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1416198350112192, "mean_inference_ms": 2.3564032897142537, "mean_action_processing_ms": 0.22313536539423637, "mean_env_wait_ms": 2.986136513552914, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 79158, "num_agent_steps_trained": 5901568, "num_env_steps_sampled": 79158, "num_env_steps_trained": 5901568, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 79158, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 79158, "timers": {"training_iteration_time_ms": 169.556, "load_time_ms": 0.284, "load_throughput": 901697.87, "learn_time_ms": 27.936, "learn_throughput": 9163.895, "synch_weights_time_ms": 5.953}, "counters": {"num_env_steps_sampled": 79158, "num_env_steps_trained": 5901568, "num_agent_steps_sampled": 79158, "num_agent_steps_trained": 5901568, "last_target_update_ts": 79158, "num_target_updates": 23053}, "done": false, "episodes_total": 817, "training_iteration": 79, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-36-12", "timestamp": 1675953372, "time_this_iter_s": 51.4840521812439, "time_total_s": 3677.4338269233704, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb040>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f70d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3677.4338269233704, "timesteps_since_restore": 0, "iterations_since_restore": 79, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.80704225352113, "ram_util_percent": 91.643661971831}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.047608986496925354, "actor_loss": 98.98199462890625, "critic_loss": 1.1853315830230713, "alpha_loss": -0.17958548665046692, "alpha_value": 0.023003842681646347, "log_alpha_value": -3.7720940113067627, "target_entropy": -5.0, "policy_t": -0.3987501263618469, "mean_q": -98.89024353027344, "max_q": -92.47525024414062, "min_q": -103.37662506103516}, "td_error": [100.61776733398438, 0.6067428588867188, 92.21299743652344, 100.06156921386719, 0.306793212890625, 341.37396240234375, 98.01605224609375, 0.4301109313964844, 0.1598968505859375, 0.3194007873535156, 0.5207405090332031, 0.14131546020507812, 0.2297210693359375, 0.0829925537109375, 98.85159301757812, 92.89603424072266, 0.2592010498046875, 0.25234222412109375, 0.17293548583984375, 0.04944610595703125, 0.3309288024902344, 0.6821136474609375, 0.5091781616210938, 93.18582153320312, 0.1744537353515625, 0.5213661193847656, 0.5014076232910156, 0.33789825439453125, 0.23430252075195312, 0.15201950073242188, 99.81301879882812, 0.229736328125, 0.9832382202148438, 100.76606750488281, 0.5268783569335938, 0.475738525390625, 98.614501953125, 91.19007873535156, 0.434844970703125, 0.7021713256835938, 0.3398284912109375, 0.20267105102539062, 0.8997802734375, 0.5676727294921875, 97.53509521484375, 0.08764266967773438, 94.86200714111328, 97.51893615722656, 0.5628738403320312, 0.6509552001953125, 93.7373046875, 0.5408134460449219, 0.025058746337890625, 0.042736053466796875, 99.52745056152344, 93.8274917602539, 97.85087585449219, 93.7385025024414, 99.00310516357422, 0.074798583984375, 95.6419677734375, 0.08223342895507812, 0.18878173828125, 0.117431640625, 0.5291671752929688, 0.6769485473632812, 0.24451446533203125, 98.1771240234375, 95.95963287353516, 93.64982604980469, 0.6793251037597656, 0.33623504638671875, 0.36371612548828125, 0.3481254577636719, 0.25272369384765625, 98.30302429199219, 0.39910125732421875, 98.9421157836914, 0.76690673828125, 0.5694160461425781, 0.2760200500488281, 0.5053825378417969, 0.191131591796875, 0.6354293823242188, 0.2034454345703125, 0.51531982421875, 0.457977294921875, 99.37155151367188, 0.16781234741210938, 0.02944183349609375, 0.0663299560546875, 0.047119140625, 93.87870788574219, 96.33656311035156, 0.15151214599609375, 98.9053955078125, 99.7923583984375, 0.5582275390625, 0.27141571044921875, 96.2645263671875, 0.023120880126953125, 0.49155426025390625, 0.38787841796875, 0.17172622680664062, 0.523468017578125, 97.73597717285156, 0.4886932373046875, 0.4769744873046875, 0.121368408203125, 93.76963806152344, 0.24188232421875, 0.5784759521484375, 0.16522598266601562, 0.5715370178222656, 98.10783386230469, 0.423614501953125, 91.41976165771484, 0.10712432861328125, 0.2598609924316406, 0.8469924926757812, 0.3386993408203125, 0.7670516967773438, 0.18526458740234375, 0.38962554931640625, 98.48628234863281, 0.08624267578125, 96.40414428710938, 0.26483154296875, 0.30438232421875, 0.2849769592285156, 0.2121734619140625, 99.01880645751953, 0.27207183837890625, 0.2283477783203125, 345.07501220703125, 0.6974983215332031, 0.6865501403808594, 0.09958648681640625, 0.6365814208984375, 95.7479248046875, 0.6615409851074219, 0.26132965087890625, 96.47649383544922, 1.3081550598144531, 0.5581321716308594, 0.4822235107421875, 93.7385025024414, 0.16349029541015625, 99.96455383300781, 100.52754211425781, 0.42082977294921875, 96.86141967773438, 0.6316261291503906, 0.237945556640625, 0.2969512939453125, 0.49925994873046875, 0.5932502746582031, 0.5723800659179688, 0.7531280517578125, 0.6773414611816406, 0.660064697265625, 0.1396636962890625, 0.40720367431640625, 0.2710075378417969, 0.4267005920410156, 97.27729797363281, 0.7529945373535156, 99.76869201660156, 0.42742156982421875, 0.03592681884765625, 94.36323547363281, 342.7087707519531, 0.3511695861816406, 0.0155487060546875, 98.86183166503906, 0.2887001037597656, 0.037487030029296875, 0.12090682983398438, 0.22257614135742188, 0.34975433349609375, 0.5519485473632812, 0.24591445922851562, 0.3882904052734375, 0.185943603515625, 0.3655967712402344, 92.12141418457031, 0.47231292724609375, 346.8226318359375, 91.48179626464844, 100.57926940917969, 0.45116424560546875, 0.31585693359375, 0.27771759033203125, 0.37425994873046875, 0.3337211608886719, 0.11269378662109375, 0.033203125, 100.40826416015625, 0.2788238525390625, 0.2751007080078125, 0.29085540771484375, 0.6798591613769531, 341.96051025390625, 0.5597305297851562, 0.33880615234375, 0.5457954406738281, 92.52613830566406, 0.0216064453125, 0.27930450439453125, 99.9488525390625, 98.48040771484375, 0.5391693115234375, 0.12378311157226562, 0.6439704895019531, 0.4644508361816406, 0.06943511962890625, 0.030300140380859375, 0.3826751708984375, 0.19025802612304688, 92.78166961669922, 0.24827194213867188, 94.964111328125, 0.2813224792480469, 0.2350006103515625, 0.5230560302734375, 0.10129928588867188, 0.537322998046875, 0.5742378234863281, 0.17538833618164062, 99.98056030273438, 0.1907958984375, 0.5297660827636719, 0.50689697265625, 0.15936279296875, 0.7340354919433594, 99.59362030029297, 0.6688880920410156, 1.0285911560058594, 0.5397567749023438, 0.8638114929199219, 344.8255920410156, 0.1979827880859375, 98.47174072265625, 0.4719429016113281, 0.13194656372070312, 0.09595108032226562, 93.45013427734375, 0.3599357604980469, 0.38231658935546875, 0.5181159973144531, 0.04424285888671875, 92.21299743652344, 0.30948638916015625, 0.44844818115234375, 0.5101966857910156, 101.06808471679688], "mean_td_error": 32.52936553955078, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 23387.0, "diff_num_grad_updates_vs_sampler_policy": 23386.0}}, "num_env_steps_sampled": 80160, "num_env_steps_trained": 5987072, "num_agent_steps_sampled": 80160, "num_agent_steps_trained": 5987072, "last_target_update_ts": 80160, "num_target_updates": 23387}, "sampler_results": {"episode_reward_max": 202.65034437179565, "episode_reward_min": -171.65506206452847, "episode_reward_mean": -72.34385556727648, "episode_len_mean": 87.9090909090909, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-157.27118510007858, -157.589127920568, 185.27401945739985, 105.5456792935729, -160.14251535385847, -150.72022999078035, -162.02908248454332, -167.57097980380058, -162.2742716446519, -171.65506206452847, 202.65034437179565], "episode_lengths": [100, 100, 41, 91, 100, 100, 100, 100, 100, 100, 35]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.153527292950288, "mean_inference_ms": 2.3734114411963905, "mean_action_processing_ms": 0.22518350289518166, "mean_env_wait_ms": 3.001164451690306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 202.65034437179565, "episode_reward_min": -171.65506206452847, "episode_reward_mean": -72.34385556727648, "episode_len_mean": 87.9090909090909, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-157.27118510007858, -157.589127920568, 185.27401945739985, 105.5456792935729, -160.14251535385847, -150.72022999078035, -162.02908248454332, -167.57097980380058, -162.2742716446519, -171.65506206452847, 202.65034437179565], "episode_lengths": [100, 100, 41, 91, 100, 100, 100, 100, 100, 100, 35]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.153527292950288, "mean_inference_ms": 2.3734114411963905, "mean_action_processing_ms": 0.22518350289518166, "mean_env_wait_ms": 3.001164451690306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 80160, "num_agent_steps_trained": 5987072, "num_env_steps_sampled": 80160, "num_env_steps_trained": 5987072, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 80160, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 80160, "timers": {"training_iteration_time_ms": 149.957, "load_time_ms": 0.254, "load_throughput": 1007262.499, "learn_time_ms": 24.679, "learn_throughput": 10373.225, "synch_weights_time_ms": 5.078}, "counters": {"num_env_steps_sampled": 80160, "num_env_steps_trained": 5987072, "num_agent_steps_sampled": 80160, "num_agent_steps_trained": 5987072, "last_target_update_ts": 80160, "num_target_updates": 23387}, "done": false, "episodes_total": 828, "training_iteration": 80, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-37-05", "timestamp": 1675953425, "time_this_iter_s": 53.07296299934387, "time_total_s": 3730.5067899227142, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2190>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d040>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3730.5067899227142, "timesteps_since_restore": 0, "iterations_since_restore": 80, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.76111111111111, "ram_util_percent": 92.28888888888888}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.08582058548927307, "actor_loss": 100.15047454833984, "critic_loss": 1.1812317371368408, "alpha_loss": -0.32754653692245483, "alpha_value": 0.02200157754123211, "log_alpha_value": -3.816641092300415, "target_entropy": -5.0, "policy_t": -0.39133399724960327, "mean_q": -100.04830932617188, "max_q": -92.80242919921875, "min_q": -105.61495971679688}, "td_error": [342.80902099609375, 100.70887756347656, 0.38105010986328125, 0.42560577392578125, 0.163787841796875, 94.71464538574219, 95.72157287597656, 0.09405899047851562, 0.3293418884277344, 0.3186607360839844, 0.22357940673828125, 97.77306365966797, 98.43877410888672, 0.4762458801269531, 0.3056068420410156, 98.43877410888672, 0.9596061706542969, 0.12443161010742188, 0.14974212646484375, 0.23785781860351562, 101.19529724121094, 1.0084953308105469, 0.8886299133300781, 0.009860992431640625, 0.505462646484375, 97.62217712402344, 0.3819618225097656, 344.98199462890625, 0.0987548828125, 96.86705017089844, 0.23211669921875, 0.03035736083984375, 0.5539093017578125, 0.4013481140136719, 0.878326416015625, 0.17734909057617188, 0.7115821838378906, 0.2844886779785156, 0.12618255615234375, 0.08478546142578125, 0.2692108154296875, 101.49102783203125, 0.3144340515136719, 0.6374168395996094, 0.7176895141601562, 0.4883842468261719, 0.4076118469238281, 97.13084411621094, 0.1605377197265625, 1.028717041015625, 341.7434997558594, 98.83344268798828, 0.70501708984375, 0.3257865905761719, 0.2848854064941406, 0.071197509765625, 0.14820480346679688, 0.5889930725097656, 0.0693206787109375, 0.2710723876953125, 0.383270263671875, 1.3118209838867188, 0.4304389953613281, 0.2856483459472656, 96.03742980957031, 97.64347076416016, 0.4247627258300781, 99.77098083496094, 95.25759887695312, 0.3681221008300781, 94.07246398925781, 92.22083282470703, 0.029750823974609375, 98.351806640625, 0.5021400451660156, 0.16472625732421875, 346.365478515625, 98.53174591064453, 0.5652923583984375, 97.88585662841797, 0.41094207763671875, 98.64164733886719, 0.50762939453125, 0.38054656982421875, 0.6039962768554688, 0.2616691589355469, 0.13378143310546875, 0.33808135986328125, 349.745849609375, 99.96174621582031, 0.454742431640625, 0.8631362915039062, 0.428619384765625, 0.47174072265625, 0.38295745849609375, 101.66260528564453, 0.25428009033203125, 0.068878173828125, 0.1554718017578125, 0.28502655029296875, 0.1797943115234375, 0.17603302001953125, 0.08354949951171875, 0.4017143249511719, 94.01102447509766, 0.2891731262207031, 0.5721817016601562, 0.53631591796875, 0.8789939880371094, 0.5346641540527344, 0.52392578125, 92.03292846679688, 0.6180381774902344, 0.4893226623535156, 102.24400329589844, 0.4115257263183594, 0.10669326782226562, 0.083831787109375, 94.37752532958984, 0.025577545166015625, 0.21446609497070312, 0.6377487182617188, 0.24306869506835938, 98.97142028808594, 99.95733642578125, 346.2708435058594, 0.25406646728515625, 0.22914886474609375, 102.4271240234375, 102.12965393066406, 98.65264892578125, 101.7791519165039, 0.09160232543945312, 0.6821861267089844, 0.43599700927734375, 98.29914093017578, 94.20304870605469, 0.2795562744140625, 1.0276031494140625, 0.369415283203125, 0.3895072937011719, 0.1629486083984375, 100.94755554199219, 95.15618896484375, 0.7773323059082031, 0.4972953796386719, 98.7967529296875, 0.2858848571777344, 0.25550079345703125, 0.4944915771484375, 0.4472541809082031, 0.15183639526367188, 0.4814262390136719, 0.3579292297363281, 0.47251129150390625, 101.46342468261719, 100.54322814941406, 0.3245048522949219, 0.5414695739746094, 98.96504974365234, 0.21392822265625, 0.048671722412109375, 0.9539794921875, 0.2978935241699219, 344.1754455566406, 0.4932670593261719, 0.16352081298828125, 0.09853363037109375, 0.293609619140625, 102.06451416015625, 346.51446533203125, 0.5698585510253906, 0.30068206787109375, 0.16958999633789062, 96.24241638183594, 0.4243927001953125, 0.5211257934570312, 93.83109283447266, 0.687713623046875, 0.27411651611328125, 0.6029396057128906, 0.2816123962402344, 0.2549171447753906, 0.39898681640625, 0.1260528564453125, 0.2037811279296875, 0.2514457702636719, 0.3620452880859375, 99.9874496459961, 0.48651123046875, 0.2771415710449219, 0.108917236328125, 0.2657928466796875, 0.4687767028808594, 0.174346923828125, 0.06229400634765625, 0.5817184448242188, 0.1645355224609375, 0.4285087585449219, 1.2167472839355469, 0.6976203918457031, 0.54803466796875, 99.3912353515625, 0.66583251953125, 0.3192901611328125, 0.6800346374511719, 0.839111328125, 0.8071823120117188, 0.2386474609375, 0.30611419677734375, 0.6334075927734375, 0.56097412109375, 0.8170433044433594, 0.4331703186035156, 0.19203948974609375, 0.13967132568359375, 0.11895751953125, 0.48961639404296875, 0.3471946716308594, 0.070159912109375, 0.17062759399414062, 102.157958984375, 0.18548202514648438, 0.187652587890625, 0.3804168701171875, 0.5892181396484375, 0.200775146484375, 99.21788787841797, 0.05340576171875, 0.4316558837890625, 102.18228912353516, 0.112396240234375, 0.36370849609375, 0.7749366760253906, 0.10872268676757812, 0.3633613586425781, 0.12279510498046875, 0.6371994018554688, 0.3931617736816406, 97.78959655761719, 0.5418968200683594, 348.81427001953125, 98.2868423461914, 0.8362388610839844, 0.5285415649414062, 0.2790870666503906, 0.23011398315429688, 0.41799163818359375, 0.3167572021484375, 97.77306365966797, 0.11797714233398438, 98.97142028808594, 94.58968353271484, 0.09010696411132812, 0.40225982666015625, 0.2623405456542969], "mean_td_error": 33.560951232910156, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 23721.0, "diff_num_grad_updates_vs_sampler_policy": 23720.0}}, "num_env_steps_sampled": 81162, "num_env_steps_trained": 6072576, "num_agent_steps_sampled": 81162, "num_agent_steps_trained": 6072576, "last_target_update_ts": 81162, "num_target_updates": 23721}, "sampler_results": {"episode_reward_max": -154.69595033675432, "episode_reward_min": -169.51182003319263, "episode_reward_mean": -163.94407005201685, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-154.69595033675432, -167.14128770679235, -158.10850709676743, -163.40271547436714, -169.51182003319263, -165.15099102258682, -164.1226975172758, -167.97480914741755, -168.13703125715256, -158.33018220961094, -166.80877877026796], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1417591448234448, "mean_inference_ms": 2.357316551901309, "mean_action_processing_ms": 0.22299008308480256, "mean_env_wait_ms": 2.9778798295714495, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -154.69595033675432, "episode_reward_min": -169.51182003319263, "episode_reward_mean": -163.94407005201685, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-154.69595033675432, -167.14128770679235, -158.10850709676743, -163.40271547436714, -169.51182003319263, -165.15099102258682, -164.1226975172758, -167.97480914741755, -168.13703125715256, -158.33018220961094, -166.80877877026796], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1417591448234448, "mean_inference_ms": 2.357316551901309, "mean_action_processing_ms": 0.22299008308480256, "mean_env_wait_ms": 2.9778798295714495, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 81162, "num_agent_steps_trained": 6072576, "num_env_steps_sampled": 81162, "num_env_steps_trained": 6072576, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 81162, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 81162, "timers": {"training_iteration_time_ms": 155.935, "load_time_ms": 0.316, "load_throughput": 809088.858, "learn_time_ms": 25.369, "learn_throughput": 10091.075, "synch_weights_time_ms": 5.795}, "counters": {"num_env_steps_sampled": 81162, "num_env_steps_trained": 6072576, "num_agent_steps_sampled": 81162, "num_agent_steps_trained": 6072576, "last_target_update_ts": 81162, "num_target_updates": 23721}, "done": false, "episodes_total": 839, "training_iteration": 81, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-38-00", "timestamp": 1675953480, "time_this_iter_s": 54.99451732635498, "time_total_s": 3785.501307249069, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb3d0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d550>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3785.501307249069, "timesteps_since_restore": 0, "iterations_since_restore": 81, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 42.6671052631579, "ram_util_percent": 92.41578947368421}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.014236725866794586, "actor_loss": 101.21610260009766, "critic_loss": 1.0526584386825562, "alpha_loss": 0.05469599366188049, "alpha_value": 0.02145281434059143, "log_alpha_value": -3.8418993949890137, "target_entropy": -5.0, "policy_t": -0.3868815004825592, "mean_q": -101.20104217529297, "max_q": -94.16169738769531, "min_q": -105.92694091796875}, "td_error": [101.80321502685547, 0.189727783203125, 0.123443603515625, 0.5744590759277344, 100.55180358886719, 0.4427375793457031, 0.48024749755859375, 0.063873291015625, 102.49362182617188, 0.6351699829101562, 345.4388122558594, 0.34122467041015625, 0.09048843383789062, 0.17458724975585938, 98.18543243408203, 0.16629791259765625, 0.8129425048828125, 0.6425895690917969, 0.5211982727050781, 0.081573486328125, 98.58213806152344, 102.1829833984375, 0.24306488037109375, 0.4029884338378906, 0.5267562866210938, 0.2961692810058594, 0.7933692932128906, 347.35498046875, 0.8268089294433594, 101.93378448486328, 0.3740425109863281, 0.26299285888671875, 100.7892837524414, 0.5081443786621094, 0.6473503112792969, 100.24281311035156, 0.15999221801757812, 0.9322357177734375, 0.6412582397460938, 349.4021301269531, 0.5042495727539062, 103.45126342773438, 0.5414390563964844, 0.8629989624023438, 96.56340026855469, 0.2864837646484375, 0.37845611572265625, 0.1925201416015625, 0.6700897216796875, 100.13513946533203, 0.49018096923828125, 0.07616043090820312, 0.9624595642089844, 0.19185256958007812, 98.43377685546875, 0.35536956787109375, 0.123748779296875, 0.22047042846679688, 102.48149108886719, 99.09581756591797, 0.2236328125, 97.56001281738281, 0.6394920349121094, 102.16053009033203, 0.46844482421875, 0.10171127319335938, 0.3869361877441406, 0.16067123413085938, 0.227996826171875, 0.2088775634765625, 0.9458885192871094, 0.21471023559570312, 99.48648071289062, 0.47814178466796875, 0.1206512451171875, 0.24921798706054688, 0.17494583129882812, 0.08815765380859375, 102.2672119140625, 0.10321044921875, 0.9888954162597656, 0.49267578125, 0.216400146484375, 0.344818115234375, 0.25353240966796875, 0.23787689208984375, 0.5820846557617188, 0.3493537902832031, 0.4689788818359375, 0.5821304321289062, 0.19759750366210938, 0.29351043701171875, 0.263519287109375, 99.45862579345703, 0.6551704406738281, 0.21175384521484375, 0.47765350341796875, 0.3004951477050781, 0.4556732177734375, 101.64967346191406, 0.06995773315429688, 0.3574066162109375, 0.046154022216796875, 0.6276969909667969, 0.4755592346191406, 0.1484222412109375, 0.09411239624023438, 0.4051704406738281, 0.33106231689453125, 0.11451339721679688, 343.05810546875, 98.39230346679688, 0.4310646057128906, 0.8683853149414062, 0.24811553955078125, 0.24594879150390625, 0.31676483154296875, 0.5894546508789062, 0.5396270751953125, 0.3829193115234375, 99.48866271972656, 0.10410690307617188, 0.3147773742675781, 0.490570068359375, 0.550811767578125, 99.54519653320312, 0.21479034423828125, 103.71682739257812, 0.23096466064453125, 0.8323593139648438, 0.1562957763671875, 0.7109451293945312, 0.7177734375, 97.34500122070312, 0.13658905029296875, 0.4261627197265625, 95.40814971923828, 100.84614562988281, 0.750640869140625, 0.84539794921875, 0.16407012939453125, 95.42720794677734, 0.17566680908203125, 0.266693115234375, 348.34619140625, 99.66602325439453, 0.8150405883789062, 0.5369720458984375, 0.42378997802734375, 0.34371185302734375, 0.9187812805175781, 0.4574775695800781, 0.6298866271972656, 94.72013854980469, 0.4172935485839844, 96.39617919921875, 0.053676605224609375, 0.37718963623046875, 0.5550003051757812, 0.4858589172363281, 0.3172874450683594, 98.85317993164062, 0.19266891479492188, 0.0646209716796875, 0.5332450866699219, 0.4510498046875, 0.18603515625, 0.1732635498046875, 0.12930679321289062, 0.14621353149414062, 0.2659454345703125, 0.45978546142578125, 0.7052993774414062, 0.8609657287597656, 0.5365943908691406, 0.28774261474609375, 99.482421875, 100.21524810791016, 0.18682479858398438, 0.5369720458984375, 0.1729583740234375, 0.25909423828125, 0.22531890869140625, 0.2447052001953125, 0.20654678344726562, 0.28246307373046875, 0.4771690368652344, 0.729156494140625, 0.0761566162109375, 0.4923744201660156, 0.382537841796875, 98.39230346679688, 1.4711837768554688, 102.73947143554688, 0.45664215087890625, 0.17723846435546875, 0.5470466613769531, 0.3215980529785156, 0.07613372802734375, 0.17453765869140625, 1.0853347778320312, 0.4239654541015625, 0.12286376953125, 95.40455627441406, 103.60960388183594, 0.162689208984375, 0.8566970825195312, 0.10428237915039062, 0.5184707641601562, 0.7979393005371094, 102.10166931152344, 0.09027099609375, 0.22031021118164062, 0.08198165893554688, 0.21105194091796875, 0.06810379028320312, 96.77442932128906, 0.156890869140625, 0.4214286804199219, 97.87882995605469, 98.99068450927734, 101.32548522949219, 0.055271148681640625, 0.6732254028320312, 0.09924697875976562, 0.5763626098632812, 349.27276611328125, 0.280517578125, 0.4448127746582031, 95.62394714355469, 95.60008239746094, 0.7654304504394531, 0.4849128723144531, 97.67971801757812, 0.18561172485351562, 0.6378822326660156, 0.5167350769042969, 98.91464233398438, 0.2726249694824219, 0.1713104248046875, 0.8060646057128906, 0.3479347229003906, 0.140594482421875, 0.55224609375, 99.03836059570312, 0.6974563598632812, 102.75694274902344, 0.4793586730957031, 0.49628448486328125, 0.208953857421875, 95.39273071289062, 0.7605400085449219, 0.4101104736328125, 350.97882080078125, 0.4284324645996094, 0.6951942443847656], "mean_td_error": 29.624122619628906, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 24055.0, "diff_num_grad_updates_vs_sampler_policy": 24054.0}}, "num_env_steps_sampled": 82164, "num_env_steps_trained": 6158080, "num_agent_steps_sampled": 82164, "num_agent_steps_trained": 6158080, "last_target_update_ts": 82164, "num_target_updates": 24055}, "sampler_results": {"episode_reward_max": -157.24960503727198, "episode_reward_min": -173.6255514100194, "episode_reward_mean": -166.47019824162126, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-170.27957665920258, -157.24960503727198, -163.69376994669437, -164.1087070927024, -172.31269567459822, -170.56378097832203, -173.6255514100194, -164.81482111662626, -162.75537701696157, -165.29809748381376], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1648231139557876, "mean_inference_ms": 2.3901475864727812, "mean_action_processing_ms": 0.22689543721309308, "mean_env_wait_ms": 3.01333411708145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -157.24960503727198, "episode_reward_min": -173.6255514100194, "episode_reward_mean": -166.47019824162126, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-170.27957665920258, -157.24960503727198, -163.69376994669437, -164.1087070927024, -172.31269567459822, -170.56378097832203, -173.6255514100194, -164.81482111662626, -162.75537701696157, -165.29809748381376], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1648231139557876, "mean_inference_ms": 2.3901475864727812, "mean_action_processing_ms": 0.22689543721309308, "mean_env_wait_ms": 3.01333411708145, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 82164, "num_agent_steps_trained": 6158080, "num_env_steps_sampled": 82164, "num_env_steps_trained": 6158080, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 82164, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 82164, "timers": {"training_iteration_time_ms": 168.648, "load_time_ms": 0.272, "load_throughput": 940476.328, "learn_time_ms": 25.446, "learn_throughput": 10060.582, "synch_weights_time_ms": 6.031}, "counters": {"num_env_steps_sampled": 82164, "num_env_steps_trained": 6158080, "num_agent_steps_sampled": 82164, "num_agent_steps_trained": 6158080, "last_target_update_ts": 82164, "num_target_updates": 24055}, "done": false, "episodes_total": 849, "training_iteration": 82, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-38-53", "timestamp": 1675953533, "time_this_iter_s": 52.590951442718506, "time_total_s": 3838.0922586917877, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b21c0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d790>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3838.0922586917877, "timesteps_since_restore": 0, "iterations_since_restore": 82, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.136986301369866, "ram_util_percent": 92.25342465753424}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1530074179172516, "actor_loss": 102.5192642211914, "critic_loss": 1.2767083644866943, "alpha_loss": 0.583731472492218, "alpha_value": 0.02203655242919922, "log_alpha_value": -3.8150527477264404, "target_entropy": -5.0, "policy_t": -0.31692296266555786, "mean_q": -102.44109344482422, "max_q": -95.09034729003906, "min_q": -106.87648010253906}, "td_error": [0.12642288208007812, 104.27212524414062, 0.5874710083007812, 0.3566627502441406, 0.4134483337402344, 1.1515007019042969, 104.27212524414062, 101.57254028320312, 0.48064422607421875, 0.686431884765625, 104.29778289794922, 0.1765289306640625, 0.48491668701171875, 0.4401512145996094, 0.4930229187011719, 0.5576896667480469, 0.119354248046875, 0.7127227783203125, 0.2549095153808594, 0.2783317565917969, 0.8577117919921875, 99.99197387695312, 0.6806449890136719, 0.4958953857421875, 0.7764511108398438, 0.5040054321289062, 1.0092086791992188, 103.35759735107422, 99.31261444091797, 0.353271484375, 0.34461212158203125, 0.9450569152832031, 94.67517852783203, 95.95060729980469, 0.19170761108398438, 0.23038864135742188, 0.30271148681640625, 0.2622947692871094, 97.3301010131836, 0.15752410888671875, 0.52178955078125, 0.5667724609375, 104.29778289794922, 0.39524078369140625, 0.5573196411132812, 0.4084205627441406, 0.532318115234375, 0.4281158447265625, 0.4473724365234375, 0.23714828491210938, 103.77535247802734, 0.22107315063476562, 0.14043426513671875, 103.79071044921875, 0.174102783203125, 0.8258514404296875, 0.16467666625976562, 0.0982818603515625, 103.85973358154297, 0.047153472900390625, 0.1922760009765625, 0.6101150512695312, 0.23989105224609375, 0.1805877685546875, 100.81682586669922, 94.71451568603516, 0.16085433959960938, 0.414215087890625, 0.5598793029785156, 97.44520568847656, 105.23200988769531, 0.0363922119140625, 0.170074462890625, 0.25705718994140625, 0.37924957275390625, 0.6106643676757812, 0.09637451171875, 0.2498779296875, 0.7579841613769531, 0.6554985046386719, 0.1700897216796875, 0.12137222290039062, 0.3104820251464844, 94.452392578125, 0.32271575927734375, 97.6212158203125, 0.53521728515625, 0.07040786743164062, 0.7761955261230469, 348.0748596191406, 104.66583251953125, 0.46167755126953125, 0.0990447998046875, 0.5105972290039062, 102.76611328125, 0.11265182495117188, 102.17828369140625, 0.31075286865234375, 0.19957351684570312, 101.78334045410156, 0.14418792724609375, 102.88774871826172, 101.09355163574219, 104.11151123046875, 0.11856842041015625, 0.10400772094726562, 0.5456962585449219, 0.19019699096679688, 0.49335479736328125, 0.5178947448730469, 0.165252685546875, 0.8379783630371094, 0.2587318420410156, 0.45316314697265625, 0.1509246826171875, 0.7393913269042969, 0.5586891174316406, 100.42325592041016, 0.49381256103515625, 0.27292633056640625, 100.08720397949219, 0.5962677001953125, 104.50359344482422, 103.77272033691406, 97.29585266113281, 0.14783096313476562, 0.0938873291015625, 0.22014617919921875, 0.6342811584472656, 0.024524688720703125, 0.6852493286132812, 0.37310028076171875, 100.5614242553711, 0.192108154296875, 1.1474151611328125, 101.05439758300781, 0.049411773681640625, 347.1025390625, 0.14455795288085938, 99.01445007324219, 104.0223617553711, 0.06465911865234375, 0.3270835876464844, 0.3840484619140625, 102.39334106445312, 103.45551300048828, 0.23757553100585938, 0.26299285888671875, 104.18461608886719, 0.44499969482421875, 0.09740066528320312, 0.3900947570800781, 0.73870849609375, 0.3386573791503906, 0.3285064697265625, 0.14259719848632812, 0.130859375, 0.460723876953125, 0.38964080810546875, 0.48062896728515625, 0.5427513122558594, 0.5372886657714844, 0.27965545654296875, 99.56363677978516, 0.38784027099609375, 0.3405494689941406, 0.3267936706542969, 0.1399688720703125, 0.2532234191894531, 97.30168914794922, 0.7370796203613281, 98.23724365234375, 0.2971992492675781, 0.47530364990234375, 0.718505859375, 0.223541259765625, 0.047451019287109375, 97.06459045410156, 0.609100341796875, 103.36935424804688, 0.3876304626464844, 0.28446197509765625, 0.17618942260742188, 0.14086151123046875, 348.7504577636719, 0.35393524169921875, 101.36622619628906, 0.6705207824707031, 0.026035308837890625, 0.23484420776367188, 95.48768615722656, 0.199859619140625, 0.594512939453125, 0.40372467041015625, 0.06679534912109375, 0.31072998046875, 0.27910614013671875, 102.2176742553711, 0.4742546081542969, 103.41729736328125, 0.6162796020507812, 0.4935760498046875, 0.36983489990234375, 101.49272918701172, 0.576385498046875, 0.8209381103515625, 0.10271453857421875, 344.7861328125, 0.7581863403320312, 0.2868499755859375, 0.4161376953125, 0.3734703063964844, 0.6552047729492188, 0.17060470581054688, 103.67839813232422, 102.4647216796875, 0.6194381713867188, 95.80545043945312, 0.5237274169921875, 0.2038116455078125, 100.10916900634766, 0.4618644714355469, 100.26499938964844, 0.8030815124511719, 0.3193321228027344, 0.05255126953125, 0.23193740844726562, 0.3371734619140625, 0.30971527099609375, 347.6905517578125, 349.80548095703125, 0.3930625915527344, 0.23456192016601562, 0.07268142700195312, 0.15372467041015625, 0.5122413635253906, 0.36421966552734375, 0.2885017395019531, 97.82875061035156, 0.1637725830078125, 344.7861328125, 0.7828445434570312, 0.3136100769042969, 0.7069053649902344, 0.35190582275390625, 103.69390869140625, 0.0821380615234375, 101.50679779052734, 0.3348197937011719, 99.16526794433594, 0.5941085815429688, 345.672119140625, 101.64511108398438, 103.64137268066406, 348.39471435546875, 0.5452117919921875], "mean_td_error": 36.159912109375, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 24389.0, "diff_num_grad_updates_vs_sampler_policy": 24388.0}}, "num_env_steps_sampled": 83166, "num_env_steps_trained": 6243584, "num_agent_steps_sampled": 83166, "num_agent_steps_trained": 6243584, "last_target_update_ts": 83166, "num_target_updates": 24389}, "sampler_results": {"episode_reward_max": -155.88041848689318, "episode_reward_min": -182.67987783253193, "episode_reward_mean": -167.41055427657233, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-167.6507991850376, -164.94820032268763, -167.69518004357815, -155.88041848689318, -161.4360726773739, -161.96245819330215, -182.67987783253193, -166.42907927930355, -178.01290246844292], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1521882233077718, "mean_inference_ms": 2.3723068846645345, "mean_action_processing_ms": 0.2247445888845171, "mean_env_wait_ms": 2.9907422299139625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -155.88041848689318, "episode_reward_min": -182.67987783253193, "episode_reward_mean": -167.41055427657233, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-167.6507991850376, -164.94820032268763, -167.69518004357815, -155.88041848689318, -161.4360726773739, -161.96245819330215, -182.67987783253193, -166.42907927930355, -178.01290246844292], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1521882233077718, "mean_inference_ms": 2.3723068846645345, "mean_action_processing_ms": 0.2247445888845171, "mean_env_wait_ms": 2.9907422299139625, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 83166, "num_agent_steps_trained": 6243584, "num_env_steps_sampled": 83166, "num_env_steps_trained": 6243584, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 83166, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 83166, "timers": {"training_iteration_time_ms": 151.715, "load_time_ms": 0.27, "load_throughput": 946611.852, "learn_time_ms": 24.818, "learn_throughput": 10315.028, "synch_weights_time_ms": 5.501}, "counters": {"num_env_steps_sampled": 83166, "num_env_steps_trained": 6243584, "num_agent_steps_sampled": 83166, "num_agent_steps_trained": 6243584, "last_target_update_ts": 83166, "num_target_updates": 24389}, "done": false, "episodes_total": 858, "training_iteration": 83, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-39-45", "timestamp": 1675953585, "time_this_iter_s": 51.881720304489136, "time_total_s": 3889.973978996277, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e37c0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d9d0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3889.973978996277, "timesteps_since_restore": 0, "iterations_since_restore": 83, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.653521126760566, "ram_util_percent": 92.30985915492958}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.254554808139801, "actor_loss": 103.06108093261719, "critic_loss": 1.3281937837600708, "alpha_loss": 0.9535560607910156, "alpha_value": 0.02361259050667286, "log_alpha_value": -3.7459752559661865, "target_entropy": -5.0, "policy_t": -0.34600362181663513, "mean_q": -102.9051513671875, "max_q": -95.58820343017578, "min_q": -107.73149108886719}, "td_error": [0.613983154296875, 0.2833061218261719, 0.185638427734375, 102.90489196777344, 103.05119323730469, 0.30425262451171875, 105.37462615966797, 101.03140258789062, 96.38876342773438, 97.39520263671875, 104.23707580566406, 0.7550086975097656, 0.6640205383300781, 1.4465789794921875, 103.158447265625, 95.8671875, 0.94171142578125, 0.16451263427734375, 0.339111328125, 104.0335922241211, 1.1042137145996094, 104.85899353027344, 0.3626251220703125, 0.7765388488769531, 0.8038330078125, 0.8222084045410156, 0.6547698974609375, 0.6249008178710938, 0.3744163513183594, 102.31668090820312, 0.25629425048828125, 0.1198577880859375, 0.082489013671875, 0.1669464111328125, 0.6854896545410156, 104.39531707763672, 0.3680000305175781, 0.20036697387695312, 0.023586273193359375, 95.77969360351562, 0.7705001831054688, 1.13909912109375, 0.7418975830078125, 352.5318603515625, 0.21619415283203125, 102.29462432861328, 0.5450325012207031, 0.5709190368652344, 0.7847900390625, 0.4299812316894531, 1.3443527221679688, 0.3030242919921875, 0.5916328430175781, 0.25113677978515625, 0.38195037841796875, 103.77525329589844, 0.1822509765625, 0.8112716674804688, 1.0293540954589844, 100.2176284790039, 0.35291290283203125, 0.3182830810546875, 0.22704696655273438, 0.6241378784179688, 102.59721374511719, 344.5211181640625, 103.38423156738281, 99.37503051757812, 0.04326629638671875, 96.51387023925781, 347.10968017578125, 0.136749267578125, 102.79475402832031, 0.5475120544433594, 103.66551208496094, 0.5098228454589844, 0.4280586242675781, 0.15012741088867188, 0.61102294921875, 0.8502273559570312, 0.17712020874023438, 0.11661529541015625, 0.4489402770996094, 0.09647369384765625, 0.128692626953125, 0.4661407470703125, 1.1868438720703125, 99.39732360839844, 0.55572509765625, 0.87506103515625, 97.20044708251953, 101.81913757324219, 0.054546356201171875, 0.8952865600585938, 1.0715293884277344, 350.32122802734375, 0.3063201904296875, 0.26080322265625, 0.32756805419921875, 0.3435249328613281, 1.091888427734375, 96.95954895019531, 1.0562629699707031, 0.6892242431640625, 104.92771911621094, 0.8654975891113281, 1.0885505676269531, 103.94453430175781, 100.10720825195312, 0.4237480163574219, 104.35802459716797, 0.5882644653320312, 0.5945701599121094, 99.15184020996094, 0.7237396240234375, 98.97046661376953, 0.7708663940429688, 345.48297119140625, 0.4740867614746094, 0.40535736083984375, 0.39612579345703125, 103.88487243652344, 0.44174957275390625, 100.80181884765625, 0.38416290283203125, 0.0188751220703125, 0.6912193298339844, 0.45574188232421875, 0.7561721801757812, 0.8766975402832031, 0.19430160522460938, 0.3761787414550781, 349.04803466796875, 0.4503440856933594, 97.7971420288086, 99.12004089355469, 103.2170639038086, 102.06051635742188, 0.6536483764648438, 0.6525039672851562, 100.50621795654297, 0.046680450439453125, 104.60374450683594, 0.0355072021484375, 0.5769996643066406, 0.6503143310546875, 0.9229087829589844, 94.9540786743164, 0.39144134521484375, 0.7401504516601562, 100.22296142578125, 0.4165382385253906, 0.19301605224609375, 0.2486419677734375, 103.54212951660156, 0.052242279052734375, 0.6155891418457031, 102.4861068725586, 0.264434814453125, 0.1212310791015625, 0.9362602233886719, 97.6881103515625, 0.8818626403808594, 0.6945838928222656, 0.5364799499511719, 0.38198089599609375, 104.17875671386719, 1.1090545654296875, 1.1496772766113281, 0.14903640747070312, 0.5623130798339844, 96.62994384765625, 100.53105163574219, 102.4665298461914, 0.21336746215820312, 96.64861297607422, 0.45581817626953125, 96.95954895019531, 104.29566955566406, 0.3115692138671875, 0.21150970458984375, 104.78563690185547, 0.14868927001953125, 0.7670059204101562, 0.3894767761230469, 0.4113616943359375, 0.3694114685058594, 0.6498489379882812, 0.3629875183105469, 0.9164772033691406, 0.35425567626953125, 0.85089111328125, 0.10496902465820312, 0.6998863220214844, 0.5169448852539062, 0.057209014892578125, 0.14134979248046875, 0.49706268310546875, 0.31906890869140625, 0.6070022583007812, 0.8245811462402344, 0.4397468566894531, 0.5075302124023438, 351.54437255859375, 0.8382949829101562, 95.9790267944336, 0.6333503723144531, 105.53233337402344, 98.6900634765625, 0.6747169494628906, 0.37979888916015625, 1.213775634765625, 0.3604393005371094, 0.9925651550292969, 0.3029060363769531, 0.5623626708984375, 0.0801544189453125, 1.1500167846679688, 99.75695037841797, 0.9509696960449219, 0.022739410400390625, 95.31485748291016, 0.036212921142578125, 102.32540893554688, 0.7645416259765625, 0.41204071044921875, 1.0231056213378906, 0.4132804870605469, 1.1250648498535156, 0.6878776550292969, 0.5665855407714844, 0.5556221008300781, 0.17266845703125, 104.54920196533203, 0.9144401550292969, 0.20472335815429688, 0.21382522583007812, 0.11970138549804688, 1.1136016845703125, 95.21504974365234, 0.0806732177734375, 0.6249465942382812, 0.49109649658203125, 0.07279205322265625, 1.0228385925292969, 0.6714401245117188, 0.174163818359375, 0.2820587158203125, 0.16599273681640625, 0.768218994140625, 0.6401252746582031, 345.29595947265625, 0.42180633544921875, 94.76272583007812, 350.94342041015625, 0.7143440246582031], "mean_td_error": 37.43914794921875, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 24723.0, "diff_num_grad_updates_vs_sampler_policy": 24722.0}}, "num_env_steps_sampled": 84168, "num_env_steps_trained": 6329088, "num_agent_steps_sampled": 84168, "num_agent_steps_trained": 6329088, "last_target_update_ts": 84168, "num_target_updates": 24723}, "sampler_results": {"episode_reward_max": 235.32005356252193, "episode_reward_min": -185.71455730497837, "episode_reward_mean": -132.62824469680587, "episode_len_mean": 92.41666666666667, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-160.01942837238312, -163.05039732903242, -161.80853130668402, -185.71455730497837, -161.9875973314047, 235.32005356252193, -170.23530074954033, -168.93036127090454, -160.30008805543184, -159.32205363363028, -162.01179118454456, -173.47888338565826], "episode_lengths": [100, 100, 100, 100, 100, 9, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.140347353751047, "mean_inference_ms": 2.3561442448285557, "mean_action_processing_ms": 0.22263646435957693, "mean_env_wait_ms": 2.969679595119118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 235.32005356252193, "episode_reward_min": -185.71455730497837, "episode_reward_mean": -132.62824469680587, "episode_len_mean": 92.41666666666667, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-160.01942837238312, -163.05039732903242, -161.80853130668402, -185.71455730497837, -161.9875973314047, 235.32005356252193, -170.23530074954033, -168.93036127090454, -160.30008805543184, -159.32205363363028, -162.01179118454456, -173.47888338565826], "episode_lengths": [100, 100, 100, 100, 100, 9, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.140347353751047, "mean_inference_ms": 2.3561442448285557, "mean_action_processing_ms": 0.22263646435957693, "mean_env_wait_ms": 2.969679595119118, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 84168, "num_agent_steps_trained": 6329088, "num_env_steps_sampled": 84168, "num_env_steps_trained": 6329088, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 84168, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 84168, "timers": {"training_iteration_time_ms": 150.337, "load_time_ms": 0.284, "load_throughput": 900563.469, "learn_time_ms": 24.812, "learn_throughput": 10317.466, "synch_weights_time_ms": 5.51}, "counters": {"num_env_steps_sampled": 84168, "num_env_steps_trained": 6329088, "num_agent_steps_sampled": 84168, "num_agent_steps_trained": 6329088, "last_target_update_ts": 84168, "num_target_updates": 24723}, "done": false, "episodes_total": 870, "training_iteration": 84, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-40-37", "timestamp": 1675953637, "time_this_iter_s": 52.08914613723755, "time_total_s": 3942.0631251335144, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e30a0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a9700>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3942.0631251335144, "timesteps_since_restore": 0, "iterations_since_restore": 84, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.732394366197184, "ram_util_percent": 92.33521126760563}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3772689700126648, "actor_loss": 104.47981262207031, "critic_loss": 1.2520136833190918, "alpha_loss": -1.4020471572875977, "alpha_value": 0.024323631078004837, "log_alpha_value": -3.7163069248199463, "target_entropy": -5.0, "policy_t": -0.32848304510116577, "mean_q": -104.45780181884766, "max_q": -97.41957092285156, "min_q": -108.84430694580078}, "td_error": [105.181396484375, 0.2220458984375, 0.5823898315429688, 0.2553863525390625, 0.4520416259765625, 102.41925811767578, 0.3868217468261719, 97.94573974609375, 106.31547546386719, 0.708892822265625, 0.24233627319335938, 347.8015441894531, 0.5816001892089844, 96.27490997314453, 0.41315460205078125, 0.4836921691894531, 348.57464599609375, 350.9775390625, 0.7224502563476562, 0.5958023071289062, 0.5065650939941406, 99.3902587890625, 105.58999633789062, 105.20344543457031, 103.26734924316406, 0.17575836181640625, 98.6784439086914, 102.78996276855469, 0.262664794921875, 99.51469421386719, 0.033580780029296875, 0.06451797485351562, 0.3466072082519531, 0.46795654296875, 0.5921630859375, 104.89347076416016, 103.68585205078125, 0.4042778015136719, 0.18319320678710938, 0.597381591796875, 0.04767608642578125, 0.6174850463867188, 102.17405700683594, 0.3398551940917969, 98.5329360961914, 0.27233123779296875, 0.7667465209960938, 0.400421142578125, 0.23180007934570312, 0.5702972412109375, 0.13721466064453125, 105.13882446289062, 0.1475372314453125, 105.24246215820312, 0.15040206909179688, 0.18790435791015625, 0.050872802734375, 0.5029296875, 0.5669326782226562, 105.4854507446289, 0.07584762573242188, 350.2725830078125, 0.11232757568359375, 103.62537384033203, 0.07527923583984375, 0.28426361083984375, 347.28424072265625, 0.18033218383789062, 0.051586151123046875, 97.78840637207031, 101.0579833984375, 0.31705474853515625, 0.14780426025390625, 0.12674331665039062, 0.18776702880859375, 0.5327835083007812, 102.77120208740234, 0.4684295654296875, 0.4597053527832031, 0.61407470703125, 0.240386962890625, 105.19093322753906, 0.2665672302246094, 1.0007171630859375, 0.282440185546875, 0.3295402526855469, 0.15009307861328125, 0.1779937744140625, 0.11788177490234375, 0.4340667724609375, 0.7846832275390625, 0.1089935302734375, 106.1120834350586, 0.20998764038085938, 102.4775161743164, 0.3480224609375, 106.78546142578125, 96.35558319091797, 0.20083236694335938, 0.4134025573730469, 0.31983184814453125, 0.5016288757324219, 0.0321197509765625, 105.66210174560547, 0.4585304260253906, 0.36914825439453125, 0.4745635986328125, 0.5211257934570312, 0.6325302124023438, 0.12459564208984375, 0.8243179321289062, 0.0472564697265625, 0.9048118591308594, 0.5493392944335938, 0.12369918823242188, 0.14106369018554688, 0.04245758056640625, 100.46438598632812, 0.15230560302734375, 0.12252044677734375, 0.4424781799316406, 98.46694946289062, 0.7985610961914062, 0.23749923706054688, 0.17559432983398438, 0.5502128601074219, 0.19221115112304688, 0.6064224243164062, 0.14893341064453125, 0.6382980346679688, 0.18060302734375, 104.3543701171875, 99.61802673339844, 0.28050994873046875, 1.1957244873046875, 0.450592041015625, 0.5716629028320312, 0.858245849609375, 100.24745178222656, 102.69739532470703, 0.4883155822753906, 97.05187225341797, 0.7356185913085938, 101.14263916015625, 0.6672325134277344, 0.8958969116210938, 0.6278533935546875, 105.66210174560547, 0.10473251342773438, 0.4659156799316406, 0.15016937255859375, 0.2920799255371094, 0.333404541015625, 0.3482246398925781, 96.43546295166016, 0.3427925109863281, 0.2817802429199219, 0.3576469421386719, 0.5383949279785156, 0.11553955078125, 0.5593414306640625, 0.5540084838867188, 0.5416221618652344, 99.41743469238281, 0.5551071166992188, 0.5946502685546875, 0.23894882202148438, 0.2592620849609375, 0.5943222045898438, 0.34346771240234375, 0.40673828125, 0.7180709838867188, 0.4302635192871094, 105.26423645019531, 0.282958984375, 0.31426239013671875, 103.02118682861328, 0.4567680358886719, 0.5951156616210938, 102.454833984375, 0.44773101806640625, 0.7299728393554688, 104.17936706542969, 98.56834411621094, 0.6067962646484375, 104.81422424316406, 350.98687744140625, 106.41825103759766, 0.26679229736328125, 0.7059555053710938, 105.4640884399414, 99.53695678710938, 104.31637573242188, 0.4003715515136719, 0.3290672302246094, 101.66024017333984, 99.87141418457031, 0.5838699340820312, 0.27808380126953125, 0.20621490478515625, 0.18500137329101562, 0.5474205017089844, 103.23348999023438, 0.4027557373046875, 0.30509185791015625, 0.3548927307128906, 0.29212188720703125, 0.2500343322753906, 0.4919090270996094, 0.5405120849609375, 0.5954017639160156, 102.10206604003906, 0.045215606689453125, 0.2292327880859375, 0.073394775390625, 0.6067390441894531, 0.8611412048339844, 0.32985687255859375, 0.2285308837890625, 102.99835205078125, 0.4215354919433594, 0.421661376953125, 351.9761047363281, 0.31182861328125, 0.2630195617675781, 104.41084289550781, 0.5185623168945312, 101.66024017333984, 105.26423645019531, 0.425933837890625, 0.070709228515625, 0.44016265869140625, 105.10592651367188, 0.14830780029296875, 0.08019638061523438, 0.35999298095703125, 0.234283447265625, 0.6692733764648438, 0.4920234680175781, 0.2909355163574219, 0.0724334716796875, 101.38993835449219, 0.21163177490234375, 0.28894805908203125, 0.3735504150390625, 0.13255691528320312, 97.94573974609375, 0.305877685546875, 0.23736572265625, 0.39508819580078125, 0.268951416015625, 96.64896392822266, 0.56292724609375, 0.07453536987304688, 0.1434326171875, 98.53300476074219], "mean_td_error": 34.97572326660156, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 25057.0, "diff_num_grad_updates_vs_sampler_policy": 25056.0}}, "num_env_steps_sampled": 85170, "num_env_steps_trained": 6414592, "num_agent_steps_sampled": 85170, "num_agent_steps_trained": 6414592, "last_target_update_ts": 85170, "num_target_updates": 25057}, "sampler_results": {"episode_reward_max": 184.66164003312588, "episode_reward_min": -173.31338399648666, "episode_reward_mean": -130.5925468192859, "episode_len_mean": 94.54545454545455, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-166.68649516254663, -164.28171659260988, -154.92491586506367, -156.71664660423994, -165.8630260154605, -154.7869249433279, -161.24581636488438, -159.81006494164467, -163.5506645590067, -173.31338399648666, 184.66164003312588], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 40]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1526175684105326, "mean_inference_ms": 2.373707121128328, "mean_action_processing_ms": 0.22506819372605777, "mean_env_wait_ms": 2.985176637973296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 184.66164003312588, "episode_reward_min": -173.31338399648666, "episode_reward_mean": -130.5925468192859, "episode_len_mean": 94.54545454545455, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-166.68649516254663, -164.28171659260988, -154.92491586506367, -156.71664660423994, -165.8630260154605, -154.7869249433279, -161.24581636488438, -159.81006494164467, -163.5506645590067, -173.31338399648666, 184.66164003312588], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 40]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1526175684105326, "mean_inference_ms": 2.373707121128328, "mean_action_processing_ms": 0.22506819372605777, "mean_env_wait_ms": 2.985176637973296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 85170, "num_agent_steps_trained": 6414592, "num_env_steps_sampled": 85170, "num_env_steps_trained": 6414592, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 85170, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 85170, "timers": {"training_iteration_time_ms": 152.385, "load_time_ms": 0.28, "load_throughput": 914056.205, "learn_time_ms": 25.327, "learn_throughput": 10107.718, "synch_weights_time_ms": 5.844}, "counters": {"num_env_steps_sampled": 85170, "num_env_steps_trained": 6414592, "num_agent_steps_sampled": 85170, "num_agent_steps_trained": 6414592, "last_target_update_ts": 85170, "num_target_updates": 25057}, "done": false, "episodes_total": 881, "training_iteration": 85, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-41-28", "timestamp": 1675953688, "time_this_iter_s": 51.67122197151184, "time_total_s": 3993.7343471050262, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588970>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 3993.7343471050262, "timesteps_since_restore": 0, "iterations_since_restore": 85, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.81126760563381, "ram_util_percent": 92.39999999999999}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.02510647475719452, "actor_loss": 105.77742004394531, "critic_loss": 1.7885878086090088, "alpha_loss": -0.09522449970245361, "alpha_value": 0.022531822323799133, "log_alpha_value": -3.7928266525268555, "target_entropy": -5.0, "policy_t": -0.42288145422935486, "mean_q": -105.67039489746094, "max_q": -98.3467025756836, "min_q": -109.8692626953125}, "td_error": [106.55903625488281, 0.1976318359375, 0.30152130126953125, 0.6862144470214844, 0.3165130615234375, 103.11427307128906, 0.8369178771972656, 0.7349090576171875, 0.3292121887207031, 102.1454849243164, 0.5230789184570312, 106.87767028808594, 0.7717742919921875, 0.2779502868652344, 0.13683700561523438, 104.60910034179688, 0.3712730407714844, 0.15306472778320312, 102.29008483886719, 0.19564437866210938, 0.4018745422363281, 0.2765693664550781, 106.08373260498047, 351.594970703125, 107.14472961425781, 106.17857360839844, 0.07605361938476562, 105.38265228271484, 0.4994087219238281, 0.19431686401367188, 106.82432556152344, 0.5309677124023438, 103.43275451660156, 0.18580245971679688, 0.7889289855957031, 353.5247802734375, 0.3189048767089844, 106.06498718261719, 0.7625770568847656, 0.2256622314453125, 0.6122169494628906, 0.3650054931640625, 0.14166259765625, 99.61836242675781, 0.17474746704101562, 0.06866455078125, 105.53697967529297, 0.5063705444335938, 0.7125778198242188, 0.16982650756835938, 105.10818481445312, 0.204864501953125, 0.5571861267089844, 0.24369430541992188, 106.1192855834961, 98.95106506347656, 0.22970962524414062, 104.60910034179688, 352.8189697265625, 0.043933868408203125, 0.14179229736328125, 104.52484130859375, 351.70880126953125, 0.4073982238769531, 0.18220138549804688, 0.24123382568359375, 0.09269332885742188, 0.13222885131835938, 103.65350341796875, 0.8419227600097656, 1.0323143005371094, 0.22378158569335938, 0.01654815673828125, 0.5472068786621094, 0.1481475830078125, 0.08777618408203125, 0.4249420166015625, 0.5445785522460938, 0.7999153137207031, 97.76295471191406, 354.90301513671875, 0.179473876953125, 0.0932159423828125, 103.37100219726562, 0.223846435546875, 106.89022064208984, 350.01824951171875, 0.3811378479003906, 0.47265625, 0.53497314453125, 0.5373954772949219, 0.9817085266113281, 0.4639892578125, 0.5021781921386719, 0.6390571594238281, 99.27729797363281, 0.3871650695800781, 0.09571456909179688, 0.5133895874023438, 0.14188003540039062, 106.33999633789062, 0.2938499450683594, 0.09194564819335938, 0.3620758056640625, 0.14623260498046875, 0.4507942199707031, 0.31066131591796875, 354.52294921875, 0.4802665710449219, 0.1899871826171875, 0.4342689514160156, 0.7091751098632812, 0.2546730041503906, 0.5368690490722656, 0.14701080322265625, 1.0605621337890625, 0.4607658386230469, 347.30706787109375, 0.3144493103027344, 106.77076721191406, 0.22696685791015625, 0.14407730102539062, 106.33999633789062, 104.939208984375, 103.70600891113281, 0.6139183044433594, 105.46177673339844, 107.33560180664062, 103.13165283203125, 0.467987060546875, 98.95570373535156, 0.7750167846679688, 103.63907623291016, 0.3709373474121094, 0.17499923706054688, 0.5242576599121094, 106.47574615478516, 0.17353439331054688, 0.3287200927734375, 351.70880126953125, 0.06652069091796875, 105.59004211425781, 107.69667053222656, 0.6884384155273438, 104.83641052246094, 0.6386451721191406, 348.5780944824219, 0.1334381103515625, 0.036365509033203125, 107.3548583984375, 0.4149436950683594, 104.792724609375, 0.15170669555664062, 349.8565673828125, 0.2826423645019531, 106.41690063476562, 106.6648178100586, 106.67440795898438, 0.12105560302734375, 103.82786560058594, 0.5868415832519531, 105.62538146972656, 0.3414573669433594, 0.16656112670898438, 0.19889450073242188, 102.94452667236328, 0.09648513793945312, 0.23218917846679688, 102.81423950195312, 103.72843933105469, 0.14602279663085938, 106.95266723632812, 351.594970703125, 0.6410942077636719, 0.04819488525390625, 0.12429046630859375, 0.48647308349609375, 0.15127944946289062, 0.4941978454589844, 108.11700439453125, 99.36482238769531, 101.8548355102539, 351.59149169921875, 0.26318359375, 107.40894317626953, 0.21923446655273438, 350.33135986328125, 101.1021728515625, 100.53907775878906, 105.02886962890625, 0.062183380126953125, 0.24379348754882812, 0.8870506286621094, 0.6132965087890625, 0.5839729309082031, 105.09175109863281, 352.8189697265625, 102.94452667236328, 104.66427612304688, 99.80782318115234, 0.21907424926757812, 0.345733642578125, 0.37425994873046875, 0.9229774475097656, 99.23124694824219, 0.374847412109375, 0.36468505859375, 0.3742408752441406, 0.2906379699707031, 0.4098167419433594, 0.09682083129882812, 103.93132019042969, 0.17916488647460938, 0.787811279296875, 0.3853950500488281, 0.2975502014160156, 0.9495849609375, 105.69893646240234, 0.9439506530761719, 0.10955047607421875, 1.06256103515625, 104.29959106445312, 0.5362815856933594, 0.3322906494140625, 0.9352836608886719, 0.601226806640625, 0.2685737609863281, 106.82432556152344, 351.90655517578125, 0.19676589965820312, 0.6367454528808594, 0.9191551208496094, 0.16801834106445312, 352.2843933105469, 0.7295074462890625, 104.71733093261719, 0.6479301452636719, 0.2631492614746094, 0.2589454650878906, 0.08766937255859375, 0.6937828063964844, 107.15013122558594, 0.2616004943847656, 0.4470863342285156, 0.3542213439941406, 0.17703628540039062, 106.65836334228516, 0.7199897766113281, 0.08448028564453125, 0.09894561767578125, 0.023555755615234375, 0.489776611328125, 104.18595886230469, 103.11427307128906, 0.0912933349609375, 0.36017608642578125], "mean_td_error": 52.555171966552734, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 25391.0, "diff_num_grad_updates_vs_sampler_policy": 25390.0}}, "num_env_steps_sampled": 86172, "num_env_steps_trained": 6500096, "num_agent_steps_sampled": 86172, "num_agent_steps_trained": 6500096, "last_target_update_ts": 86172, "num_target_updates": 25391}, "sampler_results": {"episode_reward_max": -153.46866038441658, "episode_reward_min": -166.27869933843613, "episode_reward_mean": -162.08506232086154, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-165.28804403543472, -164.42760507762432, -164.16389498859644, -153.46866038441658, -159.4734928458929, -162.59226347506046, -166.27869933843613, -158.57809130102396, -164.49480944126844], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1510292675172136, "mean_inference_ms": 2.3711743173579873, "mean_action_processing_ms": 0.2247322100226278, "mean_env_wait_ms": 2.980617783814539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -153.46866038441658, "episode_reward_min": -166.27869933843613, "episode_reward_mean": -162.08506232086154, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-165.28804403543472, -164.42760507762432, -164.16389498859644, -153.46866038441658, -159.4734928458929, -162.59226347506046, -166.27869933843613, -158.57809130102396, -164.49480944126844], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1510292675172136, "mean_inference_ms": 2.3711743173579873, "mean_action_processing_ms": 0.2247322100226278, "mean_env_wait_ms": 2.980617783814539, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 86172, "num_agent_steps_trained": 6500096, "num_env_steps_sampled": 86172, "num_env_steps_trained": 6500096, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 86172, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 86172, "timers": {"training_iteration_time_ms": 152.652, "load_time_ms": 0.269, "load_throughput": 952912.517, "learn_time_ms": 24.911, "learn_throughput": 10276.418, "synch_weights_time_ms": 5.347}, "counters": {"num_env_steps_sampled": 86172, "num_env_steps_trained": 6500096, "num_agent_steps_sampled": 86172, "num_agent_steps_trained": 6500096, "last_target_update_ts": 86172, "num_target_updates": 25391}, "done": false, "episodes_total": 890, "training_iteration": 86, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-42-20", "timestamp": 1675953740, "time_this_iter_s": 51.89799118041992, "time_total_s": 4045.632338285446, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef4c0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4045.632338285446, "timesteps_since_restore": 0, "iterations_since_restore": 86, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.54571428571428, "ram_util_percent": 92.55857142857144}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.3510201871395111, "actor_loss": 106.04756927490234, "critic_loss": 1.2845702171325684, "alpha_loss": 1.3205255270004272, "alpha_value": 0.023238059133291245, "log_alpha_value": -3.7619638442993164, "target_entropy": -5.0, "policy_t": -0.4173603057861328, "mean_q": -106.05569458007812, "max_q": -99.3006591796875, "min_q": -110.88027954101562}, "td_error": [107.13111877441406, 0.7120780944824219, 0.25390625, 0.351654052734375, 105.33747100830078, 104.06867980957031, 0.4071464538574219, 0.5466232299804688, 350.97637939453125, 108.0670166015625, 0.6242599487304688, 102.05677795410156, 0.4192161560058594, 0.19990921020507812, 99.67683410644531, 349.78289794921875, 1.03326416015625, 0.3820762634277344, 0.5407943725585938, 0.260284423828125, 0.3729743957519531, 104.75355529785156, 0.5412178039550781, 0.11188507080078125, 0.787628173828125, 0.7730979919433594, 0.6236915588378906, 0.531829833984375, 355.4007568359375, 0.3752250671386719, 100.11207580566406, 0.5578231811523438, 0.47153472900390625, 104.19021606445312, 0.3995819091796875, 0.29921722412109375, 105.75912475585938, 0.2402191162109375, 0.023250579833984375, 0.15732192993164062, 101.85964965820312, 0.521820068359375, 0.22553634643554688, 0.3121795654296875, 0.332611083984375, 0.4171638488769531, 101.78848266601562, 103.56126403808594, 0.26714324951171875, 108.87144470214844, 108.18666076660156, 0.3258552551269531, 0.9755172729492188, 0.107879638671875, 107.47067260742188, 106.25898742675781, 103.5484619140625, 0.047595977783203125, 0.14606857299804688, 0.23524093627929688, 99.87091827392578, 0.24225616455078125, 100.11207580566406, 106.08193969726562, 354.0907897949219, 1.4106864929199219, 0.03101348876953125, 0.9858779907226562, 0.06381607055664062, 106.09814453125, 106.96238708496094, 0.024784088134765625, 0.062351226806640625, 0.24410629272460938, 0.5158729553222656, 0.0317230224609375, 0.3814048767089844, 0.062015533447265625, 1.2982330322265625, 0.4502830505371094, 0.2111358642578125, 0.4515419006347656, 0.2860908508300781, 0.16060256958007812, 0.15970993041992188, 0.26755523681640625, 0.4703712463378906, 0.8056221008300781, 0.3710479736328125, 102.83518981933594, 0.22138595581054688, 0.21071243286132812, 107.19088745117188, 0.2901115417480469, 0.5340385437011719, 0.4767494201660156, 0.3673858642578125, 0.19993972778320312, 0.2611503601074219, 0.4208221435546875, 0.19338226318359375, 0.13849258422851562, 0.7825851440429688, 0.3660926818847656, 0.8994979858398438, 0.0638885498046875, 348.1793212890625, 0.19601058959960938, 0.3480491638183594, 0.21385955810546875, 0.5558052062988281, 0.33487701416015625, 0.310394287109375, 0.2592048645019531, 105.67317199707031, 355.25897216796875, 103.88330078125, 0.09695816040039062, 0.86474609375, 0.2679100036621094, 0.5827255249023438, 0.18975830078125, 105.19231414794922, 0.33072662353515625, 0.16262435913085938, 0.6056785583496094, 0.6541709899902344, 0.8291435241699219, 100.25112915039062, 0.2596397399902344, 0.215911865234375, 108.23189544677734, 107.99363708496094, 0.057647705078125, 0.18644332885742188, 99.86599731445312, 0.3005332946777344, 0.103790283203125, 106.06088256835938, 100.21687316894531, 0.20685958862304688, 0.3192787170410156, 0.10896682739257812, 0.29877471923828125, 0.5727653503417969, 0.0442962646484375, 0.4784889221191406, 0.30323028564453125, 103.50080871582031, 105.64167785644531, 0.17528533935546875, 102.05677795410156, 0.07280731201171875, 0.5986518859863281, 99.6904296875, 0.5418853759765625, 0.026622772216796875, 0.13187789916992188, 0.3190269470214844, 0.3803215026855469, 0.2819061279296875, 0.06929397583007812, 106.90835571289062, 106.53880310058594, 0.3513832092285156, 99.99568939208984, 102.6429672241211, 108.41596984863281, 0.18268585205078125, 0.869415283203125, 0.06159210205078125, 101.4700927734375, 0.011745452880859375, 0.15327835083007812, 101.92941284179688, 103.67219543457031, 0.5425605773925781, 0.10268020629882812, 0.296844482421875, 104.07279968261719, 0.2393951416015625, 103.61094665527344, 0.19476699829101562, 0.3401947021484375, 107.35820007324219, 0.4770355224609375, 0.9758033752441406, 0.5803108215332031, 0.22949600219726562, 0.3248786926269531, 0.7475776672363281, 103.71150207519531, 101.86116027832031, 0.9493179321289062, 0.5447578430175781, 1.1464195251464844, 0.3591346740722656, 107.27110290527344, 0.6129989624023438, 0.3888435363769531, 107.6585464477539, 0.6298713684082031, 0.41249847412109375, 0.6702384948730469, 0.2291412353515625, 0.273529052734375, 0.49436187744140625, 105.38716125488281, 0.3896675109863281, 0.3160972595214844, 0.4922828674316406, 0.6591567993164062, 108.62066650390625, 0.1998138427734375, 104.03312683105469, 0.3702545166015625, 0.06773757934570312, 0.4967079162597656, 0.05184173583984375, 0.6126976013183594, 107.61274719238281, 0.6161689758300781, 0.7236595153808594, 0.8065528869628906, 97.83251953125, 0.6368942260742188, 106.63993835449219, 0.6492843627929688, 0.43990325927734375, 0.14414215087890625, 103.63438415527344, 0.48256683349609375, 0.12168121337890625, 0.217864990234375, 349.78289794921875, 0.5911445617675781, 99.61805725097656, 0.3072395324707031, 100.40564727783203, 0.11118316650390625, 0.08656692504882812, 0.15959930419921875, 0.18011093139648438, 0.5454368591308594, 0.7187728881835938, 0.4672279357910156, 0.5238494873046875, 0.6587791442871094, 0.4005126953125, 0.4290962219238281, 0.5532684326171875, 0.22834396362304688, 101.71989440917969, 0.2794837951660156, 105.67317199707031, 0.4690666198730469], "mean_td_error": 35.9517822265625, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 25725.0, "diff_num_grad_updates_vs_sampler_policy": 25724.0}}, "num_env_steps_sampled": 87174, "num_env_steps_trained": 6585600, "num_agent_steps_sampled": 87174, "num_agent_steps_trained": 6585600, "last_target_update_ts": 87174, "num_target_updates": 25725}, "sampler_results": {"episode_reward_max": -151.91925486177206, "episode_reward_min": -171.7965495660901, "episode_reward_mean": -162.73048628270627, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.47354861348867, -159.60192592442036, -159.82647239416838, -171.7965495660901, -162.7164184898138, -165.72435009479523, -164.9394108504057, -151.91925486177206, -166.3302129805088, -160.9767190515995], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1492450770821787, "mean_inference_ms": 2.3687048925536764, "mean_action_processing_ms": 0.2242143723792312, "mean_env_wait_ms": 2.976488948110384, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -151.91925486177206, "episode_reward_min": -171.7965495660901, "episode_reward_mean": -162.73048628270627, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-163.47354861348867, -159.60192592442036, -159.82647239416838, -171.7965495660901, -162.7164184898138, -165.72435009479523, -164.9394108504057, -151.91925486177206, -166.3302129805088, -160.9767190515995], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1492450770821787, "mean_inference_ms": 2.3687048925536764, "mean_action_processing_ms": 0.2242143723792312, "mean_env_wait_ms": 2.976488948110384, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 87174, "num_agent_steps_trained": 6585600, "num_env_steps_sampled": 87174, "num_env_steps_trained": 6585600, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 87174, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 87174, "timers": {"training_iteration_time_ms": 150.575, "load_time_ms": 0.286, "load_throughput": 895829.988, "learn_time_ms": 24.593, "learn_throughput": 10409.609, "synch_weights_time_ms": 5.195}, "counters": {"num_env_steps_sampled": 87174, "num_env_steps_trained": 6585600, "num_agent_steps_sampled": 87174, "num_agent_steps_trained": 6585600, "last_target_update_ts": 87174, "num_target_updates": 25725}, "done": false, "episodes_total": 900, "training_iteration": 87, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-43-12", "timestamp": 1675953792, "time_this_iter_s": 51.8021285533905, "time_total_s": 4097.434466838837, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580640>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4097.434466838837, "timesteps_since_restore": 0, "iterations_since_restore": 87, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.05915492957747, "ram_util_percent": 92.6887323943662}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6027483940124512, "actor_loss": 107.44583129882812, "critic_loss": 1.400932788848877, "alpha_loss": -2.242967367172241, "alpha_value": 0.024204108864068985, "log_alpha_value": -3.7212328910827637, "target_entropy": -5.0, "policy_t": -0.3267424702644348, "mean_q": -107.26871490478516, "max_q": -99.83253479003906, "min_q": -111.94043731689453}, "td_error": [103.22044372558594, 101.33052062988281, 0.12611770629882812, 0.2614479064941406, 104.47419738769531, 0.2992744445800781, 0.6441879272460938, 0.3794097900390625, 0.11725997924804688, 0.5745277404785156, 0.15059280395507812, 104.28327178955078, 0.11147689819335938, 0.119873046875, 106.0455322265625, 105.10113525390625, 0.47275543212890625, 0.8751602172851562, 106.11563110351562, 0.21448135375976562, 1.0407676696777344, 0.5237884521484375, 0.4348335266113281, 101.5788803100586, 0.23614883422851562, 104.61616516113281, 109.89259338378906, 0.3017730712890625, 0.052097320556640625, 0.37487030029296875, 353.05145263671875, 100.96278381347656, 0.28476715087890625, 108.75726318359375, 107.6513442993164, 98.588134765625, 0.31597137451171875, 1.1367607116699219, 0.4039497375488281, 0.17140579223632812, 0.5540122985839844, 0.38897705078125, 108.02992248535156, 106.0455322265625, 0.18707275390625, 106.27645874023438, 0.2581825256347656, 0.16225433349609375, 0.4699897766113281, 0.3751564025878906, 0.6525497436523438, 103.81694793701172, 0.2394561767578125, 0.5055274963378906, 109.162353515625, 0.3845024108886719, 0.4796028137207031, 0.6277923583984375, 0.5222969055175781, 0.4913825988769531, 0.33966064453125, 0.5617790222167969, 0.6710357666015625, 0.8300437927246094, 104.66287231445312, 99.17131042480469, 108.2584228515625, 0.41014862060546875, 0.4165763854980469, 0.15311813354492188, 0.31700897216796875, 0.2909049987792969, 0.4948234558105469, 0.4626197814941406, 104.44285583496094, 0.3982276916503906, 352.8607177734375, 0.026355743408203125, 0.25661468505859375, 107.49842834472656, 99.31330871582031, 97.29568481445312, 105.00164794921875, 352.73773193359375, 102.40458679199219, 0.6655158996582031, 0.164215087890625, 104.26189422607422, 0.198944091796875, 0.6229972839355469, 0.3006019592285156, 0.3739814758300781, 0.3328895568847656, 0.5194511413574219, 356.1741943359375, 0.7833595275878906, 0.4483299255371094, 0.2785530090332031, 0.076263427734375, 105.89154052734375, 103.09661102294922, 0.5584068298339844, 0.3016242980957031, 104.82594299316406, 109.2421875, 0.18270492553710938, 0.1676788330078125, 0.6764717102050781, 0.11305618286132812, 0.27561187744140625, 0.3541297912597656, 0.7332267761230469, 0.4669761657714844, 108.41616821289062, 108.79539489746094, 0.10032272338867188, 0.18367385864257812, 109.44978332519531, 0.4910545349121094, 0.6286392211914062, 0.3070335388183594, 0.3296318054199219, 104.49850463867188, 0.44637298583984375, 0.3926963806152344, 0.5259132385253906, 0.4238395690917969, 0.37060546875, 104.24771118164062, 102.88614654541016, 109.2934341430664, 0.28481292724609375, 355.2565612792969, 0.6895561218261719, 0.3773651123046875, 0.1445465087890625, 0.2897377014160156, 0.3831596374511719, 0.23166656494140625, 0.22053146362304688, 0.17689132690429688, 0.2838935852050781, 106.93899536132812, 0.7503852844238281, 0.22075271606445312, 0.4503822326660156, 108.41990661621094, 0.15035629272460938, 0.18790054321289062, 0.4569282531738281, 100.85781860351562, 1.0999031066894531, 0.08441543579101562, 101.43650817871094, 0.5735893249511719, 0.7206687927246094, 1.1533737182617188, 0.2861976623535156, 0.8173103332519531, 108.9702377319336, 0.4537849426269531, 0.1770782470703125, 105.5350341796875, 0.5076332092285156, 0.09148788452148438, 0.153656005859375, 0.07578659057617188, 0.21990585327148438, 0.4866447448730469, 351.21588134765625, 0.4326972961425781, 105.05873107910156, 106.47952270507812, 104.16564178466797, 101.06790924072266, 1.0521163940429688, 107.53805541992188, 0.2677001953125, 104.92063903808594, 0.2500953674316406, 0.6414604187011719, 106.93899536132812, 0.4668464660644531, 0.15325927734375, 103.27822875976562, 0.20002365112304688, 104.00129699707031, 0.3965415954589844, 0.15061569213867188, 0.1497802734375, 0.26727294921875, 0.4932289123535156, 0.6820716857910156, 0.7680435180664062, 0.1749420166015625, 0.11391830444335938, 0.21990585327148438, 0.13825225830078125, 0.4533958435058594, 0.3511390686035156, 0.18395614624023438, 0.7633857727050781, 0.13924026489257812, 100.57957458496094, 0.14638519287109375, 0.2706565856933594, 0.7678031921386719, 0.29991912841796875, 0.3318748474121094, 0.4410057067871094, 0.17712020874023438, 102.8087158203125, 0.3813438415527344, 0.6374130249023438, 0.36112213134765625, 0.16271591186523438, 0.5610237121582031, 0.22138214111328125, 0.7928657531738281, 0.17624282836914062, 104.8575210571289, 0.48260498046875, 0.19618606567382812, 102.44894409179688, 0.3036460876464844, 0.43383026123046875, 104.09503173828125, 0.6984901428222656, 108.18635559082031, 106.87431335449219, 0.3690681457519531, 0.2174224853515625, 0.4795188903808594, 0.22271347045898438, 0.5740699768066406, 0.4195098876953125, 0.3219490051269531, 101.87940216064453, 0.2687835693359375, 0.5824317932128906, 106.49525451660156, 106.89427947998047, 105.18142700195312, 0.3431396484375, 0.33979034423828125, 0.23739242553710938, 0.12127304077148438, 102.41041564941406, 106.4554443359375, 0.44121551513671875, 0.3195075988769531, 0.7463111877441406, 0.4558219909667969, 352.79730224609375, 0.7236289978027344, 109.19664764404297], "mean_td_error": 38.232234954833984, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 26059.0, "diff_num_grad_updates_vs_sampler_policy": 26058.0}}, "num_env_steps_sampled": 88176, "num_env_steps_trained": 6671104, "num_agent_steps_sampled": 88176, "num_agent_steps_trained": 6671104, "last_target_update_ts": 88176, "num_target_updates": 26059}, "sampler_results": {"episode_reward_max": -156.1016564965248, "episode_reward_min": -170.0796898379922, "episode_reward_mean": -164.2917529276826, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-164.5030802488327, -167.48114255815744, -170.059987090528, -165.85304640233517, -170.0796898379922, -159.18565671890974, -165.7829701602459, -157.2049067541957, -167.67788741737604, -156.1016564965248, -163.2792585194111], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.151577075730743, "mean_inference_ms": 2.373204907738784, "mean_action_processing_ms": 0.22478061207663913, "mean_env_wait_ms": 2.9787773901250194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.1016564965248, "episode_reward_min": -170.0796898379922, "episode_reward_mean": -164.2917529276826, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-164.5030802488327, -167.48114255815744, -170.059987090528, -165.85304640233517, -170.0796898379922, -159.18565671890974, -165.7829701602459, -157.2049067541957, -167.67788741737604, -156.1016564965248, -163.2792585194111], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.151577075730743, "mean_inference_ms": 2.373204907738784, "mean_action_processing_ms": 0.22478061207663913, "mean_env_wait_ms": 2.9787773901250194, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 88176, "num_agent_steps_trained": 6671104, "num_env_steps_sampled": 88176, "num_env_steps_trained": 6671104, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 88176, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 88176, "timers": {"training_iteration_time_ms": 152.106, "load_time_ms": 0.292, "load_throughput": 877526.826, "learn_time_ms": 25.327, "learn_throughput": 10107.822, "synch_weights_time_ms": 5.317}, "counters": {"num_env_steps_sampled": 88176, "num_env_steps_trained": 6671104, "num_agent_steps_sampled": 88176, "num_agent_steps_trained": 6671104, "last_target_update_ts": 88176, "num_target_updates": 26059}, "done": false, "episodes_total": 911, "training_iteration": 88, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-44-05", "timestamp": 1675953845, "time_this_iter_s": 52.44793081283569, "time_total_s": 4149.882397651672, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580040>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057baf0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4149.882397651672, "timesteps_since_restore": 0, "iterations_since_restore": 88, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.39718309859154, "ram_util_percent": 92.4323943661972}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.22023317217826843, "actor_loss": 108.15754699707031, "critic_loss": 1.422956943511963, "alpha_loss": 0.83460533618927, "alpha_value": 0.022603636607527733, "log_alpha_value": -3.789644479751587, "target_entropy": -5.0, "policy_t": -0.3269614577293396, "mean_q": -108.12991333007812, "max_q": -101.19719696044922, "min_q": -112.804931640625}, "td_error": [103.84876251220703, 109.54714965820312, 0.21273040771484375, 0.2599067687988281, 0.5803260803222656, 355.249755859375, 0.40453338623046875, 0.7840309143066406, 106.19639587402344, 0.4364585876464844, 108.22740173339844, 0.4780998229980469, 0.5064277648925781, 354.20867919921875, 1.186248779296875, 0.6605987548828125, 104.40800476074219, 0.20285797119140625, 0.10554885864257812, 0.2584075927734375, 0.6152420043945312, 0.4224395751953125, 104.82561492919922, 0.2955589294433594, 0.7330703735351562, 0.5978775024414062, 101.79684448242188, 109.56993865966797, 105.62263488769531, 109.16410827636719, 109.95870208740234, 0.2750968933105469, 110.31879425048828, 0.12810134887695312, 0.3309173583984375, 0.3030967712402344, 0.6429634094238281, 0.31011199951171875, 102.84878540039062, 0.4709434509277344, 0.04366302490234375, 0.6755943298339844, 0.2726402282714844, 0.3548583984375, 0.6410484313964844, 1.0256729125976562, 350.6960754394531, 105.56564331054688, 0.3215522766113281, 0.24280929565429688, 0.6329383850097656, 0.3197822570800781, 354.9892578125, 103.66802978515625, 0.6453819274902344, 107.66799926757812, 0.4206581115722656, 105.59199523925781, 104.36688232421875, 0.706298828125, 0.5970344543457031, 0.11734390258789062, 0.16745758056640625, 0.12643814086914062, 0.21267318725585938, 0.44678497314453125, 0.21779251098632812, 1.1850471496582031, 0.10808944702148438, 0.3082771301269531, 108.60478973388672, 0.20705795288085938, 0.7405204772949219, 0.40323638916015625, 0.499053955078125, 0.7962608337402344, 0.3884544372558594, 104.67682647705078, 0.213592529296875, 0.30260467529296875, 110.57842254638672, 109.686279296875, 0.07683181762695312, 0.7791862487792969, 0.07004928588867188, 0.21228790283203125, 0.7736587524414062, 1.2133750915527344, 109.56993865966797, 0.8688545227050781, 0.24860763549804688, 0.08670425415039062, 0.4158935546875, 0.20428466796875, 108.70339965820312, 100.95411682128906, 0.3821678161621094, 0.24496841430664062, 108.08024597167969, 105.58175659179688, 104.85794067382812, 0.27111053466796875, 355.249755859375, 109.9303207397461, 0.7600975036621094, 111.1441650390625, 108.721923828125, 0.12801361083984375, 353.5028991699219, 0.18711090087890625, 0.2036285400390625, 1.1784934997558594, 0.18211746215820312, 0.3537940979003906, 0.17893600463867188, 106.496826171875, 0.6486473083496094, 0.3871803283691406, 0.5332527160644531, 0.11290359497070312, 0.6836280822753906, 109.78018188476562, 108.250732421875, 0.17399215698242188, 110.12818908691406, 0.3820686340332031, 0.1756744384765625, 0.3804054260253906, 0.281219482421875, 109.35874938964844, 0.07418441772460938, 108.96751403808594, 0.3085899353027344, 0.1898956298828125, 0.6120719909667969, 0.0404052734375, 0.4050445556640625, 102.41606140136719, 0.23157882690429688, 0.11888504028320312, 0.7081642150878906, 0.09419631958007812, 0.5298843383789062, 0.452117919921875, 0.2191314697265625, 100.25823211669922, 109.12008666992188, 0.8390731811523438, 106.75518798828125, 105.88253784179688, 0.227691650390625, 0.15896987915039062, 0.2664794921875, 103.3718032836914, 0.21886825561523438, 0.6951370239257812, 0.2591667175292969, 101.69537353515625, 0.4560546875, 0.06348419189453125, 0.4941520690917969, 106.44070434570312, 0.7038917541503906, 0.5526771545410156, 0.382720947265625, 109.9303207397461, 0.5916900634765625, 0.47470855712890625, 0.5540351867675781, 0.4284172058105469, 0.30231475830078125, 0.4101066589355469, 0.2847442626953125, 0.2377471923828125, 106.40876770019531, 0.3470916748046875, 0.3760185241699219, 0.17609024047851562, 355.9720458984375, 0.7557258605957031, 0.3444023132324219, 102.12344360351562, 108.20487976074219, 0.5709571838378906, 110.20785522460938, 0.3127861022949219, 0.22043228149414062, 0.5272445678710938, 0.4964752197265625, 0.4386940002441406, 353.60064697265625, 0.4139442443847656, 0.46982574462890625, 0.579193115234375, 0.33294677734375, 0.0464935302734375, 0.2571563720703125, 0.10185623168945312, 0.15344619750976562, 0.6450576782226562, 0.3730354309082031, 0.015697479248046875, 0.10627365112304688, 0.37027740478515625, 0.124542236328125, 0.582122802734375, 0.4329872131347656, 0.4273490905761719, 0.107757568359375, 0.5297164916992188, 0.17627716064453125, 0.6556167602539062, 0.11075973510742188, 0.34979248046875, 0.23322296142578125, 0.3642005920410156, 0.5218772888183594, 0.7411346435546875, 0.6673851013183594, 109.45511627197266, 101.79684448242188, 0.6416549682617188, 0.6708030700683594, 0.2978515625, 353.96728515625, 0.2869148254394531, 0.11442947387695312, 107.40362548828125, 0.1237945556640625, 0.6270256042480469, 0.6387481689453125, 0.10182571411132812, 104.87921142578125, 100.37017822265625, 0.21483612060546875, 0.5149421691894531, 107.56193542480469, 101.31407165527344, 350.13629150390625, 0.14910125732421875, 109.88650512695312, 0.47222900390625, 0.519287109375, 0.2026824951171875, 0.5417060852050781, 106.94979858398438, 108.22012329101562, 0.41107940673828125, 0.4630393981933594, 110.17134094238281, 0.19400405883789062, 107.0167236328125, 106.11185455322266, 107.77757263183594, 0.24898147583007812, 0.5509414672851562], "mean_td_error": 40.77702331542969, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 26393.0, "diff_num_grad_updates_vs_sampler_policy": 26392.0}}, "num_env_steps_sampled": 89178, "num_env_steps_trained": 6756608, "num_agent_steps_sampled": 89178, "num_agent_steps_trained": 6756608, "last_target_update_ts": 89178, "num_target_updates": 26393}, "sampler_results": {"episode_reward_max": -158.87991008907557, "episode_reward_min": -169.21210058033466, "episode_reward_mean": -162.74230231841406, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-163.5076039582491, -169.21210058033466, -163.12153916060925, -159.87924586236477, -162.154753819108, -162.94538602232933, -160.52441777288914, -164.45576360076666, -158.87991008907557], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1502112785785326, "mean_inference_ms": 2.371285132558934, "mean_action_processing_ms": 0.22432462738222242, "mean_env_wait_ms": 2.9768634551727513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -158.87991008907557, "episode_reward_min": -169.21210058033466, "episode_reward_mean": -162.74230231841406, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-163.5076039582491, -169.21210058033466, -163.12153916060925, -159.87924586236477, -162.154753819108, -162.94538602232933, -160.52441777288914, -164.45576360076666, -158.87991008907557], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1502112785785326, "mean_inference_ms": 2.371285132558934, "mean_action_processing_ms": 0.22432462738222242, "mean_env_wait_ms": 2.9768634551727513, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 89178, "num_agent_steps_trained": 6756608, "num_env_steps_sampled": 89178, "num_env_steps_trained": 6756608, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 89178, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 89178, "timers": {"training_iteration_time_ms": 173.897, "load_time_ms": 0.309, "load_throughput": 827546.685, "learn_time_ms": 26.805, "learn_throughput": 9550.595, "synch_weights_time_ms": 6.604}, "counters": {"num_env_steps_sampled": 89178, "num_env_steps_trained": 6756608, "num_agent_steps_sampled": 89178, "num_agent_steps_trained": 6756608, "last_target_update_ts": 89178, "num_target_updates": 26393}, "done": false, "episodes_total": 920, "training_iteration": 89, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-44-58", "timestamp": 1675953898, "time_this_iter_s": 53.125832080841064, "time_total_s": 4203.008229732513, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e3e50>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ddc0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4203.008229732513, "timesteps_since_restore": 0, "iterations_since_restore": 89, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.5041095890411, "ram_util_percent": 91.7794520547945}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.31664466857910156, "actor_loss": 109.52259826660156, "critic_loss": 1.3268449306488037, "alpha_loss": 1.176641583442688, "alpha_value": 0.024331890046596527, "log_alpha_value": -3.7159674167633057, "target_entropy": -5.0, "policy_t": -0.31934046745300293, "mean_q": -109.40719604492188, "max_q": -102.08684539794922, "min_q": -113.9351577758789}, "td_error": [108.49366760253906, 0.4049720764160156, 0.6520462036132812, 0.52276611328125, 0.8982810974121094, 0.5268058776855469, 0.06783294677734375, 109.32386779785156, 0.07751083374023438, 0.7526779174804688, 0.07034683227539062, 0.3881340026855469, 110.6682357788086, 0.00335693359375, 0.37056732177734375, 0.3251762390136719, 110.52473449707031, 0.18636322021484375, 0.0589752197265625, 0.3828239440917969, 0.07022476196289062, 109.31028747558594, 0.4282112121582031, 0.4865150451660156, 0.3209571838378906, 0.4471855163574219, 0.19102859497070312, 1.0316886901855469, 107.85899353027344, 111.35791778564453, 351.6226806640625, 0.5529518127441406, 0.2862434387207031, 110.05364990234375, 0.3498573303222656, 0.1656341552734375, 0.5233535766601562, 107.9655532836914, 0.14271163940429688, 0.3117828369140625, 0.08179473876953125, 0.1002960205078125, 110.78834533691406, 0.5088691711425781, 0.2292022705078125, 0.21318817138671875, 107.57598876953125, 0.4491462707519531, 110.91702270507812, 0.39440155029296875, 0.2507171630859375, 0.12208938598632812, 0.034618377685546875, 0.5067100524902344, 0.0754852294921875, 100.97402954101562, 0.18409347534179688, 106.73995971679688, 0.08317184448242188, 107.64364624023438, 0.4255790710449219, 0.2507591247558594, 0.4073600769042969, 0.3990821838378906, 0.10969161987304688, 0.23918914794921875, 108.83294677734375, 0.7615089416503906, 0.5498847961425781, 0.8663482666015625, 0.5146293640136719, 0.10178375244140625, 0.2680015563964844, 0.4230079650878906, 0.426513671875, 0.18178558349609375, 111.22029113769531, 0.08578872680664062, 0.2963981628417969, 0.2881736755371094, 0.6163444519042969, 107.64364624023438, 0.20653915405273438, 0.472503662109375, 102.64585876464844, 110.54660034179688, 0.674774169921875, 0.9091835021972656, 0.33971405029296875, 0.475921630859375, 0.4463157653808594, 0.12939453125, 110.43685913085938, 105.82504272460938, 103.6359634399414, 108.12682342529297, 110.82087707519531, 105.73676300048828, 358.75775146484375, 0.1060791015625, 0.6392669677734375, 0.40207672119140625, 0.6707801818847656, 107.61032104492188, 0.21211624145507812, 110.01344299316406, 0.3277626037597656, 0.24268722534179688, 0.6844978332519531, 0.3740386962890625, 0.3840675354003906, 110.46170043945312, 0.401336669921875, 0.6451225280761719, 110.91919708251953, 110.10130310058594, 0.6145210266113281, 0.08403396606445312, 0.1404876708984375, 0.790283203125, 0.4999656677246094, 0.6546134948730469, 351.4460754394531, 0.5153007507324219, 0.13941192626953125, 108.25362396240234, 0.1289215087890625, 0.2729682922363281, 0.24492263793945312, 102.9668197631836, 0.4804420471191406, 104.40596008300781, 104.91990661621094, 0.8781700134277344, 0.3741264343261719, 0.7790870666503906, 0.15594482421875, 0.4308052062988281, 0.07463836669921875, 0.48093414306640625, 105.3304443359375, 111.23329162597656, 0.489349365234375, 106.38867950439453, 0.1646728515625, 0.28440093994140625, 108.21613311767578, 104.25502014160156, 0.28347015380859375, 0.19936752319335938, 0.3317604064941406, 0.8034286499023438, 0.5922126770019531, 108.79971313476562, 0.5234489440917969, 110.48829650878906, 0.5313301086425781, 0.6847991943359375, 0.15633392333984375, 0.6410598754882812, 0.3419036865234375, 111.71697998046875, 0.17712020874023438, 0.4633216857910156, 0.20256423950195312, 0.1159820556640625, 0.3460121154785156, 104.99812316894531, 0.30966949462890625, 0.5, 106.28536224365234, 0.4602165222167969, 106.5767822265625, 1.0141410827636719, 0.4168701171875, 0.25362396240234375, 110.3294677734375, 353.3695983886719, 104.21025085449219, 0.2899131774902344, 0.9260025024414062, 0.6209831237792969, 0.49147796630859375, 104.62800598144531, 0.18107223510742188, 0.5385169982910156, 0.3507270812988281, 0.2969856262207031, 0.19763946533203125, 0.217437744140625, 0.2541961669921875, 351.03338623046875, 0.756683349609375, 0.2910118103027344, 0.3731956481933594, 0.20698165893554688, 0.3689994812011719, 0.23653030395507812, 110.7878646850586, 111.63322448730469, 102.24415588378906, 0.5123710632324219, 0.7880325317382812, 0.6145553588867188, 0.037334442138671875, 108.49366760253906, 0.7547988891601562, 111.7094955444336, 111.32182312011719, 0.46508026123046875, 104.64260864257812, 0.3727378845214844, 355.87396240234375, 0.2564277648925781, 0.2883872985839844, 0.5616645812988281, 105.73676300048828, 0.4728240966796875, 105.08935546875, 0.5677375793457031, 106.76130676269531, 0.33376312255859375, 0.2726249694824219, 0.7137794494628906, 354.98541259765625, 0.7462158203125, 0.048023223876953125, 110.1530532836914, 0.0406951904296875, 0.3408699035644531, 0.3641548156738281, 0.05974578857421875, 103.21981811523438, 105.66228485107422, 108.15336608886719, 105.04208374023438, 0.01326751708984375, 0.3593101501464844, 0.11052322387695312, 0.3820075988769531, 0.4010047912597656, 0.09263229370117188, 0.13673782348632812, 0.21527099609375, 0.4899177551269531, 0.5435600280761719, 0.8487052917480469, 0.07686233520507812, 0.30805206298828125, 0.09358596801757812, 0.5794258117675781, 0.013538360595703125, 0.23499679565429688, 101.93243408203125, 0.14805984497070312, 0.5561294555664062], "mean_td_error": 37.294830322265625, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 26727.0, "diff_num_grad_updates_vs_sampler_policy": 26726.0}}, "num_env_steps_sampled": 90180, "num_env_steps_trained": 6842112, "num_agent_steps_sampled": 90180, "num_agent_steps_trained": 6842112, "last_target_update_ts": 90180, "num_target_updates": 26727}, "sampler_results": {"episode_reward_max": -156.73972097039223, "episode_reward_min": -166.99343679845333, "episode_reward_mean": -160.53335815891623, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-159.25795275717974, -160.70894014835358, -163.50751739740372, -156.82570430636406, -158.63912008702755, -158.23399524390697, -166.99343679845333, -166.2922261506319, -156.73972097039223, -158.13496772944927], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1495080767806936, "mean_inference_ms": 2.370609497461668, "mean_action_processing_ms": 0.22403262125581666, "mean_env_wait_ms": 2.9754040313494317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.73972097039223, "episode_reward_min": -166.99343679845333, "episode_reward_mean": -160.53335815891623, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-159.25795275717974, -160.70894014835358, -163.50751739740372, -156.82570430636406, -158.63912008702755, -158.23399524390697, -166.99343679845333, -166.2922261506319, -156.73972097039223, -158.13496772944927], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1495080767806936, "mean_inference_ms": 2.370609497461668, "mean_action_processing_ms": 0.22403262125581666, "mean_env_wait_ms": 2.9754040313494317, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 90180, "num_agent_steps_trained": 6842112, "num_env_steps_sampled": 90180, "num_env_steps_trained": 6842112, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 90180, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 90180, "timers": {"training_iteration_time_ms": 159.581, "load_time_ms": 0.323, "load_throughput": 791436.444, "learn_time_ms": 25.478, "learn_throughput": 10047.929, "synch_weights_time_ms": 5.507}, "counters": {"num_env_steps_sampled": 90180, "num_env_steps_trained": 6842112, "num_agent_steps_sampled": 90180, "num_agent_steps_trained": 6842112, "last_target_update_ts": 90180, "num_target_updates": 26727}, "done": false, "episodes_total": 930, "training_iteration": 90, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-45-54", "timestamp": 1675953954, "time_this_iter_s": 56.28673553466797, "time_total_s": 4259.294965267181, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2910>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508820>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4259.294965267181, "timesteps_since_restore": 0, "iterations_since_restore": 90, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 44.65, "ram_util_percent": 92.50128205128205}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.2319699376821518, "actor_loss": 110.2365493774414, "critic_loss": 1.6871682405471802, "alpha_loss": -0.8517594337463379, "alpha_value": 0.02542930468916893, "log_alpha_value": -3.6718530654907227, "target_entropy": -5.0, "policy_t": -0.32333558797836304, "mean_q": -110.07645416259766, "max_q": -103.4893798828125, "min_q": -115.15715026855469}, "td_error": [0.9580154418945312, 0.2105865478515625, 0.44561767578125, 0.43804931640625, 112.64964294433594, 0.5025749206542969, 0.27819061279296875, 0.4778480529785156, 0.5252342224121094, 111.15821075439453, 0.53253173828125, 110.83624267578125, 0.2360076904296875, 0.4916114807128906, 108.25992584228516, 353.61309814453125, 0.24710845947265625, 111.22064208984375, 0.428802490234375, 110.79167175292969, 0.19889450073242188, 0.0915374755859375, 0.6508712768554688, 0.6305694580078125, 106.47525787353516, 0.09796524047851562, 356.84771728515625, 110.45817565917969, 109.89808654785156, 0.6267013549804688, 0.5354080200195312, 352.41082763671875, 0.3688316345214844, 0.22716903686523438, 0.7682418823242188, 105.94023895263672, 0.5929832458496094, 0.2558135986328125, 102.96101379394531, 0.2514076232910156, 0.5172080993652344, 107.61219787597656, 102.39566040039062, 0.07155990600585938, 0.5414657592773438, 0.1085662841796875, 109.48158264160156, 0.10796737670898438, 112.64754486083984, 0.058063507080078125, 0.4354705810546875, 0.23093414306640625, 107.59349060058594, 0.3527069091796875, 110.44132995605469, 356.15728759765625, 112.20414733886719, 0.24914932250976562, 105.7882080078125, 110.38433837890625, 0.30084991455078125, 106.74288177490234, 0.187957763671875, 0.18044281005859375, 103.87380981445312, 0.13228607177734375, 0.1233978271484375, 0.3621025085449219, 0.21086502075195312, 1.3017349243164062, 0.8791618347167969, 101.46513366699219, 112.21051025390625, 109.82185363769531, 0.13580703735351562, 0.5033302307128906, 0.20079803466796875, 0.18497467041015625, 0.8157196044921875, 0.37619781494140625, 0.3661041259765625, 0.272979736328125, 0.7051200866699219, 0.5877571105957031, 0.4929656982421875, 0.21307373046875, 0.251708984375, 0.3567619323730469, 111.93092346191406, 0.5896224975585938, 0.15362167358398438, 0.2119293212890625, 0.08532333374023438, 110.80352020263672, 0.285552978515625, 0.5890426635742188, 0.19524383544921875, 0.10260391235351562, 109.11080169677734, 110.47396850585938, 0.3090972900390625, 106.89265441894531, 109.52981567382812, 0.3819122314453125, 0.63385009765625, 107.35769653320312, 0.3999824523925781, 0.2844123840332031, 0.5246315002441406, 0.4350700378417969, 111.43089294433594, 0.14455032348632812, 0.3190650939941406, 104.7745361328125, 0.08860015869140625, 0.14809417724609375, 109.67562866210938, 0.347015380859375, 103.52901458740234, 0.7845382690429688, 0.6672210693359375, 0.484100341796875, 0.0923309326171875, 106.38533020019531, 0.6141624450683594, 113.01384735107422, 109.48158264160156, 0.4023590087890625, 106.64990234375, 0.3804206848144531, 0.30389404296875, 0.5584487915039062, 103.31294250488281, 102.62531280517578, 0.4455757141113281, 105.99356079101562, 0.5653038024902344, 0.056987762451171875, 0.13360977172851562, 0.0342864990234375, 108.54036712646484, 0.6272850036621094, 111.34815216064453, 0.32193756103515625, 106.62350463867188, 0.5547142028808594, 0.4893531799316406, 0.2165069580078125, 107.08126068115234, 0.13385009765625, 112.32931518554688, 0.21595382690429688, 0.6366310119628906, 107.48287200927734, 104.65196228027344, 0.2114410400390625, 0.26570892333984375, 0.3389167785644531, 0.2911224365234375, 0.2589149475097656, 0.7458572387695312, 0.8230438232421875, 0.048801422119140625, 0.2113800048828125, 110.55409240722656, 0.060306549072265625, 0.4166259765625, 356.365234375, 0.1556549072265625, 0.64208984375, 108.34385681152344, 0.3017997741699219, 0.472991943359375, 0.26019287109375, 355.8661804199219, 355.58868408203125, 0.30681610107421875, 0.2755699157714844, 110.9527359008789, 108.4874038696289, 0.579132080078125, 0.6233329772949219, 0.7686843872070312, 109.82049560546875, 356.0811767578125, 107.30645751953125, 110.08014678955078, 108.24356079101562, 0.16082000732421875, 113.01774597167969, 0.39513397216796875, 0.6257743835449219, 352.83367919921875, 0.17625045776367188, 107.88388061523438, 108.2692642211914, 0.60076904296875, 0.6401481628417969, 0.4901275634765625, 0.5240631103515625, 111.96786499023438, 358.3582763671875, 0.036876678466796875, 0.4666786193847656, 0.26505279541015625, 0.7155990600585938, 112.12458801269531, 0.20561981201171875, 0.6697807312011719, 111.80078125, 102.02798461914062, 0.6104850769042969, 0.31816864013671875, 0.7436599731445312, 0.508575439453125, 0.6202545166015625, 0.13398361206054688, 110.63459777832031, 0.5504112243652344, 0.08156967163085938, 104.66691589355469, 0.9964599609375, 0.15392303466796875, 0.33154296875, 0.3572959899902344, 111.0501480102539, 111.43089294433594, 0.6659965515136719, 111.8206787109375, 0.25363922119140625, 0.197418212890625, 0.053333282470703125, 0.0863494873046875, 0.1914520263671875, 0.13988494873046875, 0.065338134765625, 112.22522735595703, 104.55079650878906, 0.5542144775390625, 0.16827392578125, 0.11064910888671875, 111.45382690429688, 0.6435089111328125, 109.874755859375, 0.3259429931640625, 0.9064788818359375, 0.4113426208496094, 0.0541839599609375, 111.02085876464844, 0.5674972534179688, 102.96101379394531, 0.870086669921875, 0.30712890625, 112.42227172851562, 355.7115478515625, 0.6554183959960938], "mean_td_error": 48.217445373535156, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 27061.0, "diff_num_grad_updates_vs_sampler_policy": 27060.0}}, "num_env_steps_sampled": 91182, "num_env_steps_trained": 6927616, "num_agent_steps_sampled": 91182, "num_agent_steps_trained": 6927616, "last_target_update_ts": 91182, "num_target_updates": 27061}, "sampler_results": {"episode_reward_max": -157.62588857859373, "episode_reward_min": -175.4449739009142, "episode_reward_mean": -165.10529938475653, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-173.59496247768402, -157.62588857859373, -163.65194728970528, -173.4839808344841, -163.4090384989977, -160.20602338016033, -158.4435018748045, -175.4449739009142, -158.57148788124323, -163.02650000154972, -168.69998851418495], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.151831271387451, "mean_inference_ms": 2.374597188984983, "mean_action_processing_ms": 0.22474329743525576, "mean_env_wait_ms": 2.976213228665286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -157.62588857859373, "episode_reward_min": -175.4449739009142, "episode_reward_mean": -165.10529938475653, "episode_len_mean": 100.0, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-173.59496247768402, -157.62588857859373, -163.65194728970528, -173.4839808344841, -163.4090384989977, -160.20602338016033, -158.4435018748045, -175.4449739009142, -158.57148788124323, -163.02650000154972, -168.69998851418495], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.151831271387451, "mean_inference_ms": 2.374597188984983, "mean_action_processing_ms": 0.22474329743525576, "mean_env_wait_ms": 2.976213228665286, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 91182, "num_agent_steps_trained": 6927616, "num_env_steps_sampled": 91182, "num_env_steps_trained": 6927616, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 91182, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 91182, "timers": {"training_iteration_time_ms": 160.068, "load_time_ms": 0.257, "load_throughput": 997067.345, "learn_time_ms": 25.783, "learn_throughput": 9929.201, "synch_weights_time_ms": 5.334}, "counters": {"num_env_steps_sampled": 91182, "num_env_steps_trained": 6927616, "num_agent_steps_sampled": 91182, "num_agent_steps_trained": 6927616, "last_target_update_ts": 91182, "num_target_updates": 27061}, "done": false, "episodes_total": 941, "training_iteration": 91, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-46-47", "timestamp": 1675954007, "time_this_iter_s": 52.957135915756226, "time_total_s": 4312.252101182938, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2b20>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7790>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4312.252101182938, "timesteps_since_restore": 0, "iterations_since_restore": 91, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.03287671232877, "ram_util_percent": 92.83561643835617}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.6347337961196899, "actor_loss": 111.0171127319336, "critic_loss": 1.3677949905395508, "alpha_loss": -2.370084524154663, "alpha_value": 0.02389748953282833, "log_alpha_value": -3.7339818477630615, "target_entropy": -5.0, "policy_t": -0.3029235005378723, "mean_q": -110.9451904296875, "max_q": -104.00039672851562, "min_q": -115.90410614013672}, "td_error": [108.30039978027344, 0.5301055908203125, 0.7939186096191406, 111.86482238769531, 106.04401397705078, 113.156005859375, 112.42701721191406, 0.64788818359375, 112.1494140625, 0.22433853149414062, 0.8639030456542969, 0.5250129699707031, 0.23021316528320312, 0.052349090576171875, 0.6341285705566406, 0.4876594543457031, 0.12306976318359375, 104.40538787841797, 0.6981163024902344, 0.37529754638671875, 0.7012519836425781, 113.42935943603516, 109.51507568359375, 0.22542190551757812, 0.31937408447265625, 0.24212646484375, 0.4734077453613281, 0.4195289611816406, 0.2687721252441406, 0.4134979248046875, 0.3780860900878906, 0.5866966247558594, 0.2761192321777344, 358.6922607421875, 0.35196685791015625, 110.3255615234375, 0.8345108032226562, 0.2976493835449219, 0.587615966796875, 1.3758773803710938, 111.48945617675781, 0.09593963623046875, 106.95011138916016, 0.18555068969726562, 0.6379737854003906, 104.34033203125, 0.034755706787109375, 109.47114562988281, 0.3897857666015625, 0.28574371337890625, 111.27969360351562, 0.5791168212890625, 0.3478546142578125, 0.3431053161621094, 0.7464866638183594, 0.07309341430664062, 0.3126335144042969, 0.37174224853515625, 0.4703865051269531, 0.41364288330078125, 0.8697967529296875, 0.21906280517578125, 0.18644332885742188, 0.744171142578125, 111.27535247802734, 107.69082641601562, 0.0468597412109375, 0.17897415161132812, 0.018527984619140625, 0.22214508056640625, 0.6329994201660156, 0.8695411682128906, 112.08241271972656, 0.9748649597167969, 0.6416358947753906, 109.01099395751953, 0.20262908935546875, 0.4404792785644531, 0.8765182495117188, 0.44004058837890625, 0.7581024169921875, 0.06549835205078125, 0.28594970703125, 106.64022827148438, 112.44438171386719, 0.7978096008300781, 112.65728759765625, 111.13973999023438, 105.54716491699219, 0.1804046630859375, 0.8923912048339844, 0.10450363159179688, 106.87345123291016, 0.3017005920410156, 0.15615081787109375, 0.427398681640625, 0.8113212585449219, 0.9459419250488281, 107.72254943847656, 358.6709899902344, 0.3676033020019531, 0.4067840576171875, 0.3652381896972656, 113.93484497070312, 0.3410224914550781, 111.28886413574219, 0.1907501220703125, 0.5121841430664062, 0.2760276794433594, 0.3039741516113281, 111.90281677246094, 0.049266815185546875, 352.86614990234375, 104.65034484863281, 104.4442138671875, 107.91260528564453, 0.18295669555664062, 0.5414581298828125, 103.57206726074219, 111.29339599609375, 0.2647285461425781, 108.57967376708984, 0.06962966918945312, 0.5312728881835938, 0.8051033020019531, 0.18466567993164062, 112.02355194091797, 0.6972694396972656, 108.57518005371094, 0.4824256896972656, 0.7675437927246094, 1.2187843322753906, 108.52226257324219, 0.39434814453125, 102.23257446289062, 109.29975891113281, 0.354278564453125, 112.06575012207031, 0.09330368041992188, 0.07546615600585938, 107.45805358886719, 0.5863761901855469, 112.00094604492188, 0.4417724609375, 0.4130287170410156, 0.3785743713378906, 110.72476196289062, 0.18125534057617188, 0.22636032104492188, 112.86299133300781, 0.65142822265625, 0.17545700073242188, 0.3881568908691406, 0.20190048217773438, 0.9860382080078125, 0.2772178649902344, 0.7865371704101562, 0.1693878173828125, 113.16128540039062, 105.26558685302734, 109.00282287597656, 1.2874565124511719, 0.2548561096191406, 0.07009124755859375, 0.5076103210449219, 0.4621696472167969, 0.2134857177734375, 0.16476058959960938, 0.4896202087402344, 111.05158996582031, 0.2618217468261719, 0.4880409240722656, 0.3940696716308594, 0.5619850158691406, 113.59207153320312, 0.4318580627441406, 0.13349533081054688, 103.42338562011719, 0.4229164123535156, 109.75265502929688, 112.74712371826172, 112.18724822998047, 0.8113250732421875, 0.9785537719726562, 0.5197715759277344, 0.4674339294433594, 0.4543724060058594, 0.19451141357421875, 113.40402221679688, 0.9657211303710938, 0.19217300415039062, 106.1185302734375, 0.9079170227050781, 110.41433715820312, 0.18818283081054688, 0.250732421875, 0.24329376220703125, 0.20542144775390625, 0.7620010375976562, 0.20832061767578125, 104.68515014648438, 0.31299591064453125, 0.6093826293945312, 0.5414772033691406, 110.95833587646484, 0.045955657958984375, 112.45053100585938, 0.485504150390625, 0.4067649841308594, 1.0720634460449219, 0.11769866943359375, 0.7228889465332031, 0.6567153930664062, 0.6244087219238281, 0.3016510009765625, 0.6263961791992188, 108.36868286132812, 0.415252685546875, 356.7315368652344, 0.16612625122070312, 0.4318695068359375, 0.209075927734375, 0.6309432983398438, 0.19366455078125, 0.23721694946289062, 356.9630126953125, 0.22876358032226562, 107.49797058105469, 0.15113449096679688, 112.78092956542969, 111.4395980834961, 0.416046142578125, 0.40143585205078125, 0.23618698120117188, 0.20746994018554688, 111.36380767822266, 0.1714324951171875, 107.45805358886719, 0.2948493957519531, 0.018646240234375, 0.6578483581542969, 0.038623809814453125, 103.47532653808594, 0.1999359130859375, 0.8658103942871094, 0.36748504638671875, 0.16925048828125, 356.9630126953125, 0.5667839050292969, 0.3689918518066406, 0.5252571105957031, 111.0147705078125, 0.3322410583496094, 103.2091064453125, 0.4726219177246094, 0.47028350830078125], "mean_td_error": 38.14299774169922, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 27395.0, "diff_num_grad_updates_vs_sampler_policy": 27394.0}}, "num_env_steps_sampled": 92184, "num_env_steps_trained": 7013120, "num_agent_steps_sampled": 92184, "num_agent_steps_trained": 7013120, "last_target_update_ts": 92184, "num_target_updates": 27395}, "sampler_results": {"episode_reward_max": -156.71330001950264, "episode_reward_min": -175.22207672894, "episode_reward_mean": -165.44531422439547, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-165.96954829245806, -159.57600800693035, -167.9090326204896, -156.71330001950264, -175.22207672894, -165.48352535814047, -171.91609977185726, -164.62368296086788, -161.59455426037312], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1503810262489185, "mean_inference_ms": 2.3722372279850514, "mean_action_processing_ms": 0.22436720904887877, "mean_env_wait_ms": 2.9723903036712906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.71330001950264, "episode_reward_min": -175.22207672894, "episode_reward_mean": -165.44531422439547, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-165.96954829245806, -159.57600800693035, -167.9090326204896, -156.71330001950264, -175.22207672894, -165.48352535814047, -171.91609977185726, -164.62368296086788, -161.59455426037312], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1503810262489185, "mean_inference_ms": 2.3722372279850514, "mean_action_processing_ms": 0.22436720904887877, "mean_env_wait_ms": 2.9723903036712906, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 92184, "num_agent_steps_trained": 7013120, "num_env_steps_sampled": 92184, "num_env_steps_trained": 7013120, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 92184, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 92184, "timers": {"training_iteration_time_ms": 153.792, "load_time_ms": 0.291, "load_throughput": 879179.419, "learn_time_ms": 24.723, "learn_throughput": 10354.708, "synch_weights_time_ms": 5.748}, "counters": {"num_env_steps_sampled": 92184, "num_env_steps_trained": 7013120, "num_agent_steps_sampled": 92184, "num_agent_steps_trained": 7013120, "last_target_update_ts": 92184, "num_target_updates": 27395}, "done": false, "episodes_total": 950, "training_iteration": 92, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-47-40", "timestamp": 1675954060, "time_this_iter_s": 52.25436735153198, "time_total_s": 4364.50646853447, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be58160>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516310>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4364.50646853447, "timesteps_since_restore": 0, "iterations_since_restore": 92, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 38.668055555555554, "ram_util_percent": 93.0638888888889}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.029291346669197083, "actor_loss": 112.14824676513672, "critic_loss": 1.3056011199951172, "alpha_loss": 0.11108458042144775, "alpha_value": 0.022541290149092674, "log_alpha_value": -3.7924065589904785, "target_entropy": -5.0, "policy_t": -0.318234920501709, "mean_q": -112.0117416381836, "max_q": -105.46192932128906, "min_q": -116.74221801757812}, "td_error": [0.14957809448242188, 0.4578094482421875, 0.4094276428222656, 0.2600746154785156, 0.2870368957519531, 0.3179130554199219, 357.460693359375, 358.13079833984375, 0.30303955078125, 111.8510971069336, 0.21067428588867188, 0.40038299560546875, 0.3081550598144531, 107.24136352539062, 0.13813400268554688, 0.038227081298828125, 0.4220314025878906, 0.18355178833007812, 0.2947502136230469, 0.12998199462890625, 105.0361557006836, 0.5780487060546875, 0.5309066772460938, 0.6061134338378906, 0.5212821960449219, 0.19240188598632812, 1.1073837280273438, 108.28260803222656, 361.41375732421875, 0.11914443969726562, 0.54888916015625, 0.26271820068359375, 111.7903060913086, 0.282257080078125, 0.318695068359375, 0.27454376220703125, 0.7672882080078125, 105.74775695800781, 0.47089385986328125, 0.046611785888671875, 0.5140037536621094, 0.5297737121582031, 0.6978302001953125, 0.12843704223632812, 0.5245246887207031, 0.4367179870605469, 0.43463897705078125, 108.28260803222656, 0.07433319091796875, 358.08087158203125, 0.20334243774414062, 0.1868133544921875, 111.77330780029297, 0.4757080078125, 0.03627777099609375, 0.036327362060546875, 0.3408088684082031, 0.6848793029785156, 109.53181457519531, 0.2006683349609375, 0.5275344848632812, 0.23250579833984375, 0.29994964599609375, 1.2442741394042969, 111.47296905517578, 0.42411041259765625, 0.6080284118652344, 0.1761932373046875, 0.3393974304199219, 0.2080535888671875, 0.21300888061523438, 0.8045387268066406, 108.23348999023438, 0.20020675659179688, 0.5725364685058594, 355.8133239746094, 114.30023956298828, 0.2740440368652344, 0.021404266357421875, 0.5200843811035156, 0.1373748779296875, 106.49053192138672, 0.07930755615234375, 0.068084716796875, 0.5792884826660156, 0.2795448303222656, 105.52407836914062, 0.2826652526855469, 113.84764099121094, 0.9709739685058594, 0.5599288940429688, 108.15718078613281, 112.48328399658203, 0.3811149597167969, 0.38724517822265625, 114.25393676757812, 112.17813873291016, 0.9072532653808594, 0.3243675231933594, 0.2662696838378906, 0.15005111694335938, 0.5915985107421875, 0.2773475646972656, 0.7342681884765625, 0.26589202880859375, 0.2737617492675781, 114.02554321289062, 113.34042358398438, 0.24895095825195312, 0.2503318786621094, 0.7634620666503906, 357.681884765625, 110.56400299072266, 0.19155120849609375, 0.10445022583007812, 0.31212615966796875, 0.4853057861328125, 0.3467826843261719, 0.1210479736328125, 0.0976715087890625, 112.20634460449219, 104.40673828125, 0.15374755859375, 0.12504959106445312, 0.2617225646972656, 114.09754943847656, 113.592529296875, 0.13037109375, 109.67062377929688, 112.77725219726562, 0.7860031127929688, 0.40643310546875, 109.01695251464844, 0.19002532958984375, 0.10462188720703125, 0.4669189453125, 107.16351318359375, 0.19429397583007812, 113.47767639160156, 0.18862533569335938, 0.15267562866210938, 0.18986892700195312, 0.2854194641113281, 0.10837173461914062, 0.47075653076171875, 0.7064323425292969, 0.4899177551269531, 111.05197143554688, 0.24598312377929688, 0.4953269958496094, 0.624420166015625, 0.5117912292480469, 0.43512725830078125, 0.16331863403320312, 109.87017822265625, 0.8054580688476562, 113.23446655273438, 0.18480300903320312, 110.37916564941406, 0.4930419921875, 0.4052619934082031, 112.7733383178711, 0.3885231018066406, 0.2535667419433594, 0.2883033752441406, 357.1230773925781, 109.87017822265625, 0.18160247802734375, 0.588165283203125, 0.4959259033203125, 0.2051544189453125, 0.4894065856933594, 0.4709625244140625, 112.05013275146484, 0.22897720336914062, 0.14268112182617188, 0.6826858520507812, 0.5832138061523438, 0.14577865600585938, 0.2943687438964844, 0.1009521484375, 111.89085388183594, 0.3654060363769531, 114.03509521484375, 0.1313323974609375, 0.09334945678710938, 0.1979522705078125, 0.3104591369628906, 0.5040283203125, 0.057567596435546875, 110.54464721679688, 0.6479644775390625, 0.44962310791015625, 114.17692565917969, 0.22477340698242188, 0.6130790710449219, 109.80545806884766, 0.18473434448242188, 107.63092041015625, 0.14646530151367188, 105.74200439453125, 0.2924690246582031, 106.75601196289062, 0.6471481323242188, 111.0325927734375, 0.5052909851074219, 0.7668113708496094, 0.14654922485351562, 0.044895172119140625, 0.6732444763183594, 109.8942642211914, 0.23519515991210938, 0.5120048522949219, 0.25689697265625, 0.3094596862792969, 0.1197967529296875, 113.74667358398438, 0.12715530395507812, 0.5842666625976562, 0.3635406494140625, 109.06109619140625, 0.2888946533203125, 105.74200439453125, 0.33362579345703125, 110.3902816772461, 0.11785125732421875, 111.8369140625, 104.24303436279297, 0.048816680908203125, 0.4957084655761719, 0.34062957763671875, 0.07663345336914062, 0.5718955993652344, 0.3434333801269531, 0.08243942260742188, 0.2369537353515625, 0.20035171508789062, 111.37181091308594, 109.09125518798828, 0.431793212890625, 0.012882232666015625, 1.5819931030273438, 0.158111572265625, 0.3651847839355469, 356.10479736328125, 0.2645225524902344, 0.3430061340332031, 110.28494262695312, 109.2698974609375, 109.62757873535156, 0.306243896484375, 0.2623329162597656, 0.35202789306640625, 109.18849182128906, 0.4332008361816406, 0.44261932373046875], "mean_td_error": 37.2800178527832, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 27729.0, "diff_num_grad_updates_vs_sampler_policy": 27728.0}}, "num_env_steps_sampled": 93186, "num_env_steps_trained": 7098624, "num_agent_steps_sampled": 93186, "num_agent_steps_trained": 7098624, "last_target_update_ts": 93186, "num_target_updates": 27729}, "sampler_results": {"episode_reward_max": 238.12474328279495, "episode_reward_min": -176.24535179138184, "episode_reward_mean": -125.79478149590167, "episode_len_mean": 91.54545454545455, "episode_media": {}, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-168.18348839879036, -156.66778661310673, -155.13520281016827, 238.12474328279495, -176.24535179138184, -161.23434637486935, -157.87939385324717, -169.99454993009567, -155.0685104727745, -158.8690266609192, -162.58968283236027], "episode_lengths": [100, 100, 100, 7, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1603782725080254, "mean_inference_ms": 2.385702065161388, "mean_action_processing_ms": 0.22589508560454455, "mean_env_wait_ms": 2.986991892835226, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": 238.12474328279495, "episode_reward_min": -176.24535179138184, "episode_reward_mean": -125.79478149590167, "episode_len_mean": 91.54545454545455, "episodes_this_iter": 11, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-168.18348839879036, -156.66778661310673, -155.13520281016827, 238.12474328279495, -176.24535179138184, -161.23434637486935, -157.87939385324717, -169.99454993009567, -155.0685104727745, -158.8690266609192, -162.58968283236027], "episode_lengths": [100, 100, 100, 7, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1603782725080254, "mean_inference_ms": 2.385702065161388, "mean_action_processing_ms": 0.22589508560454455, "mean_env_wait_ms": 2.986991892835226, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 93186, "num_agent_steps_trained": 7098624, "num_env_steps_sampled": 93186, "num_env_steps_trained": 7098624, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 93186, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 93186, "timers": {"training_iteration_time_ms": 152.447, "load_time_ms": 0.279, "load_throughput": 918355.99, "learn_time_ms": 24.607, "learn_throughput": 10403.679, "synch_weights_time_ms": 6.343}, "counters": {"num_env_steps_sampled": 93186, "num_env_steps_trained": 7098624, "num_agent_steps_sampled": 93186, "num_agent_steps_trained": 7098624, "last_target_update_ts": 93186, "num_target_updates": 27729}, "done": false, "episodes_total": 961, "training_iteration": 93, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-48-32", "timestamp": 1675954112, "time_this_iter_s": 52.6350040435791, "time_total_s": 4417.141472578049, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef580>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4417.141472578049, "timesteps_since_restore": 0, "iterations_since_restore": 93, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.330555555555556, "ram_util_percent": 92.93194444444444}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.12419097870588303, "actor_loss": 113.26934814453125, "critic_loss": 1.4547345638275146, "alpha_loss": 0.4691053628921509, "alpha_value": 0.022884633392095566, "log_alpha_value": -3.777289628982544, "target_entropy": -5.0, "policy_t": -0.25671499967575073, "mean_q": -113.15587615966797, "max_q": -106.328369140625, "min_q": -118.00061798095703}, "td_error": [0.25612640380859375, 0.48260498046875, 359.5501708984375, 0.7920761108398438, 114.7314453125, 106.36163330078125, 0.06576919555664062, 111.30043029785156, 112.87835693359375, 0.23988723754882812, 0.3748741149902344, 0.3286247253417969, 0.11568069458007812, 0.77374267578125, 0.1079254150390625, 114.10106658935547, 0.8455543518066406, 0.12945556640625, 0.22403335571289062, 108.79049682617188, 109.32632446289062, 0.3936958312988281, 0.39093780517578125, 0.07066726684570312, 0.5983543395996094, 0.23662948608398438, 109.77064514160156, 0.14944076538085938, 110.44659423828125, 0.08352279663085938, 0.4791526794433594, 0.2645378112792969, 0.23023605346679688, 0.19556808471679688, 112.26394653320312, 0.977081298828125, 356.0391845703125, 0.6792869567871094, 0.50830078125, 0.14432907104492188, 0.119384765625, 0.398101806640625, 114.02217102050781, 0.46543121337890625, 0.21349334716796875, 111.99073791503906, 114.38070678710938, 0.246429443359375, 0.20029067993164062, 0.353271484375, 0.8288536071777344, 107.31764221191406, 0.17484664916992188, 0.372039794921875, 112.76638793945312, 112.59886932373047, 0.6239967346191406, 0.177337646484375, 0.8707923889160156, 0.34647369384765625, 0.9716529846191406, 0.16292190551757812, 0.2607383728027344, 110.03421020507812, 0.47052764892578125, 111.45320129394531, 114.4659652709961, 0.2930564880371094, 0.45574188232421875, 0.22332763671875, 0.43456268310546875, 113.65731811523438, 0.09109115600585938, 0.31024932861328125, 0.6966056823730469, 0.3414726257324219, 0.439208984375, 0.13479232788085938, 0.055908203125, 355.8061218261719, 108.35768127441406, 0.14649200439453125, 0.8068122863769531, 0.04212188720703125, 0.09447860717773438, 0.40105438232421875, 0.4086494445800781, 0.6909217834472656, 0.2759056091308594, 0.033660888671875, 108.84144592285156, 0.4812469482421875, 112.15528869628906, 0.2403717041015625, 0.5362396240234375, 0.2255401611328125, 112.76692199707031, 0.19269180297851562, 114.55029296875, 0.4158821105957031, 107.32516479492188, 114.06413269042969, 0.15505599975585938, 358.6422119140625, 0.418182373046875, 0.23169326782226562, 0.2978019714355469, 0.3101081848144531, 0.5219688415527344, 113.28858947753906, 0.18456649780273438, 108.37124633789062, 0.23979949951171875, 105.27023315429688, 0.5419044494628906, 111.15406036376953, 108.35768127441406, 106.78717041015625, 0.2782402038574219, 0.41225433349609375, 0.33795928955078125, 111.80618286132812, 0.66949462890625, 0.5533828735351562, 112.80340576171875, 0.2393646240234375, 115.37196350097656, 112.23617553710938, 0.19478225708007812, 111.17913818359375, 0.35062408447265625, 113.51103210449219, 0.7060394287109375, 114.95535278320312, 0.22272491455078125, 0.3753204345703125, 0.2528839111328125, 0.5289344787597656, 110.18840026855469, 0.6883049011230469, 105.7690658569336, 114.43465423583984, 112.34959411621094, 0.5685386657714844, 110.557861328125, 355.40252685546875, 0.9615211486816406, 0.4154014587402344, 112.84085083007812, 105.33708190917969, 0.24860000610351562, 110.50811767578125, 0.6646232604980469, 0.2507057189941406, 0.615753173828125, 115.68974304199219, 0.1258544921875, 0.5246849060058594, 0.4170494079589844, 0.5486869812011719, 0.062358856201171875, 0.8678665161132812, 0.23467254638671875, 0.24602890014648438, 0.3619422912597656, 108.51228332519531, 0.3215675354003906, 0.13660049438476562, 0.62396240234375, 112.98664855957031, 0.6837921142578125, 112.64611053466797, 0.8418312072753906, 0.9000358581542969, 0.41558837890625, 0.62841796875, 0.2987480163574219, 114.44763946533203, 112.88809204101562, 0.7280654907226562, 105.07502746582031, 0.5647773742675781, 0.13003921508789062, 0.5205764770507812, 0.24895095825195312, 0.175689697265625, 0.39640045166015625, 0.8415603637695312, 0.9037704467773438, 110.14122772216797, 0.12224578857421875, 0.2648200988769531, 114.35516357421875, 0.047679901123046875, 0.3118934631347656, 0.4224586486816406, 0.2730598449707031, 0.8213119506835938, 0.598785400390625, 0.1048126220703125, 0.5761260986328125, 111.57957458496094, 0.12091445922851562, 0.211334228515625, 0.07480621337890625, 114.43074798583984, 0.2613258361816406, 0.13129806518554688, 356.674072265625, 0.286346435546875, 0.8219375610351562, 0.17970657348632812, 0.3680419921875, 112.98664855957031, 0.6528778076171875, 114.92959594726562, 0.5895156860351562, 0.031291961669921875, 0.3743858337402344, 0.7376632690429688, 0.45671844482421875, 0.3654899597167969, 0.7962455749511719, 109.52456665039062, 0.23929595947265625, 0.1970367431640625, 0.01198577880859375, 106.56675720214844, 107.76675415039062, 0.09978485107421875, 0.1488037109375, 0.3866767883300781, 0.3129920959472656, 0.4347381591796875, 113.00140380859375, 114.06178283691406, 113.74141693115234, 0.4008979797363281, 0.3360862731933594, 106.70411682128906, 359.5750732421875, 0.5101737976074219, 0.0800018310546875, 112.89185333251953, 115.34789276123047, 0.33361053466796875, 0.253875732421875, 115.12544250488281, 0.4984169006347656, 0.22254562377929688, 0.12419891357421875, 0.6102294921875, 0.515594482421875, 0.8558998107910156, 0.9764671325683594, 0.6759109497070312], "mean_td_error": 40.953765869140625, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 28192.0, "diff_num_grad_updates_vs_sampler_policy": 28191.0}}, "num_env_steps_sampled": 94187, "num_env_steps_trained": 7217152, "num_agent_steps_sampled": 94187, "num_agent_steps_trained": 7217152, "last_target_update_ts": 94187, "num_target_updates": 28192}, "sampler_results": {"episode_reward_max": -154.56762316077948, "episode_reward_min": -178.36534713208675, "episode_reward_mean": -163.2691681749291, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-154.56762316077948, -157.97888205945492, -168.01060539484024, -155.74629651755095, -178.36534713208675, -160.69070971012115, -160.33285997062922, -173.4498615860939, -160.2803280428052], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2149404141522893, "mean_inference_ms": 2.4628728493502248, "mean_action_processing_ms": 0.23445714047499497, "mean_env_wait_ms": 3.0789653348426285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -154.56762316077948, "episode_reward_min": -178.36534713208675, "episode_reward_mean": -163.2691681749291, "episode_len_mean": 100.0, "episodes_this_iter": 9, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-154.56762316077948, -157.97888205945492, -168.01060539484024, -155.74629651755095, -178.36534713208675, -160.69070971012115, -160.33285997062922, -173.4498615860939, -160.2803280428052], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.2149404141522893, "mean_inference_ms": 2.4628728493502248, "mean_action_processing_ms": 0.23445714047499497, "mean_env_wait_ms": 3.0789653348426285, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 94187, "num_agent_steps_trained": 7217152, "num_env_steps_sampled": 94187, "num_env_steps_trained": 7217152, "num_env_steps_sampled_this_iter": 1001, "num_env_steps_trained_this_iter": 118528, "timesteps_total": 94187, "num_steps_trained_this_iter": 118528, "agent_timesteps_total": 94187, "timers": {"training_iteration_time_ms": 150.844, "load_time_ms": 0.266, "load_throughput": 961703.38, "learn_time_ms": 25.53, "learn_throughput": 10027.614, "synch_weights_time_ms": 3.46}, "counters": {"num_env_steps_sampled": 94187, "num_env_steps_trained": 7217152, "num_agent_steps_sampled": 94187, "num_agent_steps_trained": 7217152, "last_target_update_ts": 94187, "num_target_updates": 28192}, "done": false, "episodes_total": 970, "training_iteration": 94, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-50-00", "timestamp": 1675954200, "time_this_iter_s": 87.86418461799622, "time_total_s": 4505.005657196045, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580b80>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104e03a0>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4505.005657196045, "timesteps_since_restore": 0, "iterations_since_restore": 94, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 54.59672131147541, "ram_util_percent": 93.40655737704918}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.7856294512748718, "actor_loss": 114.1953125, "critic_loss": 1.0282127857208252, "alpha_loss": 2.91850209236145, "alpha_value": 0.02435888722538948, "log_alpha_value": -3.7148585319519043, "target_entropy": -5.0, "policy_t": -0.24442942440509796, "mean_q": -114.18828582763672, "max_q": -106.88346862792969, "min_q": -118.67935180664062}, "td_error": [115.7501220703125, 0.4814033508300781, 0.4990501403808594, 0.3154411315917969, 0.6063766479492188, 0.4105224609375, 0.3214302062988281, 0.026782989501953125, 0.3326606750488281, 0.07184600830078125, 0.1025390625, 113.00206756591797, 0.364776611328125, 0.12044525146484375, 0.24682998657226562, 0.6474647521972656, 110.95814514160156, 0.3624076843261719, 0.19756317138671875, 0.4996681213378906, 0.4088783264160156, 0.06607437133789062, 0.3460350036621094, 111.98617553710938, 115.38314056396484, 356.4472351074219, 0.5107421875, 0.67535400390625, 0.5269317626953125, 0.29141998291015625, 0.4687042236328125, 106.1458740234375, 0.40923309326171875, 114.62797546386719, 0.3127288818359375, 0.5236778259277344, 0.22319412231445312, 0.56353759765625, 0.16976547241210938, 0.76708984375, 0.27100372314453125, 0.10454559326171875, 0.6867141723632812, 115.39424133300781, 0.20749282836914062, 0.2620697021484375, 0.24549102783203125, 0.42011260986328125, 107.9280014038086, 0.31084442138671875, 0.4635467529296875, 111.3830337524414, 115.45173645019531, 0.0638275146484375, 0.17190933227539062, 0.39162445068359375, 0.16021728515625, 0.14810943603515625, 0.20398712158203125, 0.09847640991210938, 0.19087600708007812, 0.33712005615234375, 115.29910278320312, 0.16804122924804688, 115.10980987548828, 115.50155639648438, 0.32928466796875, 0.25141143798828125, 113.93621826171875, 112.03050231933594, 115.20654296875, 0.38024139404296875, 115.74690246582031, 0.6637001037597656, 0.047481536865234375, 0.02191162109375, 0.7614212036132812, 112.0746841430664, 0.2274169921875, 0.3161125183105469, 0.35883331298828125, 0.030208587646484375, 0.07880020141601562, 0.336761474609375, 115.67110443115234, 0.8013153076171875, 0.21920013427734375, 0.5288467407226562, 0.22735595703125, 0.46340179443359375, 0.0610504150390625, 0.54150390625, 0.9928550720214844, 0.2183990478515625, 108.64115905761719, 0.8270225524902344, 0.43090057373046875, 105.88656616210938, 0.47476959228515625, 110.39262390136719, 0.15961074829101562, 0.24700164794921875, 0.050327301025390625, 0.23176956176757812, 0.2785224914550781, 0.20644760131835938, 108.31449890136719, 362.5370788574219, 0.3550987243652344, 0.5771636962890625, 0.45098876953125, 0.17975997924804688, 0.34177398681640625, 0.3240623474121094, 0.5096855163574219, 0.2928886413574219, 116.1640396118164, 0.22153854370117188, 116.36812591552734, 0.36965179443359375, 0.3705253601074219, 0.3811759948730469, 0.11085128784179688, 0.24522018432617188, 0.1935882568359375, 0.6019020080566406, 0.4249610900878906, 112.01231384277344, 107.25778198242188, 0.5421066284179688, 0.12246322631835938, 0.43543243408203125, 0.31771087646484375, 0.5392036437988281, 112.57664489746094, 0.20852279663085938, 115.68788146972656, 0.10692977905273438, 0.6968002319335938, 0.2469024658203125, 0.3135337829589844, 0.17821884155273438, 0.4199485778808594, 0.192352294921875, 114.2882080078125, 0.382598876953125, 0.1817169189453125, 106.86978149414062, 0.6160087585449219, 0.478424072265625, 0.5543479919433594, 108.66150665283203, 0.8041229248046875, 112.65355682373047, 0.1483154296875, 1.5215415954589844, 0.34328460693359375, 0.5429496765136719, 0.10860061645507812, 112.07394409179688, 0.280548095703125, 107.38682556152344, 0.18056488037109375, 116.4736328125, 0.2862701416015625, 0.6036453247070312, 107.0866928100586, 0.3478431701660156, 0.8415794372558594, 106.27238464355469, 0.37064361572265625, 114.45304870605469, 0.6876602172851562, 0.15856552124023438, 0.14524078369140625, 0.18850326538085938, 116.4736328125, 0.15034866333007812, 0.051906585693359375, 0.36853790283203125, 0.10296249389648438, 0.3740806579589844, 112.24795532226562, 0.0503082275390625, 0.16909408569335938, 0.8712501525878906, 0.4165496826171875, 114.71343231201172, 0.497039794921875, 0.3771705627441406, 114.82582092285156, 0.12124252319335938, 0.4950218200683594, 0.28025054931640625, 358.23443603515625, 0.01496124267578125, 0.3992958068847656, 0.4711952209472656, 0.6354637145996094, 113.90348052978516, 0.725189208984375, 109.14922332763672, 0.2104644775390625, 0.4210052490234375, 0.24382400512695312, 0.195037841796875, 0.22237396240234375, 0.3299140930175781, 358.14605712890625, 0.10994338989257812, 0.8006973266601562, 0.9086456298828125, 0.276641845703125, 0.161102294921875, 0.16854095458984375, 0.47356414794921875, 0.3079566955566406, 0.2803306579589844, 0.4453010559082031, 0.0918731689453125, 0.2582588195800781, 0.9272537231445312, 0.3096923828125, 115.66259765625, 112.2426986694336, 0.5308761596679688, 105.83295440673828, 0.31226348876953125, 0.1644439697265625, 0.2665901184082031, 0.6583328247070312, 0.11248016357421875, 0.5933685302734375, 0.29048919677734375, 0.18120574951171875, 0.6156578063964844, 107.69334411621094, 0.2550201416015625, 0.7000656127929688, 0.7621574401855469, 0.1133270263671875, 0.6395530700683594, 0.09592437744140625, 0.4891853332519531, 0.4059791564941406, 0.3793067932128906, 0.3419189453125, 0.12443161010742188, 107.58937072753906, 0.19071197509765625, 0.4258460998535156, 113.2518081665039, 0.65863037109375, 0.16900253295898438, 0.8245620727539062, 0.10144805908203125], "mean_td_error": 28.667034149169922, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 28526.0, "diff_num_grad_updates_vs_sampler_policy": 28525.0}}, "num_env_steps_sampled": 95189, "num_env_steps_trained": 7302656, "num_agent_steps_sampled": 95189, "num_agent_steps_trained": 7302656, "last_target_update_ts": 95189, "num_target_updates": 28526}, "sampler_results": {"episode_reward_max": -156.6723095625639, "episode_reward_min": -192.23799195885658, "episode_reward_mean": -170.1869695238769, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-181.44102519750595, -159.14853070676327, -181.65320862829685, -156.6723095625639, -158.50095066428185, -192.23799195885658, -185.5121323019266, -162.85226867347956, -162.07650634646416, -161.77477119863033], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1583545836665539, "mean_inference_ms": 2.359211233054439, "mean_action_processing_ms": 0.22630920684336164, "mean_env_wait_ms": 2.931337780849296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.6723095625639, "episode_reward_min": -192.23799195885658, "episode_reward_mean": -170.1869695238769, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-181.44102519750595, -159.14853070676327, -181.65320862829685, -156.6723095625639, -158.50095066428185, -192.23799195885658, -185.5121323019266, -162.85226867347956, -162.07650634646416, -161.77477119863033], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1583545836665539, "mean_inference_ms": 2.359211233054439, "mean_action_processing_ms": 0.22630920684336164, "mean_env_wait_ms": 2.931337780849296, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 95189, "num_agent_steps_trained": 7302656, "num_env_steps_sampled": 95189, "num_env_steps_trained": 7302656, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 95189, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 95189, "timers": {"training_iteration_time_ms": 154.413, "load_time_ms": 0.304, "load_throughput": 840897.348, "learn_time_ms": 25.13, "learn_throughput": 10187.091, "synch_weights_time_ms": 5.423}, "counters": {"num_env_steps_sampled": 95189, "num_env_steps_trained": 7302656, "num_agent_steps_sampled": 95189, "num_agent_steps_trained": 7302656, "last_target_update_ts": 95189, "num_target_updates": 28526}, "done": false, "episodes_total": 980, "training_iteration": 95, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-50-54", "timestamp": 1675954254, "time_this_iter_s": 53.69957256317139, "time_total_s": 4558.705229759216, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be586d0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516940>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4558.705229759216, "timesteps_since_restore": 0, "iterations_since_restore": 95, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 40.03918918918919, "ram_util_percent": 91.60945945945946}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.1600513756275177, "actor_loss": 115.22437286376953, "critic_loss": 1.4641737937927246, "alpha_loss": -0.599424421787262, "alpha_value": 0.02363089844584465, "log_alpha_value": -3.7452001571655273, "target_entropy": -5.0, "policy_t": -0.2770153284072876, "mean_q": -115.0373764038086, "max_q": -107.6358642578125, "min_q": -119.78324890136719}, "td_error": [362.91571044921875, 114.69497680664062, 116.664306640625, 110.4901123046875, 0.4926567077636719, 0.495361328125, 111.6834487915039, 0.22039794921875, 110.99288940429688, 0.5170555114746094, 0.49688720703125, 116.02813720703125, 0.5075569152832031, 112.36856842041016, 114.44041442871094, 0.6480445861816406, 0.28745269775390625, 111.2992172241211, 0.0913238525390625, 0.12529373168945312, 111.8553695678711, 0.2951545715332031, 0.2895698547363281, 0.46668243408203125, 111.81062316894531, 110.95342254638672, 0.6248359680175781, 0.5718002319335938, 0.2284088134765625, 0.5839004516601562, 109.56183624267578, 116.21995544433594, 0.07093048095703125, 0.5394248962402344, 0.7681770324707031, 0.1829986572265625, 361.12225341796875, 115.2713623046875, 0.4003181457519531, 363.9833679199219, 111.11140441894531, 0.11066436767578125, 0.2227020263671875, 0.09543991088867188, 0.3063011169433594, 0.6315803527832031, 117.25279235839844, 0.4291191101074219, 109.01637268066406, 112.58319091796875, 114.52024841308594, 112.77397155761719, 0.33762359619140625, 0.4979209899902344, 0.1644287109375, 0.13693618774414062, 0.31884765625, 114.7963638305664, 0.1485748291015625, 0.29569244384765625, 113.91172790527344, 0.0865020751953125, 0.8313484191894531, 114.31488800048828, 0.5141830444335938, 0.22454452514648438, 112.54400634765625, 0.30095672607421875, 111.1792221069336, 0.23706436157226562, 0.1691741943359375, 0.2784309387207031, 0.15295028686523438, 0.3115386962890625, 0.7343940734863281, 0.8005294799804688, 0.1418609619140625, 0.24843978881835938, 0.4336280822753906, 115.8674545288086, 106.99720001220703, 0.10131072998046875, 113.43266296386719, 0.3927650451660156, 116.96250915527344, 0.15600204467773438, 0.520660400390625, 0.742156982421875, 0.16318511962890625, 0.2834129333496094, 116.96250915527344, 0.044036865234375, 0.38129425048828125, 0.6047401428222656, 0.542083740234375, 0.30855560302734375, 112.879638671875, 113.00138854980469, 0.3186187744140625, 108.53118133544922, 114.47450256347656, 0.5554733276367188, 109.02601623535156, 114.60233306884766, 0.0620269775390625, 0.6364898681640625, 0.18730926513671875, 0.06632614135742188, 110.89500427246094, 113.99989318847656, 113.00030517578125, 0.2464599609375, 0.23061370849609375, 0.32817840576171875, 110.44351196289062, 0.4893608093261719, 107.37200164794922, 0.3597450256347656, 0.20875167846679688, 0.5824394226074219, 114.93498992919922, 109.90556335449219, 116.38493347167969, 0.2547416687011719, 0.09810256958007812, 0.17757034301757812, 0.4320220947265625, 0.430755615234375, 115.44349670410156, 0.4364166259765625, 0.4925880432128906, 0.3412590026855469, 115.19206237792969, 0.5964736938476562, 0.6300849914550781, 0.14750289916992188, 112.92236328125, 0.595611572265625, 113.44617462158203, 0.2619476318359375, 0.3427314758300781, 0.1296539306640625, 1.009857177734375, 0.1115570068359375, 0.17364120483398438, 0.13201904296875, 113.26872253417969, 113.85710144042969, 0.16814041137695312, 0.16546249389648438, 0.22600173950195312, 0.4775276184082031, 0.4223213195800781, 0.7615432739257812, 0.29541015625, 0.1502532958984375, 0.059925079345703125, 0.5203475952148438, 116.314697265625, 0.958526611328125, 0.6392173767089844, 0.19265365600585938, 0.2761688232421875, 0.1429290771484375, 0.6114501953125, 0.26734161376953125, 114.91744232177734, 114.49068450927734, 0.5835723876953125, 0.4756927490234375, 0.15137100219726562, 0.8236465454101562, 0.18923187255859375, 0.06583404541015625, 0.0706939697265625, 0.20513534545898438, 0.393218994140625, 0.2671051025390625, 111.70684814453125, 0.2624778747558594, 0.5943603515625, 114.68147277832031, 0.0765228271484375, 0.4938812255859375, 0.250732421875, 113.68251037597656, 0.24625778198242188, 0.36605072021484375, 0.16548919677734375, 0.5003623962402344, 0.6280937194824219, 115.18864440917969, 0.3123016357421875, 0.192718505859375, 0.13074874877929688, 0.140960693359375, 0.5927734375, 0.2140960693359375, 0.4720878601074219, 0.49164581298828125, 116.48916625976562, 108.77880859375, 116.48916625976562, 0.7260665893554688, 0.20598983764648438, 0.3966026306152344, 0.052875518798828125, 0.13411331176757812, 0.5440864562988281, 360.8775939941406, 0.5055885314941406, 0.6205787658691406, 0.3567695617675781, 0.5960426330566406, 0.5321769714355469, 0.10839080810546875, 0.7143135070800781, 361.12225341796875, 0.6973152160644531, 113.04084777832031, 107.27801513671875, 0.5788116455078125, 0.2661628723144531, 115.08406066894531, 116.25001525878906, 113.24229431152344, 0.22726821899414062, 0.488311767578125, 0.34796142578125, 0.20119857788085938, 0.2894706726074219, 0.5682868957519531, 116.52241516113281, 115.69722747802734, 0.3212242126464844, 116.17930603027344, 112.43058776855469, 0.6024284362792969, 0.15687942504882812, 0.5116806030273438, 0.16481399536132812, 114.86448669433594, 0.3734550476074219, 0.494476318359375, 0.3236579895019531, 0.514739990234375, 109.21183013916016, 0.5848388671875, 0.3711814880371094, 0.16595840454101562, 0.63665771484375, 0.7364654541015625, 0.3473777770996094, 0.768707275390625, 359.081298828125, 115.00140380859375], "mean_td_error": 41.031578063964844, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 28860.0, "diff_num_grad_updates_vs_sampler_policy": 28859.0}}, "num_env_steps_sampled": 96191, "num_env_steps_trained": 7388160, "num_agent_steps_sampled": 96191, "num_agent_steps_trained": 7388160, "last_target_update_ts": 96191, "num_target_updates": 28860}, "sampler_results": {"episode_reward_max": -150.85336953401566, "episode_reward_min": -189.18622064590454, "episode_reward_mean": -170.80289669409393, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-162.73517979681492, -179.5418940782547, -178.2555582523346, -178.4172960817814, -150.85336953401566, -189.18622064590454, -185.8527176976204, -161.5672971457243, -167.36814042925835, -154.2512932792306], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.161554194486781, "mean_inference_ms": 2.375757882929913, "mean_action_processing_ms": 0.22735235751034014, "mean_env_wait_ms": 2.9422637459483254, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -150.85336953401566, "episode_reward_min": -189.18622064590454, "episode_reward_mean": -170.80289669409393, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-162.73517979681492, -179.5418940782547, -178.2555582523346, -178.4172960817814, -150.85336953401566, -189.18622064590454, -185.8527176976204, -161.5672971457243, -167.36814042925835, -154.2512932792306], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.161554194486781, "mean_inference_ms": 2.375757882929913, "mean_action_processing_ms": 0.22735235751034014, "mean_env_wait_ms": 2.9422637459483254, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 96191, "num_agent_steps_trained": 7388160, "num_env_steps_sampled": 96191, "num_env_steps_trained": 7388160, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 96191, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 96191, "timers": {"training_iteration_time_ms": 153.424, "load_time_ms": 0.308, "load_throughput": 832487.071, "learn_time_ms": 25.059, "learn_throughput": 10215.974, "synch_weights_time_ms": 5.549}, "counters": {"num_env_steps_sampled": 96191, "num_env_steps_trained": 7388160, "num_agent_steps_sampled": 96191, "num_agent_steps_trained": 7388160, "last_target_update_ts": 96191, "num_target_updates": 28860}, "done": false, "episodes_total": 990, "training_iteration": 96, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-51-47", "timestamp": 1675954307, "time_this_iter_s": 53.450644731521606, "time_total_s": 4612.155874490738, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2280>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516d30>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4612.155874490738, "timesteps_since_restore": 0, "iterations_since_restore": 96, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.78378378378379, "ram_util_percent": 91.25405405405405}}
-{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 0.8870038390159607, "actor_loss": 115.60578918457031, "critic_loss": 1.3008311986923218, "alpha_loss": 3.3117122650146484, "alpha_value": 0.023906756192445755, "log_alpha_value": -3.7335941791534424, "target_entropy": -5.0, "policy_t": -0.3005792200565338, "mean_q": -115.54031372070312, "max_q": -109.50465393066406, "min_q": -120.56295013427734}, "td_error": [113.54243469238281, 0.6626434326171875, 0.38419342041015625, 0.4043769836425781, 0.3791656494140625, 363.32525634765625, 1.0266342163085938, 108.52694702148438, 0.8524284362792969, 0.2673912048339844, 113.05345916748047, 0.7909317016601562, 115.93022155761719, 0.15678024291992188, 0.0957183837890625, 0.5517005920410156, 0.9858627319335938, 116.890625, 0.6344223022460938, 0.16827011108398438, 0.24825668334960938, 0.2602691650390625, 0.045490264892578125, 0.5141067504882812, 0.7522125244140625, 0.049648284912109375, 1.048980712890625, 0.13087081909179688, 0.3244667053222656, 112.5439682006836, 0.6522941589355469, 0.18202972412109375, 115.1943359375, 115.24266052246094, 0.17279052734375, 116.18339538574219, 0.1123199462890625, 108.54777526855469, 112.72535705566406, 0.17636489868164062, 0.5360374450683594, 0.5220184326171875, 0.6197853088378906, 0.067779541015625, 0.16089630126953125, 0.2849922180175781, 360.71527099609375, 0.70391845703125, 111.52163696289062, 116.03424072265625, 115.40925598144531, 0.5986518859863281, 109.49189758300781, 0.21741485595703125, 0.2808647155761719, 112.3011703491211, 0.630035400390625, 0.16979217529296875, 0.5684738159179688, 0.15674209594726562, 0.4209442138671875, 0.6398963928222656, 0.6215286254882812, 108.99014282226562, 117.04390716552734, 0.3482398986816406, 0.500732421875, 0.33095550537109375, 0.9292945861816406, 113.52197265625, 0.0976715087890625, 0.5079307556152344, 0.2511405944824219, 114.24427795410156, 0.18498992919921875, 0.19896316528320312, 0.11159133911132812, 0.08994293212890625, 0.21898651123046875, 0.4639701843261719, 0.13066864013671875, 116.40362548828125, 0.21143722534179688, 0.2523612976074219, 0.6958808898925781, 0.29473114013671875, 0.30776214599609375, 114.42338562011719, 0.7440948486328125, 0.15309906005859375, 115.88435363769531, 115.5075912475586, 111.8074951171875, 0.06122589111328125, 0.0984954833984375, 0.5056991577148438, 110.45881652832031, 0.24104690551757812, 108.04754638671875, 115.13284301757812, 0.2787933349609375, 0.40941619873046875, 0.10053253173828125, 0.5747642517089844, 0.7163887023925781, 0.06467056274414062, 0.4202919006347656, 0.4800529479980469, 0.32079315185546875, 114.28697204589844, 114.28697204589844, 115.29182434082031, 0.9178886413574219, 112.6068115234375, 0.5156517028808594, 115.60783386230469, 0.362579345703125, 0.3309211730957031, 114.40080261230469, 0.15430068969726562, 0.08183670043945312, 0.8772506713867188, 0.06357955932617188, 0.6029052734375, 0.7321701049804688, 0.4813575744628906, 0.08319854736328125, 0.20576858520507812, 0.38861846923828125, 0.16038131713867188, 0.6682205200195312, 0.7245826721191406, 0.2828178405761719, 360.4109802246094, 0.06789398193359375, 0.2816925048828125, 0.9403915405273438, 0.13912200927734375, 0.6888999938964844, 360.4148254394531, 0.5342941284179688, 0.5045127868652344, 0.5320930480957031, 0.123809814453125, 0.03350830078125, 0.4744415283203125, 0.5893783569335938, 0.7024497985839844, 111.8074951171875, 0.6361656188964844, 1.1696319580078125, 0.27106475830078125, 110.06513214111328, 0.13951492309570312, 113.15203857421875, 113.31582641601562, 0.8443527221679688, 0.27852630615234375, 0.27463531494140625, 0.11728668212890625, 117.4216537475586, 0.23498153686523438, 0.11212921142578125, 0.20883560180664062, 0.510986328125, 0.6676216125488281, 0.4909934997558594, 0.5034942626953125, 0.122406005859375, 111.88516235351562, 0.5894317626953125, 117.74571228027344, 0.23779678344726562, 0.0141143798828125, 0.14262008666992188, 0.21328353881835938, 111.00141143798828, 0.24284744262695312, 0.25675201416015625, 0.44921875, 115.75009155273438, 116.44116973876953, 0.8910255432128906, 1.1092414855957031, 0.5746841430664062, 0.3862152099609375, 0.8782272338867188, 0.0745697021484375, 0.10276031494140625, 360.3826904296875, 0.4639320373535156, 0.3970985412597656, 0.08739471435546875, 0.8664627075195312, 109.90316009521484, 0.6472854614257812, 0.13732528686523438, 0.13850021362304688, 0.19382095336914062, 116.68521118164062, 0.4738655090332031, 0.2755622863769531, 0.2774505615234375, 0.15149307250976562, 0.9197006225585938, 114.12799072265625, 1.1066093444824219, 0.8111991882324219, 112.72172546386719, 0.5224266052246094, 115.79810333251953, 0.30376434326171875, 116.76741027832031, 0.0857696533203125, 362.219482421875, 0.021160125732421875, 109.10811614990234, 111.95409393310547, 0.26569366455078125, 0.5215415954589844, 0.6573905944824219, 0.0327301025390625, 0.4101676940917969, 0.5009269714355469, 361.49896240234375, 117.91423034667969, 108.54777526855469, 0.3739585876464844, 0.308380126953125, 0.17171859741210938, 0.125091552734375, 115.79409790039062, 0.29312896728515625, 0.06281661987304688, 0.5083656311035156, 0.12731552124023438, 0.18725967407226562, 113.71823120117188, 0.19200897216796875, 0.3892478942871094, 0.4675254821777344, 0.9726219177246094, 0.24619674682617188, 115.79810333251953, 0.20392608642578125, 361.80059814453125, 0.22303009033203125, 0.039684295654296875, 0.1142578125, 0.49962615966796875, 0.189544677734375, 0.4914588928222656, 0.9834136962890625, 0.21151351928710938, 112.23104858398438, 0.14278411865234375], "mean_td_error": 37.32743453979492, "model": {}, "custom_metrics": {}, "num_agent_steps_trained": 256.0, "num_grad_updates_lifetime": 29194.0, "diff_num_grad_updates_vs_sampler_policy": 29193.0}}, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "last_target_update_ts": 97193, "num_target_updates": 29194}, "sampler_results": {"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-156.1826542466879, -169.85423006117344, -162.02638640999794, -185.1279215067625, -186.65800455212593, -163.31539402902126, -191.28636541962624, -157.43947839736938, -171.26552772521973, -156.39830098301172], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1364653920600976, "mean_inference_ms": 2.3486854601514455, "mean_action_processing_ms": 0.22231085102003592, "mean_env_wait_ms": 2.9007591400230686, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0}, "episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "hist_stats": {"episode_reward": [-156.1826542466879, -169.85423006117344, -162.02638640999794, -185.1279215067625, -186.65800455212593, -163.31539402902126, -191.28636541962624, -157.43947839736938, -171.26552772521973, -156.39830098301172], "episode_lengths": [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.1364653920600976, "mean_inference_ms": 2.3486854601514455, "mean_action_processing_ms": 0.22231085102003592, "mean_env_wait_ms": 2.9007591400230686, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "timers": {"training_iteration_time_ms": 161.318, "load_time_ms": 0.312, "load_throughput": 821657.349, "learn_time_ms": 25.987, "learn_throughput": 9851.041, "synch_weights_time_ms": 7.023}, "counters": {"num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "last_target_update_ts": 97193, "num_target_updates": 29194}, "done": false, "episodes_total": 1000, "training_iteration": 97, "trial_id": "80340_00000", "experiment_id": "4d5d6cddaea7444681811f5901f7f828", "date": "2023-02-09_15-52-40", "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "pid": 27220, "hostname": "Daniel", "node_ip": "192.168.152.36", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "_fake_gpus": false, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": false, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "env": "darm/DarmSFHand-v0", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": false, "rollout_fragment_length": 1, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "ignore_worker_failures": false, "recreate_failed_workers": false, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "synchronize_filters": true, "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.001, "train_batch_size": 256, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": 100, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 5, "min_time_s_per_iteration": 1, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 1000, "export_native_model_files": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "worker_cls": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "simple_optimizer": false, "replay_sequence_length": null, "twin_q": true, "q_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "policy_model_config": {"fcnet_hiddens": [256, 256], "fcnet_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": null, "custom_model": null, "custom_model_config": {}}, "tau": 0.005, "initial_alpha": 1.0, "target_entropy": "auto", "n_step": 1, "replay_buffer_config": {"_enable_replay_buffer_api": true, "type": "MultiAgentPrioritizedReplayBuffer", "capacity": 1000000, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "prioritized_replay_eps": 1e-06, "worker_side_prioritization": false}, "store_buffer_in_checkpoints": false, "training_intensity": null, "optimization": {"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, "entropy_learning_rate": 0.0003}, "grad_clip": null, "target_network_update_freq": 1, "num_steps_sampled_before_learning_starts": 10000, "_deterministic_loss": false, "_use_beta_distribution": false, "use_state_preprocessor": -1, "worker_side_prioritization": -1, "__stdout_file__": null, "__stderr_file__": null, "input": "sampler", "multiagent": {"policies": {"default_policy": "<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2fa0>"}, "policy_mapping_fn": "<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104dc280>", "policies_to_train": null, "policy_map_capacity": 100, "policy_map_cache": null, "count_steps_by": "env_steps", "observation_fn": null}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 3}, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "perf": {"cpu_util_percent": 39.38055555555556, "ram_util_percent": 91.3138888888889}}
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug-internal.log b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug-internal.log
deleted file mode 120000
index 7e1963d..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug-internal.log
+++ /dev/null
@@ -1 +0,0 @@
-run-20230209_143443-80340_00000/logs/debug-internal.log
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug.log b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug.log
deleted file mode 120000
index 033c08e..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/debug.log
+++ /dev/null
@@ -1 +0,0 @@
-run-20230209_143443-80340_00000/logs/debug.log
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/latest-run b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/latest-run
deleted file mode 120000
index aa1726f..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/latest-run
+++ /dev/null
@@ -1 +0,0 @@
-run-20230209_143443-80340_00000
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/conda-environment.yaml b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/conda-environment.yaml
deleted file mode 100644
index 5263a90..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/conda-environment.yaml
+++ /dev/null
@@ -1,281 +0,0 @@
-name: base
-channels:
-  - fastai
-  - pytorch
-  - conda-forge
-  - defaults
-dependencies:
-  - _libgcc_mutex=0.1=main
-  - _openmp_mutex=4.5=1_gnu
-  - anyio=3.6.2=pyhd8ed1ab_0
-  - argon2-cffi=21.3.0=pyhd8ed1ab_0
-  - argon2-cffi-bindings=21.2.0=py38h0a891b7_2
-  - asttokens=2.0.5=pyhd3eb1b0_0
-  - astunparse=1.6.3=py_0
-  - attrs=22.2.0=pyh71513ae_0
-  - autopep8=1.6.0=pyhd3eb1b0_1
-  - babel=2.11.0=pyhd8ed1ab_0
-  - backcall=0.2.0=pyhd3eb1b0_0
-  - beautifulsoup4=4.11.1=pyha770c72_0
-  - blas=1.0=mkl
-  - bleach=5.0.1=pyhd8ed1ab_0
-  - brotlipy=0.7.0=py38h27cfd23_1003
-  - bzip2=1.0.8=h7b6447c_0
-  - ca-certificates=2022.10.11=h06a4308_0
-  - certifi=2022.12.7=py38h06a4308_0
-  - cffi=1.15.0=py38hd667e15_1
-  - charset-normalizer=2.0.4=pyhd3eb1b0_0
-  - conda=22.11.1=py38h06a4308_4
-  - conda-content-trust=0.1.1=pyhd3eb1b0_0
-  - conda-package-handling=1.7.3=py38h27cfd23_1
-  - cpuonly=2.0=0
-  - cryptography=36.0.0=py38h9ce1e76_0
-  - cytoolz=0.11.0=py38h7b6447c_0
-  - decorator=5.1.1=pyhd3eb1b0_0
-  - defusedxml=0.7.1=pyhd8ed1ab_0
-  - entrypoints=0.4=pyhd8ed1ab_0
-  - execnb=0.1.3=py_0
-  - executing=0.8.3=pyhd3eb1b0_0
-  - fastcore=1.5.26=py_0
-  - ffmpeg=4.3=hf484d3e_0
-  - flit-core=3.6.0=pyhd3eb1b0_0
-  - freetype=2.12.1=h4a9f257_0
-  - ghapi=1.0.2=py_0
-  - giflib=5.2.1=h7b6447c_0
-  - gmp=6.2.1=h295c915_3
-  - gnutls=3.6.15=he1e5248_0
-  - idna=3.3=pyhd3eb1b0_0
-  - importlib_resources=5.10.1=pyhd8ed1ab_1
-  - intel-openmp=2021.4.0=h06a4308_3561
-  - ipykernel=5.5.5=py38hd0cf306_0
-  - ipython=8.4.0=py38h06a4308_0
-  - ipython_genutils=0.2.0=py_1
-  - jedi=0.18.1=py38h06a4308_1
-  - jinja2=3.1.2=pyhd8ed1ab_1
-  - jpeg=9e=h7f8727e_0
-  - json5=0.9.5=pyh9f0ad1d_0
-  - jsonschema=4.17.3=pyhd8ed1ab_0
-  - jupyter_client=7.0.6=pyhd8ed1ab_0
-  - jupyter_core=4.12.0=py38h578d9bd_0
-  - jupyter_server=1.23.4=pyhd8ed1ab_0
-  - jupyterlab=3.5.2=pyhd8ed1ab_0
-  - jupyterlab_pygments=0.2.2=pyhd8ed1ab_0
-  - jupyterlab_server=2.10.3=pyhd3eb1b0_1
-  - lame=3.100=h7b6447c_0
-  - lcms2=2.12=h3be6417_0
-  - ld_impl_linux-64=2.35.1=h7274673_9
-  - lerc=3.0=h295c915_0
-  - libdeflate=1.8=h7f8727e_5
-  - libffi=3.3=he6710b0_2
-  - libgcc-ng=11.2.0=h1234567_1
-  - libgomp=11.2.0=h1234567_1
-  - libiconv=1.16=h7f8727e_2
-  - libidn2=2.3.2=h7f8727e_0
-  - libpng=1.6.37=hbc83047_0
-  - libsodium=1.0.18=h36c2ea0_1
-  - libstdcxx-ng=11.2.0=h1234567_1
-  - libtasn1=4.16.0=h27cfd23_0
-  - libtiff=4.4.0=hecacb30_0
-  - libunistring=0.9.10=h27cfd23_0
-  - libwebp=1.2.4=h11a3e52_0
-  - libwebp-base=1.2.4=h5eee18b_0
-  - lz4-c=1.9.4=h6a678d5_0
-  - markupsafe=2.1.1=py38h0a891b7_1
-  - matplotlib-inline=0.1.6=py38h06a4308_0
-  - mistune=2.0.4=pyhd8ed1ab_0
-  - mkl=2021.4.0=h06a4308_640
-  - mkl-service=2.4.0=py38h7f8727e_0
-  - mkl_fft=1.3.1=py38hd3c417c_0
-  - mkl_random=1.2.2=py38h51133e4_0
-  - nbclassic=0.4.8=pyhd8ed1ab_0
-  - nbclient=0.5.13=pyhd8ed1ab_0
-  - nbconvert=7.2.7=pyhd8ed1ab_0
-  - nbconvert-core=7.2.7=pyhd8ed1ab_0
-  - nbconvert-pandoc=7.2.7=pyhd8ed1ab_0
-  - nbdev=2.2.10=py_0
-  - nbformat=5.7.1=pyhd8ed1ab_0
-  - ncurses=6.3=h7f8727e_2
-  - nest-asyncio=1.5.6=pyhd8ed1ab_0
-  - nettle=3.7.3=hbbd107a_1
-  - notebook=6.5.2=pyha770c72_1
-  - notebook-shim=0.2.2=pyhd8ed1ab_0
-  - numpy=1.23.4=py38h14f4228_0
-  - numpy-base=1.23.4=py38h31eccc5_0
-  - openh264=2.1.1=h4ff587b_0
-  - openssl=1.1.1s=h7f8727e_0
-  - packaging=21.3=pyhd3eb1b0_0
-  - pandoc=2.19.2=ha770c72_0
-  - pandocfilters=1.5.0=pyhd8ed1ab_0
-  - parso=0.8.3=pyhd3eb1b0_0
-  - pexpect=4.8.0=pyhd3eb1b0_3
-  - pickleshare=0.7.5=pyhd3eb1b0_1003
-  - pip=21.2.4=py38h06a4308_0
-  - pkgutil-resolve-name=1.3.10=pyhd8ed1ab_0
-  - pluggy=1.0.0=py38h06a4308_1
-  - prometheus_client=0.15.0=pyhd8ed1ab_0
-  - prompt-toolkit=3.0.20=pyhd3eb1b0_0
-  - ptyprocess=0.7.0=pyhd3eb1b0_2
-  - pure_eval=0.2.2=pyhd3eb1b0_0
-  - pycodestyle=2.8.0=pyhd3eb1b0_0
-  - pycosat=0.6.3=py38h7b6447c_1
-  - pycparser=2.21=pyhd3eb1b0_0
-  - pyopenssl=21.0.0=pyhd3eb1b0_1
-  - pyparsing=3.0.9=py38h06a4308_0
-  - pysocks=1.7.1=py38h06a4308_0
-  - python=3.8.12=h12debd9_0
-  - python-dateutil=2.8.2=pyhd8ed1ab_0
-  - python-fastjsonschema=2.16.2=pyhd8ed1ab_0
-  - python_abi=3.8=2_cp38
-  - pytorch=1.13.1=py3.8_cpu_0
-  - pytorch-mutex=1.0=cpu
-  - pytz=2022.7=pyhd8ed1ab_0
-  - pyyaml=6.0=py38h7f8727e_1
-  - pyzmq=19.0.2=py38ha71036d_2
-  - requests=2.27.1=pyhd3eb1b0_0
-  - ruamel.yaml=0.17.21=py38h5eee18b_0
-  - ruamel.yaml.clib=0.2.6=py38h5eee18b_1
-  - ruamel_yaml=0.15.100=py38h27cfd23_0
-  - send2trash=1.8.0=pyhd8ed1ab_0
-  - sniffio=1.3.0=pyhd8ed1ab_0
-  - soupsieve=2.3.2.post1=pyhd8ed1ab_0
-  - sqlite=3.37.0=hc218d9a_0
-  - stack_data=0.2.0=pyhd3eb1b0_0
-  - terminado=0.17.1=pyh41d4057_0
-  - tinycss2=1.2.1=pyhd8ed1ab_0
-  - tk=8.6.11=h1ccaba5_0
-  - toml=0.10.2=pyhd3eb1b0_0
-  - tomli=2.0.1=pyhd8ed1ab_0
-  - toolz=0.11.2=pyhd3eb1b0_0
-  - torchaudio=0.13.1=py38_cpu
-  - torchvision=0.14.1=py38_cpu
-  - tornado=6.1=py38h0a891b7_3
-  - tqdm=4.62.3=pyhd3eb1b0_1
-  - traitlets=5.1.1=pyhd3eb1b0_0
-  - typing_extensions=4.4.0=py38h06a4308_0
-  - wcwidth=0.2.5=pyhd3eb1b0_0
-  - webencodings=0.5.1=py_1
-  - websocket-client=1.4.2=pyhd8ed1ab_0
-  - wheel=0.37.1=pyhd3eb1b0_0
-  - xz=5.2.5=h7b6447c_0
-  - yaml=0.2.5=h7b6447c_0
-  - zeromq=4.3.4=h9c3ff4c_1
-  - zipp=3.11.0=pyhd8ed1ab_0
-  - zlib=1.2.13=h5eee18b_0
-  - zstd=1.5.2=ha4553b6_0
-  - pip:
-      - absl-py==1.2.0
-      - aiosignal==1.3.1
-      - alabaster==0.7.12
-      - ansicolors==1.1.8
-      - ansiwrap==0.8.4
-      - appdirs==1.4.4
-      - cachetools==5.2.0
-      - catkin-pkg==0.5.2
-      - chainmap==1.0.3
-      - click==8.1.3
-      - cloudpickle==2.2.0
-      - combomethod==1.0.12
-      - commonmark==0.9.1
-      - contourpy==1.0.5
-      - cycler==0.11.0
-      - cython==0.29.32
-      - darm-gym-env==0.0.1
-      - distlib==0.3.6
-      - distro==1.8.0
-      - dm-tree==0.1.8
-      - docker-pycreds==0.4.0
-      - docutils==0.17.1
-      - exceptiongroup==1.1.0
-      - fasteners==0.18
-      - filelock==3.8.2
-      - fonttools==4.37.4
-      - frozenlist==1.3.3
-      - gast==0.5.3
-      - gitdb==4.0.10
-      - gitpython==3.1.30
-      - glfw==2.5.5
-      - google-auth==2.15.0
-      - google-auth-oauthlib==0.4.6
-      - grpcio==1.51.1
-      - gym==0.21.0
-      - gym-notices==0.0.8
-      - imagehash==4.3.1
-      - imageio==2.23.0
-      - imagesize==1.4.1
-      - importlib-metadata==4.13.0
-      - iniconfig==1.1.1
-      - intspan==1.6.1
-      - ipdb==0.13.11
-      - kiwisolver==1.4.4
-      - lz4==4.0.2
-      - markdown==3.4.1
-      - matplotlib==3.6.1
-      - mementos==1.3.1
-      - msgpack==1.0.4
-      - mujoco==2.2.2
-      - networkx==2.8.8
-      - nulltype==2.3.1
-      - numpydoc==1.5.0
-      - nvidia-cublas-cu11==11.10.3.66
-      - nvidia-cuda-nvrtc-cu11==11.7.99
-      - nvidia-cuda-runtime-cu11==11.7.99
-      - nvidia-cudnn-cu11==8.5.0.96
-      - oauthlib==3.2.2
-      - options==1.4.10
-      - pandas==1.5.2
-      - pathtools==0.1.2
-      - pillow==9.2.0
-      - platformdirs==2.6.0
-      - protobuf==3.20.1
-      - psutil==5.9.4
-      - pyasn1==0.4.8
-      - pyasn1-modules==0.2.8
-      - pygame==2.1.0
-      - pygments==2.13.0
-      - pyopengl==3.1.6
-      - pyrsistent==0.19.2
-      - pytest==7.2.0
-      - pytest-instafail==0.3.0
-      - pywavelets==1.4.1
-      - ray==2.2.0
-      - readline==6.2.4.1
-      - requests-oauthlib==1.3.1
-      - rich==12.6.0
-      - rospkg==1.4.0
-      - rsa==4.9
-      - say==1.6.6
-      - scikit-image==0.19.3
-      - scipy==1.9.2
-      - sentry-sdk==1.15.0
-      - setproctitle==1.3.2
-      - setuptools==65.6.3
-      - shiboken2==5.15.2.1
-      - show==1.6.0
-      - simplere==1.2.13
-      - six==1.12.0
-      - smmap==5.0.0
-      - snowballstemmer==2.2.0
-      - sphinx==5.3.0
-      - sphinx-rtd-theme==1.1.1
-      - sphinxcontrib-applehelp==1.0.2
-      - sphinxcontrib-devhelp==1.0.2
-      - sphinxcontrib-htmlhelp==2.0.0
-      - sphinxcontrib-jsmath==1.0.1
-      - sphinxcontrib-qthelp==1.0.3
-      - sphinxcontrib-serializinghtml==1.1.5
-      - stable-baselines3==1.6.2
-      - tabulate==0.9.0
-      - tensorboard==2.11.0
-      - tensorboard-data-server==0.6.1
-      - tensorboard-plugin-wit==1.8.1
-      - tensorboardx==2.5.1
-      - tensorflow-probability==0.19.0
-      - textdata==2.4.1
-      - textwrap3==0.9.2
-      - tifffile==2022.10.10
-      - typer==0.7.0
-      - urllib3==1.26.14
-      - virtualenv==20.17.1
-      - wandb==0.13.10
-      - werkzeug==2.2.2
-prefix: /home/daniel/miniconda3
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
deleted file mode 100644
index 9d03db7..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
+++ /dev/null
@@ -1,520 +0,0 @@
-wandb_version: 1
-
-__stderr_file__:
-  desc: null
-  value: null
-__stdout_file__:
-  desc: null
-  value: null
-_deterministic_loss:
-  desc: null
-  value: false
-_disable_action_flattening:
-  desc: null
-  value: false
-_disable_execution_plan_api:
-  desc: null
-  value: true
-_disable_preprocessor_api:
-  desc: null
-  value: false
-_fake_gpus:
-  desc: null
-  value: false
-_tf_policy_handles_more_than_one_loss:
-  desc: null
-  value: false
-_use_beta_distribution:
-  desc: null
-  value: false
-_wandb:
-  desc: null
-  value:
-    cli_version: 0.13.10
-    framework: torch
-    is_jupyter_run: true
-    is_kaggle_kernel: false
-    python_version: 3.8.12
-    start_time: 1675949683.553893
-    t:
-      1:
-      - 1
-      - 30
-      - 55
-      2:
-      - 1
-      - 30
-      - 55
-      3:
-      - 13
-      - 14
-      - 15
-      - 16
-      - 19
-      - 23
-      4: 3.8.12
-      5: 0.13.10
-      8:
-      - 1
-      - 8
-      - 9
-action_space:
-  desc: null
-  value: null
-actions_in_input_normalized:
-  desc: null
-  value: false
-actor_learning_rate:
-  desc: null
-  value: 0.0003
-always_attach_evaluation_results:
-  desc: null
-  value: false
-batch_mode:
-  desc: null
-  value: truncate_episodes
-clip_actions:
-  desc: null
-  value: false
-clip_rewards:
-  desc: null
-  value: null
-compress_observations:
-  desc: null
-  value: false
-create_env_on_driver:
-  desc: null
-  value: false
-critic_learning_rate:
-  desc: null
-  value: 0.0003
-custom_eval_function:
-  desc: null
-  value: null
-custom_resources_per_worker:
-  desc: null
-  value: {}
-date:
-  desc: null
-  value: 2023-02-09_15-52-40
-disable_env_checking:
-  desc: null
-  value: false
-eager_max_retraces:
-  desc: null
-  value: 20
-eager_tracing:
-  desc: null
-  value: false
-enable_async_evaluation:
-  desc: null
-  value: false
-enable_connectors:
-  desc: null
-  value: false
-enable_tf1_exec_eagerly:
-  desc: null
-  value: false
-entropy_learning_rate:
-  desc: null
-  value: 0.0003
-env:
-  desc: null
-  value: darm/DarmSFHand-v0
-env_config:
-  desc: null
-  value: {}
-env_task_fn:
-  desc: null
-  value: null
-evaluation_config:
-  desc: null
-  value: null
-evaluation_duration:
-  desc: null
-  value: 10
-evaluation_duration_unit:
-  desc: null
-  value: episodes
-evaluation_interval:
-  desc: null
-  value: 100
-evaluation_num_workers:
-  desc: null
-  value: 0
-evaluation_parallel_to_training:
-  desc: null
-  value: false
-evaluation_sample_timeout_s:
-  desc: null
-  value: 180.0
-experiment_id:
-  desc: null
-  value: 4d5d6cddaea7444681811f5901f7f828
-exploration_config:
-  desc: null
-  value:
-    type: StochasticSampling
-explore:
-  desc: null
-  value: true
-export_native_model_files:
-  desc: null
-  value: false
-extra_python_environs_for_driver:
-  desc: null
-  value: {}
-extra_python_environs_for_worker:
-  desc: null
-  value: {}
-fake_sampler:
-  desc: null
-  value: false
-framework:
-  desc: null
-  value: torch
-gamma:
-  desc: null
-  value: 0.99
-grad_clip:
-  desc: null
-  value: null
-horizon:
-  desc: null
-  value: null
-hostname:
-  desc: null
-  value: Daniel
-ignore_worker_failures:
-  desc: null
-  value: false
-in_evaluation:
-  desc: null
-  value: false
-initial_alpha:
-  desc: null
-  value: 1.0
-input:
-  desc: null
-  value: sampler
-input_config:
-  desc: null
-  value: {}
-keep_per_episode_custom_metrics:
-  desc: null
-  value: false
-local_tf_session_args:
-  desc: null
-  value:
-    inter_op_parallelism_threads: 8
-    intra_op_parallelism_threads: 8
-log_level:
-  desc: null
-  value: WARN
-log_sys_usage:
-  desc: null
-  value: true
-logger_config:
-  desc: null
-  value: null
-logger_creator:
-  desc: null
-  value: null
-lr:
-  desc: null
-  value: 0.001
-max_requests_in_flight_per_sampler_worker:
-  desc: null
-  value: 2
-metrics_episode_collection_timeout_s:
-  desc: null
-  value: 60.0
-metrics_num_episodes_for_smoothing:
-  desc: null
-  value: 5
-min_sample_timesteps_per_iteration:
-  desc: null
-  value: 1000
-min_time_s_per_iteration:
-  desc: null
-  value: 1
-min_train_timesteps_per_iteration:
-  desc: null
-  value: 0
-model:
-  desc: null
-  value:
-    _disable_action_flattening: false
-    _disable_preprocessor_api: false
-    _time_major: false
-    _use_default_native_models: false
-    attention_dim: 64
-    attention_head_dim: 32
-    attention_init_gru_gate_bias: 2.0
-    attention_memory_inference: 50
-    attention_memory_training: 50
-    attention_num_heads: 1
-    attention_num_transformer_units: 1
-    attention_position_wise_mlp_dim: 32
-    attention_use_n_prev_actions: 0
-    attention_use_n_prev_rewards: 0
-    conv_activation: relu
-    conv_filters: null
-    custom_action_dist: null
-    custom_model: null
-    custom_model_config: {}
-    custom_preprocessor: null
-    dim: 84
-    fcnet_activation: tanh
-    fcnet_hiddens:
-    - 256
-    - 256
-    framestack: true
-    free_log_std: false
-    grayscale: false
-    lstm_cell_size: 256
-    lstm_use_prev_action: false
-    lstm_use_prev_action_reward: -1
-    lstm_use_prev_reward: false
-    max_seq_len: 20
-    no_final_linear: false
-    post_fcnet_activation: relu
-    post_fcnet_hiddens: []
-    use_attention: false
-    use_lstm: false
-    vf_share_layers: true
-    zero_mean: true
-multiagent:
-  desc: null
-  value:
-    count_steps_by: env_steps
-    observation_fn: null
-    policies:
-      default_policy: <ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2fa0>
-    policies_to_train: null
-    policy_map_cache: null
-    policy_map_capacity: 100
-    policy_mapping_fn: <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104dc280>
-n_step:
-  desc: null
-  value: 1
-no_done_at_end:
-  desc: null
-  value: false
-node_ip:
-  desc: null
-  value: 192.168.152.36
-normalize_actions:
-  desc: null
-  value: true
-num_consecutive_worker_failures_tolerance:
-  desc: null
-  value: 100
-num_cpus_for_driver:
-  desc: null
-  value: 1
-num_cpus_per_worker:
-  desc: null
-  value: 1
-num_envs_per_worker:
-  desc: null
-  value: 1
-num_gpu:
-  desc: null
-  value: 0
-num_gpus:
-  desc: null
-  value: 0
-num_gpus_per_worker:
-  desc: null
-  value: 0
-num_rollout_workers:
-  desc: null
-  value: 3
-num_steps_sampled_before_learning_starts:
-  desc: null
-  value: 10000
-num_workers:
-  desc: null
-  value: 3
-observation_filter:
-  desc: null
-  value: NoFilter
-observation_space:
-  desc: null
-  value: null
-off_policy_estimation_methods:
-  desc: null
-  value: {}
-offline_sampling:
-  desc: null
-  value: false
-ope_split_batch_by_episode:
-  desc: null
-  value: true
-optimization:
-  desc: null
-  value:
-    actor_learning_rate: 0.0003
-    critic_learning_rate: 0.0003
-    entropy_learning_rate: 0.0003
-optimizer:
-  desc: null
-  value: {}
-output:
-  desc: null
-  value: null
-output_compress_columns:
-  desc: null
-  value:
-  - obs
-  - new_obs
-output_config:
-  desc: null
-  value: {}
-output_max_file_size:
-  desc: null
-  value: 67108864
-pid:
-  desc: null
-  value: 27220
-placement_strategy:
-  desc: null
-  value: PACK
-policy_model_config:
-  desc: null
-  value:
-    custom_model: null
-    custom_model_config: {}
-    fcnet_activation: relu
-    fcnet_hiddens:
-    - 256
-    - 256
-    post_fcnet_activation: null
-    post_fcnet_hiddens: []
-postprocess_inputs:
-  desc: null
-  value: false
-preprocessor_pref:
-  desc: null
-  value: deepmind
-q_model_config:
-  desc: null
-  value:
-    custom_model: null
-    custom_model_config: {}
-    fcnet_activation: relu
-    fcnet_hiddens:
-    - 256
-    - 256
-    post_fcnet_activation: null
-    post_fcnet_hiddens: []
-recreate_failed_workers:
-  desc: null
-  value: false
-remote_env_batch_wait_ms:
-  desc: null
-  value: 0
-remote_worker_envs:
-  desc: null
-  value: false
-render_env:
-  desc: null
-  value: false
-replay_buffer_config:
-  desc: null
-  value:
-    _enable_replay_buffer_api: true
-    capacity: 1000000
-    prioritized_replay: false
-    prioritized_replay_alpha: 0.6
-    prioritized_replay_beta: 0.4
-    prioritized_replay_eps: 1.0e-06
-    type: MultiAgentPrioritizedReplayBuffer
-    worker_side_prioritization: false
-replay_sequence_length:
-  desc: null
-  value: null
-restart_failed_sub_environments:
-  desc: null
-  value: false
-rollout_fragment_length:
-  desc: null
-  value: 1
-sample_async:
-  desc: null
-  value: false
-sample_collector:
-  desc: null
-  value: ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector
-sampler_perf_stats_ema_coef:
-  desc: null
-  value: null
-seed:
-  desc: null
-  value: null
-shuffle_buffer_size:
-  desc: null
-  value: 0
-simple_optimizer:
-  desc: null
-  value: false
-soft_horizon:
-  desc: null
-  value: false
-store_buffer_in_checkpoints:
-  desc: null
-  value: false
-sync_filters_on_rollout_workers_timeout_s:
-  desc: null
-  value: 60.0
-synchronize_filters:
-  desc: null
-  value: true
-target_entropy:
-  desc: null
-  value: auto
-target_network_update_freq:
-  desc: null
-  value: 1
-tau:
-  desc: null
-  value: 0.005
-tf_session_args:
-  desc: null
-  value:
-    allow_soft_placement: true
-    device_count:
-      CPU: 1
-    gpu_options:
-      allow_growth: true
-    inter_op_parallelism_threads: 2
-    intra_op_parallelism_threads: 2
-    log_device_placement: false
-train_batch_size:
-  desc: null
-  value: 256
-training_intensity:
-  desc: null
-  value: null
-trial_id:
-  desc: null
-  value: '80340_00000'
-trial_log_path:
-  desc: null
-  value: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39
-twin_q:
-  desc: null
-  value: true
-use_state_preprocessor:
-  desc: null
-  value: -1
-validate_workers_after_construction:
-  desc: null
-  value: true
-worker_cls:
-  desc: null
-  value: null
-worker_side_prioritization:
-  desc: null
-  value: -1
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/diff.patch b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/diff.patch
deleted file mode 100644
index 6d4837e..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/diff.patch
+++ /dev/null
@@ -1,150 +0,0 @@
-diff --git a/darm_training/rllib_ppo_cartpole-v1.py b/darm_training/rllib_ppo_cartpole-v1.py
-deleted file mode 100644
-index 935aa17..0000000
---- a/darm_training/rllib_ppo_cartpole-v1.py
-+++ /dev/null
-@@ -1,22 +0,0 @@
--from ray.rllib.algorithms.ppo import PPOConfig
--from ray.tune.logger import pretty_print
--
--
--algo = (
--    PPOConfig()
--    .rollouts(num_rollout_workers=1)
--    .resources(num_gpus=0)
--    .environment(env="CartPole-v1")
--    .framework("torch")
--    .build()
--    # .training(model={"fcnet_hiddens": [64, 64]})
--    # .evaluation(evaluation_num_workers=1)
--)
--
--for i in range(10):
--    result = algo.train()
--    print(pretty_print(result))
--
--    if i % 5 == 0:
--        checkpoint_dir = algo.save()
--        print(f"Checkpoint saved in directory {checkpoint_dir}")
-\ No newline at end of file
-diff --git a/darm_training/rllib_ppo_taxi-v3.py b/darm_training/rllib_ppo_taxi-v3.py
-deleted file mode 100644
-index a3c20f2..0000000
---- a/darm_training/rllib_ppo_taxi-v3.py
-+++ /dev/null
-@@ -1,17 +0,0 @@
--from ray.rllib.algorithms.ppo import PPOConfig
--
--config = (  # 1. Configure the algorithm,
--    PPOConfig()
--    .environment("Taxi-v3")
--    .rollouts(num_rollout_workers=2)
--    .framework("torch")
--    .training(model={"fcnet_hiddens": [64, 64]})
--    .evaluation(evaluation_num_workers=1)
--)
--
--algo = config.build()  # 2. build the algorithm,
--
--for _ in range(5):
--    print(algo.train())  # 3. train it,
--
--algo.evaluate()  # 4. and evaluate it.
-\ No newline at end of file
-diff --git a/darm_training/rllib_sac_DarmHand-v0.py b/darm_training/rllib_sac_DarmHand-v0.py
-deleted file mode 100644
-index 39b48df..0000000
---- a/darm_training/rllib_sac_DarmHand-v0.py
-+++ /dev/null
-@@ -1,45 +0,0 @@
--from ray.rllib.algorithms.sac import SACConfig
--from ray.tune.logger import pretty_print
--import ray.tune as tune
--import ray
--
--import gym
--from darm_gym_env import DARMEnv
--
--env = gym.make("darm/DarmHand-v0", render_mode="human", hand_name="hand1")
--tune.register_env("darm/DarmHand-v0", lambda env_ctx: env)  # see how to do this more properly from the doc
--# https://docs.ray.io/en/latest/rllib/rllib-env.html
--
--env = gym.make("darm/DarmHand-v0")
--ray.rllib.utils.check_env(env)
--
--algo = (
--    SACConfig()
--    .rollouts(num_rollout_workers=4, rollout_fragment_length=1)
--    .resources(num_gpus=0)
--    .environment(env="HalfCheetah-v3", normalize_actions=True)
--    .framework("torch")
--    .reporting(min_sample_timesteps_per_iteration=1000)
--    .training(q_model_config={"fcnet_activation": "relu", "fcnet_hiddens": [256, 256]},
--                policy_model_config={"fcnet_activation": "relu", "fcnet_hiddens": [256, 256]},
--                tau=0.005,
--                n_step=1,
--                train_batch_size=256,
--                target_network_update_freq=1,
--                replay_buffer_config={"type": "MultiAgentPrioritizedReplayBuffer"},
--                num_steps_sampled_before_learning_starts=10000,
--                optimization_config={"actor_learning_rate": 0.0003, "critic_learning_rate": 0.0003, 
--                                    "entropy_learning_rate": 0.0003},
--                clip_actions=False
--            )
--    .build()
--    # .evaluation(evaluation_num_workers=1)
--)
--
--for i in range(20):
--    result = algo.train()
--
--    if i % 5 == 0 or i == 9:
--        print(pretty_print(result))
--        checkpoint_dir = algo.save()
--        print(f"Checkpoint saved in directory {checkpoint_dir}")
-diff --git a/darm_training/rllib_sac_cartpole-v1.py b/darm_training/rllib_sac_cartpole-v1.py
-deleted file mode 100644
-index 9a0c1b9..0000000
---- a/darm_training/rllib_sac_cartpole-v1.py
-+++ /dev/null
-@@ -1,11 +0,0 @@
--from ray.rllib.algorithms.sac import SACConfig
--from ray.tune.logger import pretty_print
--
--config = SACConfig().training(gamma=0.9, lr=0.01)  
--config = config.resources(num_gpus=0)  
--config = config.rollouts(num_rollout_workers=4, num_envs_per_worker=4)
--config = config.framework("torch")  
--print(config.to_dict())  
--# Build a Algorithm object from the config and run 1 training iteration.
--algo = config.build(env="CartPole-v1")  
--print(pretty_print(algo.train()))
-diff --git a/darm_training/sb3_sac_pendulum-v1.py b/darm_training/sb3_sac_pendulum-v1.py
-deleted file mode 100644
-index 12ce4ee..0000000
---- a/darm_training/sb3_sac_pendulum-v1.py
-+++ /dev/null
-@@ -1,22 +0,0 @@
--import gym
--import numpy as np
--
--from stable_baselines3 import SAC
--
--env = gym.make("Pendulum-v1")
--
--model = SAC("MlpPolicy", env, verbose=1)
--model.learn(total_timesteps=10000, log_interval=4)
--model.save("sac_pendulum")
--
--del model # remove to demonstrate saving and loading
--
--model = SAC.load("sac_pendulum")
--
--obs = env.reset()
--while True:
--    action, _states = model.predict(obs, deterministic=True)
--    obs, reward, done, info = env.step(action)
--    env.render()
--    if done:
--      obs = env.reset()
-\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/output.log b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/output.log
deleted file mode 100644
index 8b13789..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/output.log
+++ /dev/null
@@ -1 +0,0 @@
-
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/requirements.txt b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/requirements.txt
deleted file mode 100644
index b493b43..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/requirements.txt
+++ /dev/null
@@ -1,339 +0,0 @@
-absl-py==1.2.0
-actionlib==1.12.1
-aiosignal==1.3.1
-alabaster==0.7.12
-angles==1.9.12
-ansicolors==1.1.8
-ansiwrap==0.8.4
-anyio==3.6.2
-appdirs==1.4.4
-argon2-cffi-bindings==21.2.0
-argon2-cffi==21.3.0
-asttokens==2.0.5
-astunparse==1.6.3
-attrs==22.2.0
-autopep8==1.6.0
-babel==2.11.0
-backcall==0.2.0
-base-local-planner==1.16.7
-beautifulsoup4==4.11.1
-bleach==5.0.1
-bondpy==1.8.5
-brotlipy==0.7.0
-cachetools==5.2.0
-camera-calibration-parsers==1.11.13
-camera-calibration==1.15.0
-catkin-pkg==0.5.2
-catkin==0.7.29
-certifi==2022.12.7
-cffi==1.15.0
-chainmap==1.0.3
-charset-normalizer==2.0.4
-click==8.1.3
-cloudpickle==2.2.0
-combomethod==1.0.12
-commonmark==0.9.1
-conda-content-trust==0+unknown
-conda-package-handling==1.7.3
-conda==22.11.1
-contourpy==1.0.5
-controller-manager-msgs==0.18.4
-controller-manager==0.18.4
-cryptography==36.0.0
-cv-bridge==1.13.0
-cycler==0.11.0
-cython==0.29.32
-cytoolz==0.11.0
-darm-gym-env==0.0.1
-decorator==5.1.1
-defusedxml==0.7.1
-diagnostic-analysis==1.9.7
-diagnostic-common-diagnostics==1.9.7
-diagnostic-updater==1.9.7
-distlib==0.3.6
-distro==1.8.0
-dm-tree==0.1.8
-docker-pycreds==0.4.0
-docutils==0.17.1
-dynamic-reconfigure==1.6.3
-entrypoints==0.4
-exceptiongroup==1.1.0
-execnb==0.1.3
-executing==0.8.3
-fastcore==1.5.26
-fasteners==0.18
-fastjsonschema==2.16.2
-filelock==3.8.2
-flit-core==3.6.0
-fonttools==4.37.4
-frozenlist==1.3.3
-gast==0.5.3
-gazebo-plugins==2.8.7
-gazebo-ros==2.8.7
-gencpp==0.6.5
-geneus==2.2.6
-genlisp==0.4.16
-genmsg==0.5.16
-gennodejs==2.0.1
-genpy==0.6.16
-ghapi==1.0.2
-gitdb==4.0.10
-gitpython==3.1.30
-glfw==2.5.5
-google-auth-oauthlib==0.4.6
-google-auth==2.15.0
-grpcio==1.51.1
-gym-examples==0.0.1
-gym-notices==0.0.8
-gym==0.21.0
-idna==3.3
-image-geometry==1.13.0
-imagehash==4.3.1
-imageio==2.23.0
-imagesize==1.4.1
-importlib-metadata==5.2.0
-importlib-resources==5.10.1
-iniconfig==1.1.1
-interactive-markers==1.11.5
-intspan==1.6.1
-ipdb==0.13.11
-ipykernel==5.5.5
-ipython-genutils==0.2.0
-ipython==8.4.0
-jedi==0.18.1
-jinja2==3.1.2
-joint-state-publisher-gui==1.12.15
-joint-state-publisher==1.12.15
-json5==0.9.5
-jsonschema==4.17.3
-jupyter-client==7.0.6
-jupyter-core==4.12.0
-jupyter-server==1.23.4
-jupyterlab-pygments==0.2.2
-jupyterlab-server==2.10.3
-jupyterlab==3.5.2
-kdl-parser-py==1.13.1
-kiwisolver==1.4.4
-laser-geometry==1.6.7
-lz4==4.0.2
-markdown==3.4.1
-markupsafe==2.1.1
-matplotlib-inline==0.1.6
-matplotlib==3.6.1
-mementos==1.3.1
-message-filters==1.14.12
-mistune==2.0.4
-mkl-fft==1.3.1
-mkl-random==1.2.2
-mkl-service==2.4.0
-moveit-commander==1.0.10
-moveit-core==1.0.10
-moveit-ros-planning-interface==1.0.10
-moveit-ros-visualization==1.0.10
-msgpack==1.0.4
-mujoco-py==2.1.2.14
-mujoco==2.2.2
-nbclassic==0.4.8
-nbclient==0.5.13
-nbconvert==7.2.7
-nbdev==2.2.10
-nbformat==5.7.1
-nest-asyncio==1.5.6
-networkx==2.8.8
-notebook-shim==0.2.2
-notebook==6.5.2
-nulltype==2.3.1
-numpy==1.23.4
-numpydoc==1.5.0
-nvidia-cublas-cu11==11.10.3.66
-nvidia-cuda-nvrtc-cu11==11.7.99
-nvidia-cuda-runtime-cu11==11.7.99
-nvidia-cudnn-cu11==8.5.0.96
-oauthlib==3.2.2
-options==1.4.10
-packaging==21.3
-pandas==1.5.2
-pandocfilters==1.5.0
-parso==0.8.3
-pathtools==0.1.2
-pexpect==4.8.0
-pickleshare==0.7.5
-pillow==9.3.0
-pip==21.2.4
-pkgutil-resolve-name==1.3.10
-platformdirs==2.6.0
-pluggy==1.0.0
-prometheus-client==0.15.0
-prompt-toolkit==3.0.20
-protobuf==3.20.1
-psutil==5.9.4
-ptyprocess==0.7.0
-pure-eval==0.2.2
-pyasn1-modules==0.2.8
-pyasn1==0.4.8
-pycodestyle==2.8.0
-pycosat==0.6.3
-pycparser==2.21
-pygame==2.1.0
-pygments==2.13.0
-pyopengl==3.1.6
-pyopenssl==21.0.0
-pyparsing==3.0.9
-pyrsistent==0.19.2
-pysocks==1.7.1
-pytest-instafail==0.3.0
-pytest==7.2.0
-python-dateutil==2.8.2
-python-qt-binding==0.4.4
-pytz==2022.7
-pywavelets==1.4.1
-pyyaml==6.0
-pyzmq==19.0.2
-qt-dotgraph==0.4.2
-qt-gui-cpp==0.4.2
-qt-gui-py-common==0.4.2
-qt-gui==0.4.2
-ray==2.2.0
-readline==6.2.4.1
-requests-oauthlib==1.3.1
-requests==2.27.1
-resource-retriever==1.12.6
-rich==12.6.0
-rosbag==1.14.12
-rosboost-cfg==1.14.9
-rosclean==1.14.9
-roscreate==1.14.9
-rosgraph==1.14.12
-roslaunch==1.14.12
-roslib==1.14.9
-roslint==0.11.2
-roslz4==1.14.12
-rosmake==1.14.9
-rosmaster==1.14.12
-rosmsg==1.14.12
-rosnode==1.14.12
-rosparam==1.14.12
-rospkg==1.4.0
-rospy==1.14.12
-rosserial-python==0.8.0
-rosservice==1.14.12
-rostest==1.14.12
-rostopic==1.14.12
-rosunit==1.14.9
-roswtf==1.14.12
-rqt-action==0.4.9
-rqt-bag-plugins==0.5.1
-rqt-bag==0.5.1
-rqt-console==0.4.9
-rqt-dep==0.4.9
-rqt-graph==0.4.11
-rqt-gui-py==0.5.2
-rqt-gui==0.5.2
-rqt-image-view==0.4.16
-rqt-launch==0.4.8
-rqt-logger-level==0.4.8
-rqt-moveit==0.5.10
-rqt-msg==0.4.8
-rqt-nav-view==0.5.7
-rqt-plot==0.4.13
-rqt-pose-view==0.5.8
-rqt-publisher==0.4.8
-rqt-py-common==0.5.2
-rqt-py-console==0.4.8
-rqt-reconfigure==0.5.4
-rqt-robot-dashboard==0.5.7
-rqt-robot-monitor==0.5.13
-rqt-robot-steering==0.5.10
-rqt-runtime-monitor==0.5.7
-rqt-rviz==0.7.0
-rqt-service-caller==0.4.8
-rqt-shell==0.4.9
-rqt-srv==0.4.8
-rqt-tf-tree==0.6.0
-rqt-top==0.4.8
-rqt-topic==0.4.11
-rqt-web==0.4.8
-rsa==4.9
-ruamel-yaml-conda==0.15.100
-ruamel.yaml.clib==0.2.6
-ruamel.yaml==0.17.21
-rviz==1.13.19
-say==1.6.6
-scikit-image==0.19.3
-scipy==1.9.2
-send2trash==1.8.0
-sensor-msgs==1.12.8
-sentry-sdk==1.15.0
-setproctitle==1.3.2
-setuptools==65.6.3
-shiboken2==5.15.2.1
-show==1.6.0
-simplere==1.2.13
-six==1.12.0
-smach-ros==2.0.1
-smach==2.0.1
-smclib==1.8.5
-smmap==5.0.0
-sniffio==1.3.0
-snowballstemmer==2.2.0
-soupsieve==2.3.2.post1
-sphinx-rtd-theme==1.1.1
-sphinx==5.3.0
-sphinxcontrib-applehelp==1.0.2
-sphinxcontrib-devhelp==1.0.2
-sphinxcontrib-htmlhelp==2.0.0
-sphinxcontrib-jsmath==1.0.1
-sphinxcontrib-qthelp==1.0.3
-sphinxcontrib-serializinghtml==1.1.5
-srdfdom==0.5.2
-stable-baselines3==1.6.2
-stack-data==0.2.0
-tabulate==0.9.0
-tensorboard-data-server==0.6.1
-tensorboard-plugin-wit==1.8.1
-tensorboard==2.11.0
-tensorboardx==2.5.1
-tensorflow-probability==0.19.0
-terminado==0.17.1
-textdata==2.4.1
-textwrap3==0.9.2
-tf-conversions==1.12.1
-tf2-geometry-msgs==0.6.5
-tf2-kdl==0.6.5
-tf2-py==0.6.5
-tf2-ros==0.6.5
-tf==1.12.1
-tifffile==2022.10.10
-tinycss2==1.2.1
-toml==0.10.2
-tomli==2.0.1
-toolz==0.11.2
-topic-tools==1.14.12
-torch==1.13.1
-torchaudio==0.13.1
-torchvision==0.14.1
-tornado==6.1
-tqdm==4.62.3
-traitlets==5.1.1
-turtlebot3-automatic-parking-vision==1.1.0
-turtlebot3-automatic-parking==1.1.0
-turtlebot3-autorace-camera==1.2.0
-turtlebot3-autorace-control==1.2.0
-turtlebot3-autorace-core==1.2.0
-turtlebot3-autorace-detect==1.2.0
-turtlebot3-example==1.2.5
-turtlebot3-teleop==1.2.5
-typer==0.7.0
-typing-extensions==4.4.0
-urdfdom-py==0.4.5
-urllib3==1.26.14
-virtualenv==20.17.1
-wandb==0.13.10
-wcwidth==0.2.5
-webencodings==0.5.1
-websocket-client==1.4.2
-werkzeug==2.2.2
-wheel==0.37.1
-wiimote==1.14.0
-xacro==1.13.13
-zipp==3.11.0
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-metadata.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-metadata.json
deleted file mode 100644
index 713fda9..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-metadata.json
+++ /dev/null
@@ -1,56 +0,0 @@
-{
-    "os": "Linux-5.4.0-42-generic-x86_64-with-glibc2.17",
-    "python": "3.8.12",
-    "heartbeatAt": "2023-02-09T13:34:48.396946",
-    "startedAt": "2023-02-09T13:34:43.524992",
-    "docker": null,
-    "cuda": null,
-    "args": null,
-    "state": "running",
-    "program": "DARM/darm_mujoco/darm_training/darm_sf_hand_rllib_sac.ipynb",
-    "root": "/home/daniel/DARM/darm_mujoco",
-    "git": {
-        "remote": "git@github.com:danieladejumo17/darm-mujoco.git",
-        "commit": "fa58be7e28147d0665d0bcb11c5000148cad1f72"
-    },
-    "email": "adejumodaniel17@gmail.com",
-    "host": "Daniel",
-    "username": "daniel",
-    "executable": "/home/daniel/miniconda3/bin/python3.8",
-    "cpu_count": 2,
-    "cpu_count_logical": 4,
-    "cpu_freq": {
-        "current": 2701.0660000000003,
-        "min": 400.0,
-        "max": 2800.0
-    },
-    "cpu_freq_per_core": [
-        {
-            "current": 2699.969,
-            "min": 400.0,
-            "max": 2800.0
-        },
-        {
-            "current": 2702.15,
-            "min": 400.0,
-            "max": 2800.0
-        },
-        {
-            "current": 2700.002,
-            "min": 400.0,
-            "max": 2800.0
-        },
-        {
-            "current": 2702.143,
-            "min": 400.0,
-            "max": 2800.0
-        }
-    ],
-    "disk": {
-        "total": 29.658042907714844,
-        "used": 27.012474060058594
-    },
-    "memory": {
-        "total": 7.455364227294922
-    }
-}
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
deleted file mode 100644
index a7c9a98..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
+++ /dev/null
@@ -1 +0,0 @@
-{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug-internal.log b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug-internal.log
deleted file mode 100644
index bc8a450..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug-internal.log
+++ /dev/null
@@ -1,3897 +0,0 @@
-2023-02-09 14:34:43,555 INFO    StreamThr :27234 [internal.py:wandb_internal():87] W&B internal server running at pid: 27234, started at: 2023-02-09 14:34:43.554599
-2023-02-09 14:34:43,583 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status
-2023-02-09 14:34:43,594 INFO    WriterThread:27234 [datastore.py:open_for_write():85] open: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/run-80340_00000.wandb
-2023-02-09 14:34:43,595 DEBUG   SenderThread:27234 [sender.py:send():336] send: header
-2023-02-09 14:34:43,678 DEBUG   SenderThread:27234 [sender.py:send():336] send: run
-2023-02-09 14:34:45,774 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: check_version
-2023-02-09 14:34:45,790 INFO    SenderThread:27234 [dir_watcher.py:__init__():216] watching files in: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files
-2023-02-09 14:34:45,790 INFO    SenderThread:27234 [sender.py:_start_run_threads():1067] run started: 80340_00000 with start time 1675949683.553893
-2023-02-09 14:34:45,791 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:34:45,791 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:34:45,791 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: check_version
-2023-02-09 14:34:46,793 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:34:48,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: run_start
-2023-02-09 14:34:48,374 DEBUG   HandlerThread:27234 [system_info.py:__init__():31] System info init
-2023-02-09 14:34:48,375 DEBUG   HandlerThread:27234 [system_info.py:__init__():46] System info init done
-2023-02-09 14:34:48,375 INFO    HandlerThread:27234 [system_monitor.py:start():151] Starting system monitor
-2023-02-09 14:34:48,377 INFO    SystemMonitor:27234 [system_monitor.py:_start():116] Starting system asset monitoring threads
-2023-02-09 14:34:48,377 INFO    HandlerThread:27234 [system_monitor.py:probe():172] Collecting system info
-2023-02-09 14:34:48,378 INFO    SystemMonitor:27234 [interfaces.py:start():168] Started cpu
-2023-02-09 14:34:48,382 INFO    SystemMonitor:27234 [interfaces.py:start():168] Started disk
-2023-02-09 14:34:48,384 INFO    SystemMonitor:27234 [interfaces.py:start():168] Started memory
-2023-02-09 14:34:48,386 INFO    SystemMonitor:27234 [interfaces.py:start():168] Started network
-2023-02-09 14:34:48,396 DEBUG   HandlerThread:27234 [system_info.py:probe():195] Probing system
-2023-02-09 14:34:48,404 DEBUG   HandlerThread:27234 [system_info.py:_probe_git():180] Probing git
-2023-02-09 14:34:48,430 DEBUG   HandlerThread:27234 [system_info.py:_probe_git():188] Probing git done
-2023-02-09 14:34:48,430 DEBUG   HandlerThread:27234 [system_info.py:probe():241] Probing system done
-2023-02-09 14:34:48,431 DEBUG   HandlerThread:27234 [system_monitor.py:probe():181] {'os': 'Linux-5.4.0-42-generic-x86_64-with-glibc2.17', 'python': '3.8.12', 'heartbeatAt': '2023-02-09T13:34:48.396946', 'startedAt': '2023-02-09T13:34:43.524992', 'docker': None, 'cuda': None, 'args': None, 'state': 'running', 'program': 'DARM/darm_mujoco/darm_training/darm_sf_hand_rllib_sac.ipynb', 'root': '/home/daniel/DARM/darm_mujoco', 'git': {'remote': 'git@github.com:danieladejumo17/darm-mujoco.git', 'commit': 'fa58be7e28147d0665d0bcb11c5000148cad1f72'}, 'email': 'adejumodaniel17@gmail.com', 'host': 'Daniel', 'username': 'daniel', 'executable': '/home/daniel/miniconda3/bin/python3.8', 'cpu_count': 2, 'cpu_count_logical': 4, 'cpu_freq': {'current': 2701.0660000000003, 'min': 400.0, 'max': 2800.0}, 'cpu_freq_per_core': [{'current': 2699.969, 'min': 400.0, 'max': 2800.0}, {'current': 2702.15, 'min': 400.0, 'max': 2800.0}, {'current': 2700.002, 'min': 400.0, 'max': 2800.0}, {'current': 2702.143, 'min': 400.0, 'max': 2800.0}], 'disk': {'total': 29.658042907714844, 'used': 27.012474060058594}, 'memory': {'total': 7.455364227294922}}
-2023-02-09 14:34:48,431 INFO    HandlerThread:27234 [system_monitor.py:probe():182] Finished collecting system info
-2023-02-09 14:34:48,431 INFO    HandlerThread:27234 [system_monitor.py:probe():185] Publishing system info
-2023-02-09 14:34:48,431 DEBUG   HandlerThread:27234 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
-2023-02-09 14:34:48,432 DEBUG   HandlerThread:27234 [system_info.py:_save_pip():67] Saving pip packages done
-2023-02-09 14:34:48,432 DEBUG   HandlerThread:27234 [system_info.py:_save_conda():74] Saving list of conda packages installed into the current environment
-2023-02-09 14:34:48,791 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/requirements.txt
-2023-02-09 14:34:48,791 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/conda-environment.yaml
-2023-02-09 14:34:55,036 DEBUG   HandlerThread:27234 [system_info.py:_save_conda():86] Saving conda packages done
-2023-02-09 14:34:55,036 DEBUG   HandlerThread:27234 [system_info.py:_save_code():89] Saving code
-2023-02-09 14:34:55,036 WARNING HandlerThread:27234 [system_info.py:_save_code():91] unable to save code -- program entry not found
-2023-02-09 14:34:55,036 DEBUG   HandlerThread:27234 [system_info.py:_save_patches():127] Saving git patches
-2023-02-09 14:34:55,130 DEBUG   HandlerThread:27234 [system_info.py:_save_patches():169] Saving git patches done
-2023-02-09 14:34:55,131 INFO    HandlerThread:27234 [system_monitor.py:probe():187] Finished publishing system info
-2023-02-09 14:34:55,151 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:34:55,152 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:34:55,152 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:34:55,154 DEBUG   SenderThread:27234 [sender.py:send():336] send: files
-2023-02-09 14:34:55,154 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-metadata.json with policy now
-2023-02-09 14:34:55,155 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file diff.patch with policy now
-2023-02-09 14:34:55,200 DEBUG   SenderThread:27234 [sender.py:send():336] send: telemetry
-2023-02-09 14:34:55,202 DEBUG   SenderThread:27234 [sender.py:send():336] send: telemetry
-2023-02-09 14:34:55,202 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:34:55,205 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: stop_status
-2023-02-09 14:34:55,207 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: stop_status
-2023-02-09 14:34:55,793 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/conda-environment.yaml
-2023-02-09 14:34:55,793 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-metadata.json
-2023-02-09 14:34:55,794 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/diff.patch
-2023-02-09 14:34:56,402 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:34:56,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:34:56,413 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:34:56,414 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:34:56,417 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:34:56,793 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:34:57,832 INFO    wandb-upload_0:27234 [upload_job.py:push():138] Uploaded file /tmp/tmpearucis9wandb/4j78x9r8-wandb-metadata.json
-2023-02-09 14:34:57,832 INFO    wandb-upload_1:27234 [upload_job.py:push():138] Uploaded file /tmp/tmpearucis9wandb/1atvgelu-diff.patch
-2023-02-09 14:34:59,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:00,855 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:00,856 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:00,859 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:00,859 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:00,860 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:01,795 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:04,861 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:05,202 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:05,204 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:05,208 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:05,208 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:05,209 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:05,797 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:10,196 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:10,197 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:10,213 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:10,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:10,321 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:10,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:10,327 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:10,328 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:10,800 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:14,731 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:14,732 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:14,734 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:14,735 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:14,737 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:14,801 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:15,197 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:15,743 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:17,802 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:35:19,131 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:19,132 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:19,135 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:19,135 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:19,136 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:19,803 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:20,198 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:23,137 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:23,138 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:23,138 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:23,141 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:23,141 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:23,145 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:23,804 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:25,199 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:27,035 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:27,039 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:27,040 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:27,041 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:27,044 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:27,806 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:29,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:30,200 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:30,988 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:30,989 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:30,992 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:30,993 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:30,993 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:31,807 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:34,996 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:35,200 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:36,095 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:35:36,097 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:35:36,103 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:35:36,104 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:35:36,106 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:35:36,809 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:35:40,107 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:40,202 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:45,108 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:45,202 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:48,386 DEBUG   SystemMonitor:27234 [system_monitor.py:_start():130] Starting system metrics aggregation loop
-2023-02-09 14:35:48,387 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:35:50,204 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:50,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:35:51,813 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:35:55,204 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:35:56,760 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:00,205 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:01,761 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:05,206 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:06,761 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:10,206 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:11,762 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:15,207 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:16,763 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:18,388 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:36:20,208 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:22,389 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:25,209 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:27,390 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:28,135 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:36:28,137 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:36:28,144 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:36:28,144 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:36:28,145 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:36:28,825 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:36:30,210 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:33,146 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:35,211 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:38,147 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:40,211 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:43,148 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:45,212 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:48,149 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:48,388 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:36:50,213 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:53,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:36:54,833 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:36:55,214 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:36:59,538 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:00,215 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:04,538 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:05,215 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:09,539 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:10,216 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:14,540 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:15,217 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:18,389 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:37:20,218 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:20,390 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:20,401 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:37:20,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:37:20,406 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:37:20,407 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:37:20,409 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:37:20,841 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:37:25,218 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:25,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:26,843 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:37:30,219 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:31,779 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:35,220 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:36,779 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:40,221 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:41,780 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:45,222 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:46,781 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:48,389 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:37:50,222 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:52,390 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:37:55,223 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:37:57,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:00,224 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:02,392 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:05,225 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:07,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:10,226 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:12,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:15,227 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:17,116 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:38:17,118 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:38:17,122 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:38:17,123 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:38:17,125 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:38:17,861 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:38:18,125 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:18,390 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:38:20,227 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:23,392 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:25,228 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:28,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:30,229 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:30,866 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:38:35,230 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:35,350 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:40,231 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:40,351 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:45,232 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:45,352 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:48,391 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:38:50,232 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:50,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:38:55,237 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:38:55,392 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:00,237 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:00,394 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:05,238 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:05,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:10,243 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:10,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:15,244 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:15,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:18,391 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:39:18,833 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:39:18,834 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:39:18,843 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:39:18,844 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:39:18,844 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:39:18,882 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:39:20,244 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:20,845 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:25,245 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:25,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:30,246 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:30,852 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:32,887 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:39:35,247 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:37,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:40,247 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:42,313 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:45,248 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:47,314 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:48,392 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:39:50,249 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:52,392 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:39:55,250 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:39:57,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:00,251 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:02,394 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:05,251 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:07,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:10,252 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:12,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:14,015 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:40:14,016 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:40:14,020 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:40:14,021 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:40:14,022 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:40:14,900 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:40:15,253 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:18,023 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:18,392 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:40:20,254 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:23,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:25,255 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:28,394 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:30,256 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:33,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:35,256 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:35,906 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:40:40,257 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:40,381 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:45,258 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:45,381 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:48,393 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:40:50,259 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:50,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:40:55,259 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:40:55,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:00,260 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:00,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:04,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:41:04,325 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:41:04,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:41:04,328 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:41:04,329 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:41:04,915 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:41:05,261 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:06,334 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:08,916 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:41:10,262 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:13,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:15,263 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:18,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:18,393 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:41:20,263 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:23,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:25,265 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:28,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:30,265 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:33,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:35,266 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:38,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:40,267 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:43,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:45,267 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:48,394 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:41:49,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:50,268 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:54,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:41:55,269 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:41:57,620 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:41:57,621 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:41:57,628 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:41:57,629 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:41:57,629 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:41:57,932 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:41:59,630 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:00,270 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:04,631 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:05,271 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:09,637 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:10,272 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:10,936 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:42:15,273 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:15,702 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:18,394 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:42:20,273 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:21,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:25,274 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:26,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:30,275 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:31,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:35,276 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:36,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:40,277 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:41,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:45,278 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:46,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:48,395 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:42:49,589 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:42:49,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:42:49,594 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:42:49,595 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:42:49,597 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:42:49,948 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:42:50,278 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:51,597 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:42:55,279 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:42:56,598 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:00,280 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:01,599 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:05,281 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:06,600 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:10,282 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:11,605 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:12,955 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:43:15,282 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:17,901 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:18,395 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:43:20,283 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:23,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:25,284 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:28,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:30,285 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:33,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:35,286 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:38,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:40,286 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:41,828 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:43:41,830 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:43:41,834 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:43:41,835 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:43:41,836 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:43:41,965 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:43:43,842 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:45,287 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:45,966 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:43:48,396 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:43:50,288 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:50,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:43:55,289 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:43:55,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:00,290 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:00,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:05,290 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:05,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:10,291 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:10,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:15,292 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:15,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:18,396 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:44:20,294 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:21,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:25,295 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:26,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:30,296 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:31,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:33,674 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:44:33,675 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:44:33,682 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:44:33,683 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:44:33,684 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:44:33,981 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:44:35,297 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:36,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:40,298 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:41,686 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:45,299 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:46,691 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:47,987 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:44:48,397 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:44:50,299 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:53,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:44:55,300 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:44:58,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:00,301 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:03,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:05,301 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:08,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:10,302 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:13,401 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:15,303 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:18,397 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:45:19,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:20,304 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:24,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:25,305 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:25,844 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:45:25,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:45:25,849 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:45:25,850 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:45:25,850 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:45:25,999 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:45:29,851 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:30,306 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:34,852 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:35,306 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:39,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:40,307 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:44,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:45,308 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:48,398 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:45:50,309 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:50,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:45:52,007 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:45:55,309 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:45:56,096 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:00,310 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:01,096 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:05,311 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:06,097 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:10,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:11,098 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:15,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:16,099 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:18,065 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:46:18,067 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:46:18,070 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:46:18,071 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:46:18,072 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:46:18,399 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:46:19,016 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:46:20,313 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:21,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:23,093 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:46:25,314 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:27,094 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:30,315 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:32,094 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:35,315 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:37,095 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:40,316 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:42,096 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:45,317 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:47,097 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:48,400 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:46:50,318 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:52,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:46:55,319 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:46:57,401 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:00,320 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:02,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:05,320 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:07,403 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:10,321 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:10,694 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:47:10,696 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:47:10,703 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:47:10,704 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:47:10,705 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:47:11,108 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:47:12,706 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:15,322 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:17,706 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:18,400 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:47:20,323 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:23,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:24,112 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:47:25,324 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:29,072 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:30,324 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:34,073 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:35,325 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:39,074 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:40,326 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:44,075 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:45,327 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:48,401 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:47:49,401 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:50,327 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:54,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:47:55,328 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:47:59,403 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:00,329 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:03,768 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:48:03,770 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:48:03,774 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:48:03,775 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:48:03,776 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:48:04,124 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:48:04,776 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:05,330 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:09,777 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:10,331 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:14,778 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:15,331 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:18,401 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:48:20,332 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:20,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:25,333 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:25,408 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:26,131 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:48:30,334 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:30,862 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:35,335 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:35,862 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:40,335 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:40,863 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:45,336 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:45,864 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:48,402 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:48:50,337 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:51,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:55,338 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:48:55,497 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:48:55,499 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:48:55,503 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:48:55,504 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:48:55,505 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:48:56,140 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:48:56,510 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:48:57,140 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:49:00,339 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:02,059 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:05,340 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:07,060 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:10,341 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:12,061 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:15,341 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:17,062 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:18,402 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:49:20,342 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:22,403 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:25,343 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:27,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:30,344 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:32,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:35,345 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:37,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:40,346 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:42,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:45,346 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:47,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:48,256 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:49:48,258 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:49:48,266 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:49:48,267 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:49:48,268 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:49:48,403 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:49:49,157 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:49:50,347 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:53,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:55,348 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:49:58,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:49:59,160 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:50:00,349 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:04,102 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:05,350 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:09,103 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:10,351 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:14,104 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:15,351 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:18,403 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:50:19,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:20,352 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:24,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:25,353 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:29,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:30,355 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:34,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:35,355 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:39,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:40,356 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:40,865 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:50:40,867 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:50:40,870 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:50:40,870 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:50:40,871 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:50:41,174 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:50:44,872 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:45,356 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:48,404 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:50:50,357 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:50,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:50:55,358 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:50:55,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:00,359 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:00,411 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:01,180 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:51:05,360 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:06,158 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:10,360 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:11,159 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:15,361 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:16,159 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:18,404 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:51:20,362 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:21,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:25,363 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:26,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:30,364 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:31,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:33,026 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:51:33,027 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:51:33,031 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:51:33,032 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:51:33,033 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:51:33,190 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:51:35,364 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:37,033 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:40,365 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:42,034 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:45,366 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:47,035 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:48,405 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:51:50,367 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:52,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:51:55,368 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:51:57,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:00,369 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:02,412 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:04,200 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:52:05,369 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:08,971 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:10,370 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:13,972 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:15,371 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:18,405 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:52:19,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:20,372 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:24,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:25,002 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:52:25,004 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:52:25,011 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:52:25,012 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:52:25,013 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:52:25,207 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:52:25,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:30,014 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:30,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:35,020 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:35,374 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:36,210 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:52:40,375 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:41,072 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:45,376 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:46,073 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:48,406 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:52:50,377 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:51,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:52:55,377 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:52:56,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:00,378 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:01,408 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:05,379 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:06,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:10,380 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:11,410 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:15,381 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:16,410 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:16,710 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:53:16,711 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:53:16,714 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:53:16,715 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:53:16,719 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:53:17,223 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:53:18,406 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:53:20,382 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:22,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:25,382 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:27,408 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:30,383 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:32,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:35,384 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:37,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:53:40,385 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:45,386 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:50,387 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:53:55,388 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:00,388 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:05,389 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:08,703 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:54:10,390 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:15,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:20,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:21,158 INFO    SenderThread:27234 [retry.py:__call__():172] Retry attempt failed:
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
-    conn = connection.create_connection(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py", line 95, in create_connection
-    raise err
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
-    sock.connect(sa)
-socket.timeout: timed out
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
-    httplib_response = self._make_request(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 386, in _make_request
-    self._validate_conn(conn)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
-    conn.connect()
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 358, in connect
-    self.sock = conn = self._new_conn()
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 179, in _new_conn
-    raise ConnectTimeoutError(
-urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f55c009ac70>, 'Connection to api.wandb.ai timed out. (connect timeout=10)')
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/adapters.py", line 440, in send
-    resp = conn.urlopen(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 787, in urlopen
-    retries = retries.increment(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
-    raise MaxRetryError(_pool, url, error or ResponseError(cause))
-urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f55c009ac70>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/retry.py", line 131, in __call__
-    result = self._call_fn(*args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py", line 242, in execute
-    return self.client.execute(*args, **kwargs)  # type: ignore
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
-    result = self._get_result(document, *args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
-    return self.transport.execute(document, *args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py", line 38, in execute
-    request = requests.post(self.url, **post_args)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/api.py", line 117, in post
-    return request('post', url, data=data, json=json, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
-    return session.request(method=method, url=url, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/sessions.py", line 529, in request
-    resp = self.send(prep, **send_kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/sessions.py", line 645, in send
-    r = adapter.send(request, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/adapters.py", line 507, in send
-    raise ConnectTimeout(e, request=request)
-requests.exceptions.ConnectTimeout: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f55c009ac70>, 'Connection to api.wandb.ai timed out. (connect timeout=10)'))
-2023-02-09 14:54:25,392 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:27,042 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:54:27,042 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:54:27,044 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:54:27,044 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:54:27,046 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:54:27,046 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:54:27,246 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:54:27,247 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:54:30,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:32,051 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:54:33,248 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:54:35,394 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:37,743 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:54:40,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:42,744 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:54:45,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:47,745 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:54:48,408 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:54:50,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:53,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:54:55,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:54:58,410 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:00,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:02,154 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:55:02,155 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:55:02,160 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:55:02,161 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:55:02,162 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:55:02,257 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:55:04,168 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:05,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:10,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:15,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:20,401 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:25,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:28,145 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:55:28,265 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:55:30,403 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:33,146 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:35,403 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:38,147 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:40,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:43,148 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:45,405 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:48,149 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:48,409 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:55:50,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:53,411 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:55:54,388 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:55:54,390 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:55:54,395 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:55:54,396 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:55:54,397 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:55:55,273 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:55:55,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:55:59,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:00,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:04,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:05,408 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:09,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:10,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:15,410 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:20,410 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:25,008 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:56:25,283 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:56:25,411 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:30,009 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:30,412 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:35,010 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:35,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:40,011 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:40,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:45,011 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:45,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:48,411 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:56:50,309 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:56:50,311 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:50,311 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:56:50,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:56:50,317 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:56:50,318 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:56:50,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:56:51,291 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:56:55,319 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:56:55,416 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:00,320 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:00,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:05,321 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:05,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:10,326 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:10,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:12,298 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:57:15,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:16,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:18,411 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:57:20,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:22,412 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:25,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:27,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:30,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:32,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:35,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:37,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:40,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:42,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:43,212 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:57:43,214 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:57:43,220 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:57:43,220 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:57:43,221 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:57:43,307 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:57:45,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:48,222 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:48,412 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:57:50,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:53,412 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:57:55,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:57:58,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:00,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:03,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:05,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:08,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:10,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:13,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:14,317 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:58:15,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:18,412 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:58:19,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:20,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:24,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:25,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:29,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:30,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:34,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:35,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:35,704 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:58:35,705 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:58:35,709 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:58:35,709 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:58:35,710 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:58:36,324 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:58:39,711 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:40,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:44,717 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:45,327 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:58:45,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:48,413 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:58:50,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:50,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:58:55,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:58:55,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:00,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:00,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:05,416 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:05,437 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:10,416 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:10,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:15,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:15,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:18,413 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:59:20,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:21,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:25,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:26,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:28,533 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 14:59:28,535 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 14:59:28,538 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 14:59:28,539 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 14:59:28,540 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 14:59:29,340 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 14:59:30,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:31,541 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:35,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:36,542 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:40,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:41,543 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:45,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:46,548 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:48,346 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 14:59:48,414 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 14:59:50,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:53,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 14:59:55,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 14:59:58,416 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:00,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:03,416 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:05,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:08,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:10,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:13,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:15,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:18,414 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:00:19,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:20,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:21,275 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:00:21,276 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:00:21,280 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:00:21,281 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:00:21,282 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:00:21,356 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:00:25,283 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:25,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:30,284 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:30,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:35,285 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:35,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:40,285 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:40,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:45,286 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:45,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:48,415 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:00:50,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:00:50,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:52,369 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:00:55,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:00:56,369 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:00,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:01,371 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:05,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:06,371 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:10,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:11,372 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:14,255 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:01:14,256 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:01:14,263 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:01:14,265 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:01:14,266 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:01:14,376 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:01:15,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:17,266 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:18,415 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:01:20,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:22,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:24,381 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:01:25,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:28,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:30,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:33,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:35,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:38,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:40,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:43,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:45,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:48,416 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:01:49,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:50,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:54,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:01:55,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:01:59,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:00,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:04,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:05,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:07,883 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:02:07,885 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:02:07,891 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:02:07,892 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:02:07,893 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:02:08,394 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:02:09,893 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:10,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:14,894 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:15,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:18,416 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:02:20,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:20,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:25,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:25,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:27,400 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:02:30,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:31,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:35,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:36,847 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:40,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:41,848 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:45,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:46,849 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:48,417 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:02:50,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:52,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:02:55,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:02:57,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:00,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:01,211 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:03:01,212 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:03:01,227 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:03:01,228 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:03:01,229 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:03:01,411 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:03:03,229 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:05,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:08,230 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:10,476 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:13,231 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:15,477 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:18,232 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:18,418 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:03:20,478 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:23,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:25,479 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:28,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:30,479 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:32,420 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:03:35,480 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:37,182 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:40,481 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:42,183 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:45,482 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:47,184 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:48,418 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:03:50,483 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:52,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:03:54,639 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:03:54,640 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:03:54,644 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:03:54,644 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:03:54,645 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:03:55,427 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:03:55,484 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:03:57,646 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:00,484 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:02,652 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:04,430 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:04:05,485 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:08,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:10,486 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:13,592 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:15,487 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:18,419 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:04:19,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:20,487 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:24,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:25,488 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:29,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:30,489 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:34,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:35,490 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:39,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:40,490 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:44,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:45,491 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:47,488 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:04:47,490 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:04:47,493 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:04:47,493 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:04:47,494 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:04:48,419 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:04:48,446 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:04:50,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:50,492 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:04:55,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:04:55,493 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:00,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:00,494 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:05,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:05,495 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:09,452 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:05:10,495 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:13,850 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:15,496 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:18,420 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:05:19,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:20,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:24,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:25,498 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:29,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:30,498 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:34,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:35,499 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:39,154 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:05:39,155 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:05:39,161 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:05:39,162 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:05:39,163 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:05:39,462 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:05:40,168 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:40,500 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:42,463 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:05:45,501 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:46,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:48,421 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:05:50,502 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:52,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:05:55,502 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:05:57,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:00,503 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:02,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:05,504 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:07,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:10,505 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:12,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:15,506 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:17,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:18,421 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:06:20,507 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:23,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:25,507 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:28,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:30,508 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:31,255 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:06:31,257 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:06:31,262 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:06:31,262 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:06:31,263 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:06:31,478 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:06:34,264 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:35,509 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:39,265 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:40,510 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:44,274 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:45,482 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:06:45,510 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:48,422 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:06:50,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:50,511 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:06:55,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:06:55,512 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:00,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:00,513 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:05,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:05,514 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:10,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:10,515 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:15,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:15,515 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:18,423 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:07:20,516 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:21,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:22,980 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:07:22,981 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:07:22,986 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:07:22,987 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:07:22,988 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:07:23,495 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:07:25,517 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:26,989 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:30,518 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:31,990 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:35,519 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:36,991 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:40,519 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:41,991 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:45,520 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:46,997 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:48,584 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:07:49,503 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:07:50,521 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:53,585 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:07:55,522 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:07:58,586 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:00,523 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:03,587 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:05,523 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:08,588 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:10,524 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:13,589 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:15,310 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:08:15,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:08:15,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:08:15,319 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:08:15,320 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:08:15,511 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:08:15,525 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:18,424 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:08:19,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:20,526 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:25,514 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:08:25,526 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:29,845 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:30,527 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:34,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:35,528 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:39,847 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:40,529 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:44,848 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:45,530 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:48,424 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:08:50,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:50,530 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:08:55,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:08:55,531 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:00,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:00,532 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:05,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:05,533 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:07,958 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:09:07,959 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:09:07,964 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:09:07,964 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:09:07,966 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:09:08,528 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:09:10,534 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:10,966 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:15,534 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:15,967 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:18,425 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:09:20,535 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:21,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:23,533 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:09:25,536 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:27,880 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:30,537 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:32,880 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:35,538 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:37,881 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:40,538 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:42,882 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:45,539 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:47,883 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:48,425 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:09:50,540 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:53,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:09:55,540 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:09:58,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:00,100 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:10:00,101 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:10:00,106 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:10:00,107 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:10:00,107 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:10:00,541 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:00,544 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:10:04,108 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:05,542 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:09,109 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:10,543 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:14,110 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:15,544 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:18,426 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:10:19,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:20,544 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:24,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:25,545 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:26,553 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:10:30,546 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:30,868 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:35,547 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:35,869 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:40,547 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:40,870 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:45,548 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:45,870 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:48,426 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:10:50,549 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:51,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:52,715 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:10:52,719 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:10:52,725 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:10:52,726 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:10:52,726 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:10:53,562 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:10:55,550 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:10:56,732 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:10:58,563 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:11:00,551 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:02,659 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:05,551 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:07,660 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:10,552 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:12,660 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:15,553 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:17,661 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:18,427 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:11:20,554 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:23,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:25,555 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:28,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:30,555 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:33,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:35,556 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:38,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:40,557 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:43,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:45,059 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:11:45,062 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:11:45,065 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:11:45,065 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:11:45,066 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:11:45,558 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:45,578 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:11:48,427 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:11:49,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:50,559 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:54,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:11:55,560 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:11:59,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:00,561 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:00,583 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:12:05,293 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:05,562 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:10,294 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:10,563 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:15,295 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:15,563 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:18,428 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:12:20,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:20,564 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:25,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:25,565 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:30,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:30,566 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:35,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:35,566 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:37,709 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:12:37,711 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:12:37,715 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:12:37,716 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:12:37,717 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:12:38,595 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:12:40,567 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:40,718 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:45,568 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:45,719 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:48,428 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:12:50,569 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:51,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:12:55,570 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:12:56,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:00,571 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:01,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:02,603 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:13:05,571 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:07,544 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:10,572 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:12,545 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:15,573 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:17,545 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:18,429 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:13:20,574 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:23,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:25,575 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:28,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:30,575 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:30,694 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:13:30,697 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:13:30,703 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:13:30,704 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:13:30,705 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:13:31,612 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:13:33,710 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:35,576 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:37,614 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:13:40,577 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:41,750 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:45,578 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:46,751 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:48,430 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:13:50,578 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:52,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:13:55,579 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:13:57,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:00,580 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:02,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:05,581 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:07,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:10,582 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:12,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:15,583 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:17,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:18,430 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:14:20,583 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:23,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:25,584 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:27,577 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:14:27,581 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:14:27,587 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:14:27,588 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:14:27,589 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:14:27,631 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:14:28,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:30,585 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:33,592 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:35,586 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:38,597 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:39,638 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:14:40,586 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:44,225 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:45,587 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:48,431 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:14:49,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:50,588 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:54,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:14:55,589 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:14:59,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:00,590 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:04,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:05,590 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:09,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:10,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:14,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:15,592 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:18,432 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:15:20,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:20,593 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:22,410 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:15:22,414 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:15:22,417 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:15:22,418 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:15:22,419 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:15:22,651 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:15:25,594 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:26,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:30,594 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:31,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:35,595 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:36,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:40,596 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:41,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:42,657 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:15:45,597 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:47,484 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:48,432 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:15:50,601 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:53,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:15:55,602 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:15:58,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:00,603 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:03,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:05,604 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:08,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:10,605 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:13,437 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:15,304 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:16:15,306 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:16:15,312 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:16:15,313 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:16:15,314 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:16:15,606 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:15,668 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:16:18,433 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:16:19,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:20,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:24,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:25,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:29,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:30,608 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:34,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:35,609 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:39,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:40,610 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:44,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:45,611 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:45,677 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:16:48,433 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:16:50,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:50,611 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:16:55,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:16:55,612 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:00,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:00,613 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:05,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:05,614 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:06,939 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:17:06,941 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:17:06,948 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:17:06,950 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:17:06,951 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:17:07,683 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:17:10,615 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:10,952 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:15,615 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:15,957 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:16,686 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:17:18,434 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:17:20,616 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:22,435 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:25,617 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:27,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:30,618 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:32,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:35,619 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:37,437 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:40,620 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:42,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:45,620 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:47,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:48,434 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:17:50,621 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:53,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:55,622 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:17:58,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:17:58,677 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:17:58,678 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:17:58,681 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:17:58,682 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:17:58,683 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:17:58,699 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:18:00,623 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:03,684 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:05,623 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:08,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:10,624 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:13,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:15,625 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:18,435 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:18:19,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:20,626 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:20,706 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:18:25,503 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:25,627 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:30,503 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:30,628 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:35,504 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:35,628 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:40,505 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:40,629 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:45,506 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:45,631 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:48,436 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:18:50,298 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:18:50,299 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:18:50,304 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:18:50,305 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:18:50,306 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:18:50,632 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:50,715 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:18:51,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:18:52,716 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:18:55,633 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:18:57,119 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:00,634 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:02,120 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:05,634 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:07,121 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:10,635 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:12,121 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:15,636 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:17,122 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:18,436 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:19:20,637 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:22,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:25,638 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:27,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:30,638 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:32,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:35,639 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:37,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:40,640 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:42,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:42,918 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:19:42,922 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:19:42,923 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:19:42,923 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:19:42,925 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:19:43,732 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:19:45,641 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:47,926 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:48,437 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:19:50,642 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:53,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:19:54,735 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:19:55,643 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:19:59,593 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:00,644 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:04,594 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:05,644 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:09,595 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:10,645 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:14,595 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:15,646 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:18,437 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:20:20,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:20,647 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:25,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:25,648 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:30,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:30,648 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:34,962 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:20:34,964 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:20:34,967 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:20:34,968 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:20:34,969 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:20:35,649 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:35,748 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:20:35,970 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:40,650 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:40,971 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:45,651 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:45,972 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:48,438 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:20:50,652 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:51,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:55,652 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:20:56,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:20:57,755 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:21:00,653 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:02,051 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:05,654 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:07,052 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:10,655 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:12,053 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:15,656 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:17,053 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:18,438 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:21:20,656 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:22,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:25,657 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:26,280 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:21:26,281 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:21:26,286 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:21:26,288 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:21:26,289 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:21:26,764 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:21:28,295 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:29,765 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:21:30,658 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:34,426 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:35,659 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:39,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:40,659 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:44,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:45,660 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:48,439 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:21:49,439 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:50,661 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:54,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:21:55,662 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:21:59,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:00,663 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:04,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:05,663 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:09,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:10,664 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:14,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:15,665 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:17,052 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:22:17,053 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:22:17,059 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:22:17,060 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:22:17,061 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:22:17,780 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:22:18,439 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:22:20,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:20,666 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:25,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:25,667 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:30,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:30,667 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:31,784 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:22:35,668 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:36,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:40,669 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:41,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:45,670 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:46,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:48,440 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:22:50,671 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:52,441 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:22:55,671 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:22:57,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:00,672 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:02,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:05,673 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:07,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:08,917 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:23:08,918 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:23:08,922 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:23:08,923 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:23:08,924 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:23:09,796 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:23:10,674 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:12,925 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:15,674 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:17,926 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:18,440 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:23:20,675 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:23,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:25,676 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:28,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:30,677 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:33,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:35,678 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:35,804 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:23:40,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:40,679 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:45,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:45,679 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:48,441 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:23:50,680 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:51,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:55,681 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:23:56,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:23:59,419 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:23:59,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:23:59,428 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:23:59,429 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:23:59,431 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:23:59,812 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:24:00,682 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:02,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:05,683 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:07,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:08,814 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:24:10,683 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:13,039 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:15,684 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:18,040 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:18,441 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:24:20,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:23,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:25,686 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:28,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:30,687 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:33,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:35,688 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:38,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:40,688 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:43,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:45,689 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:48,442 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:24:49,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:50,489 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:24:50,490 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:24:50,494 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:24:50,494 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:24:50,495 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:24:50,690 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:50,827 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:24:54,496 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:24:55,691 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:24:59,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:00,692 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:04,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:05,693 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:09,503 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:10,693 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:10,833 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:25:15,161 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:15,694 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:18,443 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:25:20,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:20,695 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:25,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:25,696 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:30,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:30,697 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:35,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:35,697 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:40,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:40,698 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:40,935 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:25:40,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:25:40,942 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:25:40,943 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:25:40,944 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:25:41,843 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:25:45,699 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:45,945 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:48,443 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:25:50,700 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:51,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:25:55,701 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:25:56,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:00,701 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:01,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:05,702 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:06,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:10,703 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:11,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:12,853 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:26:15,704 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:17,530 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:18,444 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:26:20,705 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:23,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:25,705 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:28,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:30,706 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:32,478 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:26:32,483 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:26:32,488 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:26:32,489 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:26:32,491 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:26:32,859 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:26:33,491 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:35,707 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:38,492 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:40,708 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:43,498 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:44,863 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:26:45,709 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:48,444 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:26:50,445 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:50,709 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:26:55,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:26:55,710 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:00,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:00,711 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:05,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:05,712 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:10,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:10,713 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:15,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:15,714 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:18,445 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:27:20,714 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:21,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:23,991 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:27:23,992 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:27:23,996 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:27:23,997 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:27:23,998 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:27:24,875 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:27:25,716 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:27,000 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:30,717 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:32,000 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:35,718 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:37,001 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:40,719 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:42,002 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:45,720 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:47,007 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:47,882 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:27:48,446 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:27:50,721 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:53,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:27:55,721 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:27:58,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:00,722 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:03,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:05,723 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:08,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:10,723 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:13,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:14,625 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:28:14,626 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:28:14,630 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:28:14,631 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:28:14,632 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:28:14,890 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:28:15,724 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:18,446 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:28:19,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:20,725 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:20,892 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:28:25,025 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:25,726 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:30,025 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:30,727 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:35,026 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:35,728 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:40,027 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:40,728 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:45,028 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:45,729 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:48,447 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:28:50,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:50,730 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:28:55,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:28:55,730 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:00,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:00,731 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:05,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:05,687 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:29:05,689 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:29:05,696 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:29:05,697 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:29:05,698 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:29:05,732 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:05,906 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:29:10,699 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:10,733 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:15,700 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:15,734 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:18,447 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:29:20,734 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:21,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:25,735 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:25,913 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:29:30,088 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:30,736 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:35,089 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:35,737 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:40,090 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:40,738 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:45,090 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:45,738 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:48,447 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:29:50,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:50,739 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:55,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:29:55,740 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:29:57,410 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:29:57,412 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:29:57,416 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:29:57,417 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:29:57,418 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:29:57,922 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:30:00,741 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:01,419 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:05,742 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:06,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:10,742 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:11,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:15,743 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:16,421 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:18,448 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:30:20,744 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:21,449 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:25,745 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:26,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:27,932 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:30:30,746 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:32,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:35,747 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:37,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:40,747 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:42,498 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:45,748 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:47,499 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:48,449 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:30:50,749 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:52,289 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:30:52,291 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:30:52,295 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:30:52,296 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:30:52,297 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:30:52,940 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:30:53,297 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:55,750 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:30:58,303 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:30:58,942 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:31:00,751 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:03,932 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:05,752 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:08,932 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:10,753 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:13,933 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:15,753 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:18,449 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:31:19,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:20,754 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:24,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:25,755 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:29,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:30,756 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:34,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:35,757 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:39,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:40,757 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:44,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:45,758 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:46,548 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:31:46,551 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:31:46,557 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:31:46,559 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:31:46,560 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:31:46,957 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:31:48,450 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:31:50,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:50,760 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:31:55,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:31:55,760 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:00,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:00,761 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:01,962 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:32:05,762 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:06,509 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:10,763 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:11,509 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:15,763 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:16,510 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:18,450 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:32:20,764 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:22,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:25,765 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:27,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:30,766 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:32,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:35,767 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:37,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:40,768 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:42,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:43,045 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:32:43,046 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:32:43,051 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:32:43,052 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:32:43,054 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:32:43,975 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:32:45,769 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:48,055 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:48,451 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:32:50,769 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:53,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:32:55,770 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:32:58,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:00,771 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:03,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:04,982 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:33:05,771 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:09,064 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:10,772 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:14,065 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:15,773 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:18,452 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:33:19,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:20,774 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:24,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:25,775 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:29,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:30,775 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:34,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:35,779 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:36,683 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:33:36,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:33:36,688 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:33:36,689 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:33:36,690 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:33:36,992 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:33:39,691 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:40,780 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:44,691 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:45,781 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:48,452 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:33:50,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:50,781 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:33:55,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:33:55,782 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:00,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:00,783 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:05,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:05,784 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:08,002 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:34:10,784 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:12,099 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:15,785 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:17,100 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:18,453 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:34:20,786 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:22,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:25,787 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:27,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:28,506 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:34:28,507 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:34:28,516 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:34:28,517 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:34:28,518 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:34:29,008 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:34:30,788 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:32,519 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:35,788 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:37,535 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:40,012 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:34:40,789 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:44,202 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:45,790 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:48,453 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:34:49,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:50,791 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:54,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:34:55,792 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:34:59,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:00,792 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:04,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:05,793 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:09,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:10,794 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:14,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:15,795 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:18,454 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:35:20,454 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:20,795 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:20,845 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:35:20,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:35:20,850 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:35:20,851 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:35:20,852 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:35:21,025 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:35:25,796 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:25,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:30,797 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:30,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:35,797 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:35,854 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:40,798 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:40,860 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:43,032 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:35:45,799 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:47,578 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:48,455 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:35:50,800 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:53,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:35:55,800 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:35:58,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:00,801 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:03,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:05,802 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:08,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:10,803 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:12,386 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:36:12,388 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:36:12,392 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:36:12,393 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:36:12,393 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:36:13,041 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:36:14,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:15,803 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:17,042 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:36:18,455 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:36:20,804 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:21,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:25,805 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:26,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:30,806 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:31,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:35,806 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:36,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:40,807 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:41,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:45,808 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:46,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:48,455 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:36:50,809 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:52,456 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:36:55,810 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:36:57,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:00,810 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:02,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:05,507 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:37:05,508 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:37:05,514 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:37:05,515 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:37:05,516 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:37:05,811 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:06,057 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:37:07,516 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:10,812 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:12,517 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:15,813 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:17,522 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:19,175 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:37:20,062 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:37:20,814 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:24,176 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:25,814 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:29,177 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:30,815 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:34,177 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:35,816 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:39,178 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:40,817 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:44,179 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:45,817 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:48,457 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:37:49,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:50,818 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:54,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:37:55,819 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:37:59,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:00,559 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:38:00,561 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:38:00,564 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:38:00,565 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:38:00,570 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:38:00,820 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:01,076 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:38:04,571 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:05,820 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:09,572 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:10,821 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:14,573 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:15,822 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:18,457 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:38:20,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:20,823 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:23,083 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:38:25,824 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:27,520 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:30,824 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:32,521 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:35,825 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:37,522 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:40,826 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:42,523 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:45,827 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:47,523 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:48,457 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:38:50,828 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:53,186 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:38:53,192 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:38:53,194 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:38:55,605 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:38:55,606 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:38:55,606 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:38:55,829 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:38:56,092 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:38:56,093 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:39:00,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:00,830 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:05,608 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:05,830 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:10,609 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:10,831 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:15,609 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:15,832 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:18,458 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:39:20,833 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:21,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:25,834 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:26,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:30,835 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:31,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:35,835 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:36,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:40,836 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:41,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:45,114 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:39:45,115 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:39:45,121 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:39:45,122 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:39:45,122 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:39:45,837 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:46,109 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:39:47,123 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:48,458 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:39:50,838 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:52,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:55,839 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:39:57,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:39:59,113 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:40:00,839 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:03,989 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:05,840 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:08,990 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:10,841 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:13,990 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:15,842 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:18,459 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:40:19,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:20,842 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:24,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:25,843 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:29,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:30,844 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:34,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:35,845 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:37,256 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:40:37,258 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:40:37,261 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:40:37,262 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:40:37,262 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:40:38,126 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:40:40,263 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:40,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:45,264 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:45,847 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:48,460 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:40:50,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:50,848 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:40:55,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:40:55,849 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:00,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:00,849 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:02,133 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:41:05,850 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:06,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:10,851 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:11,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:15,852 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:16,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:18,460 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:41:20,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:21,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:25,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:26,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:28,981 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:41:28,983 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:41:28,986 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:41:28,986 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:41:28,987 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:41:29,142 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:41:30,854 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:31,992 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:33,144 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:41:35,855 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:37,985 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:40,856 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:42,985 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:45,856 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:47,986 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:48,461 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:41:50,857 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:53,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:41:55,858 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:41:58,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:00,859 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:03,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:05,860 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:08,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:10,860 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:13,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:15,861 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:18,461 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:42:19,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:20,862 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:20,921 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:42:20,923 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:42:20,934 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:42:20,935 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:42:20,936 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:42:21,160 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:42:24,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:25,863 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:29,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:30,864 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:34,942 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:35,864 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:37,165 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:42:40,865 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:41,284 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:45,866 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:46,285 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:48,462 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:42:50,867 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:51,462 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:42:55,868 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:42:56,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:00,869 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:01,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:05,870 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:06,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:10,870 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:11,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:12,767 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:43:12,769 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:43:12,773 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:43:12,773 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:43:12,774 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:43:13,176 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:43:15,871 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:16,775 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:18,462 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:43:20,872 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:22,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:25,873 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:27,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:30,873 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:32,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:35,874 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:37,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:39,184 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:43:40,875 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:43,382 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:45,876 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:48,383 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:48,463 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:43:50,876 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:53,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:43:55,877 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:43:58,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:00,878 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:03,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:05,269 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:44:05,271 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:44:05,275 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:44:05,275 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:44:05,276 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:44:05,879 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:06,192 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:44:09,281 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:10,880 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:11,194 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:44:15,266 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:15,880 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:18,463 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:44:20,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:20,881 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:25,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:25,882 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:30,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:30,883 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:35,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:35,883 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:40,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:40,884 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:45,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:45,885 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:48,463 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:44:50,886 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:51,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:55,887 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:44:56,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:44:58,431 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:44:58,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:44:58,440 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:44:58,440 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:44:58,441 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:44:59,209 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:45:00,887 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:02,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:05,888 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:07,443 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:10,889 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:12,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:14,213 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:45:15,890 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:18,464 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:45:19,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:20,891 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:24,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:25,892 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:29,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:30,892 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:34,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:35,893 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:39,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:40,894 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:44,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:45,895 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:48,465 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:45:50,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:50,896 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:45:54,772 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:45:54,774 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:45:54,777 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:45:54,778 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:45:54,779 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:45:55,227 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:45:55,779 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:45:55,896 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:00,780 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:00,897 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:05,781 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:05,898 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:10,782 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:10,899 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:15,787 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:15,900 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:17,234 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:46:18,465 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:46:20,900 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:21,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:25,901 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:26,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:30,902 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:31,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:35,903 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:36,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:40,904 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:41,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:45,904 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:46,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:47,781 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:46:47,783 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:46:47,787 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:46:47,787 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:46:47,788 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:46:48,244 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:46:48,465 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:46:50,905 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:52,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:46:55,906 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:46:57,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:00,907 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:02,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:05,908 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:07,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:10,909 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:12,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:15,909 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:17,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:18,466 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:47:19,269 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:47:20,910 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:23,467 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:25,911 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:28,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:30,912 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:33,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:35,913 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:38,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:40,079 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:47:40,081 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:47:40,085 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:47:40,086 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:47:40,087 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:47:40,276 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:47:40,914 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:44,088 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:45,915 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:48,467 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:47:49,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:50,279 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:47:50,916 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:47:55,025 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:47:55,917 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:00,026 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:00,917 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:05,027 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:05,918 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:10,028 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:10,919 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:15,028 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:15,920 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:18,467 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:48:20,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:20,921 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:25,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:25,922 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:30,469 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:30,923 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:32,767 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:48:32,769 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:48:32,772 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:48:32,773 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:48:32,773 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:48:33,292 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:48:35,774 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:35,924 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:40,775 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:40,924 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:45,784 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:45,925 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:48,469 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:48:50,926 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:51,478 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:48:54,301 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:48:55,927 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:48:58,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:00,935 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:03,430 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:05,936 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:08,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:10,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:13,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:15,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:18,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:18,469 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:49:20,938 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:23,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:25,939 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:28,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:30,940 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:33,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:35,941 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:38,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:40,942 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:43,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:45,942 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:48,471 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:49:49,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:50,943 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:54,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:49:55,944 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:49:59,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:00,674 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:50:00,676 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:50:00,681 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:50:00,682 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:50:00,683 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:50:00,945 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:01,323 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:50:04,684 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:05,946 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:09,685 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:10,947 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:14,686 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:15,948 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:18,470 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:50:20,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:20,949 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:25,476 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:25,950 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:27,332 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:50:30,951 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:32,325 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:35,951 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:37,325 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:40,952 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:42,326 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:45,953 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:47,327 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:48,470 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:50:50,954 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:52,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:50:54,423 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:50:54,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:50:54,436 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:50:54,437 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:50:54,438 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:50:55,340 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:50:55,955 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:50:58,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:00,342 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:51:00,955 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:04,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:05,956 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:09,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:10,957 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:14,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:15,958 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:18,471 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:51:20,476 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:20,958 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:25,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:25,959 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:30,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:30,960 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:35,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:35,961 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:40,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:40,962 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:45,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:45,963 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:47,919 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:51:47,920 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:51:47,923 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:51:47,924 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:51:47,925 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:51:48,360 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:51:48,471 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:51:50,963 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:51,472 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:51:55,964 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:51:56,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:00,965 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:01,478 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:02,365 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 15:52:05,966 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:07,230 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:10,966 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:12,230 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:15,967 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:17,231 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:18,472 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:52:20,968 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:22,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:25,969 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:27,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:30,970 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:32,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:35,970 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:37,476 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:40,510 DEBUG   SenderThread:27234 [sender.py:send():336] send: config
-2023-02-09 15:52:40,512 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: partial_history
-2023-02-09 15:52:40,516 DEBUG   SenderThread:27234 [sender.py:send():336] send: history
-2023-02-09 15:52:40,517 DEBUG   SenderThread:27234 [sender.py:send_request():363] send_request: summary_record
-2023-02-09 15:52:40,521 INFO    SenderThread:27234 [sender.py:_save_file():1321] saving file wandb-summary.json with policy end
-2023-02-09 15:52:40,971 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:41,377 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/wandb-summary.json
-2023-02-09 15:52:42,521 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:45,972 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:47,522 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:48,472 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 15:52:50,973 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:53,474 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:52:55,975 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:52:58,476 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:53:00,977 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:03,484 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 15:53:05,978 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:06,865 INFO    SenderThread:27234 [retry.py:__call__():172] Retry attempt failed:
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 174, in _new_conn
-    conn = connection.create_connection(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/util/connection.py", line 72, in create_connection
-    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
-  File "/home/daniel/miniconda3/lib/python3.8/socket.py", line 918, in getaddrinfo
-    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
-socket.gaierror: [Errno -2] Name or service not known
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 703, in urlopen
-    httplib_response = self._make_request(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 386, in _make_request
-    self._validate_conn(conn)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1042, in _validate_conn
-    conn.connect()
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 358, in connect
-    self.sock = conn = self._new_conn()
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connection.py", line 186, in _new_conn
-    raise NewConnectionError(
-urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection object at 0x7f55c012d3a0>: Failed to establish a new connection: [Errno -2] Name or service not known
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/adapters.py", line 440, in send
-    resp = conn.urlopen(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/connectionpool.py", line 787, in urlopen
-    retries = retries.increment(
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/urllib3/util/retry.py", line 592, in increment
-    raise MaxRetryError(_pool, url, error or ResponseError(cause))
-urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c012d3a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
-
-During handling of the above exception, another exception occurred:
-
-Traceback (most recent call last):
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/sdk/lib/retry.py", line 131, in __call__
-    result = self._call_fn(*args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/sdk/internal/internal_api.py", line 242, in execute
-    return self.client.execute(*args, **kwargs)  # type: ignore
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 52, in execute
-    result = self._get_result(document, *args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py", line 60, in _get_result
-    return self.transport.execute(document, *args, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/wandb/vendor/gql-0.2.0/wandb_gql/transport/requests.py", line 38, in execute
-    request = requests.post(self.url, **post_args)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/api.py", line 117, in post
-    return request('post', url, data=data, json=json, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/api.py", line 61, in request
-    return session.request(method=method, url=url, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/sessions.py", line 529, in request
-    resp = self.send(prep, **send_kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/sessions.py", line 645, in send
-    r = adapter.send(request, **kwargs)
-  File "/home/daniel/miniconda3/lib/python3.8/site-packages/requests/adapters.py", line 519, in send
-    raise ConnectionError(e, request=request)
-requests.exceptions.ConnectionError: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /graphql (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c012d3a0>: Failed to establish a new connection: [Errno -2] Name or service not known'))
-2023-02-09 15:53:10,981 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:15,982 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:20,984 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:25,986 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:30,988 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:35,990 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:40,992 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:45,994 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:50,996 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:53:55,998 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:01,000 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:06,002 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:11,004 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:16,006 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:21,008 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:26,011 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:31,013 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:36,015 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:41,017 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:46,019 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:51,021 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:54:56,021 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:01,022 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:06,022 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:11,023 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:16,024 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:21,024 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:26,025 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:31,026 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:36,026 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:41,027 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:46,028 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:51,028 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:55:56,029 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:01,030 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:06,030 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:11,031 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:16,032 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:21,032 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:26,033 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:31,033 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:36,034 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:41,035 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:46,035 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:51,036 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:56:56,037 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:01,037 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:06,038 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:11,038 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:16,039 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:21,040 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:26,040 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:31,041 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:36,042 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:41,042 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:46,043 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:51,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:57:56,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:01,045 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:06,045 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:11,046 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:16,047 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:21,048 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:26,048 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:31,049 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:36,049 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:41,050 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:46,051 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:51,051 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:58:56,052 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:01,053 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:06,053 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:11,054 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:16,054 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:21,055 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:26,056 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:31,056 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:36,057 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:41,058 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:46,058 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:51,059 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 15:59:56,060 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:01,060 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:06,061 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:11,062 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:16,062 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:21,063 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:26,064 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:31,064 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:36,065 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:41,066 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:46,066 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:51,067 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:00:56,068 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:01,068 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:06,069 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:11,069 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:16,070 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:21,071 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:26,071 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:31,072 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:36,072 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:41,073 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:46,074 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:51,074 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:01:56,075 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:01,076 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:06,076 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:11,077 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:16,078 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:21,078 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:26,079 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:31,080 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:36,080 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:41,081 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:46,081 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:51,082 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:02:56,083 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:01,083 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:06,084 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:11,084 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:16,085 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:21,086 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:26,086 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:31,087 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:36,088 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:41,088 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:46,089 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:51,089 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:03:56,090 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:01,091 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:06,091 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:11,092 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:16,093 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:21,093 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:26,094 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:31,095 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:36,095 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:41,096 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:46,096 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:51,097 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:04:56,098 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:01,098 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:06,099 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:11,099 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:16,100 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:21,101 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:26,101 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:31,102 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:36,102 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:41,103 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:46,104 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:51,104 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:05:56,105 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:01,106 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:06,106 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:11,107 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:16,108 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:21,108 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:26,109 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:31,109 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:36,110 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:41,111 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:46,111 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:51,112 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:06:56,113 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:01,113 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:06,114 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:11,114 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:16,116 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:21,117 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:26,117 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:31,118 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:36,119 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:41,119 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:46,120 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:51,120 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:07:56,121 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:01,122 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:06,122 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:11,123 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:16,123 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:21,124 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:26,125 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:31,125 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:36,126 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:41,127 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:46,127 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:51,128 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:08:56,129 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:01,129 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:06,130 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:11,131 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:16,131 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:21,132 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:24,294 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: ('Connection aborted.', OSError(101, 'Network is unreachable')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:09:26,133 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:26,581 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55a0346940>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:09:30,904 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55a03463a0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:09:31,133 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:36,134 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:40,769 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c00caf40>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:09:41,135 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:46,136 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:51,138 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:56,140 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:09:57,208 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c00ca6a0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:10:01,143 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:06,145 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:11,147 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:16,149 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:21,150 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:26,152 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:31,155 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:34,341 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c00ca880>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:10:36,157 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:41,160 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:46,162 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:51,164 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:10:56,166 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:01,168 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:06,170 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:11,172 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:16,173 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:21,176 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:26,179 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:31,180 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:36,182 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:41,185 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:46,187 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:51,190 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:11:52,780 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55a033f040>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:11:56,192 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:01,194 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:06,196 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:11,199 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:16,201 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:21,202 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:26,205 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:31,208 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:36,210 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:41,212 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:46,214 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:51,216 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:12:56,218 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:01,220 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:06,222 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:11,224 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:16,227 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:21,228 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:26,231 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:31,233 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:36,236 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:41,238 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:46,240 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:51,242 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:13:56,245 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:01,247 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:05,137 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009afa0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:14:06,249 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:11,252 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:16,255 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:21,256 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:26,259 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:31,261 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:36,263 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:41,265 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:46,268 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:51,270 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:14:56,273 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:01,275 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:06,276 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:11,279 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:16,281 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:21,284 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:26,286 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:31,288 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:36,291 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:41,292 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:46,294 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:51,296 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:15:56,299 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:01,301 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:06,303 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:11,306 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:16,307 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:21,309 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:26,311 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:31,314 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:36,317 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:41,319 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:46,321 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:51,323 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:16:56,326 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:01,327 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:06,330 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:11,332 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:16,335 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:21,336 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:26,339 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:31,341 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:36,343 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:41,345 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:46,346 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:51,349 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:17:56,351 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:01,353 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:06,355 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:11,357 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:16,360 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:21,362 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:26,364 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:31,366 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:36,368 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:41,371 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:46,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:51,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:18:56,376 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:01,377 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:06,379 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:08,502 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009afa0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:19:11,382 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:16,384 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:21,387 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:26,389 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:31,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:36,394 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:41,396 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:46,398 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:51,399 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:19:56,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:01,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:06,407 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:11,409 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:16,411 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:21,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:26,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:31,417 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:36,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:41,422 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:46,424 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:51,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:20:56,428 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:01,431 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:06,433 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:11,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:16,438 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:21,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:26,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:31,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:36,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:41,447 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:46,450 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:51,452 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:21:56,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:01,457 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:06,459 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:11,461 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:16,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:21,465 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:26,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:31,470 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:36,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:41,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:46,477 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:51,479 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:22:56,481 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:01,484 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:06,486 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:11,488 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:16,490 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:21,492 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:26,494 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:31,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:36,499 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:41,501 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:46,503 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:51,505 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:23:56,507 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:01,510 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:06,512 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:11,515 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:16,288 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009a910>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:24:16,517 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:21,519 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:26,520 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:31,524 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:36,526 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:41,528 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:46,530 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:51,532 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:24:56,535 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:01,537 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:06,539 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:11,541 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:16,543 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:21,545 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:26,548 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:31,550 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:36,552 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:41,554 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:46,556 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:51,558 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:25:56,561 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:01,562 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:06,565 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:11,566 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:16,568 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:21,570 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:26,573 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:31,575 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:36,578 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:41,580 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:46,582 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:51,584 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:26:56,587 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:01,588 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:06,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:11,593 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:16,596 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:21,598 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:26,600 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:31,602 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:36,604 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:41,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:46,609 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:51,611 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:27:56,613 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:01,616 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:06,617 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:11,620 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:16,623 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:21,625 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:26,627 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:31,630 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:36,632 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:41,634 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:46,636 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:51,638 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:28:56,640 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:01,642 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:06,644 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:11,646 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:16,649 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:21,651 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:26,653 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:31,656 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:36,658 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:41,661 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:46,662 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:51,665 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:29:52,380 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55a03490d0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:29:56,667 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:01,669 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:06,672 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:11,673 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:16,676 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:21,678 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:26,680 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:31,682 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:36,684 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:41,686 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:46,688 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:51,691 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:30:56,692 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:01,694 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:06,696 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:11,699 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:16,701 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:21,703 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:26,705 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:31,708 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:36,710 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:41,712 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:46,714 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:51,716 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:31:56,719 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:01,721 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:06,724 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:11,727 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:16,729 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:21,731 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:26,732 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:31,735 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:36,737 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:41,739 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:46,741 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:51,743 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:32:56,746 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:01,748 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:06,751 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:11,753 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:16,755 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:21,758 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:26,760 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:31,761 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:36,763 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:41,766 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:46,768 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:51,770 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:33:56,772 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:01,775 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:06,777 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:11,779 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:16,781 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:21,784 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:26,786 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:31,788 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:36,790 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:41,793 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:46,795 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:51,798 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:34:56,800 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:01,802 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:06,805 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:11,807 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:15,520 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55a0349c40>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:35:16,809 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:21,812 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:26,814 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:31,817 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:36,819 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:41,821 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:46,823 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:51,825 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:35:56,827 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:01,830 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:06,831 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:11,833 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:16,836 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:21,839 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:26,841 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:31,844 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:36,846 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:41,848 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:46,850 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:51,851 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:36:56,853 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:01,856 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:06,858 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:11,860 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:16,861 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:21,864 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:26,867 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:31,869 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:36,871 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:41,874 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:46,876 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:51,878 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:37:56,880 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:01,882 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:06,884 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:11,886 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:16,888 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:21,890 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:26,892 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:31,895 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:36,897 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:41,899 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:46,901 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:51,904 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:38:56,906 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:01,908 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:06,909 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:11,912 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:16,914 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:21,916 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:26,919 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:31,921 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:36,923 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:41,925 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:46,928 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:51,930 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:39:56,931 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:01,935 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:06,937 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:11,939 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:16,941 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:21,944 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:26,946 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:31,948 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:36,950 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:41,952 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:46,955 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:51,957 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:40:56,959 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:01,961 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:06,964 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:11,966 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:16,967 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:21,969 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:24,956 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c012d0a0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:41:26,971 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:31,973 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:36,975 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:41,976 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:46,979 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:51,982 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:41:56,984 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:01,986 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:06,988 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:11,991 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:16,993 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:21,996 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:26,998 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:32,000 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:37,002 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:42,004 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:47,006 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:52,008 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:42:57,010 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:02,013 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:07,015 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:12,017 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:17,019 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:22,022 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:27,024 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:32,026 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:37,027 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:42,030 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:47,032 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:52,034 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:43:57,036 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:02,039 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:07,042 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:12,044 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:17,046 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:22,047 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:27,050 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:32,052 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:37,055 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:42,057 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:47,059 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:52,061 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:44:57,063 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:02,065 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:07,067 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:12,070 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:17,072 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:22,074 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:27,076 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:32,078 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:37,080 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:42,083 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:47,085 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:52,087 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:45:57,090 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:02,092 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:07,095 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:12,097 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:17,099 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:22,101 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:27,103 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:32,105 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:37,108 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:42,109 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:47,112 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:52,113 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:46:57,115 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:00,156 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c012d490>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:47:02,118 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:07,120 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:12,123 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:17,125 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:22,127 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:27,129 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:32,132 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:37,134 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:42,135 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:47,137 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:52,139 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:47:57,142 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:02,144 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:07,146 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:12,148 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:17,150 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:22,152 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:27,154 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:32,156 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:37,158 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:42,160 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:47,163 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:52,165 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:48:57,168 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:02,170 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:07,172 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:12,174 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:17,176 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:22,179 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:27,180 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:32,182 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:37,184 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:42,187 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:47,189 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:52,191 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:49:57,194 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:02,196 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:07,198 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:12,200 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:17,202 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:22,204 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:27,206 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:32,208 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:37,210 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:42,212 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:47,215 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:52,217 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:50:57,219 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:02,219 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:07,223 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:12,225 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:17,227 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:22,229 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:27,231 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:32,233 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:37,236 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:42,238 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:47,240 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:52,242 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:51:57,245 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:02,247 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:07,249 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:12,252 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:17,254 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:22,256 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:27,258 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:32,259 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:37,261 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:42,263 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:45,268 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009c3d0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:52:47,266 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:52,268 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:52:57,271 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:02,273 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:07,275 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:12,277 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:17,280 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:22,283 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:27,284 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:32,287 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:37,289 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:42,291 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:47,293 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:52,295 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:53:57,298 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:02,300 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:07,302 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:12,305 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:17,307 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:22,309 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:27,312 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:32,314 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:37,316 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:42,318 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:47,320 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:52,322 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:54:57,324 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:02,327 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:07,329 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:12,330 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:17,333 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:22,336 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:27,338 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:32,341 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:37,343 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:42,345 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:47,347 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:52,348 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:55:57,351 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:02,353 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:07,356 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:12,357 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:17,360 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:22,362 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:27,364 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:32,367 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:37,368 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:42,371 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:47,373 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:52,376 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:56:57,378 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:02,380 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:07,382 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:12,383 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:17,386 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:22,388 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:27,391 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:32,393 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:37,395 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:42,397 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:47,400 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:52,402 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:57:57,404 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:02,406 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:07,408 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:12,411 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:17,413 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:22,415 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:27,418 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:32,420 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:35,959 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009c3d0>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 16:58:37,423 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:42,425 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:47,427 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:52,429 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:58:57,432 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:02,434 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:07,436 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:12,437 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:17,440 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:22,442 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:27,444 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:32,446 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:37,448 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:42,451 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:47,453 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:52,455 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 16:59:57,458 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:02,460 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:07,463 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:12,464 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:17,466 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:22,468 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:27,471 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:32,473 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:37,475 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:42,477 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:47,480 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:52,482 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:00:57,485 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:02,487 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:07,488 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:12,491 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:17,494 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:22,495 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:27,497 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:32,500 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:37,502 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:42,504 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:47,507 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:52,508 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:01:57,511 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:02,513 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:07,516 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:12,518 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:17,520 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:22,522 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:27,524 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:32,527 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:37,528 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:42,531 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:47,533 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:52,535 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:02:57,537 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:02,539 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:07,542 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:12,544 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:17,547 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:22,549 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:27,552 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:32,553 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:37,555 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:42,558 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:47,560 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:52,561 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:03:57,564 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:02,566 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:07,568 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:12,571 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:17,573 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:22,575 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:25,100 WARNING FileStreamThread:27234 [file_stream.py:request_with_retry():667] requests_with_retry encountered retryable exception: HTTPSConnectionPool(host='api.wandb.ai', port=443): Max retries exceeded with url: /files/danieladejumo/DARM/80340_00000/file_stream (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f55c009c250>: Failed to establish a new connection: [Errno -2] Name or service not known')). func: <bound method Session.post of <requests.sessions.Session object at 0x7f55c1e662b0>>, args: ('https://api.wandb.ai/files/danieladejumo/DARM/80340_00000/file_stream',), kwargs: {'json': {'files': {'wandb-summary.json': {'offset': 0, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734}']}, 'wandb-history.jsonl': {'offset': 96, 'content': ['{"episode_reward_max": -156.1826542466879, "episode_reward_min": -191.28636541962624, "episode_reward_mean": -169.9554263330996, "episode_len_mean": 100.0, "episodes_this_iter": 10, "num_faulty_episodes": 0, "num_healthy_workers": 3, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 1, "num_agent_steps_sampled": 97193, "num_agent_steps_trained": 7473664, "num_env_steps_sampled": 97193, "num_env_steps_trained": 7473664, "num_env_steps_sampled_this_iter": 1002, "num_env_steps_trained_this_iter": 85504, "timesteps_total": 97193, "num_steps_trained_this_iter": 85504, "agent_timesteps_total": 97193, "episodes_total": 1000, "training_iteration": 97, "timestamp": 1675954360, "time_this_iter_s": 52.549543619155884, "time_total_s": 4664.705418109894, "time_since_restore": 4664.705418109894, "timesteps_since_restore": 0, "iterations_since_restore": 97, "warmup_time": 8.03538990020752, "info/num_env_steps_sampled": 97193, "info/num_env_steps_trained": 7473664, "info/num_agent_steps_sampled": 97193, "info/num_agent_steps_trained": 7473664, "info/last_target_update_ts": 97193, "info/num_target_updates": 29194, "sampler_results/episode_reward_max": -156.1826542466879, "sampler_results/episode_reward_min": -191.28636541962624, "sampler_results/episode_reward_mean": -169.9554263330996, "sampler_results/episode_len_mean": 100.0, "sampler_results/episodes_this_iter": 10, "sampler_results/num_faulty_episodes": 0, "sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_perf/mean_env_render_ms": 0.0, "timers/training_iteration_time_ms": 161.318, "timers/load_time_ms": 0.312, "timers/load_throughput": 821657.349, "timers/learn_time_ms": 25.987, "timers/learn_throughput": 9851.041, "timers/synch_weights_time_ms": 7.023, "counters/num_env_steps_sampled": 97193, "counters/num_env_steps_trained": 7473664, "counters/num_agent_steps_sampled": 97193, "counters/num_agent_steps_trained": 7473664, "counters/last_target_update_ts": 97193, "counters/num_target_updates": 29194, "perf/cpu_util_percent": 39.38055555555556, "perf/ram_util_percent": 91.3138888888889, "sampler_results/sampler_perf/mean_raw_obs_processing_ms": 1.1364653920600976, "sampler_results/sampler_perf/mean_inference_ms": 2.3486854601514455, "sampler_results/sampler_perf/mean_action_processing_ms": 0.22231085102003592, "sampler_results/sampler_perf/mean_env_wait_ms": 2.9007591400230686, "sampler_results/sampler_perf/mean_env_render_ms": 0.0, "info/learner/default_policy/mean_td_error": 37.32743453979492, "info/learner/default_policy/num_agent_steps_trained": 256.0, "info/learner/default_policy/num_grad_updates_lifetime": 29194.0, "info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy": 29193.0, "info/learner/default_policy/learner_stats/allreduce_latency": 0.0, "info/learner/default_policy/learner_stats/grad_gnorm": 0.8870038390159607, "info/learner/default_policy/learner_stats/actor_loss": 115.60578918457031, "info/learner/default_policy/learner_stats/critic_loss": 1.3008311986923218, "info/learner/default_policy/learner_stats/alpha_loss": 3.3117122650146484, "info/learner/default_policy/learner_stats/alpha_value": 0.023906756192445755, "info/learner/default_policy/learner_stats/log_alpha_value": -3.7335941791534424, "info/learner/default_policy/learner_stats/target_entropy": -5.0, "info/learner/default_policy/learner_stats/policy_t": -0.3005792200565338, "info/learner/default_policy/learner_stats/mean_q": -115.54031372070312, "info/learner/default_policy/learner_stats/max_q": -109.50465393066406, "info/learner/default_policy/learner_stats/min_q": -120.56295013427734, "_timestamp": 1675954360.5104206, "_runtime": 4676.956527471542, "_step": 96}']}, 'wandb-events.jsonl': {'offset': 154, 'content': ['{"system.disk": 96.1, "system.cpu": 0.02, "system.cpu.0.cpu_percent": 41.53, "system.cpu.1.cpu_percent": 37.1, "system.cpu.2.cpu_percent": 38.65, "system.cpu.3.cpu_percent": 42.23, "system.proc.cpu.threads": 11, "system.proc.memory.availableMB": 657.12, "system.memory": 91.39, "system.proc.memory.rssMB": 284.66, "system.proc.memory.percent": 3.73, "system.network.sent": 1003265361.07, "system.network.recv": 1015202409.33, "_wandb": true, "_timestamp": 1675954368.471996, "_runtime": 4684.918103}']}}, 'dropped': 0}}
-2023-02-09 17:04:27,577 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:32,579 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:37,581 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:42,583 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:47,585 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:52,587 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:04:57,589 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:02,591 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:07,594 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:12,596 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:17,597 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:22,600 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:27,602 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:32,604 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:37,607 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:42,608 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:47,611 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:52,613 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:05:57,615 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:02,617 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:07,620 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:12,622 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:17,623 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:22,625 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:27,628 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:32,629 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:37,631 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:42,633 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:47,634 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:52,635 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:06:57,636 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:02,637 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:07,639 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:12,641 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:17,643 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:22,644 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:27,646 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:32,647 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:37,648 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:42,650 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:47,651 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:52,652 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:07:57,654 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:02,655 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:07,657 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:12,660 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:17,661 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:22,664 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:27,666 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:32,668 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:37,670 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:42,672 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:47,674 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:52,315 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,315 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,316 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,317 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,317 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,317 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,317 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,318 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,319 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,320 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,321 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,321 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,321 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,322 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,323 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,324 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,325 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,326 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,327 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,328 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,329 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,329 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,329 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,329 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,330 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,331 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,332 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,333 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,333 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,333 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,334 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,335 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,336 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,336 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,336 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,336 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,336 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,337 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,337 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,337 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,337 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,338 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,339 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,340 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,340 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,340 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,340 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,340 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,341 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,341 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,341 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,342 DEBUG   SenderThread:27234 [sender.py:send():336] send: stats
-2023-02-09 17:08:52,675 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:08:53,317 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/config.yaml
-2023-02-09 17:08:53,318 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_created():275] file/dir created: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/output.log
-2023-02-09 17:08:55,319 INFO    Thread-13 :27234 [dir_watcher.py:_on_file_modified():292] file/dir modified: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/files/output.log
-2023-02-09 17:08:57,344 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 17:08:57,676 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
-2023-02-09 17:09:02,345 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: status_report
-2023-02-09 17:09:02,678 DEBUG   HandlerThread:27234 [handler.py:handle_request():144] handle_request: keepalive
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug.log b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug.log
deleted file mode 100644
index dab7a41..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug.log
+++ /dev/null
@@ -1,125 +0,0 @@
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_setup.py:_flush():68] Configure stats pid to 27221
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_setup.py:_flush():68] Loading settings from /home/daniel/.config/wandb/settings
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_setup.py:_flush():68] Loading settings from /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/settings
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'start_method': 'thread'}
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program': '<python with no main file>'}
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_init.py:_log_setup():492] Logging user logs to /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug.log
-2023-02-09 14:34:43,529 INFO    MainThread:27221 [wandb_init.py:_log_setup():493] Logging internal logs to /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/logs/debug-internal.log
-2023-02-09 14:34:43,530 INFO    MainThread:27221 [wandb_init.py:_jupyter_setup():438] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7fde8d541a00>
-2023-02-09 14:34:43,531 INFO    MainThread:27221 [wandb_init.py:init():532] calling init triggers
-2023-02-09 14:34:43,531 INFO    MainThread:27221 [wandb_init.py:init():538] wandb.init called with sweep_config: {}
-config: {'env': 'DARMSFHand-v0', 'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003, 'framework': 'torch', 'num_rollout_workers': 3, 'num_gpu': 0, 'metrics_num_episodes_for_smoothing': 5}
-2023-02-09 14:34:43,531 INFO    MainThread:27221 [wandb_init.py:init():588] starting backend
-2023-02-09 14:34:43,531 INFO    MainThread:27221 [wandb_init.py:init():592] setting up manager
-2023-02-09 14:34:43,553 INFO    MainThread:27221 [wandb_init.py:init():599] backend started and connected
-2023-02-09 14:34:43,590 INFO    MainThread:27221 [wandb_run.py:_label_probe_notebook():1203] probe notebook
-2023-02-09 14:34:43,591 INFO    MainThread:27221 [wandb_run.py:_label_probe_notebook():1213] Unable to probe notebook: 'NoneType' object has no attribute 'get'
-2023-02-09 14:34:43,591 INFO    MainThread:27221 [wandb_init.py:init():687] updated telemetry
-2023-02-09 14:34:43,676 INFO    MainThread:27221 [wandb_init.py:init():727] communicating run to backend with 60.0 second timeout
-2023-02-09 14:34:45,772 INFO    MainThread:27221 [wandb_run.py:_on_init():2134] communicating current version
-2023-02-09 14:34:48,365 INFO    MainThread:27221 [wandb_run.py:_on_init():2143] got version response 
-2023-02-09 14:34:48,366 INFO    MainThread:27221 [wandb_init.py:init():775] starting run threads in backend
-2023-02-09 14:34:55,196 INFO    MainThread:27221 [wandb_run.py:_console_start():2114] atexit reg
-2023-02-09 14:34:55,196 INFO    MainThread:27221 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
-2023-02-09 14:34:55,198 INFO    MainThread:27221 [wandb_run.py:_redirect():2034] Wrapping output streams.
-2023-02-09 14:34:55,198 INFO    MainThread:27221 [wandb_run.py:_redirect():2059] Redirects installed.
-2023-02-09 14:34:55,199 INFO    MainThread:27221 [wandb_init.py:init():817] run started, returning control to user process
-2023-02-09 14:34:55,200 INFO    MainThread:27221 [wandb_config.py:__setitem__():155] config set trial_log_path = /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x7fde8ccf0d00>>
-2023-02-09 14:34:55,200 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb trial_log_path /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39 None
-2023-02-09 14:34:56,397 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ab700>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3808eb80>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-34-56', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:00,851 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380930a0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde38127040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-00', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:05,197 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a580>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac550>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-05', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:10,313 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805aaf0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-10', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:14,727 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805afd0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac4c0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-14', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:19,127 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2550>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b670>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-19', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:23,134 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2940>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde380ac550>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-23', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:27,030 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb910>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ba280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-27', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:30,985 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbd60>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3808ef70>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-30', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:35:36,091 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2070>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde3807b430>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-35-36', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:36:28,131 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2970>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde38127040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-36-28', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:37:20,398 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a4f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-37-20', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:38:17,112 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2c70>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cdca0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-38-17', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:39:18,828 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105ef040>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd3a0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-39-18', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:40:14,011 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2bb0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105dd430>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-40-13', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:41:04,319 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a100>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105dd670>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-41-04', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:41:57,615 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580850>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a4160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-41-57', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:42:49,584 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105882b0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a4af0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-42-49', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:43:41,824 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588460>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1058b040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-43-41', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:44:33,671 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbac0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a45e0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-44-33', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:45:25,838 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380cfb20>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cd5e0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-45-25', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:46:18,062 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be064f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-46-18', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:47:10,691 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb070>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a0d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-47-10', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:48:03,764 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105efc70>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a940>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-48-03', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:48:55,493 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105ef4f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-48-55', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:49:48,253 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2f10>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a45e0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-49-48', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:50:40,861 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2070>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105b0310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-50-40', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:51:33,021 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3811e4c0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105b0040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-51-33', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:52:24,998 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef760>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ac10>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-52-24', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:53:16,707 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580ee0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105485e0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-53-16', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:54:08,697 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580fd0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105480d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-54-08', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:55:02,150 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093eb0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a550>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-55-02', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:55:54,383 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbe50>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0820>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-55-54', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:56:50,305 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c29d0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-56-50', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:57:43,208 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb040>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef3a0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-57-43', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:58:35,701 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb310>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef0d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-58-35', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 14:59:28,529 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb1f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_14-59-28', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:00:21,272 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2a30>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105efc10>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-00-21', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:01:14,252 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2df0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105d0430>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-01-14', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:02:07,878 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105804c0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a94c0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-02-07', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:03:01,208 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093be0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a91f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-03-01', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:03:54,635 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a2e0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ef4c0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-03-54', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:04:47,484 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be58ac0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a9160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-04-47', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:05:39,151 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2af0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ddca0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-05-39', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:06:31,251 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb970>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057a0d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-06-31', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:07:22,976 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e3f10>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ec4c0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-07-22', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:08:15,306 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105884f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ec160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-08-15', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:09:07,953 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105885e0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a91f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-09-07', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:10:00,095 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bba00>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ecd30>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-10-00', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:10:52,711 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb8b0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ece50>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-10-52', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:11:45,055 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef190>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-11-45', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:12:37,706 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bbf40>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-12-37', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:13:30,691 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fbcd0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057bb80>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-13-30', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:14:27,571 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb580>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10576430>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-14-27', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:15:22,407 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb3d0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057b040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-15-22', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:16:15,301 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2a60>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105ecd30>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-16-15', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:17:06,937 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb940>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb3a0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-17-06', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:17:58,674 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb790>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-17-58', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:18:50,295 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380abaf0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb790>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-18-50', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:19:42,911 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef700>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cbb80>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-19-42', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:20:34,959 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c21f0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cbdc0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-20-34', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:21:26,277 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde38093940>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105761f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-21-26', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:22:17,049 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588880>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10576040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-22-17', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:23:08,914 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde38163070>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb550>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-23-08', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:23:59,416 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580fd0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10558160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-23-59', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:24:50,486 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588c10>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cba60>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-24-50', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:25:40,931 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb430>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105761f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-25-40', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:26:32,470 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a490>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105cb040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-26-32', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:27:23,988 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb0a0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ba60>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-27-23', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:28:14,620 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2d90>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c820>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-28-14', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:29:05,683 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2dc0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-29-05', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:29:57,407 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105bb520>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c1f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-29-57', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:30:52,285 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588ac0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057c8b0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-30-52', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:31:46,542 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380abee0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f71f0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-31-46', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:32:43,039 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a3d0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-32-43', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:33:36,679 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380efc70>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-33-36', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:34:28,502 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a730>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508160>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-34-28', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:35:20,842 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3805a670>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7a60>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-35-20', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:36:12,381 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb040>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f70d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-36-12', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:37:05,503 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2190>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d040>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-37-05', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:38:00,556 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380fb3d0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d550>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-38-00', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:38:53,183 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b21c0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d790>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-38-53', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:39:45,111 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e37c0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d9d0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-39-45', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:40:37,251 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e30a0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde105a9700>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-40-37', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:41:28,975 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10588970>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057d280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-41-28', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:42:20,917 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef4c0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-42-20', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:43:12,764 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580640>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-43-12', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:44:05,264 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580040>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057baf0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-44-05', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:44:58,427 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380e3e50>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde1057ddc0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-44-58', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:45:54,768 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2910>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10508820>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-45-54', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:46:47,775 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2b20>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104f7790>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-46-47', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:47:40,075 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be58160>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516310>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-47-40', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:48:32,764 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde380ef580>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-48-32', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:50:00,671 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde10580b80>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104e03a0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-50-00', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:50:54,419 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde3be586d0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516940>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-50-54', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:51:47,915 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105c2280>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde10516d30>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-51-47', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
-2023-02-09 15:52:40,506 INFO    MainThread:27221 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'darm/DarmSFHand-v0', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 1, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 1, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': False, 'restart_failed_sub_environments': False, 'num_consecutive_worker_failures_tolerance': 100, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 256, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 5, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 1000, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'type': 'MultiAgentPrioritizedReplayBuffer', 'capacity': 1000000, 'prioritized_replay': False, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06, 'worker_side_prioritization': False}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'grad_clip': None, 'target_network_update_freq': 1, 'num_steps_sampled_before_learning_starts': 10000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7fde105b2fa0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7fde104dc280>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '80340_00000', 'experiment_id': '4d5d6cddaea7444681811f5901f7f828', 'date': '2023-02-09_15-52-40', 'pid': 27220, 'hostname': 'Daniel', 'node_ip': '192.168.152.36'}
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/run-80340_00000.wandb b/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/run-80340_00000.wandb
deleted file mode 100644
index 1ae2bd8..0000000
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39/wandb/run-20230209_143443-80340_00000/run-80340_00000.wandb and /dev/null differ
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-33-16.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-33-16.json
deleted file mode 100644
index 5f1eea7..0000000
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-33-16.json and /dev/null differ
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-34-38.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-34-38.json
deleted file mode 100644
index 895b97d..0000000
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/basic-variant-state-2023-02-09_14-34-38.json and /dev/null differ
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-33-16.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-33-16.json
deleted file mode 100644
index 4d412bc..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-33-16.json
+++ /dev/null
@@ -1,43 +0,0 @@
-{
-  "checkpoints": [
-    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"4f54b_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"darm/DarmSFHand-v0\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 4\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595e3000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10000\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"PENDING\",\n  \"start_time\": null,\n  \"relative_logdir\": null,\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"Test_DARMSF_DELTA_TARGET\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
-  ],
-  "runner_data": {
-    "_insufficient_resources_manager": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "80059597000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944740d0e3bc9eeda12e8c0f5f6c6173745f747269616c5f6e756d944b0175622e"
-    },
-    "_max_pending_trials": 16,
-    "_metric": null,
-    "_total_time": 0,
-    "_iteration": 14,
-    "_has_errored": false,
-    "_fail_fast": false,
-    "_print_trial_errors": true,
-    "_server_port": null,
-    "_cached_trial_decisions": {},
-    "_queued_trial_decisions": {},
-    "_should_stop_experiment": false,
-    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET",
-    "_remote_checkpoint_dir": null,
-    "_stopper": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
-    },
-    "_resumed": false,
-    "_start_time": 1675949596.8921628,
-    "_last_checkpoint_time": -Infinity,
-    "_session_str": "2023-02-09_14-33-16",
-    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-33-16.json",
-    "_checkpoint_period": "auto",
-    "_trial_checkpoint_config": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
-    },
-    "launch_web_server": false
-  },
-  "stats": {
-    "start_time": 1675949596.8921628,
-    "timestamp": 1675949662.2749946
-  }
-}
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json b/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json
deleted file mode 100644
index 318461b..0000000
--- a/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json
+++ /dev/null
@@ -1,43 +0,0 @@
-{
-  "checkpoints": [
-    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"80340_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"darm/DarmSFHand-v0\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10000\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.8870038390159607,\n            \"actor_loss\": 115.60578918457031,\n            \"critic_loss\": 1.3008311986923218,\n            \"alpha_loss\": 3.3117122650146484,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041ad8c33c94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435f36ec094869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n            },\n            \"policy_t\": -0.3005792200565338,\n            \"mean_q\": -115.54031372070312,\n            \"max_q\": -109.50465393066406,\n            \"min_q\": -120.56295013427734\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 37.32743453979492,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 29194.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 29193.0\n        }\n      },\n      \"num_env_steps_sampled\": 97193,\n      \"num_env_steps_trained\": 7473664,\n      \"num_agent_steps_sampled\": 97193,\n      \"num_agent_steps_trained\": 7473664,\n      \"last_target_update_ts\": 97193,\n      \"num_target_updates\": 29194\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -156.1826542466879,\n      \"episode_reward_min\": -191.28636541962624,\n      \"episode_reward_mean\": -169.9554263330996,\n      \"episode_len_mean\": 100.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 10,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -156.1826542466879,\n          -169.85423006117344,\n          -162.02638640999794,\n          -185.1279215067625,\n          -186.65800455212593,\n          -163.31539402902126,\n          -191.28636541962624,\n          -157.43947839736938,\n          -171.26552772521973,\n          -156.39830098301172\n        ],\n        \"episode_lengths\": [\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.1364653920600976,\n        \"mean_inference_ms\": 2.3486854601514455,\n        \"mean_action_processing_ms\": 0.22231085102003592,\n        \"mean_env_wait_ms\": 2.9007591400230686,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -156.1826542466879,\n    \"episode_reward_min\": -191.28636541962624,\n    \"episode_reward_mean\": -169.9554263330996,\n    \"episode_len_mean\": 100.0,\n    \"episodes_this_iter\": 10,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -156.1826542466879,\n        -169.85423006117344,\n        -162.02638640999794,\n        -185.1279215067625,\n        -186.65800455212593,\n        -163.31539402902126,\n        -191.28636541962624,\n        -157.43947839736938,\n        -171.26552772521973,\n        -156.39830098301172\n      ],\n      \"episode_lengths\": [\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.1364653920600976,\n      \"mean_inference_ms\": 2.3486854601514455,\n      \"mean_action_processing_ms\": 0.22231085102003592,\n      \"mean_env_wait_ms\": 2.9007591400230686,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 1,\n    \"num_agent_steps_sampled\": 97193,\n    \"num_agent_steps_trained\": 7473664,\n    \"num_env_steps_sampled\": 97193,\n    \"num_env_steps_trained\": 7473664,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 97193,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 97193,\n    \"timers\": {\n      \"training_iteration_time_ms\": 161.318,\n      \"load_time_ms\": 0.312,\n      \"load_throughput\": 821657.349,\n      \"learn_time_ms\": 25.987,\n      \"learn_throughput\": 9851.041,\n      \"synch_weights_time_ms\": 7.023\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 97193,\n      \"num_env_steps_trained\": 7473664,\n      \"num_agent_steps_sampled\": 97193,\n      \"num_agent_steps_trained\": 7473664,\n      \"last_target_update_ts\": 97193,\n      \"num_target_updates\": 29194\n    },\n    \"done\": false,\n    \"episodes_total\": 1000,\n    \"training_iteration\": 97,\n    \"trial_id\": \"80340_00000\",\n    \"experiment_id\": \"4d5d6cddaea7444681811f5901f7f828\",\n    \"date\": \"2023-02-09_15-52-40\",\n    \"timestamp\": 1675954360,\n    \"time_this_iter_s\": 52.549543619155884,\n    \"time_total_s\": 4664.705418109894,\n    \"pid\": 27220,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"darm/DarmSFHand-v0\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 4664.705418109894,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 97,\n    \"warmup_time\": 8.03538990020752,\n    \"perf\": {\n      \"cpu_util_percent\": 39.38055555555556,\n      \"ram_util_percent\": 91.3138888888889\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1675954360.5438237,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": 246.4839284569025,\n      \"min\": -180.80819918960333,\n      \"avg\": -12.388895104034347,\n      \"last\": -156.1826542466879,\n      \"last-5-avg\": -76.0302426442504,\n      \"last-10-avg\": -116.6211689375341\n    },\n    \"episode_reward_min\": {\n      \"max\": -166.27869933843613,\n      \"min\": -196.84813330322504,\n      \"avg\": -184.54626515254225,\n      \"last\": -191.28636541962624,\n      \"last-5-avg\": -185.46425538957118,\n      \"last-10-avg\": -178.42735547944903\n    },\n    \"episode_reward_mean\": {\n      \"max\": -67.65054373849522,\n      \"min\": -188.20978297458754,\n      \"avg\": -155.50684557040847,\n      \"last\": -169.9554263330996,\n      \"last-5-avg\": -160.00184844438024,\n      \"last-10-avg\": -161.81272692360665\n    },\n    \"episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 79.81818181818181,\n      \"avg\": 97.06446503095981,\n      \"last\": 100.0,\n      \"last-5-avg\": 98.30909090909091,\n      \"last-10-avg\": 99.15454545454546\n    },\n    \"episodes_this_iter\": {\n      \"max\": 13,\n      \"min\": 9,\n      \"avg\": 10.30927835051546,\n      \"last\": 10,\n      \"last-5-avg\": 10.0,\n      \"last-10-avg\": 10.0\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 2.9999999999999987,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 1,\n      \"min\": 0,\n      \"avg\": 0.041237113402061855,\n      \"last\": 1,\n      \"last-5-avg\": 0.8,\n      \"last-10-avg\": 0.4\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1001,\n      \"avg\": 1001.9896907216491,\n      \"last\": 1002,\n      \"last-5-avg\": 1001.8,\n      \"last-10-avg\": 1001.9\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 118528,\n      \"min\": 0,\n      \"avg\": 77048.0824742268,\n      \"last\": 85504,\n      \"last-5-avg\": 92108.8,\n      \"last-10-avg\": 88806.4\n    },\n    \"timesteps_total\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 118528,\n      \"min\": 0,\n      \"avg\": 77048.0824742268,\n      \"last\": 85504,\n      \"last-5-avg\": 92108.8,\n      \"last-10-avg\": 88806.4\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 1000,\n      \"min\": 9,\n      \"avg\": 504.79381443298973,\n      \"last\": 1000,\n      \"last-5-avg\": 980.2,\n      \"last-10-avg\": 955.3\n    },\n    \"training_iteration\": {\n      \"max\": 97,\n      \"min\": 1,\n      \"avg\": 49.00000000000001,\n      \"last\": 97,\n      \"last-5-avg\": 95.0,\n      \"last-10-avg\": 92.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 87.86418461799622,\n      \"min\": 3.8648064136505127,\n      \"avg\": 48.089746578452534,\n      \"last\": 52.549543619155884,\n      \"last-5-avg\": 60.03978991508484,\n      \"last-10-avg\": 56.72709512710571\n    },\n    \"time_total_s\": {\n      \"max\": 4664.705418109894,\n      \"min\": 5.359312057495117,\n      \"avg\": 2127.507677638654,\n      \"last\": 4664.705418109894,\n      \"last-5-avg\": 4551.542730426789,\n      \"last-10-avg\": 4404.665781450271\n    },\n    \"time_since_restore\": {\n      \"max\": 4664.705418109894,\n      \"min\": 5.359312057495117,\n      \"avg\": 2127.507677638654,\n      \"last\": 4664.705418109894,\n      \"last-5-avg\": 4551.542730426789,\n      \"last-10-avg\": 4404.665781450271\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 97,\n      \"min\": 1,\n      \"avg\": 49.00000000000001,\n      \"last\": 97,\n      \"last-5-avg\": 95.0,\n      \"last-10-avg\": 92.5\n    },\n    \"warmup_time\": {\n      \"max\": 8.03538990020752,\n      \"min\": 8.03538990020752,\n      \"avg\": 8.03538990020752,\n      \"last\": 8.03538990020752,\n      \"last-5-avg\": 8.03538990020752,\n      \"last-10-avg\": 8.03538990020752\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": 246.4839284569025,\n      \"min\": -180.80819918960333,\n      \"avg\": -12.388895104034347,\n      \"last\": -156.1826542466879,\n      \"last-5-avg\": -76.0302426442504,\n      \"last-10-avg\": -116.6211689375341\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -166.27869933843613,\n      \"min\": -196.84813330322504,\n      \"avg\": -184.54626515254225,\n      \"last\": -191.28636541962624,\n      \"last-5-avg\": -185.46425538957118,\n      \"last-10-avg\": -178.42735547944903\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -67.65054373849522,\n      \"min\": -188.20978297458754,\n      \"avg\": -155.50684557040847,\n      \"last\": -169.9554263330996,\n      \"last-5-avg\": -160.00184844438024,\n      \"last-10-avg\": -161.81272692360665\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 79.81818181818181,\n      \"avg\": 97.06446503095981,\n      \"last\": 100.0,\n      \"last-5-avg\": 98.30909090909091,\n      \"last-10-avg\": 99.15454545454546\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 13,\n      \"min\": 9,\n      \"avg\": 10.30927835051546,\n      \"last\": 10,\n      \"last-5-avg\": 10.0,\n      \"last-10-avg\": 10.0\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.1364653920600976,\n      \"avg\": 1.1940301056313938,\n      \"last\": 1.1364653920600976,\n      \"last-5-avg\": 1.1663385713747494,\n      \"last-10-avg\": 1.1585201585600085\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.3850960676362587,\n      \"last\": 2.3486854601514455,\n      \"last-5-avg\": 2.386445898129482,\n      \"last-10-avg\": 2.3794163445376832\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22231085102003592,\n      \"avg\": 0.22820162528863516,\n      \"last\": 0.22231085102003592,\n      \"last-5-avg\": 0.22726492829065545,\n      \"last-10-avg\": 0.225857300865209\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 2.9007591400230686,\n      \"avg\": 3.0301794776166973,\n      \"last\": 2.9007591400230686,\n      \"last-5-avg\": 2.9680635788997085,\n      \"last-10-avg\": 2.971996630348232\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 189.773,\n      \"min\": 11.428,\n      \"avg\": 143.53061855670103,\n      \"last\": 161.318,\n      \"last-5-avg\": 154.4892,\n      \"last-10-avg\": 157.189\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 77.2875,\n      \"min\": 37.38260869565218,\n      \"avg\": 43.059807633885846,\n      \"last\": 39.38055555555556,\n      \"last-5-avg\": 42.6261610791119,\n      \"last-10-avg\": 41.638303035107654\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 93.40655737704918,\n      \"min\": 81.83333333333333,\n      \"avg\": 88.72794874688876,\n      \"last\": 91.3138888888889,\n      \"last-5-avg\": 92.10318084477922,\n      \"last-10-avg\": 92.31285380234146\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.1364653920600976,\n      \"avg\": 1.1940301056313938,\n      \"last\": 1.1364653920600976,\n      \"last-5-avg\": 1.1663385713747494,\n      \"last-10-avg\": 1.1585201585600085\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.3850960676362587,\n      \"last\": 2.3486854601514455,\n      \"last-5-avg\": 2.386445898129482,\n      \"last-10-avg\": 2.3794163445376832\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22231085102003592,\n      \"avg\": 0.22820162528863516,\n      \"last\": 0.22231085102003592,\n      \"last-5-avg\": 0.22726492829065545,\n      \"last-10-avg\": 0.225857300865209\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 2.9007591400230686,\n      \"avg\": 3.0301794776166973,\n      \"last\": 2.9007591400230686,\n      \"last-5-avg\": 2.9680635788997085,\n      \"last-10-avg\": 2.971996630348232\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 97193,\n      \"min\": 10020,\n      \"avg\": 49562.804123711336,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_target_updates\": {\n      \"max\": 29194,\n      \"min\": 7,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.339,\n      \"min\": 0.252,\n      \"avg\": 0.28286597938144326,\n      \"last\": 0.312,\n      \"last-5-avg\": 0.2938,\n      \"last-10-avg\": 0.2940999999999999\n    },\n    \"timers/load_throughput\": {\n      \"max\": 1014112.036,\n      \"min\": 754721.181,\n      \"avg\": 910293.1391443302,\n      \"last\": 821657.349,\n      \"last-5-avg\": 875020.2276000001,\n      \"last-10-avg\": 874785.7856999999\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 34.221,\n      \"min\": 23.921,\n      \"avg\": 25.68867010309277,\n      \"last\": 25.987,\n      \"last-5-avg\": 25.2626,\n      \"last-10-avg\": 25.4429\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 10701.707,\n      \"min\": 7480.78,\n      \"avg\": 9993.184484536083,\n      \"last\": 9851.041,\n      \"last-5-avg\": 10137.0798,\n      \"last-10-avg\": 10067.5654\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 7.622,\n      \"min\": 3.46,\n      \"avg\": 5.916463917525771,\n      \"last\": 7.023,\n      \"last-5-avg\": 5.5596000000000005,\n      \"last-10-avg\": 5.630799999999999\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 97193,\n      \"min\": 10020,\n      \"avg\": 49562.804123711336,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 29194,\n      \"min\": 7,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 52.555171966552734,\n      \"min\": 1.4600703716278076,\n      \"avg\": 19.237037835661905,\n      \"last\": 37.32743453979492,\n      \"last-5-avg\": 37.0519660949707,\n      \"last-10-avg\": 38.79243621826172\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 255.99999999999986,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 29194.0,\n      \"min\": 7.0,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194.0,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 29193.0,\n      \"min\": 6.0,\n      \"avg\": 13192.268041237117,\n      \"last\": 29193.0,\n      \"last-5-avg\": 28499.2,\n      \"last-10-avg\": 27612.6\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 8.438075065612793,\n      \"min\": 0.0007296120747923851,\n      \"avg\": 4.199410469780108,\n      \"last\": 0.8870038390159607,\n      \"last-5-avg\": 0.3972333982586861,\n      \"last-10-avg\": 0.39924969598650933\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": 115.60578918457031,\n      \"min\": -6.580883979797363,\n      \"avg\": 50.705901773272025,\n      \"last\": 115.60578918457031,\n      \"last-5-avg\": 114.08861389160157,\n      \"last-10-avg\": 111.68227081298828\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 1.7885878086090088,\n      \"min\": 0.23512327671051025,\n      \"avg\": 0.7603486101959173,\n      \"last\": 1.3008311986923218,\n      \"last-5-avg\": 1.3107106924057006,\n      \"last-10-avg\": 1.3759251356124877\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": 3.3117122650146484,\n      \"min\": -22.550003051757812,\n      \"avg\": -6.202999704469415,\n      \"last\": 3.3117122650146484,\n      \"last-5-avg\": 1.242195975780487,\n      \"last-10-avg\": 0.2757415473461151\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304248a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e425b3c94869452942e\"\n      },\n      \"avg\": 0.20847204509047185,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041ad8c33c94869452942e\"\n      },\n      \"last-5-avg\": 0.023464493080973627,\n      \"last-10-avg\": 0.023778889514505862\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415eeebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b00a8ac094869452942e\"\n      },\n      \"avg\": -2.7600312380662624,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435f36ec094869452942e\"\n      },\n      \"last-5-avg\": -3.7526698112487793,\n      \"last-10-avg\": -3.739602875709534\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"avg\": -5.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"last-5-avg\": -5.0,\n      \"last-10-avg\": -5.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.020382240414619446,\n      \"min\": -0.44182953238487244,\n      \"avg\": -0.2144594302862407,\n      \"last\": -0.3005792200565338,\n      \"last-5-avg\": -0.2793947786092758,\n      \"last-10-avg\": -0.2996277377009392\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 4.486087322235107,\n      \"min\": -115.54031372070312,\n      \"avg\": -51.340016929951226,\n      \"last\": -115.54031372070312,\n      \"last-5-avg\": -113.98671875,\n      \"last-10-avg\": -111.57610626220703\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 5.304399013519287,\n      \"min\": -109.50465393066406,\n      \"avg\": -47.25042838657025,\n      \"last\": -109.50465393066406,\n      \"last-5-avg\": -107.16285705566406,\n      \"last-10-avg\": -104.64206390380859\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 3.575044631958008,\n      \"min\": -120.56295013427734,\n      \"avg\": -54.09790204878242,\n      \"last\": -120.56295013427734,\n      \"last-5-avg\": -118.75367736816406,\n      \"last-10-avg\": -116.35101699829102\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000020c5408363c094869452946807680d43080000343928dc63c094869452946807680d4308000050cbab9763c094869452946807680d430800007c4707b463c094869452946807680d43080000905ad39663c094869452946807680d43080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b4d18c4265c094869452946807680d430800002887c92665c094869452946807680d43080000f83bcadf64c094869452946807680d43080000e8393dee65c094869452946807680d43080000a8401be765c094869452946807680d4308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d3c0a568964c094869452946807680d4308abaacaf0c05764c094869452946807680d430833332145111164c094869452946807680d43082fbad09c5ea364c094869452946807680d43081cc79d0340ae64c094869452946807680d4308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b094b0a4b0a4b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b094b0a4b0b4b094b0b4b094b0a4b0a4b0a652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b014b014b014b01652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034de9034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034de9034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dc1034dca034dd4034dde034de803652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d8f034d98034da2034dad034db6034dc1034dca034dd4034dde034de803652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5d4b5e4b5f4b604b61652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b584b594b5a4b5b4b5c4b5d4b5e4b5f4b604b61652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a5147d0000000474055f74ecd00000047404ad98b9800000047404ab9aeba00000047404a465772000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a3955cc00000047404a901b4400000047404c24b3c000000047404a7a836e00000047404a208f1c00000047404a5147d0000000474055f74ecd00000047404ad98b9800000047404ab9aeba00000047404a465772000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b035e1e4d000004740b06b021b5800004740b0a34b82d800004740b0d84089b400004740b10c81a7ec00004740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b035e1e4d000004740b06b021b5800004740b0a34b82d800004740b0d84089b400004740b10c81a7ec00004740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5d4b5e4b5f4b604b61652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b584b594b5a4b5b4b5c4b5d4b5e4b5f4b604b61652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000020c5408363c094869452946807680d43080000343928dc63c094869452946807680d4308000050cbab9763c094869452946807680d430800007c4707b463c094869452946807680d43080000905ad39663c094869452946807680d43080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b4d18c4265c094869452946807680d430800002887c92665c094869452946807680d43080000f83bcadf64c094869452946807680d43080000e8393dee65c094869452946807680d43080000a8401be765c094869452946807680d4308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d3c0a568964c094869452946807680d4308abaacaf0c05764c094869452946807680d430833332145111164c094869452946807680d43082fbad09c5ea364c094869452946807680d43081cc79d0340ae64c094869452946807680d4308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b094b0a4b0a4b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b094b0a4b0b4b094b0b4b094b0a4b0a4b0a652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4637115dc6cf23f94869452946807680d430825c30ff14367f23f94869452946807680d4308cb2cc4946264f23f94869452946807680d430841e891a0e66df23f94869452946807680d43082ed95aeff567f23f94869452946807680d43083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e68ecbda52fc024094869452946807680d430836a7ee5664f8024094869452946807680d4308977ab91c02f7024094869452946807680d43088ae99ecf2cff024094869452946807680d43085c65048357fa024094869452946807680d43084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308806fd2709cc5cc3f94869452946807680d4308d2a2255dabb6cc3f94869452946807680d43081bf4c3d619adcc3f94869452946807680d430853643d6c63c4cc3f94869452946807680d43080572949010b8cc3f94869452946807680d430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a435853d89d4074094869452946807680d430809ff84c99dd0074094869452946807680d43084a42f8a0a0cd074094869452946807680d4308dd5198e148cf074094869452946807680d4308c2b9499174c7074094869452946807680d4308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740630e4dd2f1a9fc474062db020c49ba5e4740634d374bc6a7f04740632d916872b0214740642a2d0e560419652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406303645a1cac08474065bcb439581062474063f2978d4fdf3b474064022d0e560419474063395810624dd34740630e4dd2f1a9fc474062db020c49ba5e4740634d374bc6a7f04740632d916872b0214740642a2d0e560419652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a54ffaa44faa434094869452946807680d43087bce2a5d614c4b4094869452946807680d430850f6be260405444094869452946807680d4308463eeb0653e4434094869452946807680d43080cb6600bb6b043409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c07c51e5d632444094869452946807680d43080944bba986c0434094869452946807680d4308333333333353464094869452946807680d43084420da4d3504444094869452946807680d4308d8822dd88255434094869452946807680d4308a54ffaa44faa434094869452946807680d43087bce2a5d614c4b4094869452946807680d430850f6be260405444094869452946807680d4308463eeb0653e4434094869452946807680d43080cb6600bb6b043409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308faa44ffaa43b574094869452946807680d4308ec973b09055a574094869452946807680d430870a73f6201e7564094869452946807680d43080465ef6b42d0564094869452946807680d4308c2166cc116d456409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa726b59ac1b574094869452946807680d43081d09df8ae2f1564094869452946807680d4308011550011520574094869452946807680d430858af5ebd7a35574094869452946807680d4308c2166cc11644574094869452946807680d4308faa44ffaa43b574094869452946807680d4308ec973b09055a574094869452946807680d430870a73f6201e7564094869452946807680d43080465ef6b42d0564094869452946807680d4308c2166cc116d456409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4637115dc6cf23f94869452946807680d430825c30ff14367f23f94869452946807680d4308cb2cc4946264f23f94869452946807680d430841e891a0e66df23f94869452946807680d43082ed95aeff567f23f94869452946807680d43083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e68ecbda52fc024094869452946807680d430836a7ee5664f8024094869452946807680d4308977ab91c02f7024094869452946807680d43088ae99ecf2cff024094869452946807680d43085c65048357fa024094869452946807680d43084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308806fd2709cc5cc3f94869452946807680d4308d2a2255dabb6cc3f94869452946807680d43081bf4c3d619adcc3f94869452946807680d430853643d6c63c4cc3f94869452946807680d43080572949010b8cc3f94869452946807680d430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a435853d89d4074094869452946807680d430809ff84c99dd0074094869452946807680d43084a42f8a0a0cd074094869452946807680d4308dd5198e148cf074094869452946807680d4308c2b9499174c7074094869452946807680d4308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d516c4d206e4d6e6f4dbc704d0a72652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dcb654d19674d67684db5694d036b4d516c4d206e4d6e6f4dbc704d0a72652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd1db22d0e56042473fd10624dd2f1aa0473fd374bc6a7ef9db473fd3b645a1cac083473fd3f7ced916872b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd2b020c49ba5e3473fd3c6a7ef9db22d473fd4ac083126e979473fd072b020c49ba6473fd29fbe76c8b439473fd1db22d0e56042473fd10624dd2f1aa0473fd374bc6a7ef9db473fd3b645a1cac083473fd3f7ced916872b652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847412c06a7fae147ae47412d594ec28f5c29474129a982b22d0e5647412967ce245a1cac4741291332b2b020c5652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847412ac7ada6e978d547412941355eb851ec4741282718e353f7cf47412e6d96b0a3d70a47412ad496d6872b0247412c06a7fae147ae47412d594ec28f5c29474129a982b22d0e5647412967ce245a1cac4741291332b2b020c5652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740389b645a1cac0847403987ae147ae1484740392147ae147ae14740390f1a9fbe76c9474039fcac083126e9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403953b645a1cac147403ace147ae147ae4740397a5e353f7cee474039c872b020c49c474038b916872b020c4740389b645a1cac0847403987ae147ae1484740392147ae147ae14740390f1a9fbe76c9474039fcac083126e9652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c451d6e978d4fe4740c395ce978d4fdf4740c3e58ba5e353f84740c3f3fcac0831274740c33d853f7ced91652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c3bde9374bc6a84740c2a74c28f5c28f4740c39ff6e978d4fe4740c36499ba5e353f4740c4395a9fbe76c94740c451d6e978d4fe4740c395ce978d4fdf4740c3e58ba5e353f84740c3f3fcac0831274740c33d853f7ced91652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740195f3b645a1cac47400bae147ae147ae474015b126e978d4fe474016322d0e56041947401c178d4fdf3b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474015449ba5e353f847401a6a7ef9db22d1474016072b020c49ba4740155604189374bc474016fdf3b645a1cb4740195f3b645a1cac47400bae147ae147ae474015b126e978d4fe474016322d0e56041947401c178d4fdf3b64652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d516c4d206e4d6e6f4dbc704d0a72652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dcb654d19674d67684db5694d036b4d516c4d206e4d6e6f4dbc704d0a72652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0d7a3424094869452946807680d430800000000157a444094869452946807680d4308000000c0c2aa3c4094869452946807680d4308000000c00a84444094869452946807680d430800000060e9a942409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0b91d434094869452946807680d4308000000807563444094869452946807680d430800000000bda5424094869452946807680d430800000040d51b484094869452946807680d4308000000c04d12434094869452946807680d4308000000a0d7a3424094869452946807680d430800000000157a444094869452946807680d4308000000c0c2aa3c4094869452946807680d4308000000c00a84444094869452946807680d430800000060e9a942409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004014db4094869452946807680d4308000000000088db4094869452946807680d43080000000080dbdb4094869452946807680d430800000000002fdc4094869452946807680d4308000000008082dc409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000c072d94094869452946807680d43080000000040c6d94094869452946807680d430800000000c019da4094869452946807680d430800000000406dda4094869452946807680d430800000000c0c0da4094869452946807680d4308000000004014db4094869452946807680d4308000000000088db4094869452946807680d43080000000080dbdb4094869452946807680d430800000000002fdc4094869452946807680d4308000000008082dc409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000014db4094869452946807680d430800000000c087db4094869452946807680d43080000000040dbdb4094869452946807680d430800000000c02edc4094869452946807680d4308000000004082dc409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000008072d94094869452946807680d43080000000000c6d94094869452946807680d4308000000008019da4094869452946807680d430800000000006dda4094869452946807680d43080000000080c0da4094869452946807680d4308000000000014db4094869452946807680d430800000000c087db4094869452946807680d43080000000040dbdb4094869452946807680d430800000000c02edc4094869452946807680d4308000000004082dc409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000008dfe9d3f94869452946807680d4308000000e0facabf3f94869452946807680d430800000060e023e93f94869452946807680d430800000040907cc43f94869452946807680d4308000000e05562ec3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000b749e33f94869452946807680d4308000000c09930cc3f94869452946807680d430800000000e843d43f94869452946807680d4308000000e030b1cd3f94869452946807680d430800000040bd4fe43f94869452946807680d4308000000008dfe9d3f94869452946807680d4308000000e0facabf3f94869452946807680d430800000060e023e93f94869452946807680d430800000040907cc43f94869452946807680d4308000000e05562ec3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e07c095c4094869452946807680d4308000000003d515c4094869452946807680d430800000000808c5c4094869452946807680d4308000000205cce5c4094869452946807680d430800000040c5e65c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008088dc5a4094869452946807680d430800000040150a5b4094869452946807680d43080000004072615b4094869452946807680d4308000000a0238f5b4094869452946807680d43080000006018c15b4094869452946807680d4308000000e07c095c4094869452946807680d4308000000003d515c4094869452946807680d430800000000808c5c4094869452946807680d4308000000205cce5c4094869452946807680d430800000040c5e65c409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000bee3f43f94869452946807680d4308000000c09746f73f94869452946807680d4308000000408f73f03f94869452946807680d430800000080416df73f94869452946807680d43080000006034d0f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080386af63f94869452946807680d4308000000806ec4f63f94869452946807680d4308000000c0c13af53f94869452946807680d430800000020a4fefa3f94869452946807680d4308000000007de2f53f94869452946807680d430800000000bee3f43f94869452946807680d4308000000c09746f73f94869452946807680d4308000000408f73f03f94869452946807680d430800000080416df73f94869452946807680d43080000006034d0f43f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000a70bc3f94869452946807680d430800000080d205de3f94869452946807680d4308000000a01759074094869452946807680d4308000000207c2ee3bf94869452946807680d430800000000637e0a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e098f101c094869452946807680d43080000004016b5ea3f94869452946807680d43080000002086d3f23f94869452946807680d4308000000009d41ebbf94869452946807680d4308000000e0eef502c094869452946807680d4308000000000a70bc3f94869452946807680d430800000080d205de3f94869452946807680d4308000000a01759074094869452946807680d4308000000207c2ee3bf94869452946807680d430800000000637e0a409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430483a8b83c94869452946807680d43048e78bb3c94869452946807680d43044a8cc73c94869452946807680d43049695c13c94869452946807680d43041ad8c33c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b247c63c94869452946807680d4304432bb93c94869452946807680d4304ac53c73c94869452946807680d43041e51d03c94869452946807680d4304abc4c33c94869452946807680d430483a8b83c94869452946807680d43048e78bb3c94869452946807680d43044a8cc73c94869452946807680d43049695c13c94869452946807680d43041ad8c33c9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cab672c094869452946807680d43041dbf71c094869452946807680d43043ec06dc094869452946807680d43045cb16fc094869452946807680d430435f36ec09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae286ec094869452946807680d4304898972c094869452946807680d430469d26dc094869452946807680d4304a4ff6ac094869452946807680d43048ff96ec094869452946807680d4304cab672c094869452946807680d43041dbf71c094869452946807680d43043ec06dc094869452946807680d43045cb16fc094869452946807680d430435f36ec09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000f65dd4bf94869452946807680d4308000000c0046ed0bf94869452946807680d4308000000a07649cfbf94869452946807680d4308000000809ebad1bf94869452946807680d4308000000a0b03cd3bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004059e9d4bf94869452946807680d4308000000c0efecd4bf94869452946807680d4308000000001370d4bf94869452946807680d4308000000c087b1d4bf94869452946807680d4308000000401963d3bf94869452946807680d430800000000f65dd4bf94869452946807680d4308000000c0046ed0bf94869452946807680d4308000000a07649cfbf94869452946807680d4308000000809ebad1bf94869452946807680d4308000000a0b03cd3bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060c0005cc094869452946807680d4308000000e0f9495cc094869452946807680d4308000000e00c8c5cc094869452946807680d43080000006064c25cc094869452946807680d43080000008094e25cc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a032d15ac094869452946807680d43080000008050085bc094869452946807680d4308000000800f5a5bc094869452946807680d4308000000a0e4845bc094869452946807680d4308000000007ebc5bc094869452946807680d430800000060c0005cc094869452946807680d4308000000e0f9495cc094869452946807680d4308000000e00c8c5cc094869452946807680d43080000006064c25cc094869452946807680d43080000008094e25cc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040905d5ac094869452946807680d43080000000004955ac094869452946807680d4308000000c08ab85ac094869452946807680d430800000000b2e85ac094869452946807680d4308000000404c605bc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004048f558c094869452946807680d4308000000e09e4c59c094869452946807680d4308000000e08e8559c094869452946807680d43080000000052df59c094869452946807680d43080000008006005ac094869452946807680d430800000040905d5ac094869452946807680d43080000000004955ac094869452946807680d4308000000c08ab85ac094869452946807680d430800000000b2e85ac094869452946807680d4308000000404c605bc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080802f5dc094869452946807680d4308000000200a805dc094869452946807680d4308000000807aab5dc094869452946807680d4308000000c020f25dc094869452946807680d43080000006007245ec09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002030fc5bc094869452946807680d43080000000084335cc094869452946807680d4308000000a0d97b5cc094869452946807680d4308000000c00eca5cc094869452946807680d4308000000e0dcf95cc094869452946807680d430800000080802f5dc094869452946807680d4308000000200a805dc094869452946807680d4308000000807aab5dc094869452946807680d4308000000c020f25dc094869452946807680d43080000006007245ec09486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1675949679.1124773,\n  \"relative_logdir\": \"SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"Test_DARMSF_DELTA_TARGET\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
-  ],
-  "runner_data": {
-    "_insufficient_resources_manager": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
-    },
-    "_max_pending_trials": 16,
-    "_metric": null,
-    "_total_time": 4664.705418109894,
-    "_iteration": 988,
-    "_has_errored": false,
-    "_fail_fast": false,
-    "_print_trial_errors": true,
-    "_server_port": null,
-    "_cached_trial_decisions": {},
-    "_queued_trial_decisions": {},
-    "_should_stop_experiment": false,
-    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET",
-    "_remote_checkpoint_dir": null,
-    "_stopper": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
-    },
-    "_resumed": false,
-    "_start_time": 1675949678.8755546,
-    "_last_checkpoint_time": -Infinity,
-    "_session_str": "2023-02-09_14-34-38",
-    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json",
-    "_checkpoint_period": "auto",
-    "_trial_checkpoint_config": {
-      "_type": "CLOUDPICKLE_FALLBACK",
-      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
-    },
-    "launch_web_server": false
-  },
-  "stats": {
-    "start_time": 1675949678.8755546,
-    "timestamp": 1675954365.5734942
-  }
-}
\ No newline at end of file
diff --git a/darm_training/results/Test_DARMSF_DELTA_TARGET/tuner.pkl b/darm_training/results/Test_DARMSF_DELTA_TARGET/tuner.pkl
index d323f0b..ea24d27 100644
Binary files a/darm_training/results/Test_DARMSF_DELTA_TARGET/tuner.pkl and b/darm_training/results/Test_DARMSF_DELTA_TARGET/tuner.pkl differ
diff --git a/setup.py b/setup.py
index da6271f..b2ee5c7 100644
--- a/setup.py
+++ b/setup.py
@@ -15,4 +15,5 @@ setup(
 
 # nans at the beginning means no episode has been completed as yet
 # avoid shared cpus - low utilization
-# avoid low bandwidth - long install times
\ No newline at end of file
+# avoid low bandwidth - long install times
+# only checkpoints from the latest run is resumed
\ No newline at end of file
