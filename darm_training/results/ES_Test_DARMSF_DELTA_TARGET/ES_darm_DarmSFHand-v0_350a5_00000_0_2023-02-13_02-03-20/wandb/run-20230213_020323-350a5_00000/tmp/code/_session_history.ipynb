{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4e4304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba9353f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'/home/daniel/DARM/darm_mujoco'"
     ]
    }
   ],
   "source": [
    "# Configure env variables\n",
    "\n",
    "# TODO: change path\n",
    "import os\n",
    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/home/daniel/DARM/darm_mujoco\"\n",
    "os.getenv('DARM_MUJOCO_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e515318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.es import ESConfig\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "\n",
    "import gym\n",
    "from darm_gym_env import DARMSFEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1af0edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_creator = lambda env_config: gym.make(\"darm/DarmSFHand-v0\", render_mode=None, hand_name=\"hand1\") # DARMSFEnv(render_mode=None, reaction_time=0.08, hand_name=\"hand1\") # \n",
    "\n",
    "def make_env(env_config):\n",
    "    env = gym.wrappers.TimeLimit(env=DARMSFEnv(render_mode=None, reaction_time=0.08, hand_name=\"hand1\"), max_episode_steps=100)\n",
    "    return env\n",
    "env_creator = lambda env_config: make_env(env_config) #gym.wrappers.TimeLimit(env=DARMSFEnv(render_mode=None, reaction_time=0.08, hand_name=\"hand1\"), max_episode_steps=100)\n",
    "\n",
    "register_env(\"darm/DarmSFHand-v0\", env_creator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f1fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'num_gpus': 0,\n",
      " 'num_cpus_per_worker': 1,\n",
      " 'num_gpus_per_worker': 0,\n",
      " '_fake_gpus': False,\n",
      " 'custom_resources_per_worker': {},\n",
      " 'placement_strategy': 'PACK',\n",
      " 'eager_tracing': False,\n",
      " 'eager_max_retraces': 20,\n",
      " 'tf_session_args': {'intra_op_parallelism_threads': 2,\n",
      "  'inter_op_parallelism_threads': 2,\n",
      "  'gpu_options': {'allow_growth': True},\n",
      "  'log_device_placement': False,\n",
      "  'device_count': {'CPU': 1},\n",
      "  'allow_soft_placement': True},\n",
      " 'local_tf_session_args': {'intra_op_parallelism_threads': 8,\n",
      "  'inter_op_parallelism_threads': 8},\n",
      " 'env': 'darm/DarmSFHand-v0',\n",
      " 'env_config': {},\n",
      " 'observation_space': None,\n",
      " 'action_space': None,\n",
      " 'env_task_fn': None,\n",
      " 'render_env': False,\n",
      " 'clip_rewards': None,\n",
      " 'normalize_actions': True,\n",
      " 'clip_actions': False,\n",
      " 'disable_env_checking': False,\n",
      " 'num_envs_per_worker': 8,\n",
      " 'sample_collector': ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector,\n",
      " 'sample_async': False,\n",
      " 'enable_connectors': False,\n",
      " 'rollout_fragment_length': 1,\n",
      " 'batch_mode': 'truncate_episodes',\n",
      " 'remote_worker_envs': False,\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'validate_workers_after_construction': True,\n",
      " 'ignore_worker_failures': False,\n",
      " 'recreate_failed_workers': True,\n",
      " 'restart_failed_sub_environments': True,\n",
      " 'num_consecutive_worker_failures_tolerance': 10,\n",
      " 'horizon': None,\n",
      " 'soft_horizon': False,\n",
      " 'no_done_at_end': False,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'observation_filter': 'MeanStdFilter',\n",
      " 'synchronize_filters': True,\n",
      " 'compress_observations': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'gamma': 0.99,\n",
      " 'lr': 0.001,\n",
      " 'train_batch_size': 10000,\n",
      " 'model': {'_use_default_native_models': False,\n",
      "  '_disable_preprocessor_api': False,\n",
      "  '_disable_action_flattening': False,\n",
      "  'fcnet_hiddens': [256, 256],\n",
      "  'fcnet_activation': 'tanh',\n",
      "  'conv_filters': None,\n",
      "  'conv_activation': 'relu',\n",
      "  'post_fcnet_hiddens': [],\n",
      "  'post_fcnet_activation': 'relu',\n",
      "  'free_log_std': False,\n",
      "  'no_final_linear': False,\n",
      "  'vf_share_layers': True,\n",
      "  'use_lstm': False,\n",
      "  'max_seq_len': 20,\n",
      "  'lstm_cell_size': 256,\n",
      "  'lstm_use_prev_action': False,\n",
      "  'lstm_use_prev_reward': False,\n",
      "  '_time_major': False,\n",
      "  'use_attention': False,\n",
      "  'attention_num_transformer_units': 1,\n",
      "  'attention_dim': 64,\n",
      "  'attention_num_heads': 1,\n",
      "  'attention_head_dim': 32,\n",
      "  'attention_memory_inference': 50,\n",
      "  'attention_memory_training': 50,\n",
      "  'attention_position_wise_mlp_dim': 32,\n",
      "  'attention_init_gru_gate_bias': 2.0,\n",
      "  'attention_use_n_prev_actions': 0,\n",
      "  'attention_use_n_prev_rewards': 0,\n",
      "  'framestack': True,\n",
      "  'dim': 84,\n",
      "  'grayscale': False,\n",
      "  'zero_mean': True,\n",
      "  'custom_model': None,\n",
      "  'custom_model_config': {},\n",
      "  'custom_action_dist': None,\n",
      "  'custom_preprocessor': None,\n",
      "  'lstm_use_prev_action_reward': -1},\n",
      " 'optimizer': {},\n",
      " 'max_requests_in_flight_per_sampler_worker': 2,\n",
      " 'explore': True,\n",
      " 'exploration_config': {'type': 'StochasticSampling'},\n",
      " 'input_config': {},\n",
      " 'actions_in_input_normalized': False,\n",
      " 'postprocess_inputs': False,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'output': None,\n",
      " 'output_config': {},\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_max_file_size': 67108864,\n",
      " 'offline_sampling': False,\n",
      " 'evaluation_interval': None,\n",
      " 'evaluation_duration': 10,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_sample_timeout_s': 180.0,\n",
      " 'evaluation_parallel_to_training': False,\n",
      " 'evaluation_config': {'num_envs_per_worker': 1,\n",
      "  'observation_filter': 'NoFilter'},\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'ope_split_batch_by_episode': True,\n",
      " 'evaluation_num_workers': 0,\n",
      " 'always_attach_evaluation_results': False,\n",
      " 'enable_async_evaluation': False,\n",
      " 'in_evaluation': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 60.0,\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'min_time_s_per_iteration': None,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'min_sample_timesteps_per_iteration': 0,\n",
      " 'export_native_model_files': False,\n",
      " 'logger_creator': None,\n",
      " 'logger_config': None,\n",
      " 'log_level': 'WARN',\n",
      " 'log_sys_usage': True,\n",
      " 'fake_sampler': False,\n",
      " 'seed': None,\n",
      " 'worker_cls': None,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': True,\n",
      " 'simple_optimizer': -1,\n",
      " 'replay_sequence_length': None,\n",
      " 'action_noise_std': 0.01,\n",
      " 'l2_coeff': 0.005,\n",
      " 'noise_stdev': 0.02,\n",
      " 'episodes_per_batch': 1000,\n",
      " 'eval_prob': 0.03,\n",
      " 'stepsize': 0.01,\n",
      " 'noise_size': 250000000,\n",
      " 'report_length': 10,\n",
      " 'tf_single_threaded': True,\n",
      " 'input': 'sampler',\n",
      " 'multiagent': {'policies': {'default_policy': <ray.rllib.policy.policy.PolicySpec at 0x7f2b2259c820>},\n",
      "  'policy_mapping_fn': <function ray.rllib.algorithms.algorithm_config.AlgorithmConfig.__init__.<locals>.<lambda>(aid, episode, worker, **kwargs)>,\n",
      "  'policies_to_train': None,\n",
      "  'policy_map_capacity': 100,\n",
      "  'policy_map_cache': None,\n",
      "  'count_steps_by': 'env_steps',\n",
      "  'observation_fn': None},\n",
      " 'callbacks': ray.rllib.algorithms.callbacks.DefaultCallbacks,\n",
      " 'create_env_on_driver': False,\n",
      " 'custom_eval_function': None,\n",
      " 'framework': 'torch',\n",
      " 'num_cpus_for_driver': 1,\n",
      " 'num_workers': 3}"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# change: rollout_workers\n",
    "# change: gpu\n",
    "\n",
    "config = (\n",
    "    ESConfig()\n",
    "    .environment(\n",
    "        env=\"darm/DarmSFHand-v0\"\n",
    "    )\n",
    "    .rollouts(\n",
    "        num_rollout_workers=3,\n",
    "        num_envs_per_worker=8,\n",
    "        rollout_fragment_length=1,\n",
    "        recreate_failed_workers=True,\n",
    "        num_consecutive_worker_failures_tolerance=10,\n",
    "        restart_failed_sub_environments=True,\n",
    "    )\n",
    "    .resources(num_gpus=0)\n",
    "    # .evaluation(evaluation_interval=100) # For 1000 timesteps iter; 100 evals\n",
    "    .framework(framework=\"torch\")\n",
    ")\n",
    "config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2742e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# change: rollout_workers\n",
    "# change: gpu\n",
    "# change: tags\n",
    "# change: name\n",
    "\n",
    "wandb_init = dict(\n",
    "    save_code=True,\n",
    "    resume=True,\n",
    "    config={\n",
    "        \"env\": \"DARMSFHand-v0\",\n",
    "        \"num_rollout_workers\": 3,\n",
    "        \"num_envs_per_worker\": 8,\n",
    "        \"recreate_failed_workers\": True,\n",
    "        \"num_consecutive_worker_failures_tolerance\": 10,\n",
    "        \"restart_failed_sub_environments\": True,\n",
    "        \"num_gpus\": 0,\n",
    "        \"framework\": \"torch\"\n",
    "    },\n",
    "    tags=[\"single_finger\", \"es\", \"delta_target\", \"test\", \"local\", \"no_vel_penalty\", \"effort_penalty\"],\n",
    "    notes=\"Fixed the env to use targets that are delta increaments from the starting state. Removed velocity penalty, and used only effort penalty\",\n",
    "    name=\"ES_Test_DARMSF_DELTA_TARGET\"\n",
    "    # job_type=\n",
    "    # monitor_gym=\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd288f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /home/daniel/DARM/darm-mujoco/darm_training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c13d9b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/ES_Test_DARMSF_DELTA_TARGET/ES_darm_DarmSFHand-v0_350a5_00000_0_2023-02-13_02-03-20/wandb/run-20230213_020323-350a5_00000</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/350a5_00000' target=\"_blank\">ES_Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/350a5_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/350a5_00000</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: \n",
    "# change: name\n",
    "# change: checkpoint_freq\n",
    "\n",
    "sync_config = tune.SyncConfig()\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"ES\",\n",
    "    run_config=air.RunConfig(\n",
    "        name=\"ES_Test_DARMSF_DELTA_TARGET\",\n",
    "        local_dir=f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results\",\n",
    "        sync_config=sync_config,\n",
    "        stop={\"training_iteration\": 10_000, \"episode_reward_mean\": 200},\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_at_end=True,\n",
    "            checkpoint_score_attribute=\"episode_reward_mean\",  # or leave to save last chkpts\n",
    "            checkpoint_score_order=\"max\",\n",
    "            checkpoint_frequency=1,  #50,\n",
    "            num_to_keep=3\n",
    "        ),\n",
    "        callbacks=[\n",
    "                WandbLoggerCallback(project=\"DARM\", \n",
    "                                    api_key=\"392c8a47eb0658eb5c71190757a69110e2140f4a\",\n",
    "                                    save_checkpoints=True, \n",
    "                                    **wandb_init)\n",
    "            ],\n",
    "        ),\n",
    "    param_space=config.to_dict()\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
