2023-02-13 01:19:33,192 INFO    MainThread:6015 [wandb_setup.py:_flush():68] Configure stats pid to 6015
2023-02-13 01:19:33,192 INFO    MainThread:6015 [wandb_setup.py:_flush():68] Loading settings from /home/daniel/.config/wandb/settings
2023-02-13 01:19:33,192 INFO    MainThread:6015 [wandb_setup.py:_flush():68] Loading settings from /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/ES_HalfCheetah-v3_14e1e_00000_0_2023-02-13_01-19-29/wandb/settings
2023-02-13 01:19:33,192 INFO    MainThread:6015 [wandb_setup.py:_flush():68] Loading settings from environment variables: {'_require_service': 'True', 'api_key': '***REDACTED***', 'start_method': 'thread'}
2023-02-13 01:19:33,192 INFO    MainThread:6015 [wandb_setup.py:_flush():68] Inferring run settings from compute environment: {'program': '<python with no main file>'}
2023-02-13 01:19:33,193 INFO    MainThread:6015 [wandb_init.py:_log_setup():492] Logging user logs to /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/ES_HalfCheetah-v3_14e1e_00000_0_2023-02-13_01-19-29/wandb/run-20230213_011933-14e1e_00000/logs/debug.log
2023-02-13 01:19:33,193 INFO    MainThread:6015 [wandb_init.py:_log_setup():493] Logging internal logs to /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/ES_HalfCheetah-v3_14e1e_00000_0_2023-02-13_01-19-29/wandb/run-20230213_011933-14e1e_00000/logs/debug-internal.log
2023-02-13 01:19:33,193 INFO    MainThread:6015 [wandb_init.py:_jupyter_setup():438] configuring jupyter hooks <wandb.sdk.wandb_init._WandbInit object at 0x7f16d7da3be0>
2023-02-13 01:19:33,194 INFO    MainThread:6015 [wandb_init.py:init():532] calling init triggers
2023-02-13 01:19:33,194 INFO    MainThread:6015 [wandb_init.py:init():538] wandb.init called with sweep_config: {}
config: {'env': 'HalfCheetah-v3', 'num_rollout_workers': 3, 'num_envs_per_worker': 8, 'recreate_failed_workers': True, 'num_consecutive_worker_failures_tolerance': 10, 'restart_failed_sub_environments': True, 'num_gpus': 0, 'framework': 'torch'}
2023-02-13 01:19:33,194 INFO    MainThread:6015 [wandb_init.py:init():588] starting backend
2023-02-13 01:19:33,194 INFO    MainThread:6015 [wandb_init.py:init():592] setting up manager
2023-02-13 01:19:33,205 INFO    MainThread:6015 [wandb_init.py:init():599] backend started and connected
2023-02-13 01:19:33,219 INFO    MainThread:6015 [wandb_run.py:_label_probe_notebook():1203] probe notebook
2023-02-13 01:19:33,220 INFO    MainThread:6015 [wandb_run.py:_label_probe_notebook():1213] Unable to probe notebook: 'NoneType' object has no attribute 'get'
2023-02-13 01:19:33,220 INFO    MainThread:6015 [wandb_init.py:init():687] updated telemetry
2023-02-13 01:19:33,268 INFO    MainThread:6015 [wandb_init.py:init():727] communicating run to backend with 60.0 second timeout
2023-02-13 01:19:34,419 INFO    MainThread:6015 [wandb_run.py:_on_init():2134] communicating current version
2023-02-13 01:19:36,374 INFO    MainThread:6015 [wandb_run.py:_on_init():2143] got version response 
2023-02-13 01:19:36,374 INFO    MainThread:6015 [wandb_init.py:init():775] starting run threads in backend
2023-02-13 01:19:41,556 INFO    MainThread:6015 [wandb_run.py:_console_start():2114] atexit reg
2023-02-13 01:19:41,556 INFO    MainThread:6015 [wandb_run.py:_redirect():1969] redirect: SettingsConsole.WRAP_RAW
2023-02-13 01:19:41,556 INFO    MainThread:6015 [wandb_run.py:_redirect():2034] Wrapping output streams.
2023-02-13 01:19:41,557 INFO    MainThread:6015 [wandb_run.py:_redirect():2059] Redirects installed.
2023-02-13 01:19:41,557 INFO    MainThread:6015 [wandb_init.py:init():817] run started, returning control to user process
2023-02-13 01:19:41,559 INFO    MainThread:6015 [wandb_config.py:__setitem__():155] config set trial_log_path = /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/ES_HalfCheetah-v3_14e1e_00000_0_2023-02-13_01-19-29 - <bound method Run._config_callback of <wandb.sdk.wandb_run.Run object at 0x7f172f51ebb0>>
2023-02-13 01:19:41,559 INFO    MainThread:6015 [wandb_run.py:_config_callback():1250] config_cb trial_log_path /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/ES_HalfCheetah-v3_14e1e_00000_0_2023-02-13_01-19-29 None
2023-02-13 01:25:15,884 INFO    MainThread:6015 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'HalfCheetah-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 8, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': True, 'restart_failed_sub_environments': True, 'num_consecutive_worker_failures_tolerance': 10, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 10000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'num_envs_per_worker': 1, 'observation_filter': 'NoFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'action_noise_std': 0.01, 'l2_coeff': 0.005, 'noise_stdev': 0.02, 'episodes_per_batch': 1000, 'eval_prob': 0.03, 'stepsize': 0.01, 'noise_size': 250000000, 'report_length': 10, 'tf_single_threaded': True, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7f16d40c8f40>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f16d7d8ab80>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '14e1e_00000', 'experiment_id': 'f6d671dd5c3a4f61903ff6aef3f964d4', 'date': '2023-02-13_01-25-15', 'pid': 6014, 'hostname': 'Daniel', 'node_ip': '192.168.84.35'}
2023-02-13 01:30:28,042 INFO    MainThread:6015 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'HalfCheetah-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 8, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': True, 'restart_failed_sub_environments': True, 'num_consecutive_worker_failures_tolerance': 10, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 10000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'num_envs_per_worker': 1, 'observation_filter': 'NoFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'action_noise_std': 0.01, 'l2_coeff': 0.005, 'noise_stdev': 0.02, 'episodes_per_batch': 1000, 'eval_prob': 0.03, 'stepsize': 0.01, 'noise_size': 250000000, 'report_length': 10, 'tf_single_threaded': True, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7f16d406dfa0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f16d408ef70>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '14e1e_00000', 'experiment_id': 'f6d671dd5c3a4f61903ff6aef3f964d4', 'date': '2023-02-13_01-30-28', 'pid': 6014, 'hostname': 'Daniel', 'node_ip': '192.168.84.35'}
2023-02-13 01:35:36,987 INFO    MainThread:6015 [wandb_run.py:_config_callback():1250] config_cb None None {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_gpus': 0, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, '_fake_gpus': False, 'custom_resources_per_worker': {}, 'placement_strategy': 'PACK', 'eager_tracing': False, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'env': 'HalfCheetah-v3', 'env_config': {}, 'observation_space': None, 'action_space': None, 'env_task_fn': None, 'render_env': False, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, 'disable_env_checking': False, 'num_envs_per_worker': 8, 'sample_collector': 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector', 'sample_async': False, 'enable_connectors': False, 'rollout_fragment_length': 200, 'batch_mode': 'truncate_episodes', 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'validate_workers_after_construction': True, 'ignore_worker_failures': False, 'recreate_failed_workers': True, 'restart_failed_sub_environments': True, 'num_consecutive_worker_failures_tolerance': 10, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'preprocessor_pref': 'deepmind', 'observation_filter': 'MeanStdFilter', 'synchronize_filters': True, 'compress_observations': False, 'enable_tf1_exec_eagerly': False, 'sampler_perf_stats_ema_coef': None, 'gamma': 0.99, 'lr': 0.001, 'train_batch_size': 10000, 'model': {'_use_default_native_models': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'conv_filters': None, 'conv_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'lstm_use_prev_action_reward': -1}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 180.0, 'evaluation_parallel_to_training': False, 'evaluation_config': {'num_envs_per_worker': 1, 'observation_filter': 'NoFilter'}, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_workers': 0, 'always_attach_evaluation_results': False, 'enable_async_evaluation': False, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 60.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'worker_cls': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_execution_plan_api': True, 'simple_optimizer': False, 'replay_sequence_length': None, 'action_noise_std': 0.01, 'l2_coeff': 0.005, 'noise_stdev': 0.02, 'episodes_per_batch': 1000, 'eval_prob': 0.03, 'stepsize': 0.01, 'noise_size': 250000000, 'report_length': 10, 'tf_single_threaded': True, '__stdout_file__': None, '__stderr_file__': None, 'input': 'sampler', 'multiagent': {'policies': {'default_policy': '<ray.rllib.policy.policy.PolicySpec object at 0x7f16d40d6df0>'}, 'policy_mapping_fn': '<function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f16d408eee0>', 'policies_to_train': None, 'policy_map_capacity': 100, 'policy_map_cache': None, 'count_steps_by': 'env_steps', 'observation_fn': None}, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch', 'num_cpus_for_driver': 1, 'num_workers': 3, 'trial_id': '14e1e_00000', 'experiment_id': 'f6d671dd5c3a4f61903ff6aef3f964d4', 'date': '2023-02-13_01-35-36', 'pid': 6014, 'hostname': 'Daniel', 'node_ip': '192.168.84.35'}
2023-02-13 01:35:37,416 INFO    MainThread:6015 [wandb_run.py:_finish():1854] finishing run danieladejumo/HalfCheetah/14e1e_00000
2023-02-13 01:35:37,488 INFO    MainThread:6015 [jupyter.py:save_history():478] saving 8 cells to _session_history.ipynb
2023-02-13 01:35:37,489 INFO    MainThread:6015 [wandb_run.py:_config_callback():1250] config_cb ('_wandb', 'session_history') code/_session_history.ipynb None
2023-02-13 01:35:37,494 INFO    MainThread:6015 [jupyter.py:_save_ipynb():390] looking for notebook: DARM/darm_mujoco/darm_training/es_halfcheetah_test.ipynb
2023-02-13 01:35:37,494 INFO    MainThread:6015 [wandb_init.py:_jupyter_teardown():420] cleaning up jupyter logic
2023-02-13 01:35:37,494 INFO    MainThread:6015 [wandb_run.py:_atexit_cleanup():2083] got exitcode: 0
2023-02-13 01:35:37,495 INFO    MainThread:6015 [wandb_run.py:_restore():2066] restore
2023-02-13 01:35:37,495 INFO    MainThread:6015 [wandb_run.py:_restore():2072] restore done
