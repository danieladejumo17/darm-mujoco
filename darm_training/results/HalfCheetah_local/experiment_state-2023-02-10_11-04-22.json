{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"4a7ee_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"HalfCheetah-v3\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 3000,\n    \"episode_reward_mean\": 150\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 9.758378982543945,\n            \"actor_loss\": -25.98797607421875,\n            \"critic_loss\": 0.1140708327293396,\n            \"alpha_loss\": -8.783862113952637,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af22d03e94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304466f66bf94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": 0.009235848672688007,\n            \"mean_q\": 24.703245162963867,\n            \"max_q\": 29.371721267700195,\n            \"min_q\": 17.71662712097168\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 1.220942497253418,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 3013.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 3012.0\n        }\n      },\n      \"num_env_steps_sampled\": 19038,\n      \"num_env_steps_trained\": 771328,\n      \"num_agent_steps_sampled\": 19038,\n      \"num_agent_steps_trained\": 771328,\n      \"last_target_update_ts\": 19038,\n      \"num_target_updates\": 3013\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -190.51257700856925,\n      \"episode_reward_min\": -334.0085722934719,\n      \"episode_reward_mean\": -259.55740757502326,\n      \"episode_len_mean\": 1000.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 0,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -259.6053751951275,\n          -190.51257700856925,\n          -334.0085722934719,\n          -307.29519873564004,\n          -206.36531464230757\n        ],\n        \"episode_lengths\": [\n          1000,\n          1000,\n          1000,\n          1000,\n          1000\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.3236382406449168,\n        \"mean_inference_ms\": 2.3153769610507147,\n        \"mean_action_processing_ms\": 0.2232992425872684,\n        \"mean_env_wait_ms\": 0.27413021622578043,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -190.51257700856925,\n    \"episode_reward_min\": -334.0085722934719,\n    \"episode_reward_mean\": -259.55740757502326,\n    \"episode_len_mean\": 1000.0,\n    \"episodes_this_iter\": 0,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -259.6053751951275,\n        -190.51257700856925,\n        -334.0085722934719,\n        -307.29519873564004,\n        -206.36531464230757\n      ],\n      \"episode_lengths\": [\n        1000,\n        1000,\n        1000,\n        1000,\n        1000\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.3236382406449168,\n      \"mean_inference_ms\": 2.3153769610507147,\n      \"mean_action_processing_ms\": 0.2232992425872684,\n      \"mean_env_wait_ms\": 0.27413021622578043,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 19038,\n    \"num_agent_steps_trained\": 771328,\n    \"num_env_steps_sampled\": 19038,\n    \"num_env_steps_trained\": 771328,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 19038,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 19038,\n    \"timers\": {\n      \"training_iteration_time_ms\": 158.002,\n      \"load_time_ms\": 0.297,\n      \"load_throughput\": 862166.231,\n      \"learn_time_ms\": 25.808,\n      \"learn_throughput\": 9919.35,\n      \"synch_weights_time_ms\": 5.692\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 19038,\n      \"num_env_steps_trained\": 771328,\n      \"num_agent_steps_sampled\": 19038,\n      \"num_agent_steps_trained\": 771328,\n      \"last_target_update_ts\": 19038,\n      \"num_target_updates\": 3013\n    },\n    \"done\": false,\n    \"episodes_total\": 18,\n    \"training_iteration\": 19,\n    \"trial_id\": \"4a7ee_00000\",\n    \"experiment_id\": \"eb2ab4e9039e47baa7a0744ff713e4f8\",\n    \"date\": \"2023-02-10_11-13-16\",\n    \"timestamp\": 1676023996,\n    \"time_this_iter_s\": 57.6614248752594,\n    \"time_total_s\": 519.9319005012512,\n    \"pid\": 8770,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"HalfCheetah-v3\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 519.9319005012512,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 19,\n    \"warmup_time\": 8.903371334075928,\n    \"perf\": {\n      \"cpu_util_percent\": 46.8,\n      \"ram_util_percent\": 80.81625\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1676023996.1123667,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": -190.51257700856925,\n      \"min\": -243.23089576113307,\n      \"avg\": NaN,\n      \"last\": -190.51257700856925,\n      \"last-5-avg\": -190.51257700856925,\n      \"last-10-avg\": -203.0780053480731\n    },\n    \"episode_reward_min\": {\n      \"max\": -330.3177143457895,\n      \"min\": -355.12658862007805,\n      \"avg\": NaN,\n      \"last\": -334.0085722934719,\n      \"last-5-avg\": -340.7050926404039,\n      \"last-10-avg\": -347.915840630241\n    },\n    \"episode_reward_mean\": {\n      \"max\": -259.55740757502326,\n      \"min\": -307.28499560212276,\n      \"avg\": NaN,\n      \"last\": -259.55740757502326,\n      \"last-5-avg\": -271.2481972615016,\n      \"last-10-avg\": -286.5052530055308\n    },\n    \"episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": 1000.0\n    },\n    \"episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.9473684210526315,\n      \"last\": 0,\n      \"last-5-avg\": 1.2,\n      \"last-10-avg\": 0.9\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3.0,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1002,\n      \"avg\": 1002.0,\n      \"last\": 1002,\n      \"last-5-avg\": 1002.0,\n      \"last-10-avg\": 1002.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 40596.21052631578,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 77132.8\n    },\n    \"timesteps_total\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 40596.21052631578,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 77132.8\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 18,\n      \"min\": 0,\n      \"avg\": 9.0,\n      \"last\": 18,\n      \"last-5-avg\": 16.2,\n      \"last-10-avg\": 13.5\n    },\n    \"training_iteration\": {\n      \"max\": 19,\n      \"min\": 1,\n      \"avg\": 10.0,\n      \"last\": 19,\n      \"last-5-avg\": 17.0,\n      \"last-10-avg\": 14.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 57.6614248752594,\n      \"min\": 3.0801594257354736,\n      \"avg\": 27.364836868486904,\n      \"last\": 57.6614248752594,\n      \"last-5-avg\": 54.532642650604245,\n      \"last-10-avg\": 49.023561882972714\n    },\n    \"time_total_s\": {\n      \"max\": 519.9319005012512,\n      \"min\": 3.607553005218506,\n      \"avg\": 152.89207467279934,\n      \"last\": 519.9319005012512,\n      \"last-5-avg\": 409.8927820682526,\n      \"last-10-avg\": 275.7548598766327\n    },\n    \"time_since_restore\": {\n      \"max\": 519.9319005012512,\n      \"min\": 3.607553005218506,\n      \"avg\": 152.89207467279934,\n      \"last\": 519.9319005012512,\n      \"last-5-avg\": 409.8927820682526,\n      \"last-10-avg\": 275.7548598766327\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 19,\n      \"min\": 1,\n      \"avg\": 10.0,\n      \"last\": 19,\n      \"last-5-avg\": 17.0,\n      \"last-10-avg\": 14.5\n    },\n    \"warmup_time\": {\n      \"max\": 8.903371334075928,\n      \"min\": 8.903371334075928,\n      \"avg\": 8.903371334075928,\n      \"last\": 8.903371334075928,\n      \"last-5-avg\": 8.903371334075928,\n      \"last-10-avg\": 8.903371334075928\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": -190.51257700856925,\n      \"min\": -243.23089576113307,\n      \"avg\": NaN,\n      \"last\": -190.51257700856925,\n      \"last-5-avg\": -190.51257700856925,\n      \"last-10-avg\": -203.0780053480731\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -330.3177143457895,\n      \"min\": -355.12658862007805,\n      \"avg\": NaN,\n      \"last\": -334.0085722934719,\n      \"last-5-avg\": -340.7050926404039,\n      \"last-10-avg\": -347.915840630241\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -259.55740757502326,\n      \"min\": -307.28499560212276,\n      \"avg\": NaN,\n      \"last\": -259.55740757502326,\n      \"last-5-avg\": -271.2481972615016,\n      \"last-10-avg\": -286.5052530055308\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": 1000.0\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.9473684210526315,\n      \"last\": 0,\n      \"last-5-avg\": 1.2,\n      \"last-10-avg\": 0.9\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 174.53,\n      \"min\": 8.762,\n      \"avg\": 86.75263157894737,\n      \"last\": 158.002,\n      \"last-5-avg\": 158.3898,\n      \"last-10-avg\": 155.5267\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 19038,\n      \"min\": 1002,\n      \"avg\": 10020.0,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 771328,\n      \"min\": 0,\n      \"avg\": 203452.63157894736,\n      \"last\": 771328,\n      \"last-5-avg\": 600320.0,\n      \"last-10-avg\": 386560.0\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 66.575,\n      \"min\": 38.8125,\n      \"avg\": 53.26269904784791,\n      \"last\": 46.8,\n      \"last-5-avg\": 42.639616438356164,\n      \"last-10-avg\": 43.91512819091106\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 80.81625,\n      \"min\": 78.14999999999999,\n      \"avg\": 79.30324978256142,\n      \"last\": 80.81625,\n      \"last-5-avg\": 80.25399337899542,\n      \"last-10-avg\": 80.0746745868667\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.3581311074329996,\n      \"min\": 1.3230577929349638,\n      \"avg\": 1.33733580236112,\n      \"last\": 1.3236382406449168,\n      \"last-5-avg\": 1.3364890443114112,\n      \"last-10-avg\": 1.3447155011304959\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.3153769610507147,\n      \"min\": 2.151980674239083,\n      \"avg\": 2.219290608421141,\n      \"last\": 2.3153769610507147,\n      \"last-5-avg\": 2.3063684922242027,\n      \"last-10-avg\": 2.273690322673204\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.22377951748507718,\n      \"min\": 0.21583743601431976,\n      \"avg\": 0.2196867601735452,\n      \"last\": 0.2232992425872684,\n      \"last-5-avg\": 0.22358740752595369,\n      \"last-10-avg\": 0.2220812297960723\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.27413021622578043,\n      \"min\": 0.26093142576968803,\n      \"avg\": 0.26729435947325747,\n      \"last\": 0.27413021622578043,\n      \"last-5-avg\": 0.2740830511764608,\n      \"last-10-avg\": 0.27211198234623746\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.3581311074329996,\n      \"min\": 1.3230577929349638,\n      \"avg\": 1.33733580236112,\n      \"last\": 1.3236382406449168,\n      \"last-5-avg\": 1.3364890443114112,\n      \"last-10-avg\": 1.3447155011304959\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.3153769610507147,\n      \"min\": 2.151980674239083,\n      \"avg\": 2.219290608421141,\n      \"last\": 2.3153769610507147,\n      \"last-5-avg\": 2.3063684922242027,\n      \"last-10-avg\": 2.273690322673204\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.22377951748507718,\n      \"min\": 0.21583743601431976,\n      \"avg\": 0.2196867601735452,\n      \"last\": 0.2232992425872684,\n      \"last-5-avg\": 0.22358740752595369,\n      \"last-10-avg\": 0.2220812297960723\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.27413021622578043,\n      \"min\": 0.26093142576968803,\n      \"avg\": 0.26729435947325747,\n      \"last\": 0.27413021622578043,\n      \"last-5-avg\": 0.2740830511764608,\n      \"last-10-avg\": 0.27211198234623746\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 19038,\n      \"min\": 10020,\n      \"avg\": 12393.15789473684,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"info/num_target_updates\": {\n      \"max\": 3013,\n      \"min\": 7,\n      \"avg\": 798.0526315789473,\n      \"last\": 3013,\n      \"last-5-avg\": 2345.0,\n      \"last-10-avg\": 1510.0\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.349,\n      \"min\": 0.254,\n      \"avg\": 0.27563157894736834,\n      \"last\": 0.297,\n      \"last-5-avg\": 0.2868,\n      \"last-10-avg\": 0.2888\n    },\n    \"timers/load_throughput\": {\n      \"max\": 1008018.986,\n      \"min\": 734333.076,\n      \"avg\": 935813.6849473683,\n      \"last\": 862166.231,\n      \"last-5-avg\": 904344.9422,\n      \"last-10-avg\": 895518.4745000001\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 29.089,\n      \"min\": 25.055,\n      \"avg\": 27.675421052631577,\n      \"last\": 25.808,\n      \"last-5-avg\": 26.418,\n      \"last-10-avg\": 26.403200000000005\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 10217.491,\n      \"min\": 8800.493,\n      \"avg\": 9285.588842105262,\n      \"last\": 9919.35,\n      \"last-5-avg\": 9714.1384,\n      \"last-10-avg\": 9722.175099999999\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 7.846,\n      \"min\": 5.253,\n      \"avg\": 6.863736842105261,\n      \"last\": 5.692,\n      \"last-5-avg\": 5.8262,\n      \"last-10-avg\": 5.9797\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 19038,\n      \"min\": 10020,\n      \"avg\": 12393.15789473684,\n      \"last\": 19038,\n      \"last-5-avg\": 17034.0,\n      \"last-10-avg\": 14529.0\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 3013,\n      \"min\": 7,\n      \"avg\": 798.0526315789473,\n      \"last\": 3013,\n      \"last-5-avg\": 2345.0,\n      \"last-10-avg\": 1510.0\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 3.1362533569335938,\n      \"min\": 1.0904772281646729,\n      \"avg\": 2.2625858532754997,\n      \"last\": 1.220942497253418,\n      \"last-5-avg\": 1.2302432537078858,\n      \"last-10-avg\": 1.4762850999832153\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 3013.0,\n      \"min\": 7.0,\n      \"avg\": 798.0526315789473,\n      \"last\": 3013.0,\n      \"last-5-avg\": 2345.0,\n      \"last-10-avg\": 1510.0\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 3012.0,\n      \"min\": 6.0,\n      \"avg\": 797.0526315789473,\n      \"last\": 3012.0,\n      \"last-5-avg\": 2344.0,\n      \"last-10-avg\": 1509.0\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 10.096208572387695,\n      \"min\": 9.758378982543945,\n      \"avg\": 10.013554071125231,\n      \"last\": 9.758378982543945,\n      \"last-5-avg\": 9.898587799072265,\n      \"last-10-avg\": 9.939165019989014\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": -4.647748947143555,\n      \"min\": -25.98797607421875,\n      \"avg\": -11.337958938197085,\n      \"last\": -25.98797607421875,\n      \"last-5-avg\": -23.274127960205078,\n      \"last-10-avg\": -17.359147930145262\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 1.8881553411483765,\n      \"min\": 0.1140708327293396,\n      \"avg\": 1.0764859914779665,\n      \"last\": 0.1140708327293396,\n      \"last-5-avg\": 0.1592902958393097,\n      \"last-10-avg\": 0.3459835767745972\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": -0.018178138881921768,\n      \"min\": -8.783862113952637,\n      \"avg\": -2.355020321121341,\n      \"last\": -8.783862113952637,\n      \"last-5-avg\": -6.919980239868164,\n      \"last-10-avg\": -4.458178285136819\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041c8a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af22d03e94869452942e\"\n      },\n      \"avg\": 0.8221195951888436,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304af22d03e94869452942e\"\n      },\n      \"last-5-avg\": 0.5013428032398224,\n      \"last-10-avg\": 0.6636462122201919\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047afeebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304466f66bf94869452942e\"\n      },\n      \"avg\": -0.23809613564394805,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304466f66bf94869452942e\"\n      },\n      \"last-5-avg\": -0.7004472374916076,\n      \"last-10-avg\": -0.4507622151868418\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.05603480711579323,\n      \"min\": -0.02402987889945507,\n      \"avg\": 0.011977905370785217,\n      \"last\": 0.009235848672688007,\n      \"last-5-avg\": 0.03681669104844332,\n      \"last-10-avg\": 0.022349088941700755\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 24.703245162963867,\n      \"min\": 0.5784788131713867,\n      \"avg\": 8.10848765624197,\n      \"last\": 24.703245162963867,\n      \"last-5-avg\": 21.547025299072267,\n      \"last-10-avg\": 14.885495615005492\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 29.371721267700195,\n      \"min\": 1.1348023414611816,\n      \"avg\": 10.60254920156378,\n      \"last\": 29.371721267700195,\n      \"last-5-avg\": 26.363083267211913,\n      \"last-10-avg\": 19.12352137565613\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 18.13233184814453,\n      \"min\": 0.23879346251487732,\n      \"avg\": 5.46182202979138,\n      \"last\": 17.71662712097168,\n      \"last-5-avg\": 15.63188304901123,\n      \"last-10-avg\": 10.162547740340234\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f2f48448897f6bc094869452946807680d4308f2f48448897f6bc094869452946807680d430810cc0f7ef5976ac094869452946807680d430810cc0f7ef5976ac094869452946807680d430810cc0f7ef5976ac094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d4308d181b31c23e074c094869452946807680d4308d181b31c23e074c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d4308d181b31c23e074c094869452946807680d4308d181b31c23e074c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d430848943424eb3870c094869452946807680d430848943424eb3870c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b2615307a75772c094869452946807680d4308b2615307a75772c094869452946807680d4308f0698c578f3473c094869452946807680d4308f0698c578f3473c094869452946807680d4308f0698c578f3473c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d430848943424eb3870c094869452946807680d430848943424eb3870c09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b004b004b034b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b034b004b004b034b004b004b034b00652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034dea034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034dea034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0f4b0f4b0f4b124b12652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b094b094b0c4b0c4b0c4b0f4b0f4b0f4b124b12652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0f4b104b114b124b13652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0a4b0b4b0c4b0d4b0e4b0f4b104b114b124b13652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404b4425f800000047404b24edbc00000047404aa3ff8c00000047404a73275a00000047404cd4a992000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740135a80b000000047404b32121200000047404aa1a41800000047404a7d34f400000047404a0d096200000047404b4425f800000047404b24edbc00000047404aa3ff8c00000047404a73275a00000047404cd4a992000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474072dcd14a000000474076416f0180000047407995eef300000047407ce453de4000004740803f7488400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474041446fd80000004740563b40f5000000474061c609808000004740686556bd80000047406ee89916000000474072dcd14a000000474076416f0180000047407995eef300000047407ce453de4000004740803f7488400000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474072dcd14a000000474076416f0180000047407995eef300000047407ce453de4000004740803f7488400000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474041446fd80000004740563b40f5000000474061c609808000004740686556bd80000047406ee89916000000474072dcd14a000000474076416f0180000047407995eef300000047407ce453de4000004740803f7488400000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0f4b104b114b124b13652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0a4b0b4b0c4b0d4b0e4b0f4b104b114b124b13652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000474021ce86b0000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f2f48448897f6bc094869452946807680d4308f2f48448897f6bc094869452946807680d430810cc0f7ef5976ac094869452946807680d430810cc0f7ef5976ac094869452946807680d430810cc0f7ef5976ac094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c094869452946807680d4308910fe60767d067c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d4308d181b31c23e074c094869452946807680d4308d181b31c23e074c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d43087ff4c981063276c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d430866be3b06b69275c094869452946807680d4308d181b31c23e074c094869452946807680d4308d181b31c23e074c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d430848943424eb3870c094869452946807680d430848943424eb3870c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308b2615307a75772c094869452946807680d4308b2615307a75772c094869452946807680d4308f0698c578f3473c094869452946807680d4308f0698c578f3473c094869452946807680d4308f0698c578f3473c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d4308fb0f0444ac7071c094869452946807680d430848943424eb3870c094869452946807680d430848943424eb3870c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b004b004b034b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b034b004b004b034b004b004b034b00652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847406415ba5e353f7d4740631a7ef9db22d147406599e353f7ced9474062743126e978d5474063c010624dd2f2652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847405dff6c8b43958147406496d916872b02474065d0f5c28f5c29474062e2b851eb851f4740631fef9db22d0e47406415ba5e353f7d4740631a7ef9db22d147406599e353f7ced9474062743126e978d5474063c010624dd2f2652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059552000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d00074a005501004a00a302004a00f103004a003f05004a008d06004a00db07004a002909004a00770a004a00c50b00652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fd1ba18cde16454094869452946807680d43082c40ee351712454094869452946807680d43086fe0c0810387444094869452946807680d43082f2c2517fb82444094869452946807680d430866666666666647409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308833aa8833ae84e4094869452946807680d430822dbf97e6a3c454094869452946807680d43080eb707a9eb70444094869452946807680d4308c7711cc771fc444094869452946807680d4308000000000068434094869452946807680d4308fd1ba18cde16454094869452946807680d43082c40ee351712454094869452946807680d43086fe0c0810387444094869452946807680d43082f2c2517fb82444094869452946807680d430866666666666647409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e17a14ae4701544094869452946807680d4308b865ad8e09fe534094869452946807680d4308f5ead5ab570f544094869452946807680d4308e698fec9600e544094869452946807680d43080ad7a3703d3454409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f1155ff115bf534094869452946807680d43089ae0c13c51ff534094869452946807680d4308196701369f11544094869452946807680d4308bcbbbbbbbb07544094869452946807680d43086cc1166cc106544094869452946807680d4308e17a14ae4701544094869452946807680d4308b865ad8e09fe534094869452946807680d4308f5ead5ab570f544094869452946807680d4308e698fec9600e544094869452946807680d43080ad7a3703d3454409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308dae0b44a9f2df53f94869452946807680d4308dae0b44a9f2df53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430896aadca3c485f53f94869452946807680d430896aadca3c485f53f94869452946807680d430810ae21afe7baf53f94869452946807680d430810ae21afe7baf53f94869452946807680d430810ae21afe7baf53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308dae0b44a9f2df53f94869452946807680d4308dae0b44a9f2df53f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d43085bff2c5be485024094869452946807680d43085bff2c5be48502409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a806a3976a0014094869452946807680d43085a806a3976a0014094869452946807680d4308b44fbe7b0321024094869452946807680d4308b44fbe7b0321024094869452946807680d4308b44fbe7b0321024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d43085bff2c5be485024094869452946807680d43085bff2c5be48502409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308402311d01195cc3f94869452946807680d4308402311d01195cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fb3e947a0aeecb3f94869452946807680d4308fb3e947a0aeecb3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308402311d01195cc3f94869452946807680d4308402311d01195cc3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308a93f6276598bd13f94869452946807680d4308a93f6276598bd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308deea7bdab417d13f94869452946807680d4308deea7bdab417d13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308a93f6276598bd13f94869452946807680d4308a93f6276598bd13f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308dae0b44a9f2df53f94869452946807680d4308dae0b44a9f2df53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430896aadca3c485f53f94869452946807680d430896aadca3c485f53f94869452946807680d430810ae21afe7baf53f94869452946807680d430810ae21afe7baf53f94869452946807680d430810ae21afe7baf53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308ea8af1b25985f53f94869452946807680d4308dae0b44a9f2df53f94869452946807680d4308dae0b44a9f2df53f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d43085bff2c5be485024094869452946807680d43085bff2c5be48502409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243085a806a3976a0014094869452946807680d43085a806a3976a0014094869452946807680d4308b44fbe7b0321024094869452946807680d4308b44fbe7b0321024094869452946807680d4308b44fbe7b0321024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d430895b4cfa22467024094869452946807680d43085bff2c5be485024094869452946807680d43085bff2c5be48502409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308402311d01195cc3f94869452946807680d4308402311d01195cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308fb3e947a0aeecb3f94869452946807680d4308fb3e947a0aeecb3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d43080a3b6517a56fcc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308f8788ea6cea4cc3f94869452946807680d4308402311d01195cc3f94869452946807680d4308402311d01195cc3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308a93f6276598bd13f94869452946807680d4308a93f6276598bd13f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308deea7bdab417d13f94869452946807680d4308deea7bdab417d13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d66c099f826bd13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308d4843dc10f8ad13f94869452946807680d4308a93f6276598bd13f94869452946807680d4308a93f6276598bd13f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d8d064ddb074d29094d770a4dc50b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d55014da3024df1034d3f054d8d064ddb074d29094d770a4dc50b652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd15810624dd2f2473fd0d4fdf3b645a2473fd65604189374bc473fd04189374bc6a8473fd3020c49ba5e35652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd0b4395810624e473fd3333333333333473fd5810624dd2f1b473fd15810624dd2f2473fd24dd2f1a9fbe7473fd15810624dd2f2473fd0d4fdf3b645a2473fd65604189374bc473fd04189374bc6a8473fd3020c49ba5e35652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847412cc8c52c08312747412db967a9fbe76d47412668fa26e978d547412ec325f8d4fdf447412a4fac7645a1cb652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847412decd4483126e947412a14b3a1cac0834741273c860bc6a7f047412cc6d42f1a9fbe47412b4785ec8b439647412cc8c52c08312747412db967a9fbe76d47412668fa26e978d547412ec325f8d4fdf447412a4fac7645a1cb652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403b08b439581062474039774bc6a7ef9e47403cba1cac0831274740390e147ae147ae474039ced916872b02652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403d16c8b439581047403916872b020c4a47403aac8b4395810647403916872b020c4a47403a00c49ba5e35447403b08b439581062474039774bc6a7ef9e47403cba1cac0831274740390e147ae147ae474039ced916872b02652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c27ecef9db22d14740c3a2510624dd2f4740c167cced9168734740c3f4bed916872b4740c35faccccccccd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c1303f1a9fbe774740c3ee10a3d70a3d4740c2beb22d0e56044740c3ee1a9fbe76c94740c33a6b020c49ba4740c27ecef9db22d14740c3a2510624dd2f4740c167cced9168734740c3f4bed916872b4740c35faccccccccd652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401b0f5c28f5c28f47401503126e978d50474018083126e978d5474015a6e978d4fdf4474016c49ba5e353f8652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401f624dd2f1a9fc474016df3b645a1cac4740161a9fbe76c8b4474016676c8b439581474017e6666666666647401b0f5c28f5c28f47401503126e978d50474018083126e978d5474015a6e978d4fdf4474016c49ba5e353f8652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284db63a4da03e4d8a424d74464d5e4a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a4da03e4d8a424d74464d5e4a652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d8d064ddb074d29094d770a4dc50b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d55014da3024df1034d3f054d8d064ddb074d29094d770a4dc50b652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000800f81f63f94869452946807680d4308000000c03291f23f94869452946807680d4308000000000ffcf13f94869452946807680d43080000008015d4f33f94869452946807680d430800000000fb88f33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000c17094094869452946807680d430800000040d940fa3f94869452946807680d430800000000e5d2f63f94869452946807680d430800000000d314f53f94869452946807680d4308000000409872f13f94869452946807680d4308000000800f81f63f94869452946807680d4308000000c03291f23f94869452946807680d4308000000000ffcf13f94869452946807680d43080000008015d4f33f94869452946807680d430800000000fb88f33f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000349a4094869452946807680d430800000000006c9f4094869452946807680d4308000000000052a24094869452946807680d43080000000000eea44094869452946807680d430800000000008aa7409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000001c4094869452946807680d4308000000000050754094869452946807680d4308000000000018854094869452946807680d43080000000000888f4094869452946807680d43080000000000fc944094869452946807680d43080000000000349a4094869452946807680d430800000000006c9f4094869452946807680d4308000000000052a24094869452946807680d43080000000000eea44094869452946807680d430800000000008aa7409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000309a4094869452946807680d43080000000000689f4094869452946807680d4308000000000050a24094869452946807680d43080000000000eca44094869452946807680d4308000000000088a7409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000184094869452946807680d4308000000000040754094869452946807680d4308000000000010854094869452946807680d43080000000000808f4094869452946807680d43080000000000f8944094869452946807680d43080000000000309a4094869452946807680d43080000000000689f4094869452946807680d4308000000000050a24094869452946807680d43080000000000eca44094869452946807680d4308000000000088a7409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000a704244094869452946807680d4308000000e07bf9234094869452946807680d43080000000058d8234094869452946807680d4308000000609da1234094869452946807680d4308000000404a8423409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000404231244094869452946807680d4308000000a0ca2b244094869452946807680d4308000000403ac9234094869452946807680d43080000004017c7234094869452946807680d430800000080c5de234094869452946807680d430800000000a704244094869452946807680d4308000000e07bf9234094869452946807680d43080000000058d8234094869452946807680d4308000000609da1234094869452946807680d4308000000404a8423409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020421934c094869452946807680d43080000004032de35c094869452946807680d4308000000201f5b37c094869452946807680d4308000000c0620f39c094869452946807680d430800000000ecfc39c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000804b9712c094869452946807680d43080000008008d921c094869452946807680d4308000000004f2027c094869452946807680d43080000006029422dc094869452946807680d4308000000a0f57431c094869452946807680d430800000020421934c094869452946807680d43080000004032de35c094869452946807680d4308000000201f5b37c094869452946807680d4308000000c0620f39c094869452946807680d430800000000ecfc39c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000601379c33f94869452946807680d4308000000a04842c63f94869452946807680d430800000080fee7c53f94869452946807680d430800000040e5b4c73f94869452946807680d430800000000bf33bd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060e235fe3f94869452946807680d4308000000802208cd3f94869452946807680d4308000000c0d811c93f94869452946807680d43080000008082ccc93f94869452946807680d4308000000003654c33f94869452946807680d4308000000601379c33f94869452946807680d4308000000a04842c63f94869452946807680d430800000080fee7c53f94869452946807680d430800000040e5b4c73f94869452946807680d430800000000bf33bd3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020f00514c094869452946807680d4308000000c0e0fd17c094869452946807680d430800000080bed01bc094869452946807680d430800000060106f1fc094869452946807680d430800000060569121c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000404a9d92bf94869452946807680d4308000000609a77f0bf94869452946807680d4308000000c007f5ffbf94869452946807680d43080000002049bb07c094869452946807680d43080000000010c40fc094869452946807680d430800000020f00514c094869452946807680d4308000000c0e0fd17c094869452946807680d430800000080bed01bc094869452946807680d430800000060106f1fc094869452946807680d430800000060569121c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243049c401b3f94869452946807680d4304e36a0c3f94869452946807680d4304840bfe3e94869452946807680d4304d4eae53e94869452946807680d4304af22d03e9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041c8a7f3f94869452946807680d4304272a673f94869452946807680d4304eb32513f94869452946807680d430447a73d3f94869452946807680d4304b7a82b3f94869452946807680d43049c401b3f94869452946807680d4304e36a0c3f94869452946807680d4304840bfe3e94869452946807680d4304d4eae53e94869452946807680d4304af22d03e9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304380800bf94869452946807680d43041dbe19bf94869452946807680d4304806833bf94869452946807680d430472f44cbf94869452946807680d4304466f66bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243047afeebba94869452946807680d43041efed0bd94869452946807680d4304c4bc4ebe94869452946807680d4304dd9699be94869452946807680d43042ea1ccbe94869452946807680d4304380800bf94869452946807680d43041dbe19bf94869452946807680d4304806833bf94869452946807680d430472f44cbf94869452946807680d4304466f66bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000800dc8a83f94869452946807680d43080000002098b0ac3f94869452946807680d430800000000e17a9c3f94869452946807680d4308000000008acfa53f94869452946807680d4308000000a03eea823f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000008c73d3f94869452946807680d4308000000e0499b98bf94869452946807680d430800000060cc4762bf94869452946807680d430800000060282eab3f94869452946807680d43080000006085d6883f94869452946807680d4308000000800dc8a83f94869452946807680d43080000002098b0ac3f94869452946807680d430800000000e17a9c3f94869452946807680d4308000000008acfa53f94869452946807680d4308000000a03eea823f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0f4fd314094869452946807680d43080000004078fa334094869452946807680d4308000000c03090354094869452946807680d4308000000808b7f374094869452946807680d4308000000e007b438409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000e682e23f94869452946807680d4308000000a0a247154094869452946807680d43080000008050a9204094869452946807680d430800000060e1a4274094869452946807680d4308000000c028232e4094869452946807680d4308000000e0f4fd314094869452946807680d43080000004078fa334094869452946807680d4308000000c03090354094869452946807680d4308000000808b7f374094869452946807680d4308000000e007b438409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040a7c2354094869452946807680d4308000000409442394094869452946807680d4308000000002c1c3b4094869452946807680d4308000000802e503c4094869452946807680d430800000020295f3d409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000802628f23f94869452946807680d4308000000c0ec86224094869452946807680d4308000000e09a16284094869452946807680d4308000000e0150f314094869452946807680d4308000000c01beb334094869452946807680d430800000040a7c2354094869452946807680d4308000000409442394094869452946807680d4308000000002c1c3b4094869452946807680d4308000000802e503c4094869452946807680d430800000020295f3d409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e030a0294094869452946807680d430800000000ade72b4094869452946807680d43080000004016172f4094869452946807680d430800000080e021324094869452946807680d4308000000e074b731409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0c890ce3f94869452946807680d4308000000401685f23f94869452946807680d4308000000a088e50d4094869452946807680d430800000060e251204094869452946807680d4308000000407558244094869452946807680d4308000000e030a0294094869452946807680d430800000000ade72b4094869452946807680d43080000004016172f4094869452946807680d430800000080e021324094869452946807680d4308000000e074b731409486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1676023462.4371772,\n  \"relative_logdir\": \"SAC_HalfCheetah-v3_4a7ee_00000_0_2023-02-10_11-04-22\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"HalfCheetah_local\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 519.9319005012512,
    "_iteration": 118,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1676023462.2135649,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-02-10_11-04-22",
    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/experiment_state-2023-02-10_11-04-22.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1676023462.2135649,
    "timestamp": 1676024026.1640556
  }
}