{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"45677_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"HalfCheetah-v3\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 3000,\n    \"episode_reward_mean\": 150\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 7.748189926147461,\n            \"actor_loss\": -28.348724365234375,\n            \"critic_loss\": 0.0571567639708519,\n            \"alpha_loss\": -17.404212951660156,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044eacd83d94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430439c20fc094869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": 0.03609086945652962,\n            \"mean_q\": 27.962879180908203,\n            \"max_q\": 40.63548278808594,\n            \"min_q\": 18.630765914916992\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 1.353323221206665,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 7689.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 7688.0\n        }\n      },\n      \"num_env_steps_sampled\": 33066,\n      \"num_env_steps_trained\": 1968384,\n      \"num_agent_steps_sampled\": 33066,\n      \"num_agent_steps_trained\": 1968384,\n      \"last_target_update_ts\": 33066,\n      \"num_target_updates\": 7689\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -167.91988759326725,\n      \"episode_reward_min\": -263.95626261651586,\n      \"episode_reward_mean\": -215.57811427532747,\n      \"episode_len_mean\": 1000.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 3,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -215.8739431473014,\n          -218.1805715779573,\n          -211.95990644159554,\n          -263.95626261651586,\n          -167.91988759326725\n        ],\n        \"episode_lengths\": [\n          1000,\n          1000,\n          1000,\n          1000,\n          1000\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.357153863304131,\n        \"mean_inference_ms\": 2.490057054053702,\n        \"mean_action_processing_ms\": 0.23928675805918923,\n        \"mean_env_wait_ms\": 0.29093273375258427,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -167.91988759326725,\n    \"episode_reward_min\": -263.95626261651586,\n    \"episode_reward_mean\": -215.57811427532747,\n    \"episode_len_mean\": 1000.0,\n    \"episodes_this_iter\": 3,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -215.8739431473014,\n        -218.1805715779573,\n        -211.95990644159554,\n        -263.95626261651586,\n        -167.91988759326725\n      ],\n      \"episode_lengths\": [\n        1000,\n        1000,\n        1000,\n        1000,\n        1000\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.357153863304131,\n      \"mean_inference_ms\": 2.490057054053702,\n      \"mean_action_processing_ms\": 0.23928675805918923,\n      \"mean_env_wait_ms\": 0.29093273375258427,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 33066,\n    \"num_agent_steps_trained\": 1968384,\n    \"num_env_steps_sampled\": 33066,\n    \"num_env_steps_trained\": 1968384,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 33066,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 33066,\n    \"timers\": {\n      \"training_iteration_time_ms\": 153.919,\n      \"load_time_ms\": 0.294,\n      \"load_throughput\": 870766.218,\n      \"learn_time_ms\": 24.925,\n      \"learn_throughput\": 10270.825,\n      \"synch_weights_time_ms\": 6.021\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 33066,\n      \"num_env_steps_trained\": 1968384,\n      \"num_agent_steps_sampled\": 33066,\n      \"num_agent_steps_trained\": 1968384,\n      \"last_target_update_ts\": 33066,\n      \"num_target_updates\": 7689\n    },\n    \"done\": false,\n    \"episodes_total\": 33,\n    \"training_iteration\": 33,\n    \"trial_id\": \"45677_00000\",\n    \"experiment_id\": \"4b3554eec46b41eeb5d922821f573f3e\",\n    \"date\": \"2023-02-10_13-28-53\",\n    \"timestamp\": 1676032133,\n    \"time_this_iter_s\": 61.43078112602234,\n    \"time_total_s\": 1361.6633477210999,\n    \"pid\": 14767,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"HalfCheetah-v3\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 1361.6633477210999,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 33,\n    \"warmup_time\": 11.184238195419312,\n    \"perf\": {\n      \"cpu_util_percent\": 51.79411764705881,\n      \"ram_util_percent\": 92.46705882352937\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1676032133.9112446,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": -167.91988759326725,\n      \"min\": -301.00610848406444,\n      \"avg\": NaN,\n      \"last\": -167.91988759326725,\n      \"last-5-avg\": -208.1520654109373,\n      \"last-10-avg\": -207.3317118802408\n    },\n    \"episode_reward_min\": {\n      \"max\": -261.72637729761584,\n      \"min\": -466.9075788295796,\n      \"avg\": NaN,\n      \"last\": -263.95626261651586,\n      \"last-5-avg\": -266.5187338662117,\n      \"last-10-avg\": -279.1423233228581\n    },\n    \"episode_reward_mean\": {\n      \"max\": -215.57811427532747,\n      \"min\": -359.7539484348061,\n      \"avg\": NaN,\n      \"last\": -215.57811427532747,\n      \"last-5-avg\": -232.22864308214912,\n      \"last-10-avg\": -244.22475333080092\n    },\n    \"episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": 1000.0\n    },\n    \"episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.9999999999999998,\n      \"last\": 3,\n      \"last-5-avg\": 1.2,\n      \"last-10-avg\": 1.2\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3.0,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1002,\n      \"avg\": 1002.0,\n      \"last\": 1002,\n      \"last-5-avg\": 1002.0,\n      \"last-10-avg\": 1002.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 59647.999999999985,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 85504.0\n    },\n    \"timesteps_total\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 59647.999999999985,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 85504.0\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 33,\n      \"min\": 0,\n      \"avg\": 16.0,\n      \"last\": 33,\n      \"last-5-avg\": 30.0,\n      \"last-10-avg\": 27.6\n    },\n    \"training_iteration\": {\n      \"max\": 33,\n      \"min\": 1,\n      \"avg\": 17.0,\n      \"last\": 33,\n      \"last-5-avg\": 31.0,\n      \"last-10-avg\": 28.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 62.7315571308136,\n      \"min\": 3.1232755184173584,\n      \"avg\": 41.26252568851817,\n      \"last\": 61.43078112602234,\n      \"last-5-avg\": 58.58255987167358,\n      \"last-10-avg\": 59.140746569633485\n    },\n    \"time_total_s\": {\n      \"max\": 1361.6633477210999,\n      \"min\": 3.926569700241089,\n      \"avg\": 509.58331869587744,\n      \"last\": 1361.6633477210999,\n      \"last-5-avg\": 1245.324155330658,\n      \"last-10-avg\": 1097.8018674373627\n    },\n    \"time_since_restore\": {\n      \"max\": 1361.6633477210999,\n      \"min\": 3.926569700241089,\n      \"avg\": 509.58331869587744,\n      \"last\": 1361.6633477210999,\n      \"last-5-avg\": 1245.324155330658,\n      \"last-10-avg\": 1097.8018674373627\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 33,\n      \"min\": 1,\n      \"avg\": 17.0,\n      \"last\": 33,\n      \"last-5-avg\": 31.0,\n      \"last-10-avg\": 28.5\n    },\n    \"warmup_time\": {\n      \"max\": 11.184238195419312,\n      \"min\": 11.184238195419312,\n      \"avg\": 11.184238195419312,\n      \"last\": 11.184238195419312,\n      \"last-5-avg\": 11.184238195419312,\n      \"last-10-avg\": 11.184238195419312\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": -167.91988759326725,\n      \"min\": -301.00610848406444,\n      \"avg\": NaN,\n      \"last\": -167.91988759326725,\n      \"last-5-avg\": -208.1520654109373,\n      \"last-10-avg\": -207.3317118802408\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -261.72637729761584,\n      \"min\": -466.9075788295796,\n      \"avg\": NaN,\n      \"last\": -263.95626261651586,\n      \"last-5-avg\": -266.5187338662117,\n      \"last-10-avg\": -279.1423233228581\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -215.57811427532747,\n      \"min\": -359.7539484348061,\n      \"avg\": NaN,\n      \"last\": -215.57811427532747,\n      \"last-5-avg\": -232.22864308214912,\n      \"last-10-avg\": -244.22475333080092\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": 1000.0\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.9999999999999998,\n      \"last\": 3,\n      \"last-5-avg\": 1.2,\n      \"last-10-avg\": 1.2\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 219.385,\n      \"min\": 8.779,\n      \"avg\": 125.04857575757576,\n      \"last\": 153.919,\n      \"last-5-avg\": 178.9472,\n      \"last-10-avg\": 180.5336\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 33066,\n      \"min\": 1002,\n      \"avg\": 17034.0,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 1968384,\n      \"min\": 0,\n      \"avg\": 716427.6363636362,\n      \"last\": 1968384,\n      \"last-5-avg\": 1797376.0,\n      \"last-10-avg\": 1583616.0\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 68.47999999999999,\n      \"min\": 41.24933333333334,\n      \"avg\": 52.035990449998664,\n      \"last\": 51.79411764705881,\n      \"last-5-avg\": 47.8423745903107,\n      \"last-10-avg\": 48.57477958663382\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 93.43373493975903,\n      \"min\": 83.47066666666669,\n      \"avg\": 88.47221486285615,\n      \"last\": 92.46705882352937,\n      \"last-5-avg\": 90.99756571475699,\n      \"last-10-avg\": 89.57611812644545\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.3877914450262903,\n      \"min\": 1.351870742678741,\n      \"avg\": 1.3723721877758768,\n      \"last\": 1.357153863304131,\n      \"last-5-avg\": 1.3550296162751467,\n      \"last-10-avg\": 1.3535337174731858\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.490057054053702,\n      \"min\": 2.284554608297612,\n      \"avg\": 2.388677927265442,\n      \"last\": 2.490057054053702,\n      \"last-5-avg\": 2.475680583145483,\n      \"last-10-avg\": 2.4628352929102078\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.23928675805918923,\n      \"min\": 0.22521393884964896,\n      \"avg\": 0.23393827954313007,\n      \"last\": 0.23928675805918923,\n      \"last-5-avg\": 0.2382295727465092,\n      \"last-10-avg\": 0.2372626825968931\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.29093273375258427,\n      \"min\": 0.28169495146320206,\n      \"avg\": 0.28605108034488186,\n      \"last\": 0.29093273375258427,\n      \"last-5-avg\": 0.2892137661495754,\n      \"last-10-avg\": 0.28756056246331185\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.3877914450262903,\n      \"min\": 1.351870742678741,\n      \"avg\": 1.3723721877758768,\n      \"last\": 1.357153863304131,\n      \"last-5-avg\": 1.3550296162751467,\n      \"last-10-avg\": 1.3535337174731858\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.490057054053702,\n      \"min\": 2.284554608297612,\n      \"avg\": 2.388677927265442,\n      \"last\": 2.490057054053702,\n      \"last-5-avg\": 2.475680583145483,\n      \"last-10-avg\": 2.4628352929102078\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.23928675805918923,\n      \"min\": 0.22521393884964896,\n      \"avg\": 0.23393827954313007,\n      \"last\": 0.23928675805918923,\n      \"last-5-avg\": 0.2382295727465092,\n      \"last-10-avg\": 0.2372626825968931\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.29093273375258427,\n      \"min\": 0.28169495146320206,\n      \"avg\": 0.28605108034488186,\n      \"last\": 0.29093273375258427,\n      \"last-5-avg\": 0.2892137661495754,\n      \"last-10-avg\": 0.28756056246331185\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 33066,\n      \"min\": 10020,\n      \"avg\": 18400.363636363632,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"info/num_target_updates\": {\n      \"max\": 7689,\n      \"min\": 7,\n      \"avg\": 2800.4545454545446,\n      \"last\": 7689,\n      \"last-5-avg\": 7021.0,\n      \"last-10-avg\": 6186.0\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.414,\n      \"min\": 0.267,\n      \"avg\": 0.3014848484848483,\n      \"last\": 0.294,\n      \"last-5-avg\": 0.3524,\n      \"last-10-avg\": 0.341\n    },\n    \"timers/load_throughput\": {\n      \"max\": 959554.803,\n      \"min\": 618657.423,\n      \"avg\": 862156.6947878783,\n      \"last\": 870766.218,\n      \"last-5-avg\": 741815.2954,\n      \"last-10-avg\": 762027.5210999999\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 48.277,\n      \"min\": 24.863,\n      \"avg\": 33.56193939393938,\n      \"last\": 24.925,\n      \"last-5-avg\": 27.9832,\n      \"last-10-avg\": 27.9861\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 10296.432,\n      \"min\": 5302.758,\n      \"avg\": 8202.217666666666,\n      \"last\": 10270.825,\n      \"last-5-avg\": 9248.948799999998,\n      \"last-10-avg\": 9201.6129\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 8.408,\n      \"min\": 5.409,\n      \"avg\": 6.959424242424243,\n      \"last\": 6.021,\n      \"last-5-avg\": 6.421199999999999,\n      \"last-10-avg\": 6.4052999999999995\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 33066,\n      \"min\": 10020,\n      \"avg\": 18400.363636363632,\n      \"last\": 33066,\n      \"last-5-avg\": 31062.0,\n      \"last-10-avg\": 28557.0\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 7689,\n      \"min\": 7,\n      \"avg\": 2800.4545454545446,\n      \"last\": 7689,\n      \"last-5-avg\": 7021.0,\n      \"last-10-avg\": 6186.0\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 3.2864890098571777,\n      \"min\": 1.156814694404602,\n      \"avg\": 1.9984515074527618,\n      \"last\": 1.353323221206665,\n      \"last-5-avg\": 1.2972617387771606,\n      \"last-10-avg\": 1.434236216545105\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 7689.0,\n      \"min\": 7.0,\n      \"avg\": 2800.4545454545446,\n      \"last\": 7689.0,\n      \"last-5-avg\": 7021.0,\n      \"last-10-avg\": 6186.0\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 7688.0,\n      \"min\": 6.0,\n      \"avg\": 2799.4545454545446,\n      \"last\": 7688.0,\n      \"last-5-avg\": 7020.0,\n      \"last-10-avg\": 6185.0\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 10.09823226928711,\n      \"min\": 7.748189926147461,\n      \"avg\": 9.475573366338555,\n      \"last\": 7.748189926147461,\n      \"last-5-avg\": 7.991802215576172,\n      \"last-10-avg\": 8.504152584075928\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": -4.580167293548584,\n      \"min\": -29.544424057006836,\n      \"avg\": -18.711959694371075,\n      \"last\": -28.348724365234375,\n      \"last-5-avg\": -28.976812744140624,\n      \"last-10-avg\": -29.164619064331056\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 2.294586420059204,\n      \"min\": 0.0571567639708519,\n      \"avg\": 0.8105104369196025,\n      \"last\": 0.0571567639708519,\n      \"last-5-avg\": 0.10931317657232284,\n      \"last-10-avg\": 0.14115701094269753\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": -0.018128670752048492,\n      \"min\": -17.404212951660156,\n      \"avg\": -7.314873385158451,\n      \"last\": -17.404212951660156,\n      \"last-5-avg\": -16.42570552825928,\n      \"last-10-avg\": -15.333701896667481\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041e8a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044eacd83d94869452942e\"\n      },\n      \"avg\": 0.5631139770601733,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243044eacd83d94869452942e\"\n      },\n      \"last-5-avg\": 0.12876650989055632,\n      \"last-10-avg\": 0.16800255328416824\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430493faebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430439c20fc094869452942e\"\n      },\n      \"avg\": -0.8275391220072793,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430439c20fc094869452942e\"\n      },\n      \"last-5-avg\": -2.058555841445923,\n      \"last-10-avg\": -1.8208290815353394\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.10912421345710754,\n      \"min\": 0.0021583351772278547,\n      \"avg\": 0.04330768765684104,\n      \"last\": 0.03609086945652962,\n      \"last-5-avg\": 0.06580119356513023,\n      \"last-10-avg\": 0.06367682963609696\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 29.043176651000977,\n      \"min\": 0.5254952907562256,\n      \"avg\": 16.565785090128582,\n      \"last\": 27.962879180908203,\n      \"last-5-avg\": 28.529638290405273,\n      \"last-10-avg\": 28.612049865722657\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 41.33992004394531,\n      \"min\": 0.9012696146965027,\n      \"avg\": 22.308325879501574,\n      \"last\": 40.63548278808594,\n      \"last-5-avg\": 40.13520736694336,\n      \"last-10-avg\": 38.608377075195314\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 22.114208221435547,\n      \"min\": 0.17365172505378723,\n      \"avg\": 11.482594459345844,\n      \"last\": 18.630765914916992,\n      \"last-5-avg\": 20.271973037719725,\n      \"last-10-avg\": 20.249417877197267\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ac8c70dafe266cc094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430887221bb86ffd64c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cac3ae82464168c094869452946807680d4308cac3ae82464168c094869452946807680d4308cac3ae82464168c094869452946807680d4308ac8c70dafe266cc094869452946807680d4308ac8c70dafe266cc094869452946807680d4308ac8c70dafe266cc094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430887221bb86ffd64c09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430828bcfa1755b771c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d43082b8507da4c7f70c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308308c9c91de9472c094869452946807680d4308308c9c91de9472c094869452946807680d4308308c9c91de9472c094869452946807680d430828bcfa1755b771c094869452946807680d430828bcfa1755b771c094869452946807680d430828bcfa1755b771c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d43082b8507da4c7f70c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a30e4951dd3b6fc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d43083b3c82e97ff26ac09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d86bfca7444770c094869452946807680d4308d86bfca7444770c094869452946807680d4308d86bfca7444770c094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d43083b3c82e97ff26ac09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b034b004b004b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b004b004b034b004b004b034b004b004b03652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034dea034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034dea034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1b4b1e4b1e4b1e4b21652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b184b184b184b1b4b1b4b1b4b1e4b1e4b1e4b21652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1d4b1e4b1f4b204b21652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b184b194b1a4b1b4b1c4b1d4b1e4b1f4b204b21652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404f5da3aa00000047404cfd02ac00000047404b29a20c00000047404c396a6400000047404eb723d6000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404dd25df600000047404e73465a00000047404e5d8dd400000047404d7172d200000047404d2aac4400000047404f5da3aa00000047404cfd02ac00000047404b29a20c00000047404c396a6400000047404eb723d6000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474091adedad10000047409295d5c27000004740936f22d2d0000047409450ee25f0000047409546a744a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474089ef31eb40000047408bd66650e0000047408dbc3f2e20000047408f93565b400000474090b3008fc00000474091adedad10000047409295d5c27000004740936f22d2d0000047409450ee25f0000047409546a744a00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474091adedad10000047409295d5c27000004740936f22d2d0000047409450ee25f0000047409546a744a00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474089ef31eb40000047408bd66650e0000047408dbc3f2e20000047408f93565b400000474090b3008fc00000474091adedad10000047409295d5c27000004740936f22d2d0000047409450ee25f0000047409546a744a00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b1d4b1e4b1f4b204b21652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b184b194b1a4b1b4b1c4b1d4b1e4b1f4b204b21652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e5478000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e54780000004740265e5478000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ac8c70dafe266cc094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430887221bb86ffd64c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cac3ae82464168c094869452946807680d4308cac3ae82464168c094869452946807680d4308cac3ae82464168c094869452946807680d4308ac8c70dafe266cc094869452946807680d4308ac8c70dafe266cc094869452946807680d4308ac8c70dafe266cc094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430821879e57f7fb6ac094869452946807680d430887221bb86ffd64c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430828bcfa1755b771c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d43082b8507da4c7f70c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308308c9c91de9472c094869452946807680d4308308c9c91de9472c094869452946807680d4308308c9c91de9472c094869452946807680d430828bcfa1755b771c094869452946807680d430828bcfa1755b771c094869452946807680d430828bcfa1755b771c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d4308121dcd3d9f5b70c094869452946807680d43082b8507da4c7f70c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a30e4951dd3b6fc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d43083b3c82e97ff26ac09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d86bfca7444770c094869452946807680d4308d86bfca7444770c094869452946807680d4308d86bfca7444770c094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308a30e4951dd3b6fc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d4308b04b9054bdfc6cc094869452946807680d43083b3c82e97ff26ac09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b034b004b004b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b004b004b034b004b004b034b004b004b03652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740662624dd2f1aa047406b6c51eb851eb847406381ba5e353f7d47406785f3b645a1cb4740633d6872b020c5652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740670970a3d70a3d47406731e353f7ced947406680f5c28f5c294740667d16872b020c47406699d2f1a9fbe74740662624dd2f1aa047406b6c51eb851eb847406381ba5e353f7d47406785f3b645a1cb4740633d6872b020c5652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004b12004a009913004a00e714004a003516004a008317004a00d118004a001f1a004a006d1b004a00bb1c004a00091e00652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a307c1687ad04a4094869452946807680d4308aef398bc377e474094869452946807680d43081be8b4814e1b454094869452946807680d430814616e5a784b464094869452946807680d4308a4a5a5a5a5e549409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ff04ec4fc0de484094869452946807680d4308710227700277494094869452946807680d43084bb9944bb994494094869452946807680d430891ef31adb6a3474094869452946807680d43086666666666b6474094869452946807680d4308a307c1687ad04a4094869452946807680d4308aef398bc377e474094869452946807680d43081be8b4814e1b454094869452946807680d430814616e5a784b464094869452946807680d4308a4a5a5a5a5e549409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080f073cfe7040564094869452946807680d43084b6a94b18a7e564094869452946807680d43082ace3e7c86fd564094869452946807680d43087b46961ed2e4564094869452946807680d43087b17b14ae41d57409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308dc90bc0dc97b554094869452946807680d4308a00eeaa00eca554094869452946807680d4308dbb66ddbb645564094869452946807680d43081cc7711cc751564094869452946807680d43085d8fc2f52854564094869452946807680d43080f073cfe7040564094869452946807680d43084b6a94b18a7e564094869452946807680d43082ace3e7c86fd564094869452946807680d43087b46961ed2e4564094869452946807680d43087b17b14ae41d57409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895891032f9a2f53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308318028f8e6b6f53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083e97433743a1f53f94869452946807680d43083e97433743a1f53f94869452946807680d43083e97433743a1f53f94869452946807680d430895891032f9a2f53f94869452946807680d430895891032f9a2f53f94869452946807680d430895891032f9a2f53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308318028f8e6b6f53f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086f61471aaba9034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d430894ad6208a3eb03409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308434a7387da8e034094869452946807680d4308434a7387da8e034094869452946807680d4308434a7387da8e034094869452946807680d43086f61471aaba9034094869452946807680d43086f61471aaba9034094869452946807680d43086f61471aaba9034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d430894ad6208a3eb03409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c639ec7b3a4fce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d430855731dd0f2a0ce3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e61e01f81434ce3f94869452946807680d4308e61e01f81434ce3f94869452946807680d4308e61e01f81434ce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d430855731dd0f2a0ce3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080eca1bf9945bd23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430809683354a49ed23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082858c6501f42d23f94869452946807680d43082858c6501f42d23f94869452946807680d43082858c6501f42d23f94869452946807680d43080eca1bf9945bd23f94869452946807680d43080eca1bf9945bd23f94869452946807680d43080eca1bf9945bd23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430809683354a49ed23f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430895891032f9a2f53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308318028f8e6b6f53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083e97433743a1f53f94869452946807680d43083e97433743a1f53f94869452946807680d43083e97433743a1f53f94869452946807680d430895891032f9a2f53f94869452946807680d430895891032f9a2f53f94869452946807680d430895891032f9a2f53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308bf567d2b0baff53f94869452946807680d4308318028f8e6b6f53f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243086f61471aaba9034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d430894ad6208a3eb03409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308434a7387da8e034094869452946807680d4308434a7387da8e034094869452946807680d4308434a7387da8e034094869452946807680d43086f61471aaba9034094869452946807680d43086f61471aaba9034094869452946807680d43086f61471aaba9034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d4308b0aca6fd8dd0034094869452946807680d430894ad6208a3eb03409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c639ec7b3a4fce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d430855731dd0f2a0ce3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e61e01f81434ce3f94869452946807680d4308e61e01f81434ce3f94869452946807680d4308e61e01f81434ce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d4308c639ec7b3a4fce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d43084d85e4bb7382ce3f94869452946807680d430855731dd0f2a0ce3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080eca1bf9945bd23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430809683354a49ed23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082858c6501f42d23f94869452946807680d43082858c6501f42d23f94869452946807680d43082858c6501f42d23f94869452946807680d43080eca1bf9945bd23f94869452946807680d43080eca1bf9945bd23f94869452946807680d43080eca1bf9945bd23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430852948c530e86d23f94869452946807680d430809683354a49ed23f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dd1184d1f1a4d6d1b4dbb1c4d091e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d4b124d99134de7144d35164d83174dd1184d1f1a4d6d1b4dbb1c4d091e652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fda7ef9db22d0e5473fd820c49ba5e354473fd29fbe76c8b439473fd8b4395810624e473fd2d0e560418937652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd3a5e353f7ced9473fd2e147ae147ae1473fd51eb851eb851f473fd570a3d70a3d71473fd8624dd2f1a9fc473fda7ef9db22d0e5473fd820c49ba5e354473fd29fbe76c8b439473fd8b4395810624e473fd2d0e560418937652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474122e142d89374bc474124b53170a3d70a47412acef845a1cac147412438dff5c28f5c47412a92dc6f9db22d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284741296b563ef9db2347412a787b95810625474127a5429d2f1aa04741274d71c83126e947412485b73df3b646474122e142d89374bc474124b53170a3d70a47412acef845a1cac147412438dff5c28f5c47412a92dc6f9db22d652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403bf70a3d70a3d7474040c7ef9db22d0e47403987ae147ae14847403bef1a9fbe76c9474038eccccccccccd652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ca45a1cac083147403cb374bc6a7efa47403b05a1cac0831247403c9cac083126e947403af7ced916872b47403bf70a3d70a3d7474040c7ef9db22d0e47403987ae147ae14847403bef1a9fbe76c9474038eccccccccccd652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c1e12d916872b04740bdcbafdf3b645a4740c395b083126e984740c1e63f9db22d0e4740c40f699999999a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c174fe560418934740c16bd978d4fdf44740c280e9fbe76c8b4740c179a3126e978d4740c28a4c6a7ef9db4740c1e12d916872b04740bdcbafdf3b645a4740c395b083126e984740c1e63f9db22d0e4740c40f699999999a652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740197ae147ae147b47401d04189374bc6a47401876c8b43958104740196147ae147ae147401815810624dd2f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401b872b020c49ba47401b3020c49ba5e34740183851eb851eb8474018d70a3d70a3d747401803126e978d504740197ae147ae147b47401d04189374bc6a47401876c8b43958104740196147ae147ae147401815810624dd2f652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d82714d6c754d56794d407d4d2a81652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284df05d4dda614dc4654dae694d986d4d82714d6c754d56794d407d4d2a81652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dd1184d1f1a4d6d1b4dbb1c4d091e652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d4b124d99134de7144d35164d83174dd1184d1f1a4d6d1b4dbb1c4d091e652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e04996f23f94869452946807680d43080000000010eff43f94869452946807680d430800000040a5dff53f94869452946807680d430800000040b6bbf43f94869452946807680d43080000004036a7f53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000ee31fa3f94869452946807680d4308000000005625f93f94869452946807680d4308000000c0dedef73f94869452946807680d4308000000a031aafb3f94869452946807680d4308000000c010d2f63f94869452946807680d4308000000e04996f23f94869452946807680d43080000000010eff43f94869452946807680d430800000040a5dff53f94869452946807680d430800000040b6bbf43f94869452946807680d43080000004036a7f53f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000d1b84094869452946807680d430800000000001fba4094869452946807680d430800000000006dbb4094869452946807680d43080000000000bbbc4094869452946807680d4308000000000009be409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000004bb24094869452946807680d4308000000000099b34094869452946807680d43080000000000e7b44094869452946807680d4308000000000035b64094869452946807680d4308000000000083b74094869452946807680d43080000000000d1b84094869452946807680d430800000000001fba4094869452946807680d430800000000006dbb4094869452946807680d43080000000000bbbc4094869452946807680d4308000000000009be409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000d0b84094869452946807680d430800000000001eba4094869452946807680d430800000000006cbb4094869452946807680d43080000000000babc4094869452946807680d4308000000000008be409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000004ab24094869452946807680d4308000000000098b34094869452946807680d43080000000000e6b44094869452946807680d4308000000000034b64094869452946807680d4308000000000082b74094869452946807680d43080000000000d0b84094869452946807680d430800000000001eba4094869452946807680d430800000000006cbb4094869452946807680d43080000000000babc4094869452946807680d4308000000000008be409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080d6a7204094869452946807680d4308000000c0630a204094869452946807680d430800000040e01e204094869452946807680d430800000080ac351f4094869452946807680d43080000008025fe1e409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000406f6e224094869452946807680d4308000000c03dad224094869452946807680d430800000060ca18224094869452946807680d4308000000e0ecbf214094869452946807680d430800000020db35214094869452946807680d430800000080d6a7204094869452946807680d4308000000c0630a204094869452946807680d430800000040e01e204094869452946807680d430800000080ac351f4094869452946807680d43080000008025fe1e409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0df7d3dc094869452946807680d430800000000234f3dc094869452946807680d430800000040b93e3dc094869452946807680d430800000020507d3cc094869452946807680d43080000000046593cc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000084443dc094869452946807680d4308000000a08c433dc094869452946807680d43080000008050593dc094869452946807680d4308000000405a563dc094869452946807680d4308000000605f8b3dc094869452946807680d4308000000a0df7d3dc094869452946807680d430800000000234f3dc094869452946807680d430800000040b93e3dc094869452946807680d430800000020507d3cc094869452946807680d43080000000046593cc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0e7afc03f94869452946807680d43080000004090b8be3f94869452946807680d430800000040700abf3f94869452946807680d4308000000801a27be3f94869452946807680d4308000000c0a643ad3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020921cc73f94869452946807680d430800000080157ac63f94869452946807680d43080000008025dec43f94869452946807680d4308000000805477c83f94869452946807680d4308000000c053ccc33f94869452946807680d4308000000c0e7afc03f94869452946807680d43080000004090b8be3f94869452946807680d430800000040700abf3f94869452946807680d4308000000801a27be3f94869452946807680d4308000000c0a643ad3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000401e272fc094869452946807680d430800000060e2842fc094869452946807680d4308000000006d9830c094869452946807680d430800000060ffca30c094869452946807680d4308000000807a6731c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004038a129c094869452946807680d4308000000c00ec72bc094869452946807680d4308000000c02da72cc094869452946807680d4308000000e00fcf2dc094869452946807680d4308000000c03a8c2ec094869452946807680d4308000000401e272fc094869452946807680d430800000060e2842fc094869452946807680d4308000000006d9830c094869452946807680d430800000060ffca30c094869452946807680d4308000000807a6731c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430417c21d3e94869452946807680d430490860f3e94869452946807680d4304d9a7023e94869452946807680d43046004ee3d94869452946807680d43044eacd83d9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ace97e3e94869452946807680d4304da68673e94869452946807680d43044f38523e94869452946807680d430438f63e3e94869452946807680d4304b98e2d3e94869452946807680d430417c21d3e94869452946807680d430490860f3e94869452946807680d4304d9a7023e94869452946807680d43046004ee3d94869452946807680d43044eacd83d9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048c69efbf94869452946807680d4304c083fbbf94869452946807680d430420c503c094869452946807680d4304e6be09c094869452946807680d430439c20fc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243048efdb1bf94869452946807680d4304475fbebf94869452946807680d430425aacabf94869452946807680d430487f6d6bf94869452946807680d4304fb31e3bf94869452946807680d43048c69efbf94869452946807680d4304c083fbbf94869452946807680d430420c503c094869452946807680d4304e6be09c094869452946807680d430439c20fc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008090efbb3f94869452946807680d430800000000255eae3f94869452946807680d4308000000606dccb13f94869452946807680d430800000000d722ac3f94869452946807680d4308000000a0807aa23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0bce7b13f94869452946807680d4308000000a0ba12ae3f94869452946807680d4308000000e07bffb73f94869452946807680d43080000000093cba53f94869452946807680d43080000000047e6a53f94869452946807680d43080000008090efbb3f94869452946807680d430800000000255eae3f94869452946807680d4308000000606dccb13f94869452946807680d430800000000d722ac3f94869452946807680d4308000000a0807aa23f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000073dd3c4094869452946807680d4308000000e047e63c4094869452946807680d430800000040addd3c4094869452946807680d430800000080080e3c4094869452946807680d4308000000407ff63b409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a077833c4094869452946807680d43080000000008883c4094869452946807680d4308000000802aaa3c4094869452946807680d43080000006031b83c4094869452946807680d4308000000a00d0b3d4094869452946807680d43080000000073dd3c4094869452946807680d4308000000e047e63c4094869452946807680d430800000040addd3c4094869452946807680d430800000080080e3c4094869452946807680d4308000000407ff63b409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080d013444094869452946807680d4308000000e0c592434094869452946807680d43080000008082ab444094869452946807680d43080000000018b3434094869452946807680d430800000080575144409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040c214424094869452946807680d43080000000001c9414094869452946807680d4308000000209277434094869452946807680d4308000000e0ef94424094869452946807680d430800000060ebc9424094869452946807680d430800000080d013444094869452946807680d4308000000e0c592434094869452946807680d43080000008082ab444094869452946807680d43080000000018b3434094869452946807680d430800000080575144409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000003975344094869452946807680d430800000080335c334094869452946807680d4308000000c03c1d364094869452946807680d430800000000fdcb344094869452946807680d4308000000e079a132409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e022fe344094869452946807680d430800000060c1e5344094869452946807680d43080000004071ba334094869452946807680d430800000020fc76334094869452946807680d4308000000c0100d344094869452946807680d4308000000003975344094869452946807680d430800000080335c334094869452946807680d4308000000c03c1d364094869452946807680d430800000000fdcb344094869452946807680d4308000000e079a132409486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1676030755.36199,\n  \"relative_logdir\": \"SAC_HalfCheetah-v3_45677_00000_0_2023-02-10_13-05-55\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"HalfCheetah_local\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 1361.6633477210999,
    "_iteration": 296,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1676030755.1110694,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-02-10_13-05-55",
    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_local/experiment_state-2023-02-10_13-05-55.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1676030755.1110694,
    "timestamp": 1676032178.9892817
  }
}