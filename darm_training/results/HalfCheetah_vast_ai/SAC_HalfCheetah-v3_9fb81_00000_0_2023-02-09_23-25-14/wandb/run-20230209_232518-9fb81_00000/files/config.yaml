wandb_version: 1

__stderr_file__:
  desc: null
  value: null
__stdout_file__:
  desc: null
  value: null
_deterministic_loss:
  desc: null
  value: false
_disable_action_flattening:
  desc: null
  value: false
_disable_execution_plan_api:
  desc: null
  value: true
_disable_preprocessor_api:
  desc: null
  value: false
_fake_gpus:
  desc: null
  value: false
_tf_policy_handles_more_than_one_loss:
  desc: null
  value: false
_use_beta_distribution:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    cli_version: 0.13.10
    framework: torch
    is_jupyter_run: true
    is_kaggle_kernel: false
    python_version: 3.8.12
    start_time: 1675981518.633458
    t:
      1:
      - 1
      - 30
      - 55
      2:
      - 1
      - 30
      - 55
      3:
      - 13
      - 14
      - 15
      - 16
      - 19
      - 23
      4: 3.8.12
      5: 0.13.10
      8:
      - 1
      - 8
      - 9
action_space:
  desc: null
  value: null
actions_in_input_normalized:
  desc: null
  value: false
actor_learning_rate:
  desc: null
  value: 0.0003
always_attach_evaluation_results:
  desc: null
  value: false
batch_mode:
  desc: null
  value: truncate_episodes
clip_actions:
  desc: null
  value: false
clip_rewards:
  desc: null
  value: null
compress_observations:
  desc: null
  value: false
create_env_on_driver:
  desc: null
  value: false
critic_learning_rate:
  desc: null
  value: 0.0003
custom_eval_function:
  desc: null
  value: null
custom_resources_per_worker:
  desc: null
  value: {}
date:
  desc: null
  value: 2023-02-09_23-27-01
disable_env_checking:
  desc: null
  value: false
eager_max_retraces:
  desc: null
  value: 20
eager_tracing:
  desc: null
  value: false
enable_async_evaluation:
  desc: null
  value: false
enable_connectors:
  desc: null
  value: false
enable_tf1_exec_eagerly:
  desc: null
  value: false
entropy_learning_rate:
  desc: null
  value: 0.0003
env:
  desc: null
  value: HalfCheetah-v3
env_config:
  desc: null
  value: {}
env_task_fn:
  desc: null
  value: null
evaluation_config:
  desc: null
  value: null
evaluation_duration:
  desc: null
  value: 10
evaluation_duration_unit:
  desc: null
  value: episodes
evaluation_interval:
  desc: null
  value: 100
evaluation_num_workers:
  desc: null
  value: 0
evaluation_parallel_to_training:
  desc: null
  value: false
evaluation_sample_timeout_s:
  desc: null
  value: 180.0
experiment_id:
  desc: null
  value: 359c2c77b76b4dd6977ec99c57b8d411
exploration_config:
  desc: null
  value:
    type: StochasticSampling
explore:
  desc: null
  value: true
export_native_model_files:
  desc: null
  value: false
extra_python_environs_for_driver:
  desc: null
  value: {}
extra_python_environs_for_worker:
  desc: null
  value: {}
fake_sampler:
  desc: null
  value: false
framework:
  desc: null
  value: torch
gamma:
  desc: null
  value: 0.99
grad_clip:
  desc: null
  value: null
horizon:
  desc: null
  value: null
hostname:
  desc: null
  value: Daniel
ignore_worker_failures:
  desc: null
  value: false
in_evaluation:
  desc: null
  value: false
initial_alpha:
  desc: null
  value: 1.0
input:
  desc: null
  value: sampler
input_config:
  desc: null
  value: {}
keep_per_episode_custom_metrics:
  desc: null
  value: false
local_tf_session_args:
  desc: null
  value:
    inter_op_parallelism_threads: 8
    intra_op_parallelism_threads: 8
log_level:
  desc: null
  value: WARN
log_sys_usage:
  desc: null
  value: true
logger_config:
  desc: null
  value: null
logger_creator:
  desc: null
  value: null
lr:
  desc: null
  value: 0.001
max_requests_in_flight_per_sampler_worker:
  desc: null
  value: 2
metrics_episode_collection_timeout_s:
  desc: null
  value: 60.0
metrics_num_episodes_for_smoothing:
  desc: null
  value: 5
min_sample_timesteps_per_iteration:
  desc: null
  value: 1000
min_time_s_per_iteration:
  desc: null
  value: 1
min_train_timesteps_per_iteration:
  desc: null
  value: 0
model:
  desc: null
  value:
    _disable_action_flattening: false
    _disable_preprocessor_api: false
    _time_major: false
    _use_default_native_models: false
    attention_dim: 64
    attention_head_dim: 32
    attention_init_gru_gate_bias: 2.0
    attention_memory_inference: 50
    attention_memory_training: 50
    attention_num_heads: 1
    attention_num_transformer_units: 1
    attention_position_wise_mlp_dim: 32
    attention_use_n_prev_actions: 0
    attention_use_n_prev_rewards: 0
    conv_activation: relu
    conv_filters: null
    custom_action_dist: null
    custom_model: null
    custom_model_config: {}
    custom_preprocessor: null
    dim: 84
    fcnet_activation: tanh
    fcnet_hiddens:
    - 256
    - 256
    framestack: true
    free_log_std: false
    grayscale: false
    lstm_cell_size: 256
    lstm_use_prev_action: false
    lstm_use_prev_action_reward: -1
    lstm_use_prev_reward: false
    max_seq_len: 20
    no_final_linear: false
    post_fcnet_activation: relu
    post_fcnet_hiddens: []
    use_attention: false
    use_lstm: false
    vf_share_layers: true
    zero_mean: true
multiagent:
  desc: null
  value:
    count_steps_by: env_steps
    observation_fn: null
    policies:
      default_policy: <ray.rllib.policy.policy.PolicySpec object at 0x7f4124334610>
    policies_to_train: null
    policy_map_cache: null
    policy_map_capacity: 100
    policy_mapping_fn: <function AlgorithmConfig.__init__.<locals>.<lambda> at 0x7f41243cad30>
n_step:
  desc: null
  value: 1
no_done_at_end:
  desc: null
  value: false
node_ip:
  desc: null
  value: 192.168.152.36
normalize_actions:
  desc: null
  value: true
num_consecutive_worker_failures_tolerance:
  desc: null
  value: 100
num_cpus_for_driver:
  desc: null
  value: 1
num_cpus_per_worker:
  desc: null
  value: 1
num_envs_per_worker:
  desc: null
  value: 1
num_gpu:
  desc: null
  value: 0
num_gpus:
  desc: null
  value: 0
num_gpus_per_worker:
  desc: null
  value: 0
num_rollout_workers:
  desc: null
  value: 3
num_steps_sampled_before_learning_starts:
  desc: null
  value: 10000
num_workers:
  desc: null
  value: 3
observation_filter:
  desc: null
  value: NoFilter
observation_space:
  desc: null
  value: null
off_policy_estimation_methods:
  desc: null
  value: {}
offline_sampling:
  desc: null
  value: false
ope_split_batch_by_episode:
  desc: null
  value: true
optimization:
  desc: null
  value:
    actor_learning_rate: 0.0003
    critic_learning_rate: 0.0003
    entropy_learning_rate: 0.0003
optimizer:
  desc: null
  value: {}
output:
  desc: null
  value: null
output_compress_columns:
  desc: null
  value:
  - obs
  - new_obs
output_config:
  desc: null
  value: {}
output_max_file_size:
  desc: null
  value: 67108864
pid:
  desc: null
  value: 5255
placement_strategy:
  desc: null
  value: PACK
policy_model_config:
  desc: null
  value:
    custom_model: null
    custom_model_config: {}
    fcnet_activation: relu
    fcnet_hiddens:
    - 256
    - 256
    post_fcnet_activation: null
    post_fcnet_hiddens: []
postprocess_inputs:
  desc: null
  value: false
preprocessor_pref:
  desc: null
  value: deepmind
q_model_config:
  desc: null
  value:
    custom_model: null
    custom_model_config: {}
    fcnet_activation: relu
    fcnet_hiddens:
    - 256
    - 256
    post_fcnet_activation: null
    post_fcnet_hiddens: []
recreate_failed_workers:
  desc: null
  value: false
remote_env_batch_wait_ms:
  desc: null
  value: 0
remote_worker_envs:
  desc: null
  value: false
render_env:
  desc: null
  value: false
replay_buffer_config:
  desc: null
  value:
    _enable_replay_buffer_api: true
    capacity: 1000000
    prioritized_replay: false
    prioritized_replay_alpha: 0.6
    prioritized_replay_beta: 0.4
    prioritized_replay_eps: 1.0e-06
    type: MultiAgentPrioritizedReplayBuffer
    worker_side_prioritization: false
replay_sequence_length:
  desc: null
  value: null
restart_failed_sub_environments:
  desc: null
  value: false
rollout_fragment_length:
  desc: null
  value: 1
sample_async:
  desc: null
  value: false
sample_collector:
  desc: null
  value: ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector
sampler_perf_stats_ema_coef:
  desc: null
  value: null
seed:
  desc: null
  value: null
shuffle_buffer_size:
  desc: null
  value: 0
simple_optimizer:
  desc: null
  value: false
soft_horizon:
  desc: null
  value: false
store_buffer_in_checkpoints:
  desc: null
  value: false
sync_filters_on_rollout_workers_timeout_s:
  desc: null
  value: 60.0
synchronize_filters:
  desc: null
  value: true
target_entropy:
  desc: null
  value: auto
target_network_update_freq:
  desc: null
  value: 1
tau:
  desc: null
  value: 0.005
tf_session_args:
  desc: null
  value:
    allow_soft_placement: true
    device_count:
      CPU: 1
    gpu_options:
      allow_growth: true
    inter_op_parallelism_threads: 2
    intra_op_parallelism_threads: 2
    log_device_placement: false
train_batch_size:
  desc: null
  value: 256
training_intensity:
  desc: null
  value: null
trial_id:
  desc: null
  value: 9fb81_00000
trial_log_path:
  desc: null
  value: /home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_vast_ai/SAC_HalfCheetah-v3_9fb81_00000_0_2023-02-09_23-25-14
twin_q:
  desc: null
  value: true
use_state_preprocessor:
  desc: null
  value: -1
validate_workers_after_construction:
  desc: null
  value: true
worker_cls:
  desc: null
  value: null
worker_side_prioritization:
  desc: null
  value: -1
