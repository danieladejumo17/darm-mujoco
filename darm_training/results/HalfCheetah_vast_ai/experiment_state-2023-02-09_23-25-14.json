{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"9fb81_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"HalfCheetah-v3\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_vast_ai\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 3000,\n    \"episode_reward_mean\": 150\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 10.07202434539795,\n            \"actor_loss\": -9.025458335876465,\n            \"critic_loss\": 0.2415330410003662,\n            \"alpha_loss\": -1.027607798576355,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304692b673f94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcf2d0bd94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n            },\n            \"policy_t\": 0.04645523428916931,\n            \"mean_q\": 5.41398286819458,\n            \"max_q\": 11.071789741516113,\n            \"min_q\": 1.4648659229278564\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 1.7262011766433716,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 341.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 340.0\n        }\n      },\n      \"num_env_steps_sampled\": 11022,\n      \"num_env_steps_trained\": 87296,\n      \"num_agent_steps_sampled\": 11022,\n      \"num_agent_steps_trained\": 87296,\n      \"last_target_update_ts\": 11022,\n      \"num_target_updates\": 341\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -233.99772775695823,\n      \"episode_reward_min\": -340.8995194641167,\n      \"episode_reward_mean\": -292.9808384674325,\n      \"episode_len_mean\": 1000.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 0,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -321.0240325291854,\n          -297.97974884848054,\n          -271.00316373842156,\n          -340.8995194641167,\n          -233.99772775695823\n        ],\n        \"episode_lengths\": [\n          1000,\n          1000,\n          1000,\n          1000,\n          1000\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.4851522110455198,\n        \"mean_inference_ms\": 2.506559229549628,\n        \"mean_action_processing_ms\": 0.2388331049747872,\n        \"mean_env_wait_ms\": 0.29935671098171135,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -233.99772775695823,\n    \"episode_reward_min\": -340.8995194641167,\n    \"episode_reward_mean\": -292.9808384674325,\n    \"episode_len_mean\": 1000.0,\n    \"episodes_this_iter\": 0,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -321.0240325291854,\n        -297.97974884848054,\n        -271.00316373842156,\n        -340.8995194641167,\n        -233.99772775695823\n      ],\n      \"episode_lengths\": [\n        1000,\n        1000,\n        1000,\n        1000,\n        1000\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.4851522110455198,\n      \"mean_inference_ms\": 2.506559229549628,\n      \"mean_action_processing_ms\": 0.2388331049747872,\n      \"mean_env_wait_ms\": 0.29935671098171135,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 11022,\n    \"num_agent_steps_trained\": 87296,\n    \"num_env_steps_sampled\": 11022,\n    \"num_env_steps_trained\": 87296,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 11022,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 11022,\n    \"timers\": {\n      \"training_iteration_time_ms\": 170.46,\n      \"load_time_ms\": 0.284,\n      \"load_throughput\": 902455.727,\n      \"learn_time_ms\": 26.165,\n      \"learn_throughput\": 9784.193,\n      \"synch_weights_time_ms\": 5.59\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 11022,\n      \"num_env_steps_trained\": 87296,\n      \"num_agent_steps_sampled\": 11022,\n      \"num_agent_steps_trained\": 87296,\n      \"last_target_update_ts\": 11022,\n      \"num_target_updates\": 341\n    },\n    \"done\": false,\n    \"episodes_total\": 9,\n    \"training_iteration\": 11,\n    \"trial_id\": \"9fb81_00000\",\n    \"experiment_id\": \"359c2c77b76b4dd6977ec99c57b8d411\",\n    \"date\": \"2023-02-09_23-27-01\",\n    \"timestamp\": 1675981621,\n    \"time_this_iter_s\": 54.45015358924866,\n    \"time_total_s\": 93.1621904373169,\n    \"pid\": 5255,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"HalfCheetah-v3\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 93.1621904373169,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 11,\n    \"warmup_time\": 9.499566316604614,\n    \"perf\": {\n      \"cpu_util_percent\": 42.11200000000001,\n      \"ram_util_percent\": 60.25200000000002\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1675981621.909131,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": -207.128532707221,\n      \"min\": -233.99772775695823,\n      \"avg\": NaN,\n      \"last\": -233.99772775695823,\n      \"last-5-avg\": -223.25004973706336,\n      \"last-10-avg\": NaN\n    },\n    \"episode_reward_min\": {\n      \"max\": -267.65659239306837,\n      \"min\": -340.8995194641167,\n      \"avg\": NaN,\n      \"last\": -340.8995194641167,\n      \"last-5-avg\": -332.9493246901441,\n      \"last-10-avg\": NaN\n    },\n    \"episode_reward_mean\": {\n      \"max\": -237.5544262135841,\n      \"min\": -292.9808384674325,\n      \"avg\": NaN,\n      \"last\": -292.9808384674325,\n      \"last-5-avg\": -288.8486975556351,\n      \"last-10-avg\": NaN\n    },\n    \"episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": NaN\n    },\n    \"episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.8181818181818182,\n      \"last\": 0,\n      \"last-5-avg\": 0.6,\n      \"last-10-avg\": 0.9\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3.0,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1002,\n      \"avg\": 1002.0,\n      \"last\": 1002,\n      \"last-5-avg\": 1002.0,\n      \"last-10-avg\": 1002.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 7936.0,\n      \"last\": 85504,\n      \"last-5-avg\": 17459.2,\n      \"last-10-avg\": 8729.6\n    },\n    \"timesteps_total\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 7936.0,\n      \"last\": 85504,\n      \"last-5-avg\": 17459.2,\n      \"last-10-avg\": 8729.6\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 9,\n      \"min\": 0,\n      \"avg\": 4.909090909090909,\n      \"last\": 9,\n      \"last-5-avg\": 7.8,\n      \"last-10-avg\": 5.4\n    },\n    \"training_iteration\": {\n      \"max\": 11,\n      \"min\": 1,\n      \"avg\": 6.0,\n      \"last\": 11,\n      \"last-5-avg\": 9.0,\n      \"last-10-avg\": 6.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 54.45015358924866,\n      \"min\": 2.937443494796753,\n      \"avg\": 8.469290039756082,\n      \"last\": 54.45015358924866,\n      \"last-5-avg\": 14.460501289367675,\n      \"last-10-avg\": 8.939828419685364\n    },\n    \"time_total_s\": {\n      \"max\": 93.1621904373169,\n      \"min\": 3.763906240463257,\n      \"avg\": 26.77064631202004,\n      \"last\": 93.1621904373169,\n      \"last-5-avg\": 44.57782979011536,\n      \"last-10-avg\": 29.07132031917572\n    },\n    \"time_since_restore\": {\n      \"max\": 93.1621904373169,\n      \"min\": 3.763906240463257,\n      \"avg\": 26.77064631202004,\n      \"last\": 93.1621904373169,\n      \"last-5-avg\": 44.57782979011536,\n      \"last-10-avg\": 29.07132031917572\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 11,\n      \"min\": 1,\n      \"avg\": 6.0,\n      \"last\": 11,\n      \"last-5-avg\": 9.0,\n      \"last-10-avg\": 6.5\n    },\n    \"warmup_time\": {\n      \"max\": 9.499566316604614,\n      \"min\": 9.499566316604614,\n      \"avg\": 9.499566316604614,\n      \"last\": 9.499566316604614,\n      \"last-5-avg\": 9.499566316604614,\n      \"last-10-avg\": 9.499566316604614\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": -207.128532707221,\n      \"min\": -233.99772775695823,\n      \"avg\": NaN,\n      \"last\": -233.99772775695823,\n      \"last-5-avg\": -223.25004973706336,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -267.65659239306837,\n      \"min\": -340.8995194641167,\n      \"avg\": NaN,\n      \"last\": -340.8995194641167,\n      \"last-5-avg\": -332.9493246901441,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -237.5544262135841,\n      \"min\": -292.9808384674325,\n      \"avg\": NaN,\n      \"last\": -292.9808384674325,\n      \"last-5-avg\": -288.8486975556351,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 1000.0,\n      \"min\": 1000.0,\n      \"avg\": NaN,\n      \"last\": 1000.0,\n      \"last-5-avg\": 1000.0,\n      \"last-10-avg\": NaN\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 3,\n      \"min\": 0,\n      \"avg\": 0.8181818181818182,\n      \"last\": 0,\n      \"last-5-avg\": 0.6,\n      \"last-10-avg\": 0.9\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 170.46,\n      \"min\": 8.488,\n      \"avg\": 34.55463636363636,\n      \"last\": 170.46,\n      \"last-5-avg\": 63.962,\n      \"last-10-avg\": 36.911500000000004\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 11022,\n      \"min\": 1002,\n      \"avg\": 6012.0,\n      \"last\": 11022,\n      \"last-5-avg\": 9018.0,\n      \"last-10-avg\": 6513.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 87296,\n      \"min\": 0,\n      \"avg\": 8098.909090909091,\n      \"last\": 87296,\n      \"last-5-avg\": 17817.6,\n      \"last-10-avg\": 8908.8\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 84.6,\n      \"min\": 42.11200000000001,\n      \"avg\": 65.66749783549784,\n      \"last\": 42.11200000000001,\n      \"last-5-avg\": 65.87116190476192,\n      \"last-10-avg\": 65.78758095238095\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 60.25200000000002,\n      \"min\": 55.15,\n      \"avg\": 56.964770562770575,\n      \"last\": 60.25200000000002,\n      \"last-5-avg\": 58.80249523809524,\n      \"last-10-avg\": 57.13124761904762\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.4851522110455198,\n      \"min\": 1.357218639998786,\n      \"avg\": 1.4035173712772866,\n      \"last\": 1.4851522110455198,\n      \"last-5-avg\": 1.4507101600832668,\n      \"last-10-avg\": 1.4138059782280645\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.506559229549628,\n      \"min\": 2.2267540969417596,\n      \"avg\": 2.324516645101207,\n      \"last\": 2.506559229549628,\n      \"last-5-avg\": 2.4261001940971902,\n      \"last-10-avg\": 2.346241655803306\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2388331049747872,\n      \"min\": 0.22318316440956268,\n      \"avg\": 0.22828692400433487,\n      \"last\": 0.2388331049747872,\n      \"last-5-avg\": 0.23379866659494017,\n      \"last-10-avg\": 0.22942109280317316\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.29935671098171135,\n      \"min\": 0.2716187426084377,\n      \"avg\": 0.28103927784914057,\n      \"last\": 0.29935671098171135,\n      \"last-5-avg\": 0.2909831213027899,\n      \"last-10-avg\": 0.2831327301248523\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.4851522110455198,\n      \"min\": 1.357218639998786,\n      \"avg\": 1.4035173712772866,\n      \"last\": 1.4851522110455198,\n      \"last-5-avg\": 1.4507101600832668,\n      \"last-10-avg\": 1.4138059782280645\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.506559229549628,\n      \"min\": 2.2267540969417596,\n      \"avg\": 2.324516645101207,\n      \"last\": 2.506559229549628,\n      \"last-5-avg\": 2.4261001940971902,\n      \"last-10-avg\": 2.346241655803306\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2388331049747872,\n      \"min\": 0.22318316440956268,\n      \"avg\": 0.22828692400433487,\n      \"last\": 0.2388331049747872,\n      \"last-5-avg\": 0.23379866659494017,\n      \"last-10-avg\": 0.22942109280317316\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 0.29935671098171135,\n      \"min\": 0.2716187426084377,\n      \"avg\": 0.28103927784914057,\n      \"last\": 0.29935671098171135,\n      \"last-5-avg\": 0.2909831213027899,\n      \"last-10-avg\": 0.2831327301248523\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 11022,\n      \"min\": 10020,\n      \"avg\": 10111.09090909091,\n      \"last\": 11022,\n      \"last-5-avg\": 10521.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"info/num_target_updates\": {\n      \"max\": 341,\n      \"min\": 7,\n      \"avg\": 37.36363636363637,\n      \"last\": 341,\n      \"last-5-avg\": 174.0,\n      \"last-10-avg\": 174.0\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.304,\n      \"min\": 0.284,\n      \"avg\": 0.30218181818181816,\n      \"last\": 0.284,\n      \"last-5-avg\": 0.294,\n      \"last-10-avg\": 0.294\n    },\n    \"timers/load_throughput\": {\n      \"max\": 902455.727,\n      \"min\": 841773.185,\n      \"avg\": 847289.7797272729,\n      \"last\": 902455.727,\n      \"last-5-avg\": 872114.456,\n      \"last-10-avg\": 872114.456\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 30.888,\n      \"min\": 26.165,\n      \"avg\": 30.458636363636366,\n      \"last\": 26.165,\n      \"last-5-avg\": 28.5265,\n      \"last-10-avg\": 28.5265\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 9784.193,\n      \"min\": 8287.932,\n      \"avg\": 8423.955727272729,\n      \"last\": 9784.193,\n      \"last-5-avg\": 9036.0625,\n      \"last-10-avg\": 9036.0625\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 6.391,\n      \"min\": 5.59,\n      \"avg\": 6.318181818181818,\n      \"last\": 5.59,\n      \"last-5-avg\": 5.9905,\n      \"last-10-avg\": 5.9905\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 11022,\n      \"min\": 10020,\n      \"avg\": 10111.09090909091,\n      \"last\": 11022,\n      \"last-5-avg\": 10521.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 341,\n      \"min\": 7,\n      \"avg\": 37.36363636363637,\n      \"last\": 341,\n      \"last-5-avg\": 174.0,\n      \"last-10-avg\": 174.0\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 3.1768412590026855,\n      \"min\": 1.7262011766433716,\n      \"avg\": 3.044964887879112,\n      \"last\": 1.7262011766433716,\n      \"last-5-avg\": 2.4515212178230286,\n      \"last-10-avg\": 2.4515212178230286\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 341.0,\n      \"min\": 7.0,\n      \"avg\": 37.36363636363637,\n      \"last\": 341.0,\n      \"last-5-avg\": 174.0,\n      \"last-10-avg\": 174.0\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 340.0,\n      \"min\": 6.0,\n      \"avg\": 36.36363636363637,\n      \"last\": 340.0,\n      \"last-5-avg\": 173.0,\n      \"last-10-avg\": 173.0\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 10.07524585723877,\n      \"min\": 10.07202434539795,\n      \"avg\": 10.074952992525969,\n      \"last\": 10.07202434539795,\n      \"last-5-avg\": 10.07363510131836,\n      \"last-10-avg\": 10.07363510131836\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": -4.5863142013549805,\n      \"min\": -9.025458335876465,\n      \"avg\": -4.989872759038752,\n      \"last\": -9.025458335876465,\n      \"last-5-avg\": -6.805886268615723,\n      \"last-10-avg\": -6.805886268615723\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 1.549490213394165,\n      \"min\": 0.2415330410003662,\n      \"avg\": 1.4305850159038198,\n      \"last\": 0.2415330410003662,\n      \"last-5-avg\": 0.8955116271972656,\n      \"last-10-avg\": 0.8955116271972656\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": -0.01813848502933979,\n      \"min\": -1.027607798576355,\n      \"avg\": -0.109908422624523,\n      \"last\": -1.027607798576355,\n      \"last-5-avg\": -0.5228731418028474,\n      \"last-10-avg\": -0.5228731418028474\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041f8a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304692b673f94869452942e\"\n      },\n      \"avg\": 0.9895472038875927,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304692b673f94869452942e\"\n      },\n      \"last-5-avg\": 0.950603723526001,\n      \"last-10-avg\": 0.950603723526001\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041bf8ebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcf2d0bd94869452942e\"\n      },\n      \"avg\": -0.010911724932322448,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304fcf2d0bd94869452942e\"\n      },\n      \"last-5-avg\": -0.05191312887473032,\n      \"last-10-avg\": -0.05191312887473032\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"avg\": -6.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452942e\"\n      },\n      \"last-5-avg\": -6.0,\n      \"last-10-avg\": -6.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.04645523428916931,\n      \"min\": 0.008360075764358044,\n      \"avg\": 0.011823271993886341,\n      \"last\": 0.04645523428916931,\n      \"last-5-avg\": 0.027407655026763678,\n      \"last-10-avg\": 0.027407655026763678\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 5.41398286819458,\n      \"min\": 0.5474985241889954,\n      \"avg\": 0.9899061918258667,\n      \"last\": 5.41398286819458,\n      \"last-5-avg\": 2.9807406961917877,\n      \"last-10-avg\": 2.9807406961917877\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 11.071789741516113,\n      \"min\": 1.01040780544281,\n      \"avg\": 1.925078890540383,\n      \"last\": 11.071789741516113,\n      \"last-5-avg\": 6.041098773479462,\n      \"last-10-avg\": 6.041098773479462\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 1.4648659229278564,\n      \"min\": 0.1603139340877533,\n      \"avg\": 0.2789095694368536,\n      \"last\": 1.4648659229278564,\n      \"last-5-avg\": 0.8125899285078049,\n      \"last-10-avg\": 0.8125899285078049\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f70066781ba70c094869452946807680d43087f70066781ba70c094869452946807680d43087f70066781ba70c094869452946807680d430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871ec0adcbdb16dc094869452946807680d430871ec0adcbdb16dc094869452946807680d430871ec0adcbdb16dc094869452946807680d43082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b034b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b034b004b004b034b004b004b034b004b00652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034dea034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034dea034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b064b064b094b094b09652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b034b034b034b064b064b064b094b094b09652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b074b084b094b0a4b0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b024b034b044b054b064b074b084b094b0a4b0b652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740122f5ca00000004740172b34d0000000474009b3aa400000004740113468a000000047404b399ea2000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847400aa328400000004740077fe26000000047400875ad2000000047400d4d79e00000004740106efac00000004740122f5ca00000004740172b34d0000000474009b3aa400000004740113468a000000047404b399ea2000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403967eb6800000047403f32b89c0000004740413496f20000004740435b24060000004740574a6154000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401c5fd1900000004740240fe16000000047402a2d4ca8000000474030c05590000000474034dc144000000047403967eb6800000047403f32b89c0000004740413496f20000004740435b24060000004740574a6154000000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403967eb6800000047403f32b89c0000004740413496f20000004740435b24060000004740574a6154000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401c5fd1900000004740240fe16000000047402a2d4ca8000000474030c05590000000474034dc144000000047403967eb6800000047403f32b89c0000004740413496f20000004740435b24060000004740574a6154000000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b074b084b094b0a4b0b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b024b034b044b054b064b074b084b094b0a4b0b652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000474022ffc728000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d430861bf9ff01ce469c094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc094869452946807680d43084ecec262ed3f6dc09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087f70066781ba70c094869452946807680d43087f70066781ba70c094869452946807680d43087f70066781ba70c094869452946807680d430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d430843eeee6f621074c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c094869452946807680d4308f287856e644e75c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430871ec0adcbdb16dc094869452946807680d430871ec0adcbdb16dc094869452946807680d430871ec0adcbdb16dc094869452946807680d43082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43082b7b346468aa71c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c094869452946807680d43088044ad83b14f72c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952b010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428477ff80000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f4094869452946807680d43080000000000408f409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b034b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b034b004b004b034b004b004b034b004b00652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847402bf9db22d0e560474021f851eb851eb8474021ee147ae147ae47405d5a5e353f7cee4740654eb851eb851f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402121cac083126f4740218083126e978d474020f9db22d0e5604740252353f7ced917474029dcac083126e947402bf9db22d0e560474021f851eb851eb8474021ee147ae147ae47405d5a5e353f7cee4740654eb851eb851f652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d661b4d501f4d3a234d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dd4074dbe0b4da80f4d92134d7c174d661b4d501f4d3a234d24274d0e2b652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059530000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004d00074a00550100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953a000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004d00074a00550100652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d5411dd4419d534094869452946807680d4308666666666626554094869452946807680d430814ae47e17a14504094869452946807680d4308f0eeeeeeeeee4d4094869452946807680d430876931804560e45409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f6285c8fc2b54f4094869452946807680d43083333333333134e4094869452946807680d43080000000000a04e4094869452946807680d43086666666666e6504094869452946807680d4308666666666606534094869452946807680d4308d5411dd4419d534094869452946807680d4308666666666626554094869452946807680d430814ae47e17a14504094869452946807680d4308f0eeeeeeeeee4d4094869452946807680d430876931804560e45409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308421dd4411d944c4094869452946807680d43089a99999999594d4094869452946807680d43088ec2f5285c8f4d4094869452946807680d43084544444444644d4094869452946807680d4308c94b378941204e409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a99999999994b4094869452946807680d43089a99999999994b4094869452946807680d43083333333333934b4094869452946807680d43083333333333b34b4094869452946807680d4308cccccccccc2c4c4094869452946807680d4308421dd4411d944c4094869452946807680d43089a99999999594d4094869452946807680d43088ec2f5285c8f4d4094869452946807680d43084544444444644d4094869452946807680d4308c94b378941204e409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e80f85e42ab7f53f94869452946807680d4308e80f85e42ab7f53f94869452946807680d4308e80f85e42ab7f53f94869452946807680d430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d04409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087dcab47364d0014094869452946807680d43087dcab47364d0014094869452946807680d43087dcab47364d0014094869452946807680d43089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d04409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308151414144491cc3f94869452946807680d4308151414144491cc3f94869452946807680d4308151414144491cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ebf71e943362d13f94869452946807680d4308ebf71e943362d13f94869452946807680d4308ebf71e943362d13f94869452946807680d430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e80f85e42ab7f53f94869452946807680d4308e80f85e42ab7f53f94869452946807680d4308e80f85e42ab7f53f94869452946807680d430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d430886c2dc317f62f63f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f94869452946807680d43088f5c00f72ec3f73f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d04409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243087dcab47364d0014094869452946807680d43087dcab47364d0014094869452946807680d43087dcab47364d0014094869452946807680d43089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43089a808ca87b71024094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d044094869452946807680d43088b38e3ec6e0d04409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308151414144491cc3f94869452946807680d4308151414144491cc3f94869452946807680d4308151414144491cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d43089b5b4a78a9f5cc3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f94869452946807680d4308f2cf884b1592ce3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ebf71e943362d13f94869452946807680d4308ebf71e943362d13f94869452946807680d4308ebf71e943362d13f94869452946807680d430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d430813eb3c99add1d13f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f94869452946807680d4308f24ae00ca928d33f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059522010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b074d5501652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d5501652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd374bc6a7ef9db473fd22d0e56041893652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd374bc6a7ef9db473fd22d0e56041893652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474129b05a5eb851ec47412b8a6f74395810652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474129b05a5eb851ec47412b8a6f74395810652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847403ee353f7ced91747403a2a3d70a3d70a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403ee353f7ced91747403a2a3d70a3d70a652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c02ff74bc6a7f04740c31c18b4395810652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c02ff74bc6a7f04740c31c18b4395810652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401990624dd2f1aa4740165c28f5c28f5c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401990624dd2f1aa4740165c28f5c28f5c652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d24274d0e2b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059528000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b074d5501652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d5501652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c02b6a094094869452946807680d430800000020859efb3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c02b6a094094869452946807680d430800000020859efb3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000001c4094869452946807680d430800000000005075409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000001c4094869452946807680d430800000000005075409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000184094869452946807680d430800000000004075409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000184094869452946807680d430800000000004075409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a08626244094869452946807680d430800000060e02424409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a08626244094869452946807680d430800000060e02424409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0625812c094869452946807680d4308000000e0080d22c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0625812c094869452946807680d4308000000e0080d22c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040b6caf83f94869452946807680d4308000000008eeace3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040b6caf83f94869452946807680d4308000000008eeace3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020e59292bf94869452946807680d4308000000e01471f0bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020e59292bf94869452946807680d4308000000e01471f0bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041f8a7f3f94869452946807680d4304692b673f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041f8a7f3f94869452946807680d4304692b673f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041bf8ebba94869452946807680d4304fcf2d0bd9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041bf8ebba94869452946807680d4304fcf2d0bd9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059595000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000c0c094869452946807680d43040000c0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060161f813f94869452946807680d430800000000fbc8a73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060161f813f94869452946807680d430800000000fbc8a73f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a01b85e13f94869452946807680d430800000020eba715409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a01b85e13f94869452946807680d430800000020eba715409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060a12af03f94869452946807680d4308000000a0c12426409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060a12af03f94869452946807680d4308000000a0c12426409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c02a85c43f94869452946807680d4308000000401770f73f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005959d000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c02a85c43f94869452946807680d4308000000401770f73f9486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1675981514.7551544,\n  \"relative_logdir\": \"SAC_HalfCheetah-v3_9fb81_00000_0_2023-02-09_23-25-14\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"HalfCheetah_vast_ai\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 93.1621904373169,
    "_iteration": 34,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_vast_ai",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1675981514.508904,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-02-09_23-25-14",
    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/HalfCheetah_vast_ai/experiment_state-2023-02-09_23-25-14.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1675981514.508904,
    "timestamp": 1675981677.0104299
  }
}