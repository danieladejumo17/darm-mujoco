{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"80340_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"darm/DarmSFHand-v0\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10000\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 8.438075065612793,\n            \"actor_loss\": -6.517789363861084,\n            \"critic_loss\": 0.6616898775100708,\n            \"alpha_loss\": -4.246946334838867,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430458c21a3f94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c1d800bf94869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n            },\n            \"policy_t\": -0.005959862377494574,\n            \"mean_q\": 4.486087322235107,\n            \"max_q\": 5.304399013519287,\n            \"min_q\": 3.3463962078094482\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 12.24126148223877,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 1677.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 1676.0\n        }\n      },\n      \"num_env_steps_sampled\": 15030,\n      \"num_env_steps_trained\": 429312,\n      \"num_agent_steps_sampled\": 15030,\n      \"num_agent_steps_trained\": 429312,\n      \"last_target_update_ts\": 15030,\n      \"num_target_updates\": 1677\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -167.4954197704792,\n      \"episode_reward_min\": -191.98499378561974,\n      \"episode_reward_mean\": -184.26235711947083,\n      \"episode_len_mean\": 100.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 12,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -168.570613399148,\n          -191.98499378561974,\n          -187.01995192468166,\n          -186.29515251517296,\n          -187.99071127176285,\n          -190.23062424361706,\n          -185.3246492445469,\n          -167.4954197704792,\n          -185.65701182186604,\n          -189.5101600587368,\n          -181.4457355439663,\n          -189.62326185405254\n        ],\n        \"episode_lengths\": [\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.2540615208410804,\n        \"mean_inference_ms\": 2.3901244801516417,\n        \"mean_action_processing_ms\": 0.23206122611594004,\n        \"mean_env_wait_ms\": 3.0908723684125796,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -167.4954197704792,\n    \"episode_reward_min\": -191.98499378561974,\n    \"episode_reward_mean\": -184.26235711947083,\n    \"episode_len_mean\": 100.0,\n    \"episodes_this_iter\": 12,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -168.570613399148,\n        -191.98499378561974,\n        -187.01995192468166,\n        -186.29515251517296,\n        -187.99071127176285,\n        -190.23062424361706,\n        -185.3246492445469,\n        -167.4954197704792,\n        -185.65701182186604,\n        -189.5101600587368,\n        -181.4457355439663,\n        -189.62326185405254\n      ],\n      \"episode_lengths\": [\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.2540615208410804,\n      \"mean_inference_ms\": 2.3901244801516417,\n      \"mean_action_processing_ms\": 0.23206122611594004,\n      \"mean_env_wait_ms\": 3.0908723684125796,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 0,\n    \"num_agent_steps_sampled\": 15030,\n    \"num_agent_steps_trained\": 429312,\n    \"num_env_steps_sampled\": 15030,\n    \"num_env_steps_trained\": 429312,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 15030,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 15030,\n    \"timers\": {\n      \"training_iteration_time_ms\": 153.463,\n      \"load_time_ms\": 0.265,\n      \"load_throughput\": 967858.143,\n      \"learn_time_ms\": 24.791,\n      \"learn_throughput\": 10326.337,\n      \"synch_weights_time_ms\": 5.938\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 15030,\n      \"num_env_steps_trained\": 429312,\n      \"num_agent_steps_sampled\": 15030,\n      \"num_agent_steps_trained\": 429312,\n      \"last_target_update_ts\": 15030,\n      \"num_target_updates\": 1677\n    },\n    \"done\": false,\n    \"episodes_total\": 154,\n    \"training_iteration\": 15,\n    \"trial_id\": \"80340_00000\",\n    \"experiment_id\": \"4d5d6cddaea7444681811f5901f7f828\",\n    \"date\": \"2023-02-09_14-40-13\",\n    \"timestamp\": 1675950013,\n    \"time_this_iter_s\": 55.12917709350586,\n    \"time_total_s\": 322.3778626918793,\n    \"pid\": 27220,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"darm/DarmSFHand-v0\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 322.3778626918793,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 15,\n    \"warmup_time\": 8.03538990020752,\n    \"perf\": {\n      \"cpu_util_percent\": 44.62894736842105,\n      \"ram_util_percent\": 86.69868421052634\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1675950014.0460618,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": 216.8899323642254,\n      \"min\": -178.81081108748913,\n      \"avg\": 7.91901637117068,\n      \"last\": -167.4954197704792,\n      \"last-5-avg\": -25.228183555603028,\n      \"last-10-avg\": 61.51932683214545\n    },\n    \"episode_reward_min\": {\n      \"max\": -188.52998483181,\n      \"min\": -196.0045984685421,\n      \"avg\": -192.2586578339338,\n      \"last\": -191.98499378561974,\n      \"last-5-avg\": -192.17592669278383,\n      \"last-10-avg\": -192.40880938619375\n    },\n    \"episode_reward_mean\": {\n      \"max\": -116.5225211687386,\n      \"min\": -188.20978297458754,\n      \"avg\": -164.6815068223914,\n      \"last\": -184.26235711947083,\n      \"last-5-avg\": -170.34278751042154,\n      \"last-10-avg\": -161.39485942305754\n    },\n    \"episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 91.6,\n      \"avg\": 97.25393939393939,\n      \"last\": 100.0,\n      \"last-5-avg\": 97.51,\n      \"last-10-avg\": 96.72090909090909\n    },\n    \"episodes_this_iter\": {\n      \"max\": 12,\n      \"min\": 9,\n      \"avg\": 10.266666666666666,\n      \"last\": 12,\n      \"last-5-avg\": 10.4,\n      \"last-10-avg\": 10.5\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 3.0,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1002,\n      \"avg\": 1002.0,\n      \"last\": 1002,\n      \"last-5-avg\": 1002.0,\n      \"last-10-avg\": 1002.0\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 28620.799999999996,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 42931.2\n    },\n    \"timesteps_total\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 85504,\n      \"min\": 0,\n      \"avg\": 28620.799999999996,\n      \"last\": 85504,\n      \"last-5-avg\": 85504.0,\n      \"last-10-avg\": 42931.2\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 154,\n      \"min\": 9,\n      \"avg\": 81.2,\n      \"last\": 154,\n      \"last-5-avg\": 133.0,\n      \"last-10-avg\": 107.2\n    },\n    \"training_iteration\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 61.66024971008301,\n      \"min\": 3.8648064136505127,\n      \"avg\": 21.491857512791952,\n      \"last\": 55.12917709350586,\n      \"last-5-avg\": 55.52769575119019,\n      \"last-10-avg\": 29.883503794670105\n    },\n    \"time_total_s\": {\n      \"max\": 322.3778626918793,\n      \"min\": 5.359312057495117,\n      \"avg\": 86.18368782997132,\n      \"last\": 322.3778626918793,\n      \"last-5-avg\": 208.17378988265992,\n      \"last-10-avg\": 122.08286399841309\n    },\n    \"time_since_restore\": {\n      \"max\": 322.3778626918793,\n      \"min\": 5.359312057495117,\n      \"avg\": 86.18368782997132,\n      \"last\": 322.3778626918793,\n      \"last-5-avg\": 208.17378988265992,\n      \"last-10-avg\": 122.08286399841309\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 15,\n      \"min\": 1,\n      \"avg\": 8.0,\n      \"last\": 15,\n      \"last-5-avg\": 13.0,\n      \"last-10-avg\": 10.5\n    },\n    \"warmup_time\": {\n      \"max\": 8.03538990020752,\n      \"min\": 8.03538990020752,\n      \"avg\": 8.03538990020752,\n      \"last\": 8.03538990020752,\n      \"last-5-avg\": 8.03538990020752,\n      \"last-10-avg\": 8.03538990020752\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": 216.8899323642254,\n      \"min\": -178.81081108748913,\n      \"avg\": 7.91901637117068,\n      \"last\": -167.4954197704792,\n      \"last-5-avg\": -25.228183555603028,\n      \"last-10-avg\": 61.51932683214545\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -188.52998483181,\n      \"min\": -196.0045984685421,\n      \"avg\": -192.2586578339338,\n      \"last\": -191.98499378561974,\n      \"last-5-avg\": -192.17592669278383,\n      \"last-10-avg\": -192.40880938619375\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -116.5225211687386,\n      \"min\": -188.20978297458754,\n      \"avg\": -164.6815068223914,\n      \"last\": -184.26235711947083,\n      \"last-5-avg\": -170.34278751042154,\n      \"last-10-avg\": -161.39485942305754\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 91.6,\n      \"avg\": 97.25393939393939,\n      \"last\": 100.0,\n      \"last-5-avg\": 97.51,\n      \"last-10-avg\": 96.72090909090909\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 12,\n      \"min\": 9,\n      \"avg\": 10.266666666666666,\n      \"last\": 12,\n      \"last-5-avg\": 10.4,\n      \"last-10-avg\": 10.5\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.2485003268254837,\n      \"avg\": 1.3025507636851499,\n      \"last\": 1.2540615208410804,\n      \"last-5-avg\": 1.2550467988738303,\n      \"last-10-avg\": 1.2748085744819877\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.406503849649475,\n      \"last\": 2.3901244801516417,\n      \"last-5-avg\": 2.3514309768691453,\n      \"last-10-avg\": 2.360428079400535\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22676882362765344,\n      \"avg\": 0.2371802038322465,\n      \"last\": 0.23206122611594004,\n      \"last-5-avg\": 0.2296218730852599,\n      \"last-10-avg\": 0.2315817788272036\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 3.0715565853129996,\n      \"avg\": 3.2085516561757905,\n      \"last\": 3.0908723684125796,\n      \"last-5-avg\": 3.086195384611492,\n      \"last-10-avg\": 3.1312474086851596\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 158.074,\n      \"min\": 11.428,\n      \"avg\": 66.54686666666666,\n      \"last\": 153.463,\n      \"last-5-avg\": 151.9248,\n      \"last-10-avg\": 91.74680000000001\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 15030,\n      \"min\": 1002,\n      \"avg\": 8016.0,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 10521.0\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 429312,\n      \"min\": 0,\n      \"avg\": 86220.8,\n      \"last\": 429312,\n      \"last-5-avg\": 258304.0,\n      \"last-10-avg\": 129331.2\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 77.2875,\n      \"min\": 41.026760563380286,\n      \"avg\": 59.295564305532345,\n      \"last\": 44.62894736842105,\n      \"last-5-avg\": 45.25207386897796,\n      \"last-10-avg\": 53.71912026782231\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 87.08588235294118,\n      \"min\": 81.83333333333333,\n      \"avg\": 83.09985082229576,\n      \"last\": 86.69868421052634,\n      \"last-5-avg\": 84.81776675260159,\n      \"last-10-avg\": 83.5976333763008\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.2485003268254837,\n      \"avg\": 1.3025507636851499,\n      \"last\": 1.2540615208410804,\n      \"last-5-avg\": 1.2550467988738303,\n      \"last-10-avg\": 1.2748085744819877\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.406503849649475,\n      \"last\": 2.3901244801516417,\n      \"last-5-avg\": 2.3514309768691453,\n      \"last-10-avg\": 2.360428079400535\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22676882362765344,\n      \"avg\": 0.2371802038322465,\n      \"last\": 0.23206122611594004,\n      \"last-5-avg\": 0.2296218730852599,\n      \"last-10-avg\": 0.2315817788272036\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 3.0715565853129996,\n      \"avg\": 3.2085516561757905,\n      \"last\": 3.0908723684125796,\n      \"last-5-avg\": 3.086195384611492,\n      \"last-10-avg\": 3.1312474086851596\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 15030,\n      \"min\": 10020,\n      \"avg\": 11021.999999999998,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 12525.0\n    },\n    \"info/num_target_updates\": {\n      \"max\": 1677,\n      \"min\": 7,\n      \"avg\": 341.0,\n      \"last\": 1677,\n      \"last-5-avg\": 1009.0,\n      \"last-10-avg\": 842.0\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.312,\n      \"min\": 0.252,\n      \"avg\": 0.26206666666666667,\n      \"last\": 0.265,\n      \"last-5-avg\": 0.2782,\n      \"last-10-avg\": 0.27416666666666667\n    },\n    \"timers/load_throughput\": {\n      \"max\": 1014112.036,\n      \"min\": 821468.766,\n      \"avg\": 980910.2227333332,\n      \"last\": 967858.143,\n      \"last-5-avg\": 925502.3362,\n      \"last-10-avg\": 939354.3078333334\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 27.281,\n      \"min\": 24.088,\n      \"avg\": 26.511666666666663,\n      \"last\": 24.791,\n      \"last-5-avg\": 24.973,\n      \"last-10-avg\": 25.35766666666667\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 10627.877,\n      \"min\": 9383.851,\n      \"avg\": 9677.191666666666,\n      \"last\": 10326.337,\n      \"last-5-avg\": 10263.873,\n      \"last-10-avg\": 10117.202666666666\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 6.972,\n      \"min\": 5.172,\n      \"avg\": 6.603799999999998,\n      \"last\": 5.938,\n      \"last-5-avg\": 5.867399999999999,\n      \"last-10-avg\": 6.0515\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 15030,\n      \"min\": 10020,\n      \"avg\": 11021.999999999998,\n      \"last\": 15030,\n      \"last-5-avg\": 13026.0,\n      \"last-10-avg\": 12525.0\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 1677,\n      \"min\": 7,\n      \"avg\": 341.0,\n      \"last\": 1677,\n      \"last-5-avg\": 1009.0,\n      \"last-10-avg\": 842.0\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 16.14298439025879,\n      \"min\": 1.4600703716278076,\n      \"avg\": 4.655125331878662,\n      \"last\": 12.24126148223877,\n      \"last-5-avg\": 11.04523525238037,\n      \"last-10-avg\": 9.447707772254944\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 256.0,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 1677.0,\n      \"min\": 7.0,\n      \"avg\": 341.0,\n      \"last\": 1677.0,\n      \"last-5-avg\": 1009.0,\n      \"last-10-avg\": 842.0\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 1676.0,\n      \"min\": 6.0,\n      \"avg\": 340.0,\n      \"last\": 1676.0,\n      \"last-5-avg\": 1008.0,\n      \"last-10-avg\": 841.0\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 8.438075065612793,\n      \"min\": 8.365665435791016,\n      \"avg\": 8.380664380391437,\n      \"last\": 8.438075065612793,\n      \"last-5-avg\": 8.410662269592285,\n      \"last-10-avg\": 8.403162797292074\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": -3.411156177520752,\n      \"min\": -6.580883979797363,\n      \"avg\": -4.274615287780762,\n      \"last\": -6.517789363861084,\n      \"last-5-avg\": -6.001533508300781,\n      \"last-10-avg\": -5.569803953170776\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 0.847157895565033,\n      \"min\": 0.2495899796485901,\n      \"avg\": 0.3647812604904175,\n      \"last\": 0.6616898775100708,\n      \"last-5-avg\": 0.5951638221740723,\n      \"last-10-avg\": 0.5375681817531586\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": -0.015058223158121109,\n      \"min\": -4.246946334838867,\n      \"avg\": -0.8587450886766116,\n      \"last\": -4.246946334838867,\n      \"last-5-avg\": -2.5461188197135924,\n      \"last-10-avg\": -2.124275386954347\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304248a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430458c21a3f94869452942e\"\n      },\n      \"avg\": 0.9142458319664,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430458c21a3f94869452942e\"\n      },\n      \"last-5-avg\": 0.7463342785835266,\n      \"last-10-avg\": 0.788312166929245\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415eeebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c1d800bf94869452942e\"\n      },\n      \"avg\": -0.10207642330788076,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304c1d800bf94869452942e\"\n      },\n      \"last-5-avg\": -0.30262926369905474,\n      \"last-10-avg\": -0.25249105360126123\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"avg\": -5.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"last-5-avg\": -5.0,\n      \"last-10-avg\": -5.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.020382240414619446,\n      \"min\": -0.03436039388179779,\n      \"avg\": 0.00938143721432425,\n      \"last\": -0.005959862377494574,\n      \"last-5-avg\": -0.012620169186266138,\n      \"last-10-avg\": -0.007119767586118542\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 4.486087322235107,\n      \"min\": 0.06157306209206581,\n      \"avg\": 1.2092273458838463,\n      \"last\": 4.486087322235107,\n      \"last-5-avg\": 3.5045359134674072,\n      \"last-10-avg\": 2.930708771571517\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 5.304399013519287,\n      \"min\": 0.09083694219589233,\n      \"avg\": 1.467417804400126,\n      \"last\": 5.304399013519287,\n      \"last-5-avg\": 4.220579528808594,\n      \"last-10-avg\": 3.5322890977064767\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 3.575044631958008,\n      \"min\": 0.00958795566111803,\n      \"avg\": 0.8720239481578269,\n      \"last\": 3.3463962078094482,\n      \"last-5-avg\": 2.596895933151245,\n      \"last-10-avg\": 2.1656779369028905\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000070537a1c6b4094869452946807680d43080000a860a569644094869452946807680d43080000b8074c6365c094869452946807680d43080000d0977bf764c094869452946807680d43080000907adaef64c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b886f275614094869452946807680d43080000d4f33a8d684094869452946807680d43080000c0150d556a4094869452946807680d430800007081e379534094869452946807680d4308000010ac0a2b5d4094869452946807680d4308000070537a1c6b4094869452946807680d43080000a860a569644094869452946807680d43080000b8074c6365c094869452946807680d43080000d0977bf764c094869452946807680d43080000907adaef64c09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000d0ab0f1768c094869452946807680d43080000c87cc8af67c094869452946807680d43080000f05da93068c094869452946807680d43080000dc5c1f2568c094869452946807680d43080000b01185ff67c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b0ab258068c094869452946807680d43080000f07524c967c094869452946807680d43080000f800a7a767c094869452946807680d4308000040c06c5a68c094869452946807680d430800004cd24d1b68c094869452946807680d43080000d0ab0f1768c094869452946807680d43080000c87cc8af67c094869452946807680d43080000f05da93068c094869452946807680d43080000dc5c1f2568c094869452946807680d43080000b01185ff67c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9947cbb83762c094869452946807680d43080000c841965863c094869452946807680d4308721c4302b52267c094869452946807680d430800007c496fbb66c094869452946807680d43080000c23a650867c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaa0143249e63c094869452946807680d4308cdccbaae9efc61c094869452946807680d430833334d30eefc61c094869452946807680d4308bae86276076364c094869452946807680d430866664cb6c94c63c094869452946807680d43089a9947cbb83762c094869452946807680d43080000c841965863c094869452946807680d4308721c4302b52267c094869452946807680d430800007c496fbb66c094869452946807680d43080000c23a650867c09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333333f3564094869452946807680d43080000000000f0574094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000030584094869452946807680d43089a9999999959574094869452946807680d4308333333333313574094869452946807680d4308bae8a28b2efa584094869452946807680d4308333333333353584094869452946807680d43083333333333f3564094869452946807680d43080000000000f0574094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0a4b0c4b094b094b0c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0c4b0a4b0a4b0b4b0a4b0a4b0c4b094b094b0c652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034dea034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034dea034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a004e01004a004e01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b704b7c4b854b8e4b9a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b3d4b474b514b5c4b664b704b7c4b854b8e4b9a652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474049fdc63c00000047404a1ae06600000047404c54071a00000047404ed4831000000047404b9088e0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740118441b000000047400fb50aa000000047400eeb1fa000000047400f4cf1800000004740144e7740000000474049fdc63c00000047404a1ae06600000047404c54071a00000047404ed4831000000047404b9088e0000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740582e352f0000004740629dd2b1000000474069b2d477800000474070b3fa9dc00000474074260bb9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bec06fc00000047403fe2a850000000474041e00622000000474043d4d53a0000004740465ea4220000004740582e352f0000004740629dd2b1000000474069b2d477800000474070b3fa9dc00000474074260bb9c00000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740582e352f0000004740629dd2b1000000474069b2d477800000474070b3fa9dc00000474074260bb9c00000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403bec06fc00000047403fe2a850000000474041e00622000000474043d4d53a0000004740465ea4220000004740582e352f0000004740629dd2b1000000474069b2d477800000474070b3fa9dc00000474074260bb9c00000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b0c4b0d4b0e4b0f652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b064b074b084b094b0a4b0b4b0c4b0d4b0e4b0f652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000070537a1c6b4094869452946807680d43080000a860a569644094869452946807680d43080000b8074c6365c094869452946807680d43080000d0977bf764c094869452946807680d43080000907adaef64c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b886f275614094869452946807680d43080000d4f33a8d684094869452946807680d43080000c0150d556a4094869452946807680d430800007081e379534094869452946807680d4308000010ac0a2b5d4094869452946807680d4308000070537a1c6b4094869452946807680d43080000a860a569644094869452946807680d43080000b8074c6365c094869452946807680d43080000d0977bf764c094869452946807680d43080000907adaef64c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000d0ab0f1768c094869452946807680d43080000c87cc8af67c094869452946807680d43080000f05da93068c094869452946807680d43080000dc5c1f2568c094869452946807680d43080000b01185ff67c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b0ab258068c094869452946807680d43080000f07524c967c094869452946807680d43080000f800a7a767c094869452946807680d4308000040c06c5a68c094869452946807680d430800004cd24d1b68c094869452946807680d43080000d0ab0f1768c094869452946807680d43080000c87cc8af67c094869452946807680d43080000f05da93068c094869452946807680d43080000dc5c1f2568c094869452946807680d43080000b01185ff67c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243089a9947cbb83762c094869452946807680d43080000c841965863c094869452946807680d4308721c4302b52267c094869452946807680d430800007c496fbb66c094869452946807680d43080000c23a650867c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308abaa0143249e63c094869452946807680d4308cdccbaae9efc61c094869452946807680d430833334d30eefc61c094869452946807680d4308bae86276076364c094869452946807680d430866664cb6c94c63c094869452946807680d43089a9947cbb83762c094869452946807680d43080000c841965863c094869452946807680d4308721c4302b52267c094869452946807680d430800007c496fbb66c094869452946807680d43080000c23a650867c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083333333333f3564094869452946807680d43080000000000f0574094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000030584094869452946807680d43089a9999999959574094869452946807680d4308333333333313574094869452946807680d4308bae8a28b2efa584094869452946807680d4308333333333353584094869452946807680d43083333333333f3564094869452946807680d43080000000000f0574094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0a4b0c4b094b094b0c652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0c4b0a4b0a4b0b4b0a4b0a4b0c4b094b094b0c652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861b3a316b438f43f94869452946807680d43088c17aa0b0e07f43f94869452946807680d4308172c8c7adbf9f33f94869452946807680d43084817bc551b1df43f94869452946807680d43088ff332d0a210f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d46acef27947f53f94869452946807680d430855ea817f9aecf43f94869452946807680d4308c419a369539cf43f94869452946807680d43089495ba049373f43f94869452946807680d43086ba8921ed24cf43f94869452946807680d430861b3a316b438f43f94869452946807680d43088c17aa0b0e07f43f94869452946807680d4308172c8c7adbf9f33f94869452946807680d43084817bc551b1df43f94869452946807680d43088ff332d0a210f43f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430845637d680f91024094869452946807680d430817a722ac4093024094869452946807680d4308827b8a1878c4024094869452946807680d4308ecafca75e506034094869452946807680d430861f65c95f91e03409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ef08d2c78cad034094869452946807680d43082be623689f33034094869452946807680d4308a6dae52022d8024094869452946807680d43084c1fe4092e9d024094869452946807680d43088ebf2c986d70024094869452946807680d430845637d680f91024094869452946807680d430817a722ac4093024094869452946807680d4308827b8a1878c4024094869452946807680d4308ecafca75e506034094869452946807680d430861f65c95f91e03409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ef5a1b1be32cd3f94869452946807680d4308c895198a581dcd3f94869452946807680d43089e0ca639e259cd3f94869452946807680d4308a58f914a1797cd3f94869452946807680d430840376ba82eb4cd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088dda8f34a30ccf3f94869452946807680d4308aee8a6f9fd62ce3f94869452946807680d4308f591cc28b6b1cd3f94869452946807680d4308c440101c5e4fcd3f94869452946807680d43084ed89dc4c206cd3f94869452946807680d43088ef5a1b1be32cd3f94869452946807680d4308c895198a581dcd3f94869452946807680d43089e0ca639e259cd3f94869452946807680d4308a58f914a1797cd3f94869452946807680d430840376ba82eb4cd3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eade80b2c7bd084094869452946807680d4308b5dc4d428c92084094869452946807680d4308333ad635eba1084094869452946807680d43082967f69149c6084094869452946807680d43086889d34a1bba08409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a8467c682c210a4094869452946807680d4308a66e0f7179ac094094869452946807680d4308fff63d09b551094094869452946807680d4308202c2f8ddd12094094869452946807680d43085d4197f215db084094869452946807680d4308eade80b2c7bd084094869452946807680d4308b5dc4d428c92084094869452946807680d4308333ad635eba1084094869452946807680d43082967f69149c6084094869452946807680d43086889d34a1bba08409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474062cfef9db22d0e474062614fdf3b645a474062d189374bc6a8474063c25e353f7cee4740632ed0e5604189652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847402850e5604189374740296e978d4fdf3b474026fdf3b645a1cb474026db22d0e5604247405b82f1a9fbe76d474062cfef9db22d0e474062614fdf3b645a474062d189374bc6a8474063c25e353f7cee4740632ed0e5604189652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d7c174d661b4d501f4d3a234d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059546000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004d00074a005501004a00a302004a00f103004a003f05004a008d0600652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083b45e0e36c83444094869452946807680d4308842dd8822d90444094869452946807680d43084f52a38c55b4474094869452946807680d43084aaf157ce2084a4094869452946807680d43080823ed58815046409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308565555555575504094869452946807680d43081111111111714f4094869452946807680d43082322222222c24e4094869452946807680d4308ae47e17a14ee4e4094869452946807680d430834333333336b4d4094869452946807680d43083b45e0e36c83444094869452946807680d4308842dd8822d90444094869452946807680d43084f52a38c55b4474094869452946807680d43084aaf157ce2084a4094869452946807680d43080823ed58815046409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308f8ed524fc6af544094869452946807680d4308711cc7711cbb544094869452946807680d4308fac6075c9628554094869452946807680d4308e64bb2187fc5554094869452946807680d43084d9cfa3db7ac55409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308676666666696544094869452946807680d4308999999999999544094869452946807680d43080000000000a0544094869452946807680d43080000000000a0544094869452946807680d4308cdcccccccc88544094869452946807680d4308f8ed524fc6af544094869452946807680d4308711cc7711cbb544094869452946807680d4308fac6075c9628554094869452946807680d4308e64bb2187fc5554094869452946807680d43084d9cfa3db7ac55409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430861b3a316b438f43f94869452946807680d43088c17aa0b0e07f43f94869452946807680d4308172c8c7adbf9f33f94869452946807680d43084817bc551b1df43f94869452946807680d43088ff332d0a210f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308d46acef27947f53f94869452946807680d430855ea817f9aecf43f94869452946807680d4308c419a369539cf43f94869452946807680d43089495ba049373f43f94869452946807680d43086ba8921ed24cf43f94869452946807680d430861b3a316b438f43f94869452946807680d43088c17aa0b0e07f43f94869452946807680d4308172c8c7adbf9f33f94869452946807680d43084817bc551b1df43f94869452946807680d43088ff332d0a210f43f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430845637d680f91024094869452946807680d430817a722ac4093024094869452946807680d4308827b8a1878c4024094869452946807680d4308ecafca75e506034094869452946807680d430861f65c95f91e03409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308ef08d2c78cad034094869452946807680d43082be623689f33034094869452946807680d4308a6dae52022d8024094869452946807680d43084c1fe4092e9d024094869452946807680d43088ebf2c986d70024094869452946807680d430845637d680f91024094869452946807680d430817a722ac4093024094869452946807680d4308827b8a1878c4024094869452946807680d4308ecafca75e506034094869452946807680d430861f65c95f91e03409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088ef5a1b1be32cd3f94869452946807680d4308c895198a581dcd3f94869452946807680d43089e0ca639e259cd3f94869452946807680d4308a58f914a1797cd3f94869452946807680d430840376ba82eb4cd3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243088dda8f34a30ccf3f94869452946807680d4308aee8a6f9fd62ce3f94869452946807680d4308f591cc28b6b1cd3f94869452946807680d4308c440101c5e4fcd3f94869452946807680d43084ed89dc4c206cd3f94869452946807680d43088ef5a1b1be32cd3f94869452946807680d4308c895198a581dcd3f94869452946807680d43089e0ca639e259cd3f94869452946807680d4308a58f914a1797cd3f94869452946807680d430840376ba82eb4cd3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308eade80b2c7bd084094869452946807680d4308b5dc4d428c92084094869452946807680d4308333ad635eba1084094869452946807680d43082967f69149c6084094869452946807680d43086889d34a1bba08409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a8467c682c210a4094869452946807680d4308a66e0f7179ac094094869452946807680d4308fff63d09b551094094869452946807680d4308202c2f8ddd12094094869452946807680d43085d4197f215db084094869452946807680d4308eade80b2c7bd084094869452946807680d4308b5dc4d428c92084094869452946807680d4308333ad635eba1084094869452946807680d43082967f69149c6084094869452946807680d43086889d34a1bba08409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d55014da3024df1034d3f054d8d06652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059533000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d55014da3024df1034d3f054d8d06652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd29fbe76c8b439473fd020c49ba5e354473fd15810624dd2f2473fd3f7ced916872b473fd0f5c28f5c28f6652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd04189374bc6a8473fd29fbe76c8b439473fd020c49ba5e354473fd15810624dd2f2473fd3f7ced916872b473fd0f5c28f5c28f6652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847412adfdb0c49ba5e47412ef2c0126e978d47412ccab66c8b439647412911b9883126e947412d896449374bc7652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847412ec7cc54fdf3b647412adfdb0c49ba5e47412ef2c0126e978d47412ccab66c8b439647412911b9883126e947412d896449374bc7652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474038fd2f1a9fbe7747403816872b020c4a474038578d4fdf3b6447403aa7ae147ae148474038ca7ef9db22d1652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403b47ef9db22d0e474038fd2f1a9fbe7747403816872b020c4a474038578d4fdf3b6447403aa7ae147ae148474038ca7ef9db22d1652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c40236872b020c4740c4c1f04189374c4740c48a54dd2f1aa04740c2c207ef9db22d4740c42b2b22d0e560652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c253eced9168734740c40236872b020c4740c4c1f04189374c4740c48a54dd2f1aa04740c2c207ef9db22d4740c42b2b22d0e560652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847401778d4fdf3b646474014b020c49ba5e3474019de353f7ced91474017916872b020c5474017c083126e978d652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059558000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847401be353f7ced91747401778d4fdf3b646474014b020c49ba5e3474019de353f7ced91474017916872b020c5474017c083126e978d652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d0e2b4df82e4de2324dcc364db63a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059534000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d24274d0e2b4df82e4de2324dcc364db63a652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d55014da3024df1034d3f054d8d06652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059533000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b074d55014da3024df1034d3f054d8d06652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a09a24304094869452946807680d430800000000c3a0204094869452946807680d4308000000c0d15e244094869452946807680d4308000000c07caf204094869452946807680d4308000000a0867b28409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0725cf73f94869452946807680d4308000000a09a24304094869452946807680d430800000000c3a0204094869452946807680d4308000000c0d15e244094869452946807680d4308000000c07caf204094869452946807680d4308000000a0867b28409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000050754094869452946807680d4308000000000018854094869452946807680d43080000000000888f4094869452946807680d43080000000000fc944094869452946807680d43080000000000349a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000000001c4094869452946807680d4308000000000050754094869452946807680d4308000000000018854094869452946807680d43080000000000888f4094869452946807680d43080000000000fc944094869452946807680d43080000000000349a409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000040754094869452946807680d4308000000000010854094869452946807680d43080000000000808f4094869452946807680d43080000000000f8944094869452946807680d43080000000000309a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000184094869452946807680d4308000000000040754094869452946807680d4308000000000010854094869452946807680d43080000000000808f4094869452946807680d43080000000000f8944094869452946807680d43080000000000309a409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000006033cc204094869452946807680d430800000080c5dd204094869452946807680d430800000040dcc6204094869452946807680d4308000000202bca204094869452946807680d4308000000604be020409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008038bb204094869452946807680d43080000006033cc204094869452946807680d430800000080c5dd204094869452946807680d430800000040dcc6204094869452946807680d4308000000202bca204094869452946807680d4308000000604be020409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000002d1b14c094869452946807680d4308000000c012d616c094869452946807680d4308000000a08fb118c094869452946807680d430800000040d3521ac094869452946807680d43080000006037121ac09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000400c4a0bc094869452946807680d4308000000002d1b14c094869452946807680d4308000000c012d616c094869452946807680d4308000000a08fb118c094869452946807680d430800000040d3521ac094869452946807680d43080000006037121ac09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0ea1beb3f94869452946807680d43080000008002f9dd3f94869452946807680d4308000000c01265e13f94869452946807680d4308000000c0b31fdd3f94869452946807680d430800000040902ce53f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008090f2cf3f94869452946807680d4308000000e0ea1beb3f94869452946807680d43080000008002f9dd3f94869452946807680d4308000000c01265e13f94869452946807680d4308000000c0b31fdd3f94869452946807680d430800000040902ce53f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000206168ebbf94869452946807680d4308000000606448fbbf94869452946807680d4308000000406d4f04c094869452946807680d430800000000cb100bc094869452946807680d430800000080dffc10c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080d8d68ebf94869452946807680d4308000000206168ebbf94869452946807680d4308000000606448fbbf94869452946807680d4308000000406d4f04c094869452946807680d430800000000cb100bc094869452946807680d430800000080dffc10c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304472e673f94869452946807680d43047b22513f94869452946807680d430495253d3f94869452946807680d430422162b3f94869452946807680d430458c21a3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304248a7f3f94869452946807680d4304472e673f94869452946807680d43047b22513f94869452946807680d430495253d3f94869452946807680d430422162b3f94869452946807680d430458c21a3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430495d9d0bd94869452946807680d43043e0d4fbe94869452946807680d430477f59abe94869452946807680d43042057cebe94869452946807680d4304c1d800bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415eeebba94869452946807680d430495d9d0bd94869452946807680d43043e0d4fbe94869452946807680d430477f59abe94869452946807680d43042057cebe94869452946807680d4304c1d800bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d1000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000c0a4d06dbf94869452946807680d4308000000a0894c32bf94869452946807680d4308000000c0845093bf94869452946807680d430800000080af97a1bf94869452946807680d4308000000605e6978bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000000015df943f94869452946807680d4308000000c0a4d06dbf94869452946807680d4308000000a0894c32bf94869452946807680d4308000000c0845093bf94869452946807680d430800000080af97a1bf94869452946807680d4308000000605e6978bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000020e935004094869452946807680d4308000000001ea6074094869452946807680d43080000008008b20d4094869452946807680d4308000000a0705e114094869452946807680d4308000000e0c0f111409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000208186af3f94869452946807680d430800000020e935004094869452946807680d4308000000001ea6074094869452946807680d43080000008008b20d4094869452946807680d4308000000a0705e114094869452946807680d4308000000e0c0f111409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e04aea054094869452946807680d4308000000e0d0350c4094869452946807680d4308000000801c81114094869452946807680d4308000000407fa0144094869452946807680d430800000060b43715409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000001741b73f94869452946807680d4308000000e04aea054094869452946807680d4308000000e0d0350c4094869452946807680d4308000000801c81114094869452946807680d4308000000407fa0144094869452946807680d430800000060b43715409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000801b93e83f94869452946807680d430800000040b5d1024094869452946807680d4308000000609e8a074094869452946807680d430800000000b1990c4094869452946807680d4308000000606bc50a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595e9000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0d9a2833f94869452946807680d4308000000801b93e83f94869452946807680d430800000040b5d1024094869452946807680d4308000000609e8a074094869452946807680d430800000000b1990c4094869452946807680d4308000000606bc50a409486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1675949679.1124773,\n  \"relative_logdir\": \"SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"Test_DARMSF_DELTA_TARGET\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 322.3778626918793,
    "_iteration": 80,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1675949678.8755546,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-02-09_14-34-38",
    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1675949678.8755546,
    "timestamp": 1675950044.114155
  }
}