{
  "checkpoints": [
    "{\n  \"stub\": false,\n  \"trainable_name\": \"SAC\",\n  \"trial_id\": \"80340_00000\",\n  \"config\": {\n    \"extra_python_environs_for_driver\": {},\n    \"extra_python_environs_for_worker\": {},\n    \"num_gpus\": 0,\n    \"num_cpus_per_worker\": 1,\n    \"num_gpus_per_worker\": 0,\n    \"_fake_gpus\": false,\n    \"custom_resources_per_worker\": {},\n    \"placement_strategy\": \"PACK\",\n    \"eager_tracing\": false,\n    \"eager_max_retraces\": 20,\n    \"tf_session_args\": {\n      \"intra_op_parallelism_threads\": 2,\n      \"inter_op_parallelism_threads\": 2,\n      \"gpu_options\": {\n        \"allow_growth\": true\n      },\n      \"log_device_placement\": false,\n      \"device_count\": {\n        \"CPU\": 1\n      },\n      \"allow_soft_placement\": true\n    },\n    \"local_tf_session_args\": {\n      \"intra_op_parallelism_threads\": 8,\n      \"inter_op_parallelism_threads\": 8\n    },\n    \"env\": \"darm/DarmSFHand-v0\",\n    \"env_config\": {},\n    \"observation_space\": null,\n    \"action_space\": null,\n    \"env_task_fn\": null,\n    \"render_env\": false,\n    \"clip_rewards\": null,\n    \"normalize_actions\": true,\n    \"clip_actions\": false,\n    \"disable_env_checking\": false,\n    \"num_envs_per_worker\": 1,\n    \"sample_collector\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n    },\n    \"sample_async\": false,\n    \"enable_connectors\": false,\n    \"rollout_fragment_length\": 1,\n    \"batch_mode\": \"truncate_episodes\",\n    \"remote_worker_envs\": false,\n    \"remote_env_batch_wait_ms\": 0,\n    \"validate_workers_after_construction\": true,\n    \"ignore_worker_failures\": false,\n    \"recreate_failed_workers\": false,\n    \"restart_failed_sub_environments\": false,\n    \"num_consecutive_worker_failures_tolerance\": 100,\n    \"horizon\": null,\n    \"soft_horizon\": false,\n    \"no_done_at_end\": false,\n    \"preprocessor_pref\": \"deepmind\",\n    \"observation_filter\": \"NoFilter\",\n    \"synchronize_filters\": true,\n    \"compress_observations\": false,\n    \"enable_tf1_exec_eagerly\": false,\n    \"sampler_perf_stats_ema_coef\": null,\n    \"gamma\": 0.99,\n    \"lr\": 0.001,\n    \"train_batch_size\": 256,\n    \"model\": {\n      \"_use_default_native_models\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"tanh\",\n      \"conv_filters\": null,\n      \"conv_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": \"relu\",\n      \"free_log_std\": false,\n      \"no_final_linear\": false,\n      \"vf_share_layers\": true,\n      \"use_lstm\": false,\n      \"max_seq_len\": 20,\n      \"lstm_cell_size\": 256,\n      \"lstm_use_prev_action\": false,\n      \"lstm_use_prev_reward\": false,\n      \"_time_major\": false,\n      \"use_attention\": false,\n      \"attention_num_transformer_units\": 1,\n      \"attention_dim\": 64,\n      \"attention_num_heads\": 1,\n      \"attention_head_dim\": 32,\n      \"attention_memory_inference\": 50,\n      \"attention_memory_training\": 50,\n      \"attention_position_wise_mlp_dim\": 32,\n      \"attention_init_gru_gate_bias\": 2.0,\n      \"attention_use_n_prev_actions\": 0,\n      \"attention_use_n_prev_rewards\": 0,\n      \"framestack\": true,\n      \"dim\": 84,\n      \"grayscale\": false,\n      \"zero_mean\": true,\n      \"custom_model\": null,\n      \"custom_model_config\": {},\n      \"custom_action_dist\": null,\n      \"custom_preprocessor\": null,\n      \"lstm_use_prev_action_reward\": -1\n    },\n    \"optimizer\": {},\n    \"max_requests_in_flight_per_sampler_worker\": 2,\n    \"explore\": true,\n    \"exploration_config\": {\n      \"type\": \"StochasticSampling\"\n    },\n    \"input_config\": {},\n    \"actions_in_input_normalized\": false,\n    \"postprocess_inputs\": false,\n    \"shuffle_buffer_size\": 0,\n    \"output\": null,\n    \"output_config\": {},\n    \"output_compress_columns\": [\n      \"obs\",\n      \"new_obs\"\n    ],\n    \"output_max_file_size\": 67108864,\n    \"offline_sampling\": false,\n    \"evaluation_interval\": 100,\n    \"evaluation_duration\": 10,\n    \"evaluation_duration_unit\": \"episodes\",\n    \"evaluation_sample_timeout_s\": 180.0,\n    \"evaluation_parallel_to_training\": false,\n    \"evaluation_config\": null,\n    \"off_policy_estimation_methods\": {},\n    \"ope_split_batch_by_episode\": true,\n    \"evaluation_num_workers\": 0,\n    \"always_attach_evaluation_results\": false,\n    \"enable_async_evaluation\": false,\n    \"in_evaluation\": false,\n    \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n    \"keep_per_episode_custom_metrics\": false,\n    \"metrics_episode_collection_timeout_s\": 60.0,\n    \"metrics_num_episodes_for_smoothing\": 5,\n    \"min_time_s_per_iteration\": 1,\n    \"min_train_timesteps_per_iteration\": 0,\n    \"min_sample_timesteps_per_iteration\": 1000,\n    \"export_native_model_files\": false,\n    \"logger_creator\": null,\n    \"logger_config\": null,\n    \"log_level\": \"WARN\",\n    \"log_sys_usage\": true,\n    \"fake_sampler\": false,\n    \"seed\": null,\n    \"worker_cls\": null,\n    \"_tf_policy_handles_more_than_one_loss\": false,\n    \"_disable_preprocessor_api\": false,\n    \"_disable_action_flattening\": false,\n    \"_disable_execution_plan_api\": true,\n    \"simple_optimizer\": -1,\n    \"replay_sequence_length\": null,\n    \"twin_q\": true,\n    \"q_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"policy_model_config\": {\n      \"fcnet_hiddens\": [\n        256,\n        256\n      ],\n      \"fcnet_activation\": \"relu\",\n      \"post_fcnet_hiddens\": [],\n      \"post_fcnet_activation\": null,\n      \"custom_model\": null,\n      \"custom_model_config\": {}\n    },\n    \"tau\": 0.005,\n    \"initial_alpha\": 1.0,\n    \"target_entropy\": \"auto\",\n    \"n_step\": 1,\n    \"replay_buffer_config\": {\n      \"_enable_replay_buffer_api\": true,\n      \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n      \"capacity\": 1000000,\n      \"prioritized_replay\": false,\n      \"prioritized_replay_alpha\": 0.6,\n      \"prioritized_replay_beta\": 0.4,\n      \"prioritized_replay_eps\": 1e-06,\n      \"worker_side_prioritization\": false\n    },\n    \"store_buffer_in_checkpoints\": false,\n    \"training_intensity\": null,\n    \"optimization\": {\n      \"actor_learning_rate\": 0.0003,\n      \"critic_learning_rate\": 0.0003,\n      \"entropy_learning_rate\": 0.0003\n    },\n    \"grad_clip\": null,\n    \"target_network_update_freq\": 1,\n    \"num_steps_sampled_before_learning_starts\": 10000,\n    \"_deterministic_loss\": false,\n    \"_use_beta_distribution\": false,\n    \"use_state_preprocessor\": -1,\n    \"worker_side_prioritization\": -1,\n    \"input\": \"sampler\",\n    \"multiagent\": {\n      \"policies\": {\n        \"default_policy\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n        }\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n      },\n      \"policies_to_train\": null,\n      \"policy_map_capacity\": 100,\n      \"policy_map_cache\": null,\n      \"count_steps_by\": \"env_steps\",\n      \"observation_fn\": null\n    },\n    \"callbacks\": {\n      \"_type\": \"CLOUDPICKLE_FALLBACK\",\n      \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n    },\n    \"create_env_on_driver\": false,\n    \"custom_eval_function\": null,\n    \"framework\": \"torch\",\n    \"num_cpus_for_driver\": 1,\n    \"num_workers\": 3\n  },\n  \"local_dir\": \"/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059546000000000000008c197261792e74756e652e6578706572696d656e742e747269616c948c095f4c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"placement_group_factory\": \"800595d5000000000000008c237261792e74756e652e657865637574696f6e2e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d948c0343505594473ff0000000000000737d946808473ff0000000000000737d946808473ff0000000000000737d946808473ff000000000000073658c155f686561645f62756e646c655f69735f656d70747994898c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\",\n  \"stopping_criterion\": {\n    \"training_iteration\": 10000\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"custom_metrics\": {},\n    \"episode_media\": {},\n    \"info\": {\n      \"learner\": {\n        \"default_policy\": {\n          \"learner_stats\": {\n            \"allreduce_latency\": 0.0,\n            \"grad_gnorm\": 0.8870038390159607,\n            \"actor_loss\": 115.60578918457031,\n            \"critic_loss\": 1.3008311986923218,\n            \"alpha_loss\": 3.3117122650146484,\n            \"alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041ad8c33c94869452942e\"\n            },\n            \"log_alpha_value\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435f36ec094869452942e\"\n            },\n            \"target_entropy\": {\n              \"_type\": \"CLOUDPICKLE_FALLBACK\",\n              \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n            },\n            \"policy_t\": -0.3005792200565338,\n            \"mean_q\": -115.54031372070312,\n            \"max_q\": -109.50465393066406,\n            \"min_q\": -120.56295013427734\n          },\n          \"td_error\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"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\"\n          },\n          \"mean_td_error\": 37.32743453979492,\n          \"model\": {},\n          \"custom_metrics\": {},\n          \"num_agent_steps_trained\": 256.0,\n          \"num_grad_updates_lifetime\": 29194.0,\n          \"diff_num_grad_updates_vs_sampler_policy\": 29193.0\n        }\n      },\n      \"num_env_steps_sampled\": 97193,\n      \"num_env_steps_trained\": 7473664,\n      \"num_agent_steps_sampled\": 97193,\n      \"num_agent_steps_trained\": 7473664,\n      \"last_target_update_ts\": 97193,\n      \"num_target_updates\": 29194\n    },\n    \"sampler_results\": {\n      \"episode_reward_max\": -156.1826542466879,\n      \"episode_reward_min\": -191.28636541962624,\n      \"episode_reward_mean\": -169.9554263330996,\n      \"episode_len_mean\": 100.0,\n      \"episode_media\": {},\n      \"episodes_this_iter\": 10,\n      \"policy_reward_min\": {},\n      \"policy_reward_max\": {},\n      \"policy_reward_mean\": {},\n      \"custom_metrics\": {},\n      \"hist_stats\": {\n        \"episode_reward\": [\n          -156.1826542466879,\n          -169.85423006117344,\n          -162.02638640999794,\n          -185.1279215067625,\n          -186.65800455212593,\n          -163.31539402902126,\n          -191.28636541962624,\n          -157.43947839736938,\n          -171.26552772521973,\n          -156.39830098301172\n        ],\n        \"episode_lengths\": [\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100,\n          100\n        ]\n      },\n      \"sampler_perf\": {\n        \"mean_raw_obs_processing_ms\": 1.1364653920600976,\n        \"mean_inference_ms\": 2.3486854601514455,\n        \"mean_action_processing_ms\": 0.22231085102003592,\n        \"mean_env_wait_ms\": 2.9007591400230686,\n        \"mean_env_render_ms\": 0.0\n      },\n      \"num_faulty_episodes\": 0\n    },\n    \"episode_reward_max\": -156.1826542466879,\n    \"episode_reward_min\": -191.28636541962624,\n    \"episode_reward_mean\": -169.9554263330996,\n    \"episode_len_mean\": 100.0,\n    \"episodes_this_iter\": 10,\n    \"policy_reward_min\": {},\n    \"policy_reward_max\": {},\n    \"policy_reward_mean\": {},\n    \"hist_stats\": {\n      \"episode_reward\": [\n        -156.1826542466879,\n        -169.85423006117344,\n        -162.02638640999794,\n        -185.1279215067625,\n        -186.65800455212593,\n        -163.31539402902126,\n        -191.28636541962624,\n        -157.43947839736938,\n        -171.26552772521973,\n        -156.39830098301172\n      ],\n      \"episode_lengths\": [\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100,\n        100\n      ]\n    },\n    \"sampler_perf\": {\n      \"mean_raw_obs_processing_ms\": 1.1364653920600976,\n      \"mean_inference_ms\": 2.3486854601514455,\n      \"mean_action_processing_ms\": 0.22231085102003592,\n      \"mean_env_wait_ms\": 2.9007591400230686,\n      \"mean_env_render_ms\": 0.0\n    },\n    \"num_faulty_episodes\": 0,\n    \"num_healthy_workers\": 3,\n    \"num_in_flight_async_reqs\": 0,\n    \"num_remote_worker_restarts\": 1,\n    \"num_agent_steps_sampled\": 97193,\n    \"num_agent_steps_trained\": 7473664,\n    \"num_env_steps_sampled\": 97193,\n    \"num_env_steps_trained\": 7473664,\n    \"num_env_steps_sampled_this_iter\": 1002,\n    \"num_env_steps_trained_this_iter\": 85504,\n    \"timesteps_total\": 97193,\n    \"num_steps_trained_this_iter\": 85504,\n    \"agent_timesteps_total\": 97193,\n    \"timers\": {\n      \"training_iteration_time_ms\": 161.318,\n      \"load_time_ms\": 0.312,\n      \"load_throughput\": 821657.349,\n      \"learn_time_ms\": 25.987,\n      \"learn_throughput\": 9851.041,\n      \"synch_weights_time_ms\": 7.023\n    },\n    \"counters\": {\n      \"num_env_steps_sampled\": 97193,\n      \"num_env_steps_trained\": 7473664,\n      \"num_agent_steps_sampled\": 97193,\n      \"num_agent_steps_trained\": 7473664,\n      \"last_target_update_ts\": 97193,\n      \"num_target_updates\": 29194\n    },\n    \"done\": false,\n    \"episodes_total\": 1000,\n    \"training_iteration\": 97,\n    \"trial_id\": \"80340_00000\",\n    \"experiment_id\": \"4d5d6cddaea7444681811f5901f7f828\",\n    \"date\": \"2023-02-09_15-52-40\",\n    \"timestamp\": 1675954360,\n    \"time_this_iter_s\": 52.549543619155884,\n    \"time_total_s\": 4664.705418109894,\n    \"pid\": 27220,\n    \"hostname\": \"Daniel\",\n    \"node_ip\": \"192.168.152.36\",\n    \"config\": {\n      \"extra_python_environs_for_driver\": {},\n      \"extra_python_environs_for_worker\": {},\n      \"num_gpus\": 0,\n      \"num_cpus_per_worker\": 1,\n      \"num_gpus_per_worker\": 0,\n      \"_fake_gpus\": false,\n      \"custom_resources_per_worker\": {},\n      \"placement_strategy\": \"PACK\",\n      \"eager_tracing\": false,\n      \"eager_max_retraces\": 20,\n      \"tf_session_args\": {\n        \"intra_op_parallelism_threads\": 2,\n        \"inter_op_parallelism_threads\": 2,\n        \"gpu_options\": {\n          \"allow_growth\": true\n        },\n        \"log_device_placement\": false,\n        \"device_count\": {\n          \"CPU\": 1\n        },\n        \"allow_soft_placement\": true\n      },\n      \"local_tf_session_args\": {\n        \"intra_op_parallelism_threads\": 8,\n        \"inter_op_parallelism_threads\": 8\n      },\n      \"env\": \"darm/DarmSFHand-v0\",\n      \"env_config\": {},\n      \"observation_space\": null,\n      \"action_space\": null,\n      \"env_task_fn\": null,\n      \"render_env\": false,\n      \"clip_rewards\": null,\n      \"normalize_actions\": true,\n      \"clip_actions\": false,\n      \"disable_env_checking\": false,\n      \"num_envs_per_worker\": 1,\n      \"sample_collector\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059551000000000000008c357261792e726c6c69622e6576616c756174696f6e2e636f6c6c6563746f72732e73696d706c655f6c6973745f636f6c6c6563746f72948c1353696d706c654c697374436f6c6c6563746f729493942e\"\n      },\n      \"sample_async\": false,\n      \"enable_connectors\": false,\n      \"rollout_fragment_length\": 1,\n      \"batch_mode\": \"truncate_episodes\",\n      \"remote_worker_envs\": false,\n      \"remote_env_batch_wait_ms\": 0,\n      \"validate_workers_after_construction\": true,\n      \"ignore_worker_failures\": false,\n      \"recreate_failed_workers\": false,\n      \"restart_failed_sub_environments\": false,\n      \"num_consecutive_worker_failures_tolerance\": 100,\n      \"horizon\": null,\n      \"soft_horizon\": false,\n      \"no_done_at_end\": false,\n      \"preprocessor_pref\": \"deepmind\",\n      \"observation_filter\": \"NoFilter\",\n      \"synchronize_filters\": true,\n      \"compress_observations\": false,\n      \"enable_tf1_exec_eagerly\": false,\n      \"sampler_perf_stats_ema_coef\": null,\n      \"gamma\": 0.99,\n      \"lr\": 0.001,\n      \"train_batch_size\": 256,\n      \"model\": {\n        \"_use_default_native_models\": false,\n        \"_disable_preprocessor_api\": false,\n        \"_disable_action_flattening\": false,\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"tanh\",\n        \"conv_filters\": null,\n        \"conv_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": \"relu\",\n        \"free_log_std\": false,\n        \"no_final_linear\": false,\n        \"vf_share_layers\": true,\n        \"use_lstm\": false,\n        \"max_seq_len\": 20,\n        \"lstm_cell_size\": 256,\n        \"lstm_use_prev_action\": false,\n        \"lstm_use_prev_reward\": false,\n        \"_time_major\": false,\n        \"use_attention\": false,\n        \"attention_num_transformer_units\": 1,\n        \"attention_dim\": 64,\n        \"attention_num_heads\": 1,\n        \"attention_head_dim\": 32,\n        \"attention_memory_inference\": 50,\n        \"attention_memory_training\": 50,\n        \"attention_position_wise_mlp_dim\": 32,\n        \"attention_init_gru_gate_bias\": 2.0,\n        \"attention_use_n_prev_actions\": 0,\n        \"attention_use_n_prev_rewards\": 0,\n        \"framestack\": true,\n        \"dim\": 84,\n        \"grayscale\": false,\n        \"zero_mean\": true,\n        \"custom_model\": null,\n        \"custom_model_config\": {},\n        \"custom_action_dist\": null,\n        \"custom_preprocessor\": null,\n        \"lstm_use_prev_action_reward\": -1\n      },\n      \"optimizer\": {},\n      \"max_requests_in_flight_per_sampler_worker\": 2,\n      \"explore\": true,\n      \"exploration_config\": {\n        \"type\": \"StochasticSampling\"\n      },\n      \"input_config\": {},\n      \"actions_in_input_normalized\": false,\n      \"postprocess_inputs\": false,\n      \"shuffle_buffer_size\": 0,\n      \"output\": null,\n      \"output_config\": {},\n      \"output_compress_columns\": [\n        \"obs\",\n        \"new_obs\"\n      ],\n      \"output_max_file_size\": 67108864,\n      \"offline_sampling\": false,\n      \"evaluation_interval\": 100,\n      \"evaluation_duration\": 10,\n      \"evaluation_duration_unit\": \"episodes\",\n      \"evaluation_sample_timeout_s\": 180.0,\n      \"evaluation_parallel_to_training\": false,\n      \"evaluation_config\": null,\n      \"off_policy_estimation_methods\": {},\n      \"ope_split_batch_by_episode\": true,\n      \"evaluation_num_workers\": 0,\n      \"always_attach_evaluation_results\": false,\n      \"enable_async_evaluation\": false,\n      \"in_evaluation\": false,\n      \"sync_filters_on_rollout_workers_timeout_s\": 60.0,\n      \"keep_per_episode_custom_metrics\": false,\n      \"metrics_episode_collection_timeout_s\": 60.0,\n      \"metrics_num_episodes_for_smoothing\": 5,\n      \"min_time_s_per_iteration\": 1,\n      \"min_train_timesteps_per_iteration\": 0,\n      \"min_sample_timesteps_per_iteration\": 1000,\n      \"export_native_model_files\": false,\n      \"logger_creator\": null,\n      \"logger_config\": null,\n      \"log_level\": \"WARN\",\n      \"log_sys_usage\": true,\n      \"fake_sampler\": false,\n      \"seed\": null,\n      \"worker_cls\": null,\n      \"_tf_policy_handles_more_than_one_loss\": false,\n      \"_disable_preprocessor_api\": false,\n      \"_disable_action_flattening\": false,\n      \"_disable_execution_plan_api\": true,\n      \"simple_optimizer\": false,\n      \"replay_sequence_length\": null,\n      \"twin_q\": true,\n      \"q_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"policy_model_config\": {\n        \"fcnet_hiddens\": [\n          256,\n          256\n        ],\n        \"fcnet_activation\": \"relu\",\n        \"post_fcnet_hiddens\": [],\n        \"post_fcnet_activation\": null,\n        \"custom_model\": null,\n        \"custom_model_config\": {}\n      },\n      \"tau\": 0.005,\n      \"initial_alpha\": 1.0,\n      \"target_entropy\": \"auto\",\n      \"n_step\": 1,\n      \"replay_buffer_config\": {\n        \"_enable_replay_buffer_api\": true,\n        \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n        \"capacity\": 1000000,\n        \"prioritized_replay\": false,\n        \"prioritized_replay_alpha\": 0.6,\n        \"prioritized_replay_beta\": 0.4,\n        \"prioritized_replay_eps\": 1e-06,\n        \"worker_side_prioritization\": false\n      },\n      \"store_buffer_in_checkpoints\": false,\n      \"training_intensity\": null,\n      \"optimization\": {\n        \"actor_learning_rate\": 0.0003,\n        \"critic_learning_rate\": 0.0003,\n        \"entropy_learning_rate\": 0.0003\n      },\n      \"grad_clip\": null,\n      \"target_network_update_freq\": 1,\n      \"num_steps_sampled_before_learning_starts\": 10000,\n      \"_deterministic_loss\": false,\n      \"_use_beta_distribution\": false,\n      \"use_state_preprocessor\": -1,\n      \"worker_side_prioritization\": -1,\n      \"__stdout_file__\": null,\n      \"__stderr_file__\": null,\n      \"input\": \"sampler\",\n      \"multiagent\": {\n        \"policies\": {\n          \"default_policy\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059571000000000000008c177261792e726c6c69622e706f6c6963792e706f6c696379948c0a506f6c696379537065639493942981947d94288c0c706f6c6963795f636c617373944e8c116f62736572766174696f6e5f7370616365944e8c0c616374696f6e5f7370616365944e8c06636f6e666967944e75622e\"\n          }\n        },\n        \"policy_mapping_fn\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005950f030000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b034b004b004b044b014b5b430474005300944e85948c1144454641554c545f504f4c4943595f4944948594288c03616964948c07657069736f6465948c06776f726b6572948c066b77617267739474948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e7079948c083c6c616d6264613e944d12014300942929749452947d94288c0b5f5f7061636b6167655f5f948c147261792e726c6c69622e616c676f726974686d73948c085f5f6e616d655f5f948c257261792e726c6c69622e616c676f726974686d732e616c676f726974686d5f636f6e666967948c085f5f66696c655f5f948c5c2f686f6d652f64616e69656c2f6d696e69636f6e6461332f6c69622f707974686f6e332e382f736974652d7061636b616765732f7261792f726c6c69622f616c676f726974686d732f616c676f726974686d5f636f6e6669672e707994754e4e4e749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f7365747374617465949394681f7d947d9428681a68138c0c5f5f7175616c6e616d655f5f948c2a416c676f726974686d436f6e6669672e5f5f696e69745f5f2e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681b8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f944e8c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d94680b8c0e64656661756c745f706f6c69637994737586948652302e\"\n        },\n        \"policies_to_train\": null,\n        \"policy_map_capacity\": 100,\n        \"policy_map_cache\": null,\n        \"count_steps_by\": \"env_steps\",\n        \"observation_fn\": null\n      },\n      \"callbacks\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059537000000000000008c1e7261792e726c6c69622e616c676f726974686d732e63616c6c6261636b73948c1044656661756c7443616c6c6261636b739493942e\"\n      },\n      \"create_env_on_driver\": false,\n      \"custom_eval_function\": null,\n      \"framework\": \"torch\",\n      \"num_cpus_for_driver\": 1,\n      \"num_workers\": 3\n    },\n    \"time_since_restore\": 4664.705418109894,\n    \"timesteps_since_restore\": 0,\n    \"iterations_since_restore\": 97,\n    \"warmup_time\": 8.03538990020752,\n    \"perf\": {\n      \"cpu_util_percent\": 39.38055555555556,\n      \"ram_util_percent\": 91.3138888888889\n    },\n    \"experiment_tag\": \"0\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": 1675954360.5438237,\n  \"metric_analysis\": {\n    \"episode_reward_max\": {\n      \"max\": 246.4839284569025,\n      \"min\": -180.80819918960333,\n      \"avg\": -12.388895104034347,\n      \"last\": -156.1826542466879,\n      \"last-5-avg\": -76.0302426442504,\n      \"last-10-avg\": -116.6211689375341\n    },\n    \"episode_reward_min\": {\n      \"max\": -166.27869933843613,\n      \"min\": -196.84813330322504,\n      \"avg\": -184.54626515254225,\n      \"last\": -191.28636541962624,\n      \"last-5-avg\": -185.46425538957118,\n      \"last-10-avg\": -178.42735547944903\n    },\n    \"episode_reward_mean\": {\n      \"max\": -67.65054373849522,\n      \"min\": -188.20978297458754,\n      \"avg\": -155.50684557040847,\n      \"last\": -169.9554263330996,\n      \"last-5-avg\": -160.00184844438024,\n      \"last-10-avg\": -161.81272692360665\n    },\n    \"episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 79.81818181818181,\n      \"avg\": 97.06446503095981,\n      \"last\": 100.0,\n      \"last-5-avg\": 98.30909090909091,\n      \"last-10-avg\": 99.15454545454546\n    },\n    \"episodes_this_iter\": {\n      \"max\": 13,\n      \"min\": 9,\n      \"avg\": 10.30927835051546,\n      \"last\": 10,\n      \"last-5-avg\": 10.0,\n      \"last-10-avg\": 10.0\n    },\n    \"num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_healthy_workers\": {\n      \"max\": 3,\n      \"min\": 3,\n      \"avg\": 2.9999999999999987,\n      \"last\": 3,\n      \"last-5-avg\": 3.0,\n      \"last-10-avg\": 3.0\n    },\n    \"num_in_flight_async_reqs\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"num_remote_worker_restarts\": {\n      \"max\": 1,\n      \"min\": 0,\n      \"avg\": 0.041237113402061855,\n      \"last\": 1,\n      \"last-5-avg\": 0.8,\n      \"last-10-avg\": 0.4\n    },\n    \"num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"max\": 1002,\n      \"min\": 1001,\n      \"avg\": 1001.9896907216491,\n      \"last\": 1002,\n      \"last-5-avg\": 1001.8,\n      \"last-10-avg\": 1001.9\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"max\": 118528,\n      \"min\": 0,\n      \"avg\": 77048.0824742268,\n      \"last\": 85504,\n      \"last-5-avg\": 92108.8,\n      \"last-10-avg\": 88806.4\n    },\n    \"timesteps_total\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"num_steps_trained_this_iter\": {\n      \"max\": 118528,\n      \"min\": 0,\n      \"avg\": 77048.0824742268,\n      \"last\": 85504,\n      \"last-5-avg\": 92108.8,\n      \"last-10-avg\": 88806.4\n    },\n    \"agent_timesteps_total\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"done\": {\n      \"max\": false,\n      \"min\": false,\n      \"avg\": 0.0,\n      \"last\": false,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"episodes_total\": {\n      \"max\": 1000,\n      \"min\": 9,\n      \"avg\": 504.79381443298973,\n      \"last\": 1000,\n      \"last-5-avg\": 980.2,\n      \"last-10-avg\": 955.3\n    },\n    \"training_iteration\": {\n      \"max\": 97,\n      \"min\": 1,\n      \"avg\": 49.00000000000001,\n      \"last\": 97,\n      \"last-5-avg\": 95.0,\n      \"last-10-avg\": 92.5\n    },\n    \"time_this_iter_s\": {\n      \"max\": 87.86418461799622,\n      \"min\": 3.8648064136505127,\n      \"avg\": 48.089746578452534,\n      \"last\": 52.549543619155884,\n      \"last-5-avg\": 60.03978991508484,\n      \"last-10-avg\": 56.72709512710571\n    },\n    \"time_total_s\": {\n      \"max\": 4664.705418109894,\n      \"min\": 5.359312057495117,\n      \"avg\": 2127.507677638654,\n      \"last\": 4664.705418109894,\n      \"last-5-avg\": 4551.542730426789,\n      \"last-10-avg\": 4404.665781450271\n    },\n    \"time_since_restore\": {\n      \"max\": 4664.705418109894,\n      \"min\": 5.359312057495117,\n      \"avg\": 2127.507677638654,\n      \"last\": 4664.705418109894,\n      \"last-5-avg\": 4551.542730426789,\n      \"last-10-avg\": 4404.665781450271\n    },\n    \"timesteps_since_restore\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"iterations_since_restore\": {\n      \"max\": 97,\n      \"min\": 1,\n      \"avg\": 49.00000000000001,\n      \"last\": 97,\n      \"last-5-avg\": 95.0,\n      \"last-10-avg\": 92.5\n    },\n    \"warmup_time\": {\n      \"max\": 8.03538990020752,\n      \"min\": 8.03538990020752,\n      \"avg\": 8.03538990020752,\n      \"last\": 8.03538990020752,\n      \"last-5-avg\": 8.03538990020752,\n      \"last-10-avg\": 8.03538990020752\n    },\n    \"info/num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"max\": 246.4839284569025,\n      \"min\": -180.80819918960333,\n      \"avg\": -12.388895104034347,\n      \"last\": -156.1826542466879,\n      \"last-5-avg\": -76.0302426442504,\n      \"last-10-avg\": -116.6211689375341\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"max\": -166.27869933843613,\n      \"min\": -196.84813330322504,\n      \"avg\": -184.54626515254225,\n      \"last\": -191.28636541962624,\n      \"last-5-avg\": -185.46425538957118,\n      \"last-10-avg\": -178.42735547944903\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"max\": -67.65054373849522,\n      \"min\": -188.20978297458754,\n      \"avg\": -155.50684557040847,\n      \"last\": -169.9554263330996,\n      \"last-5-avg\": -160.00184844438024,\n      \"last-10-avg\": -161.81272692360665\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"max\": 100.0,\n      \"min\": 79.81818181818181,\n      \"avg\": 97.06446503095981,\n      \"last\": 100.0,\n      \"last-5-avg\": 98.30909090909091,\n      \"last-10-avg\": 99.15454545454546\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"max\": 13,\n      \"min\": 9,\n      \"avg\": 10.30927835051546,\n      \"last\": 10,\n      \"last-5-avg\": 10.0,\n      \"last-10-avg\": 10.0\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"max\": 0,\n      \"min\": 0,\n      \"avg\": 0.0,\n      \"last\": 0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.1364653920600976,\n      \"avg\": 1.1940301056313938,\n      \"last\": 1.1364653920600976,\n      \"last-5-avg\": 1.1663385713747494,\n      \"last-10-avg\": 1.1585201585600085\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.3850960676362587,\n      \"last\": 2.3486854601514455,\n      \"last-5-avg\": 2.386445898129482,\n      \"last-10-avg\": 2.3794163445376832\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22231085102003592,\n      \"avg\": 0.22820162528863516,\n      \"last\": 0.22231085102003592,\n      \"last-5-avg\": 0.22726492829065545,\n      \"last-10-avg\": 0.225857300865209\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 2.9007591400230686,\n      \"avg\": 3.0301794776166973,\n      \"last\": 2.9007591400230686,\n      \"last-5-avg\": 2.9680635788997085,\n      \"last-10-avg\": 2.971996630348232\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"max\": 189.773,\n      \"min\": 11.428,\n      \"avg\": 143.53061855670103,\n      \"last\": 161.318,\n      \"last-5-avg\": 154.4892,\n      \"last-10-avg\": 157.189\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_env_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"max\": 97193,\n      \"min\": 1002,\n      \"avg\": 49097.95876288661,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"max\": 7473664,\n      \"min\": 0,\n      \"avg\": 3377310.3505154625,\n      \"last\": 7473664,\n      \"last-5-avg\": 7296051.2,\n      \"last-10-avg\": 7069081.6\n    },\n    \"perf/cpu_util_percent\": {\n      \"max\": 77.2875,\n      \"min\": 37.38260869565218,\n      \"avg\": 43.059807633885846,\n      \"last\": 39.38055555555556,\n      \"last-5-avg\": 42.6261610791119,\n      \"last-10-avg\": 41.638303035107654\n    },\n    \"perf/ram_util_percent\": {\n      \"max\": 93.40655737704918,\n      \"min\": 81.83333333333333,\n      \"avg\": 88.72794874688876,\n      \"last\": 91.3138888888889,\n      \"last-5-avg\": 92.10318084477922,\n      \"last-10-avg\": 92.31285380234146\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"max\": 1.427876296921156,\n      \"min\": 1.1364653920600976,\n      \"avg\": 1.1940301056313938,\n      \"last\": 1.1364653920600976,\n      \"last-5-avg\": 1.1663385713747494,\n      \"last-10-avg\": 1.1585201585600085\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"max\": 2.599548937669441,\n      \"min\": 2.304896534791573,\n      \"avg\": 2.3850960676362587,\n      \"last\": 2.3486854601514455,\n      \"last-5-avg\": 2.386445898129482,\n      \"last-10-avg\": 2.3794163445376832\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"max\": 0.2599483698754762,\n      \"min\": 0.22231085102003592,\n      \"avg\": 0.22820162528863516,\n      \"last\": 0.22231085102003592,\n      \"last-5-avg\": 0.22726492829065545,\n      \"last-10-avg\": 0.225857300865209\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"max\": 3.5897183774122556,\n      \"min\": 2.9007591400230686,\n      \"avg\": 3.0301794776166973,\n      \"last\": 2.9007591400230686,\n      \"last-5-avg\": 2.9680635788997085,\n      \"last-10-avg\": 2.971996630348232\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/last_target_update_ts\": {\n      \"max\": 97193,\n      \"min\": 10020,\n      \"avg\": 49562.804123711336,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"info/num_target_updates\": {\n      \"max\": 29194,\n      \"min\": 7,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"timers/load_time_ms\": {\n      \"max\": 0.339,\n      \"min\": 0.252,\n      \"avg\": 0.28286597938144326,\n      \"last\": 0.312,\n      \"last-5-avg\": 0.2938,\n      \"last-10-avg\": 0.2940999999999999\n    },\n    \"timers/load_throughput\": {\n      \"max\": 1014112.036,\n      \"min\": 754721.181,\n      \"avg\": 910293.1391443302,\n      \"last\": 821657.349,\n      \"last-5-avg\": 875020.2276000001,\n      \"last-10-avg\": 874785.7856999999\n    },\n    \"timers/learn_time_ms\": {\n      \"max\": 34.221,\n      \"min\": 23.921,\n      \"avg\": 25.68867010309277,\n      \"last\": 25.987,\n      \"last-5-avg\": 25.2626,\n      \"last-10-avg\": 25.4429\n    },\n    \"timers/learn_throughput\": {\n      \"max\": 10701.707,\n      \"min\": 7480.78,\n      \"avg\": 9993.184484536083,\n      \"last\": 9851.041,\n      \"last-5-avg\": 10137.0798,\n      \"last-10-avg\": 10067.5654\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"max\": 7.622,\n      \"min\": 3.46,\n      \"avg\": 5.916463917525771,\n      \"last\": 7.023,\n      \"last-5-avg\": 5.5596000000000005,\n      \"last-10-avg\": 5.630799999999999\n    },\n    \"counters/last_target_update_ts\": {\n      \"max\": 97193,\n      \"min\": 10020,\n      \"avg\": 49562.804123711336,\n      \"last\": 97193,\n      \"last-5-avg\": 95189.2,\n      \"last-10-avg\": 92684.6\n    },\n    \"counters/num_target_updates\": {\n      \"max\": 29194,\n      \"min\": 7,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"max\": 52.555171966552734,\n      \"min\": 1.4600703716278076,\n      \"avg\": 19.237037835661905,\n      \"last\": 37.32743453979492,\n      \"last-5-avg\": 37.0519660949707,\n      \"last-10-avg\": 38.79243621826172\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"max\": 256.0,\n      \"min\": 256.0,\n      \"avg\": 255.99999999999986,\n      \"last\": 256.0,\n      \"last-5-avg\": 256.0,\n      \"last-10-avg\": 256.0\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"max\": 29194.0,\n      \"min\": 7.0,\n      \"avg\": 13193.268041237117,\n      \"last\": 29194.0,\n      \"last-5-avg\": 28500.2,\n      \"last-10-avg\": 27613.6\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"max\": 29193.0,\n      \"min\": 6.0,\n      \"avg\": 13192.268041237117,\n      \"last\": 29193.0,\n      \"last-5-avg\": 28499.2,\n      \"last-10-avg\": 27612.6\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"max\": 0.0,\n      \"min\": 0.0,\n      \"avg\": 0.0,\n      \"last\": 0.0,\n      \"last-5-avg\": 0.0,\n      \"last-10-avg\": 0.0\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"max\": 8.438075065612793,\n      \"min\": 0.0007296120747923851,\n      \"avg\": 4.199410469780108,\n      \"last\": 0.8870038390159607,\n      \"last-5-avg\": 0.3972333982586861,\n      \"last-10-avg\": 0.39924969598650933\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"max\": 115.60578918457031,\n      \"min\": -6.580883979797363,\n      \"avg\": 50.705901773272025,\n      \"last\": 115.60578918457031,\n      \"last-5-avg\": 114.08861389160157,\n      \"last-10-avg\": 111.68227081298828\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"max\": 1.7885878086090088,\n      \"min\": 0.23512327671051025,\n      \"avg\": 0.7603486101959173,\n      \"last\": 1.3008311986923218,\n      \"last-5-avg\": 1.3107106924057006,\n      \"last-10-avg\": 1.3759251356124877\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"max\": 3.3117122650146484,\n      \"min\": -22.550003051757812,\n      \"avg\": -6.202999704469415,\n      \"last\": 3.3117122650146484,\n      \"last-5-avg\": 1.242195975780487,\n      \"last-10-avg\": 0.2757415473461151\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304248a7f3f94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243046e425b3c94869452942e\"\n      },\n      \"avg\": 0.20847204509047185,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243041ad8c33c94869452942e\"\n      },\n      \"last-5-avg\": 0.023464493080973627,\n      \"last-10-avg\": 0.023778889514505862\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430415eeebba94869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b00a8ac094869452942e\"\n      },\n      \"avg\": -2.7600312380662624,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430435f36ec094869452942e\"\n      },\n      \"last-5-avg\": -3.7526698112487793,\n      \"last-10-avg\": -3.739602875709534\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"max\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"min\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"avg\": -5.0,\n      \"last\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059565000000000000008c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452942e\"\n      },\n      \"last-5-avg\": -5.0,\n      \"last-10-avg\": -5.0\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"max\": 0.020382240414619446,\n      \"min\": -0.44182953238487244,\n      \"avg\": -0.2144594302862407,\n      \"last\": -0.3005792200565338,\n      \"last-5-avg\": -0.2793947786092758,\n      \"last-10-avg\": -0.2996277377009392\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"max\": 4.486087322235107,\n      \"min\": -115.54031372070312,\n      \"avg\": -51.340016929951226,\n      \"last\": -115.54031372070312,\n      \"last-5-avg\": -113.98671875,\n      \"last-10-avg\": -111.57610626220703\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"max\": 5.304399013519287,\n      \"min\": -109.50465393066406,\n      \"avg\": -47.25042838657025,\n      \"last\": -109.50465393066406,\n      \"last-5-avg\": -107.16285705566406,\n      \"last-10-avg\": -104.64206390380859\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"max\": 3.575044631958008,\n      \"min\": -120.56295013427734,\n      \"avg\": -54.09790204878242,\n      \"last\": -120.56295013427734,\n      \"last-5-avg\": -118.75367736816406,\n      \"last-10-avg\": -116.35101699829102\n    }\n  },\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {\n    \"episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000020c5408363c094869452946807680d43080000343928dc63c094869452946807680d4308000050cbab9763c094869452946807680d430800007c4707b463c094869452946807680d43080000905ad39663c094869452946807680d43080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      }\n    },\n    \"episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b4d18c4265c094869452946807680d430800002887c92665c094869452946807680d43080000f83bcadf64c094869452946807680d43080000e8393dee65c094869452946807680d43080000a8401be765c094869452946807680d4308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      }\n    },\n    \"episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d3c0a568964c094869452946807680d4308abaacaf0c05764c094869452946807680d430833332145111164c094869452946807680d43082fbad09c5ea364c094869452946807680d43081cc79d0340ae64c094869452946807680d4308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      }\n    },\n    \"episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b094b0a4b0a4b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b094b0a4b0b4b094b0b4b094b0a4b0a4b0a652e\"\n      }\n    },\n    \"num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_healthy_workers\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b034b034b034b034b03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b034b034b034b034b034b034b034b034b034b03652e\"\n      }\n    },\n    \"num_in_flight_async_reqs\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"num_remote_worker_restarts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b014b014b014b01652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b014b014b014b01652e\"\n      }\n    },\n    \"num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"num_env_steps_sampled_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dea034de9034dea034dea034dea03652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dea034dea034dea034dea034dea034dea034de9034dea034dea034dea03652e\"\n      }\n    },\n    \"num_env_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"num_steps_trained_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a004e01004a004e01004a004e01004a004e01004a004e01004a004e01004a00cf01004a004e01004a004e01004a004e0100652e\"\n      }\n    },\n    \"agent_timesteps_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"done\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059527000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288989898989652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942889898989898989898989652e\"\n      }\n    },\n    \"episodes_total\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284dc1034dca034dd4034dde034de803652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284d8f034d98034da2034dad034db6034dc1034dca034dd4034dde034de803652e\"\n      }\n    },\n    \"training_iteration\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5d4b5e4b5f4b604b61652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b584b594b5a4b5b4b5c4b5d4b5e4b5f4b604b61652e\"\n      }\n    },\n    \"time_this_iter_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847404a5147d0000000474055f74ecd00000047404ad98b9800000047404ab9aeba00000047404a465772000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847404a3955cc00000047404a901b4400000047404c24b3c000000047404a7a836e00000047404a208f1c00000047404a5147d0000000474055f74ecd00000047404ad98b9800000047404ab9aeba00000047404a465772000000652e\"\n      }\n    },\n    \"time_total_s\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b035e1e4d000004740b06b021b5800004740b0a34b82d800004740b0d84089b400004740b10c81a7ec00004740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      }\n    },\n    \"time_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740b035e1e4d000004740b06b021b5800004740b0a34b82d800004740b0d84089b400004740b10c81a7ec00004740b14124378c00004740b1990172c000004740b1ceb489f000004740b20427e76400004740b238b496480000652e\"\n      }\n    },\n    \"timesteps_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"iterations_since_restore\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b5d4b5e4b5f4b604b61652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b584b594b5a4b5b4b5c4b5d4b5e4b5f4b604b61652e\"\n      }\n    },\n    \"warmup_time\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000474020121ea0000000652e\"\n      }\n    },\n    \"info/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"info/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"sampler_results/episode_reward_max\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000020c5408363c094869452946807680d43080000343928dc63c094869452946807680d4308000050cbab9763c094869452946807680d430800007c4707b463c094869452946807680d43080000905ad39663c094869452946807680d43080000a0e5fdc36d4094869452946807680d430800000cf8295263c094869452946807680d43080000588f839563c094869452946807680d43080000a0cd4edb62c094869452946807680d43080000b84dd88563c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_min\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000b4d18c4265c094869452946807680d430800002887c92665c094869452946807680d43080000f83bcadf64c094869452946807680d43080000e8393dee65c094869452946807680d43080000a8401be765c094869452946807680d4308000000ecd90766c094869452946807680d4308000078ecb04b66c094869452946807680d4308000050a19d0768c094869452946807680d430800000085f5a567c094869452946807680d43080000d0e729e967c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_reward_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308175d3c0a568964c094869452946807680d4308abaacaf0c05764c094869452946807680d430833332145111164c094869452946807680d43082fbad09c5ea364c094869452946807680d43081cc79d0340ae64c094869452946807680d4308461735b3dd725fc094869452946807680d4308398e93069d6864c094869452946807680d4308cdcc82a7fb4565c094869452946807680d430866666854b15965c094869452946807680d4308cdcc3eda923e65c09486945294652e\"\n      }\n    },\n    \"sampler_results/episode_len_mean\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308a38b2ebae8e2564094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d4308000000000000594094869452946807680d430800000000000059409486945294652e\"\n      }\n    },\n    \"sampler_results/episodes_this_iter\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b0b4b094b0a4b0a4b0a652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b0b4b094b0a4b0b4b094b0b4b094b0a4b0a4b0a652e\"\n      }\n    },\n    \"sampler_results/num_faulty_episodes\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005952c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284b004b004b004b004b00652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059536000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284b004b004b004b004b004b004b004b004b004b00652e\"\n      }\n    },\n    \"sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4637115dc6cf23f94869452946807680d430825c30ff14367f23f94869452946807680d4308cb2cc4946264f23f94869452946807680d430841e891a0e66df23f94869452946807680d43082ed95aeff567f23f94869452946807680d43083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e68ecbda52fc024094869452946807680d430836a7ee5664f8024094869452946807680d4308977ab91c02f7024094869452946807680d43088ae99ecf2cff024094869452946807680d43085c65048357fa024094869452946807680d43084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308806fd2709cc5cc3f94869452946807680d4308d2a2255dabb6cc3f94869452946807680d43081bf4c3d619adcc3f94869452946807680d430853643d6c63c4cc3f94869452946807680d43080572949010b8cc3f94869452946807680d430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a435853d89d4074094869452946807680d430809ff84c99dd0074094869452946807680d43084a42f8a0a0cd074094869452946807680d4308dd5198e148cf074094869452946807680d4308c2b9499174c7074094869452946807680d4308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      }\n    },\n    \"sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"timers/training_iteration_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740630e4dd2f1a9fc474062db020c49ba5e4740634d374bc6a7f04740632d916872b0214740642a2d0e560419652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847406303645a1cac08474065bcb439581062474063f2978d4fdf3b474064022d0e560419474063395810624dd34740630e4dd2f1a9fc474062db020c49ba5e4740634d374bc6a7f04740632d916872b0214740642a2d0e560419652e\"\n      }\n    },\n    \"counters/num_env_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_env_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"counters/num_agent_steps_sampled\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a00cb65004a001967004a006768004a00b569004a00036b004a00516c004a00206e004a006e6f004a00bc70004a000a7200652e\"\n      }\n    },\n    \"perf/cpu_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a54ffaa44faa434094869452946807680d43087bce2a5d614c4b4094869452946807680d430850f6be260405444094869452946807680d4308463eeb0653e4434094869452946807680d43080cb6600bb6b043409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c07c51e5d632444094869452946807680d43080944bba986c0434094869452946807680d4308333333333353464094869452946807680d43084420da4d3504444094869452946807680d4308d8822dd88255434094869452946807680d4308a54ffaa44faa434094869452946807680d43087bce2a5d614c4b4094869452946807680d430850f6be260405444094869452946807680d4308463eeb0653e4434094869452946807680d43080cb6600bb6b043409486945294652e\"\n      }\n    },\n    \"perf/ram_util_percent\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308faa44ffaa43b574094869452946807680d4308ec973b09055a574094869452946807680d430870a73f6201e7564094869452946807680d43080465ef6b42d0564094869452946807680d4308c2166cc116d456409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308aa726b59ac1b574094869452946807680d43081d09df8ae2f1564094869452946807680d4308011550011520574094869452946807680d430858af5ebd7a35574094869452946807680d4308c2166cc11644574094869452946807680d4308faa44ffaa43b574094869452946807680d4308ec973b09055a574094869452946807680d430870a73f6201e7564094869452946807680d43080465ef6b42d0564094869452946807680d4308c2166cc116d456409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_raw_obs_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308c4637115dc6cf23f94869452946807680d430825c30ff14367f23f94869452946807680d4308cb2cc4946264f23f94869452946807680d430841e891a0e66df23f94869452946807680d43082ed95aeff567f23f94869452946807680d43083b93b6cee890f23f94869452946807680d4308e6f6155c6570f33f94869452946807680d43080e50e0d09e88f23f94869452946807680d430838a3ddd9b995f23f94869452946807680d430868f1be55f62ef23f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_inference_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308e68ecbda52fc024094869452946807680d430836a7ee5664f8024094869452946807680d4308977ab91c02f7024094869452946807680d43088ae99ecf2cff024094869452946807680d43085c65048357fa024094869452946807680d43084df1def6ea15034094869452946807680d43080c5331aef6b3034094869452946807680d4308e2989223aadf024094869452946807680d4308752f53598d01034094869452946807680d430884873f9a1bca02409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_action_processing_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308806fd2709cc5cc3f94869452946807680d4308d2a2255dabb6cc3f94869452946807680d43081bf4c3d619adcc3f94869452946807680d430853643d6c63c4cc3f94869452946807680d43080572949010b8cc3f94869452946807680d430869d37f5221eacc3f94869452946807680d43081baf530bb102ce3f94869452946807680d430820851639b3f7cc3f94869452946807680d4308dd7316cee119cd3f94869452946807680d43085da75695ae74cc3f9486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_wait_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308a435853d89d4074094869452946807680d430809ff84c99dd0074094869452946807680d43084a42f8a0a0cd074094869452946807680d4308dd5198e148cf074094869452946807680d4308c2b9499174c7074094869452946807680d4308cc2769015ce5074094869452946807680d43089055d593b8a1084094869452946807680d43082d37f2386173074094869452946807680d4308a36f2893c189074094869452946807680d4308fec63f35c13407409486945294652e\"\n      }\n    },\n    \"sampler_results/sampler_perf/mean_env_render_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"info/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d516c4d206e4d6e6f4dbc704d0a72652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dcb654d19674d67684db5694d036b4d516c4d206e4d6e6f4dbc704d0a72652e\"\n      }\n    },\n    \"timers/load_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b058694529428473fd1db22d0e56042473fd10624dd2f1aa0473fd374bc6a7ef9db473fd3b645a1cac083473fd3f7ced916872b652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428473fd2b020c49ba5e3473fd3c6a7ef9db22d473fd4ac083126e979473fd072b020c49ba6473fd29fbe76c8b439473fd1db22d0e56042473fd10624dd2f1aa0473fd374bc6a7ef9db473fd3b645a1cac083473fd3f7ced916872b652e\"\n      }\n    },\n    \"timers/load_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b05869452942847412c06a7fae147ae47412d594ec28f5c29474129a982b22d0e5647412967ce245a1cac4741291332b2b020c5652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847412ac7ada6e978d547412941355eb851ec4741282718e353f7cf47412e6d96b0a3d70a47412ad496d6872b0247412c06a7fae147ae47412d594ec28f5c29474129a982b22d0e5647412967ce245a1cac4741291332b2b020c5652e\"\n      }\n    },\n    \"timers/learn_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740389b645a1cac0847403987ae147ae1484740392147ae147ae14740390f1a9fbe76c9474039fcac083126e9652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a869452942847403953b645a1cac147403ace147ae147ae4740397a5e353f7cee474039c872b020c49c474038b916872b020c4740389b645a1cac0847403987ae147ae1484740392147ae147ae14740390f1a9fbe76c9474039fcac083126e9652e\"\n      }\n    },\n    \"timers/learn_throughput\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740c451d6e978d4fe4740c395ce978d4fdf4740c3e58ba5e353f84740c3f3fcac0831274740c33d853f7ced91652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284740c3bde9374bc6a84740c2a74c28f5c28f4740c39ff6e978d4fe4740c36499ba5e353f4740c4395a9fbe76c94740c451d6e978d4fe4740c395ce978d4fdf4740c3e58ba5e353f84740c3f3fcac0831274740c33d853f7ced91652e\"\n      }\n    },\n    \"timers/synch_weights_time_ms\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005954f000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284740195f3b645a1cac47400bae147ae147ae474015b126e978d4fe474016322d0e56041947401c178d4fdf3b64652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005957c000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a8694529428474015449ba5e353f847401a6a7ef9db22d1474016072b020c49ba4740155604189374bc474016fdf3b645a1cb4740195f3b645a1cac47400bae147ae147ae474015b126e978d4fe474016322d0e56041947401c178d4fdf3b64652e\"\n      }\n    },\n    \"counters/last_target_update_ts\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005953b000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059554000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284a705801004a5a5c01004a446001004a2e6401004a186801004a026c01004aeb6f01004ad57301004abf7701004aa97b0100652e\"\n      }\n    },\n    \"counters/num_target_updates\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059531000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294284d516c4d206e4d6e6f4dbc704d0a72652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059540000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294284dcb654d19674d67684db5694d036b4d516c4d206e4d6e6f4dbc704d0a72652e\"\n      }\n    },\n    \"info/learner/default_policy/mean_td_error\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a0d7a3424094869452946807680d430800000000157a444094869452946807680d4308000000c0c2aa3c4094869452946807680d4308000000c00a84444094869452946807680d430800000060e9a942409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e0b91d434094869452946807680d4308000000807563444094869452946807680d430800000000bda5424094869452946807680d430800000040d51b484094869452946807680d4308000000c04d12434094869452946807680d4308000000a0d7a3424094869452946807680d430800000000157a444094869452946807680d4308000000c0c2aa3c4094869452946807680d4308000000c00a84444094869452946807680d430800000060e9a942409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_agent_steps_trained\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d4308000000000000704094869452946807680d430800000000000070409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/num_grad_updates_lifetime\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000004014db4094869452946807680d4308000000000088db4094869452946807680d43080000000080dbdb4094869452946807680d430800000000002fdc4094869452946807680d4308000000008082dc409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000c072d94094869452946807680d43080000000040c6d94094869452946807680d430800000000c019da4094869452946807680d430800000000406dda4094869452946807680d430800000000c0c0da4094869452946807680d4308000000004014db4094869452946807680d4308000000000088db4094869452946807680d43080000000080dbdb4094869452946807680d430800000000002fdc4094869452946807680d4308000000008082dc409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/diff_num_grad_updates_vs_sampler_policy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000014db4094869452946807680d430800000000c087db4094869452946807680d43080000000040dbdb4094869452946807680d430800000000c02edc4094869452946807680d4308000000004082dc409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000008072d94094869452946807680d43080000000000c6d94094869452946807680d4308000000008019da4094869452946807680d430800000000006dda4094869452946807680d43080000000080c0da4094869452946807680d4308000000000014db4094869452946807680d430800000000c087db4094869452946807680d43080000000040dbdb4094869452946807680d430800000000c02edc4094869452946807680d4308000000004082dc409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/allreduce_latency\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d4308000000000000000094869452946807680d430800000000000000009486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/grad_gnorm\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000008dfe9d3f94869452946807680d4308000000e0facabf3f94869452946807680d430800000060e023e93f94869452946807680d430800000040907cc43f94869452946807680d4308000000e05562ec3f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000b749e33f94869452946807680d4308000000c09930cc3f94869452946807680d430800000000e843d43f94869452946807680d4308000000e030b1cd3f94869452946807680d430800000040bd4fe43f94869452946807680d4308000000008dfe9d3f94869452946807680d4308000000e0facabf3f94869452946807680d430800000060e023e93f94869452946807680d430800000040907cc43f94869452946807680d4308000000e05562ec3f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/actor_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e07c095c4094869452946807680d4308000000003d515c4094869452946807680d430800000000808c5c4094869452946807680d4308000000205cce5c4094869452946807680d430800000040c5e65c409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000008088dc5a4094869452946807680d430800000040150a5b4094869452946807680d43080000004072615b4094869452946807680d4308000000a0238f5b4094869452946807680d43080000006018c15b4094869452946807680d4308000000e07c095c4094869452946807680d4308000000003d515c4094869452946807680d430800000000808c5c4094869452946807680d4308000000205cce5c4094869452946807680d430800000040c5e65c409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/critic_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000bee3f43f94869452946807680d4308000000c09746f73f94869452946807680d4308000000408f73f03f94869452946807680d430800000080416df73f94869452946807680d43080000006034d0f43f9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080386af63f94869452946807680d4308000000806ec4f63f94869452946807680d4308000000c0c13af53f94869452946807680d430800000020a4fefa3f94869452946807680d4308000000007de2f53f94869452946807680d430800000000bee3f43f94869452946807680d4308000000c09746f73f94869452946807680d4308000000408f73f03f94869452946807680d430800000080416df73f94869452946807680d43080000006034d0f43f9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_loss\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000000a70bc3f94869452946807680d430800000080d205de3f94869452946807680d4308000000a01759074094869452946807680d4308000000207c2ee3bf94869452946807680d430800000000637e0a409486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000e098f101c094869452946807680d43080000004016b5ea3f94869452946807680d43080000002086d3f23f94869452946807680d4308000000009d41ebbf94869452946807680d4308000000e0eef502c094869452946807680d4308000000000a70bc3f94869452946807680d430800000080d205de3f94869452946807680d4308000000a01759074094869452946807680d4308000000207c2ee3bf94869452946807680d430800000000637e0a409486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430483a8b83c94869452946807680d43048e78bb3c94869452946807680d43044a8cc73c94869452946807680d43049695c13c94869452946807680d43041ad8c33c9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304b247c63c94869452946807680d4304432bb93c94869452946807680d4304ac53c73c94869452946807680d43041e51d03c94869452946807680d4304abc4c33c94869452946807680d430483a8b83c94869452946807680d43048e78bb3c94869452946807680d43044a8cc73c94869452946807680d43049695c13c94869452946807680d43041ad8c33c9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/log_alpha_value\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304cab672c094869452946807680d43041dbf71c094869452946807680d43043ec06dc094869452946807680d43045cb16fc094869452946807680d430435f36ec09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624304ae286ec094869452946807680d4304898972c094869452946807680d430469d26dc094869452946807680d4304a4ff6ac094869452946807680d43048ff96ec094869452946807680d4304cab672c094869452946807680d43041dbf71c094869452946807680d43043ec06dc094869452946807680d43045cb16fc094869452946807680d430435f36ec09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/target_entropy\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c2000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"8005950d010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c094869452946807680d43040000a0c09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/policy_t\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000000f65dd4bf94869452946807680d4308000000c0046ed0bf94869452946807680d4308000000a07649cfbf94869452946807680d4308000000809ebad1bf94869452946807680d4308000000a0b03cd3bf9486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004059e9d4bf94869452946807680d4308000000c0efecd4bf94869452946807680d4308000000001370d4bf94869452946807680d4308000000c087b1d4bf94869452946807680d4308000000401963d3bf94869452946807680d430800000000f65dd4bf94869452946807680d4308000000c0046ed0bf94869452946807680d4308000000a07649cfbf94869452946807680d4308000000809ebad1bf94869452946807680d4308000000a0b03cd3bf9486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/mean_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000060c0005cc094869452946807680d4308000000e0f9495cc094869452946807680d4308000000e00c8c5cc094869452946807680d43080000006064c25cc094869452946807680d43080000008094e25cc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494624308000000a032d15ac094869452946807680d43080000008050085bc094869452946807680d4308000000800f5a5bc094869452946807680d4308000000a0e4845bc094869452946807680d4308000000007ebc5bc094869452946807680d430800000060c0005cc094869452946807680d4308000000e0f9495cc094869452946807680d4308000000e00c8c5cc094869452946807680d43080000006064c25cc094869452946807680d43080000008094e25cc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/max_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000040905d5ac094869452946807680d43080000000004955ac094869452946807680d4308000000c08ab85ac094869452946807680d430800000000b2e85ac094869452946807680d4308000000404c605bc09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000004048f558c094869452946807680d4308000000e09e4c59c094869452946807680d4308000000e08e8559c094869452946807680d43080000000052df59c094869452946807680d43080000008006005ac094869452946807680d430800000040905d5ac094869452946807680d43080000000004955ac094869452946807680d4308000000c08ab85ac094869452946807680d430800000000b2e85ac094869452946807680d4308000000404c605bc09486945294652e\"\n      }\n    },\n    \"info/learner/default_policy/learner_stats/min_q\": {\n      \"5\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595d6000000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0586945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b00749462430800000080802f5dc094869452946807680d4308000000200a805dc094869452946807680d4308000000807aab5dc094869452946807680d4308000000c020f25dc094869452946807680d43080000006007245ec09486945294652e\"\n      },\n      \"10\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059535010000000000008c0b636f6c6c656374696f6e73948c056465717565949394294b0a86945294288c156e756d70792e636f72652e6d756c74696172726179948c067363616c61729493948c056e756d7079948c0564747970659493948c02663894898887945294284b038c013c944e4e4e4affffffff4affffffff4b0074946243080000002030fc5bc094869452946807680d43080000000084335cc094869452946807680d4308000000a0d97b5cc094869452946807680d4308000000c00eca5cc094869452946807680d4308000000e0dcf95cc094869452946807680d430800000080802f5dc094869452946807680d4308000000200a805dc094869452946807680d4308000000807aab5dc094869452946807680d4308000000c020f25dc094869452946807680d43080000006007245ec09486945294652e\"\n      }\n    }\n  },\n  \"export_formats\": [],\n  \"status\": \"RUNNING\",\n  \"start_time\": 1675949679.1124773,\n  \"relative_logdir\": \"SAC_darm_DarmSFHand-v0_80340_00000_0_2023-02-09_14-34-39\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_filename\": null,\n  \"pickled_error_filename\": null,\n  \"trial_name_creator\": null,\n  \"trial_dirname_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"experiment_dir_name\": \"Test_DARMSF_DELTA_TARGET\",\n  \"saving_to\": null,\n  \"sync_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059581000000000000008c0f7261792e74756e652e73796e636572948c0a53796e63436f6e6669679493942981947d94288c0a75706c6f61645f646972944e8c0673796e636572948c046175746f948c1273796e635f6f6e5f636865636b706f696e7494888c0b73796e635f706572696f64944d2c018c0c73796e635f74696d656f7574944d080775622e\"\n  },\n  \"custom_syncer\": null,\n  \"checkpoint_config\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595bd000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e\"\n  },\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059587020000000000008c257261792e74756e652e657865637574696f6e2e636865636b706f696e745f6d616e61676572948c125f436865636b706f696e744d616e616765729493942981947d94288c145f636865636b706f696e745f7374726174656779948c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c12747261696e696e675f697465726174696f6e948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875628c155f6c61746573745f636865636b706f696e745f6964944b008c1a5f746f705f7065727369737465645f636865636b706f696e7473945d948c1a5f626573745f7065727369737465645f636865636b706f696e74944e8c1c5f6c61746573745f7065727369737465645f636865636b706f696e74944e8c195f6c61746573745f6d656d6f72795f636865636b706f696e74944e8c185f636865636b706f696e74735f746f5f636c65616e5f7570948f948c195f6e65776573745f6d656d6f72795f636865636b706f696e74948c247261792e6169722e5f696e7465726e616c2e636865636b706f696e745f6d616e61676572948c125f547261636b6564436865636b706f696e749493942981947d94288c0b6469725f6f725f64617461944e8c026964944e8c0c73746f726167655f6d6f646594681b8c11436865636b706f696e7453746f726167659493944b01859452948c076d657472696373947d948c076e6f64655f6970944e756275622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 0,\n  \"num_restore_failures\": 0,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false,\n  \"__relative_checkpoint_dirs\": []\n}"
  ],
  "runner_data": {
    "_insufficient_resources_manager": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059596000000000000008c317261792e74756e652e657865637574696f6e2e696e73756666696369656e745f7265736f75726365735f6d616e61676572948c1d5f496e73756666696369656e745265736f75726365734d616e616765729493942981947d94288c185f6e6f5f72756e6e696e675f747269616c735f73696e6365944affffffff8c0f5f6c6173745f747269616c5f6e756d944affffffff75622e"
    },
    "_max_pending_trials": 16,
    "_metric": null,
    "_total_time": 4664.705418109894,
    "_iteration": 988,
    "_has_errored": false,
    "_fail_fast": false,
    "_print_trial_errors": true,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "8005952c000000000000008c157261792e74756e652e73746f707065722e6e6f6f70948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1675949678.8755546,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2023-02-09_14-34-38",
    "checkpoint_file": "/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-09_14-34-38.json",
    "_checkpoint_period": "auto",
    "_trial_checkpoint_config": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "800595ab000000000000008c0e7261792e6169722e636f6e666967948c10436865636b706f696e74436f6e6669679493942981947d94288c0b6e756d5f746f5f6b656570944e8c1a636865636b706f696e745f73636f72655f617474726962757465948c00948c16636865636b706f696e745f73636f72655f6f72646572948c036d6178948c14636865636b706f696e745f6672657175656e6379944b008c11636865636b706f696e745f61745f656e64948875622e"
    },
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1675949678.8755546,
    "timestamp": 1675954365.5734942
  }
}