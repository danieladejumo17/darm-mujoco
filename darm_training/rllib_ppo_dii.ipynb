{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799cc8cb-e1a5-4a58-a984-efc11326303e",
   "metadata": {},
   "source": [
    "## Installation and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23a9220-2972-4248-9c15-0f55802c4359",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/darm-mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f874e73d-f740-45bf-bed4-117e846ac0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/darm-mujoco'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure env variables\n",
    "\n",
    "# TODO: change path\n",
    "import os\n",
    "os.environ[\"DARM_MUJOCO_PATH\"] = \"/workspace/darm-mujoco\"\n",
    "os.getenv('DARM_MUJOCO_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1faaeaf7-f077-4e44-a4aa-4e81374219e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "Copyright (C) 2017 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if GCC is installed\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95b2f04-9248-4bc8-91dd-334075cf0646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sudo] password for daniel: \n",
      "[sudo] password for daniel: \n"
     ]
    }
   ],
   "source": [
    "# Install GCC if absent\n",
    "!sudo apt update\n",
    "!sudo apt install build-essential -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f22778-56c3-4fea-a3de-6e4ac487ea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setup Mujoco for gym - If needed\n",
    "# !apt-get install -y \\\n",
    "#     libgl1-mesa-dev \\\n",
    "#     libgl1-mesa-glx \\\n",
    "#     libglew-dev \\\n",
    "#     libosmesa6-dev \\\n",
    "#     software-properties-common\n",
    "\n",
    "# !apt-get install -y patchelf\n",
    "\n",
    "# !pip install gym\n",
    "\n",
    "# !pip install free-mujoco-py\n",
    "\n",
    "# import mujoco_py\n",
    "# import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b21d33a5-8591-4a1c-891e-a71073ff1c91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray[rllib] in /home/daniel/miniconda3/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: torch in /home/daniel/miniconda3/lib/python3.8/site-packages (1.13.1)\n",
      "Requirement already satisfied: pyyaml in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (6.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (8.1.3)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.23.4)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.51.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.0.4)\n",
      "Requirement already satisfied: filelock in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.8.2)\n",
      "Requirement already satisfied: aiosignal in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.1)\n",
      "Requirement already satisfied: jsonschema in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.17.3)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (20.17.1)\n",
      "Requirement already satisfied: attrs in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (22.2.0)\n",
      "Requirement already satisfied: requests in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.27.1)\n",
      "Requirement already satisfied: frozenlist in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.3.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.20.1)\n",
      "Requirement already satisfied: scikit-image in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.19.3)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (2.5.1)\n",
      "Requirement already satisfied: matplotlib!=3.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (3.6.1)\n",
      "Requirement already satisfied: scipy in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.9.2)\n",
      "Requirement already satisfied: tabulate in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.9.0)\n",
      "Requirement already satisfied: typer in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.7.0)\n",
      "Requirement already satisfied: gym<0.24.0,>=0.21.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.21.0)\n",
      "Requirement already satisfied: lz4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (4.0.2)\n",
      "Requirement already satisfied: pandas in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (1.5.2)\n",
      "Requirement already satisfied: rich in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (12.6.0)\n",
      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from ray[rllib]) (0.1.8)\n",
      "Requirement already satisfied: typing_extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gym<0.24.0,>=0.21.0->ray[rllib]) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (4.37.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from matplotlib!=3.4.3->ray[rllib]) (9.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib!=3.4.3->ray[rllib]) (1.12.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (0.3.6)\n",
      "Requirement already satisfied: platformdirs<3,>=2.4 in /home/daniel/miniconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[rllib]) (2.6.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (1.3.10)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (0.19.2)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from jsonschema->ray[rllib]) (5.10.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema->ray[rllib]) (3.11.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from pandas->ray[rllib]) (2022.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests->ray[rllib]) (3.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (2.13.0)\n",
      "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from rich->ray[rllib]) (0.9.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.8.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (1.4.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2022.10.10)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from scikit-image->ray[rllib]) (2.23.0)\n",
      "Requirement already satisfied: wandb in /home/daniel/miniconda3/lib/python3.8/site-packages (0.13.10)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.12.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: setproctitle in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: PyYAML in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: setuptools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (65.6.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: typing-extensions in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (4.4.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (2.27.1)\n",
      "Requirement already satisfied: pathtools in /home/daniel/miniconda3/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from docker-pycreds>=0.4.0->wandb) (1.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: tensorflow_probability in /home/daniel/miniconda3/lib/python3.8/site-packages (0.19.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (2.2.0)\n",
      "Requirement already satisfied: absl-py in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (1.23.4)\n",
      "Requirement already satisfied: gast>=0.3.2 in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.5.3)\n",
      "Requirement already satisfied: decorator in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (5.1.1)\n",
      "Requirement already satisfied: dm-tree in /home/daniel/miniconda3/lib/python3.8/site-packages (from tensorflow_probability) (0.1.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install ray[rllib] torch\n",
    "!pip install wandb\n",
    "!pip install tensorflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773175aa-0f05-4ed7-80e3-bd401c43d56d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco\n",
      "running install\n",
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "/home/daniel/miniconda3/lib/python3.8/site-packages/setuptools/command/easy_install.py:144: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing darm_gym_env.egg-info/PKG-INFO\n",
      "writing dependency_links to darm_gym_env.egg-info/dependency_links.txt\n",
      "writing requirements to darm_gym_env.egg-info/requires.txt\n",
      "writing top-level names to darm_gym_env.egg-info/top_level.txt\n",
      "reading manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "writing manifest file 'darm_gym_env.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_sf_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/__init__.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/multi_darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/darm_gym.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "copying build/lib/darm_gym_env/env_test.py -> build/bdist.linux-x86_64/egg/darm_gym_env\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_sf_gym.py to darm_sf_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/multi_darm_gym.py to multi_darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/darm_gym.py to darm_gym.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/darm_gym_env/env_test.py to env_test.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying darm_gym_env.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "darm_gym_env.__pycache__.darm_gym.cpython-38: module references __file__\n",
      "darm_gym_env.__pycache__.multi_darm_gym.cpython-38: module references __file__\n",
      "creating 'dist/darm_gym_env-0.0.1-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing darm_gym_env-0.0.1-py3.8.egg\n",
      "removing '/home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg' (and everything under it)\n",
      "creating /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Extracting darm_gym_env-0.0.1-py3.8.egg to /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "darm-gym-env 0.0.1 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /home/daniel/miniconda3/lib/python3.8/site-packages/darm_gym_env-0.0.1-py3.8.egg\n",
      "Processing dependencies for darm-gym-env==0.0.1\n",
      "Searching for gym==0.21.0\n",
      "Best match: gym 0.21.0\n",
      "Adding gym 0.21.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for mujoco==2.2.2\n",
      "Best match: mujoco 2.2.2\n",
      "Adding mujoco 2.2.2 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for cloudpickle==2.2.0\n",
      "Best match: cloudpickle 2.2.0\n",
      "Adding cloudpickle 2.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for numpy==1.23.4\n",
      "Best match: numpy 1.23.4\n",
      "Adding numpy 1.23.4 to easy-install.pth file\n",
      "Installing f2py script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3 script to /home/daniel/miniconda3/bin\n",
      "Installing f2py3.8 script to /home/daniel/miniconda3/bin\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for PyOpenGL==3.1.6\n",
      "Best match: PyOpenGL 3.1.6\n",
      "Adding PyOpenGL 3.1.6 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for glfw==2.5.5\n",
      "Best match: glfw 2.5.5\n",
      "Adding glfw 2.5.5 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Searching for absl-py==1.2.0\n",
      "Best match: absl-py 1.2.0\n",
      "Adding absl-py 1.2.0 to easy-install.pth file\n",
      "\n",
      "Using /home/daniel/miniconda3/lib/python3.8/site-packages\n",
      "Finished processing dependencies for darm-gym-env==0.0.1\n"
     ]
    }
   ],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07e3679f-78c0-46dd-a387-c2b63c39958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if mujoco import is successful\n",
    "import mujoco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e486c3f-2352-4846-8c0f-0933541cf336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If mujoco import fails, update pandas and restart runtime\n",
    "!pip install pandas -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7437812-150d-4a05-9747-faff614ae31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If GLFW is absent\n",
    "# %%bash\n",
    "# sudo apt-get install libglfw3 -y\n",
    "# sudo apt-get install libglfw3-dev -y\n",
    "# pip install --user glfw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c7e52e-b467-4d91-8fe9-d1035e51c932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "from ray import air, tune\n",
    "from ray.air import session\n",
    "from ray.air.integrations.wandb import setup_wandb\n",
    "from ray.air.integrations.wandb import WandbLoggerCallback\n",
    "\n",
    "import os\n",
    "import gym\n",
    "from darm_gym_env import DARMEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5333384d-540b-4760-931f-6cd3c0a65e8c",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "    - Change single_finger=False (In env register and config)\n",
    "    - Change run_local_dir\n",
    "    - Change run name, tags, and notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2cb250-242a-446f-a47e-2c8438d64ea8",
   "metadata": {},
   "source": [
    "## Register Environment with RLlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ee4bf2a-d82c-4aaa-b278-f11a080e28af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_env(env_config):\n",
    "    env = gym.wrappers.TimeLimit(env=DARMEnv(digits=[\"ii\"],\n",
    "                                             start_state_file=\"DARMHand_SF_start_state.npy\"),\n",
    "                                 max_episode_steps=200)\n",
    "    # env = gym.wrappers.TransformObservation(env, lambda obs: obs*100)\n",
    "    return env\n",
    "\n",
    "env_creator = lambda env_config: make_env(env_config)\n",
    "register_env(\"darm/DarmHand-v0\", env_creator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049729f3-c175-4d9c-b449-43af66f121a5",
   "metadata": {},
   "source": [
    "## Configure and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0ed8ba-4f6b-47f9-b0e7-37d0eec71647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# change: rollout_workers\n",
    "# change: num_envs_per_worker\n",
    "# change: gpu\n",
    "\n",
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(\n",
    "        env=\"darm/DarmHand-v0\"\n",
    "    )\n",
    "    .training(\n",
    "        gamma=0.995,\n",
    "        lambda_=0.95,\n",
    "        clip_param=0.2,\n",
    "        kl_coeff=1.0,\n",
    "        num_sgd_iter=20,\n",
    "        lr=0.0001,\n",
    "        sgd_minibatch_size=32768,\n",
    "        train_batch_size=320000,\n",
    "        model={\n",
    "            'fcnet_hiddens': [64, 256, 256, 64], # [32, 256, 256, 64],\n",
    "            'fcnet_activation': 'relu'\n",
    "        }\n",
    "        # model  //={\"free_log_std\": true}, {\"use_lstm\": True},\n",
    "    )\n",
    "    .rollouts(\n",
    "        num_rollout_workers=3,#121,\n",
    "        num_envs_per_worker=4,\n",
    "        # rollout_fragment_length=1,\n",
    "        recreate_failed_workers=True,\n",
    "        num_consecutive_worker_failures_tolerance=10,\n",
    "        restart_failed_sub_environments=True,\n",
    "        batch_mode=\"complete_episodes\",     # watch out\n",
    "        observation_filter=\"MeanStdFilter\"  # watch out\n",
    "    )\n",
    "    .resources(num_gpus=0)#1)\n",
    "    # .evaluation(evaluation_interval=100) # For 1000 timesteps iter; 100 evals\n",
    "    .framework(framework=\"torch\")\n",
    ")\n",
    "# config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f0fa8e-5023-44c3-a9f7-8a6b041617a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# change: run name\n",
    "# change: notes\n",
    "# change: tags\n",
    "# change: wandb config\n",
    "\n",
    "env_tag = \"dii\"\n",
    "run_name = f\"RLlib_SAC_{env_tag}_position\"\n",
    "\n",
    "notes = \"\"\"\n",
    "- The environment was updated such that the target is within a range from the start point\n",
    "- Velocity penalty was removed and only effort penalty was used\n",
    "- The reward function was updated according to the reach task reward used in facebookresearch/myosuite [https://github.com/facebookresearch/myosuite/blob/main/myosuite/envs/myo/reach_v0.py]\n",
    "- The done signal is trigerred only when the fingertip goes beyond a threshold. The episode continues to the maximum timestep otherwise.\n",
    "- The friction and damping coefficient of the environment is updated. Values are inspired from Deepmind's Mujoco Menagerie [https://github.com/deepmind/mujoco_menagerie/blob/main/shadow_hand/right_hand.xml]\n",
    "- The range of action from the model was changed to [-1, 1]. This action is mapped to the actual action sent to mujoco e.g [0, 2]]. This change is inspired from values used in OpenAI's Gym Mujoco environments.\n",
    "- max_episode_steps was updated to 200.\n",
    "- Velocity vector (size [3,]) was added to observation. Observation size is now (9,)\n",
    "- Action range was increased to [0, 5]\n",
    "<Changes: ID 3>\n",
    "- Observation warpper to scale observation from m and m/s to cm and cm/s was applied\n",
    "<Changes: ID 4>\n",
    "- Max Tension for Digitorum Extensor Communis was increased to 10\n",
    "- FIXED: Velocity Observation from (prev_pos - new_pos)/time to (new_pos - prev_pos)/time\n",
    "- FIXED: Removed weight of 1 from 'sparse', 'solved', and 'done' in reward weighting\n",
    "- Reduced max_target_th to 5*0.004 m. I.e. 20 mm\n",
    "- Increased the number of envs to 24 to experiment with scaling the training\n",
    "<Changes: ID 5>\n",
    "- Updated Env Definition\n",
    "    - Updated observation space. Increased observation of the state\n",
    "    including target pose (7,); kinematic chain (12,) or (9,) for digit I;\n",
    "    velocity (3,); and contacts with other fingers and the palm (6,)\n",
    "    - Target is now specified as position and orientation of fingertip\n",
    "    - Reward function now includes penalty terms for the angular\n",
    "    displacement and contact with other fingers\n",
    "    - Action space is still the continuous torque value applied to each\n",
    "    tendon\n",
    "    - Distance parameters passed into the environment and returned from the\n",
    "    environment are now all specified in cm.\n",
    "    - Environment modified in such a way that any combination of the 5\n",
    "    digits can be used\n",
    "    - Start states file now needs to be saved in the start_states sub-folder\n",
    "    of the darm_gym_env directory, and passed as a parameter when creating\n",
    "    the environment. This alows for the dynamics of combining different\n",
    "    digits.\n",
    "<Changes: ID 6>\n",
    "- New Position Servo Environment\n",
    "- Changed the action space to gym.spaces.MultiBinary\n",
    "\n",
    "- Digit II; No Wrist Environment\n",
    "- This run was trained on vast_ai using RLlib's SAC algorithm.\n",
    "\"\"\"\n",
    "\n",
    "tags = [\"digit_ii\", \"ppo\", \"rllib\", \"vast_ai\", \"position_servo\"]\n",
    "\n",
    "\n",
    "\n",
    "wandb_init = dict(\n",
    "    save_code=True,\n",
    "    resume=True,\n",
    "    config={\n",
    "        \"env\": config.env,\n",
    "        \"num_rollout_workers\": config.num_rollout_workers,\n",
    "        \"num_envs_per_worker\": config.num_envs_per_worker,\n",
    "        \"recreate_failed_workers\": config.recreate_failed_workers,\n",
    "        \"num_consecutive_worker_failures_tolerance\": config.num_consecutive_worker_failures_tolerance,\n",
    "        \"restart_failed_sub_environments\": config.restart_failed_sub_environments,\n",
    "        \"num_gpus\": config.num_gpus,\n",
    "        \"framework\": config.framework_str,\n",
    "        \n",
    "        \"stop_episode_reward_mean\": 1_300,\n",
    "        \"run_local_dir\": f\"{os.getenv('DARM_MUJOCO_PATH')}/darm_training/results/{env_tag}\",\n",
    "        \n",
    "        \"checkpoint_at_end\": True,\n",
    "        \"checkpoint_score_attribute\": \"episode_reward_mean\",  # or leave to save last chkpts\n",
    "        \"checkpoint_score_order\": \"max\",\n",
    "        \"checkpoint_frequency\": 50,   # iterations\n",
    "        \"num_checkpoints_to_keep\": 3,\n",
    "        \"save_checkpoints_to_wandb\": True\n",
    "    },\n",
    "    tags=tags,\n",
    "    notes=notes,\n",
    "    name=run_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d7468b3-f377-4c7f-a0c3-6dec032fdc37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daniel/DARM/darm_mujoco/darm_training\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a16938-b39a-4a1f-a1a2-ec3cd1d76fbf",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "727ee5b8-0cc3-4831-91ee-34514946c66a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:36:46,420\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-04-09 00:37:09</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:21.37        </td></tr>\n",
       "<tr><td>Memory:      </td><td>5.5/7.5 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/1.21 GiB heap, 0.0/0.6 GiB objects\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                     </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_darm_DarmHand-v0_3ac57_00000</td><td style=\"text-align: right;\">           1</td><td>/home/daniel/DARM/darm_mujoco/darm_training/results/dii/RLlib_SAC_dii_position/PPO_darm_DarmHand-v0_3ac57_00000_0_2023-04-09_00-36-48/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_darm_DarmHand-v0_3ac57_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:36:52,111\tWARNING algorithm_config.py:488 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:36:52,433\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:36:56,400 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 208240640; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m Loaded XML file successfully\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m Number of tendon position actuators: 5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m 2023-04-09 00:37:00,557\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11322, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa2493258b0>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11322)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m 2023-04-09 00:37:00,657\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m 2023-04-09 00:37:00,672\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11320, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f959687c850>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=11320)\u001b[0m Number of tendon position actuators: 5\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:37:00,894\tERROR trial_runner.py:1088 -- Trial PPO_darm_DarmHand-v0_3ac57_00000: Error processing event.\n",
      "ray.tune.error._TuneNoNextExecutorEventError: Traceback (most recent call last):\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 1070, in get_next_executor_event\n",
      "    future_result = ray.get(ready_future)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\n",
      "    self.add_workers(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\n",
      "    raise result.get()\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\n",
      "    result = ray.get(r)\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11320, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f959687c850>)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "    self._build_policy_map(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "    self.policy_map.create_policy(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "    policy = create_policy_for_framework(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "    return policy_class(observation_space, action_space, merged_config)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "    TorchPolicyV2.__init__(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "    model, dist_class = self._init_model_and_dist_class()\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "    dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "    self.workers = WorkerSet(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\n",
      "    raise e.args[0].args[2]\n",
      "NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:37:00,872\tERROR actor_manager.py:486 -- Ray error, taking actor 1 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11320, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f959687c850>)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:37:00,872\tERROR actor_manager.py:486 -- Ray error, taking actor 2 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11321, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb2c4141a00>)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:37:00,872\tERROR actor_manager.py:486 -- Ray error, taking actor 3 out of service. The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11322, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fa2493258b0>)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m 2023-04-09 00:37:00,876\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.add_workers(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise result.get()\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     result = ray.get(r)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11320, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f959687c850>)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m \n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m \u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     super().__init__(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     self.workers = WorkerSet(\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m     raise e.args[0].args[2]\n",
      "\u001b[2m\u001b[36m(PPO pid=11183)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m 2023-04-09 00:37:00,866\tERROR worker.py:763 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11321, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb2c4141a00>)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     self._build_policy_map(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     self.policy_map.create_policy(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     policy = create_policy_for_framework(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     return policy_class(observation_space, action_space, merged_config)\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     TorchPolicyV2.__init__(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     model, dist_class = self._init_model_and_dist_class()\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m   File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m     raise NotImplementedError(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m NotImplementedError: Unsupported args: MultiBinary(5) None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=11321)\u001b[0m Number of tendon position actuators: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/dii/RLlib_SAC_dii_position/PPO_darm_DarmHand-v0_3ac57_00000_0_2023-04-09_00-36-48/wandb/run-20230409_003651-3ac57_00000</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/3ac57_00000' target=\"_blank\">RLlib_SAC_dii_position</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/3ac57_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/3ac57_00000</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:06,409 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 207908864; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">RLlib_SAC_dii_position</strong> at: <a href='https://wandb.ai/danieladejumo/DARM/runs/3ac57_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/3ac57_00000</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230409_003651-3ac57_00000/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                      </th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_darm_DarmHand-v0_3ac57_00000</td><td>3ac57_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 00:37:09,340\tERROR ray_trial_executor.py:118 -- An exception occurred when trying to stop the Ray actor:Traceback (most recent call last):\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/execution/ray_trial_executor.py\", line 109, in _post_stop_cleanup\n",
      "    ray.get(future, timeout=timeout)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/_private/worker.py\", line 2311, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 239, in _setup\n",
      "    self.add_workers(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 612, in add_workers\n",
      "    raise result.get()\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py\", line 473, in __fetch_result\n",
      "    result = ray.get(r)\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11320, ip=192.168.39.35, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f959687c850>)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 712, in __init__\n",
      "    self._build_policy_map(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1970, in _build_policy_map\n",
      "    self.policy_map.create_policy(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\", line 146, in create_policy\n",
      "    policy = create_policy_for_framework(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/policy.py\", line 126, in create_policy_for_framework\n",
      "    return policy_class(observation_space, action_space, merged_config)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py\", line 51, in __init__\n",
      "    TorchPolicyV2.__init__(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 88, in __init__\n",
      "    model, dist_class = self._init_model_and_dist_class()\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/torch_policy_v2.py\", line 453, in _init_model_and_dist_class\n",
      "    dist_class, logit_dim = ModelCatalog.get_action_dist(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 340, in get_action_dist\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=11183, ip=192.168.39.35, repr=PPO)\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 441, in __init__\n",
      "    super().__init__(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 169, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/algorithm.py\", line 566, in setup\n",
      "    self.workers = WorkerSet(\n",
      "  File \"/home/daniel/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\", line 191, in __init__\n",
      "    raise e.args[0].args[2]\n",
      "NotImplementedError: Unsupported args: MultiBinary(5) None\n",
      "\n",
      "2023-04-09 00:37:09,443\tERROR tune.py:758 -- Trials did not complete: [PPO_darm_DarmHand-v0_3ac57_00000]\n",
      "2023-04-09 00:37:09,444\tINFO tune.py:762 -- Total run time: 21.68 seconds (21.37 seconds for the tuning loop).\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:16,427 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 207917056; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:26,448 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210341888; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:36,467 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210341888; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:46,485 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210317312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:37:56,504 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210309120; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:38:06,522 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210309120; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:38:16,543 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210309120; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:38:26,561 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210305024; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-04-09 00:38:36,578 E 10923 10968] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-04-09_00-36-44_370111_10817 is over 95% full, available space: 210305024; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "sync_config = tune.SyncConfig()\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config.to_dict(),\n",
    "    run_config=air.RunConfig(\n",
    "        name=run_name,\n",
    "        sync_config=sync_config,\n",
    "        stop={\"episode_reward_mean\": wandb_init[\"config\"][\"stop_episode_reward_mean\"]},\n",
    "        \n",
    "        local_dir=wandb_init[\"config\"][\"run_local_dir\"],\n",
    "        checkpoint_config=air.CheckpointConfig(\n",
    "            checkpoint_at_end = wandb_init[\"config\"][\"checkpoint_at_end\"],\n",
    "            checkpoint_score_attribute = wandb_init[\"config\"][\"checkpoint_score_attribute\"],  # or leave to save last chkpts\n",
    "            checkpoint_score_order = wandb_init[\"config\"][\"checkpoint_score_order\"],\n",
    "            checkpoint_frequency = wandb_init[\"config\"][\"checkpoint_frequency\"],\n",
    "            num_to_keep = wandb_init[\"config\"][\"num_checkpoints_to_keep\"]\n",
    "        ),\n",
    "        callbacks=[\n",
    "                WandbLoggerCallback(project=\"DARM\", \n",
    "                                    api_key=\"392c8a47eb0658eb5c71190757a69110e2140f4a\",\n",
    "                                    save_checkpoints=wandb_init[\"config\"][\"save_checkpoints_to_wandb\"], \n",
    "                                    **wandb_init)\n",
    "            ],\n",
    "        )\n",
    ")\n",
    "\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e3264d3-86a3-430c-bae2-940f2da854d2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/DARM/darm_mujoco/darm_training/results/darm_sf_hand/test1_SF_RLlib_PPO'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-22 11:42:45,948 E 5245 5295] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-22_11-21-52_053720_4034 is over 95% full, available space: 707887104; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-22 11:42:55,966 E 5245 5295] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-22_11-21-52_053720_4034 is over 95% full, available space: 707854336; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# Ensure wandb is sysncing to cloud\n",
    "# cd to darm_training again if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed17fb23-77b1-4e35-95b7-a44b6e342691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.tuner.Tuner at 0x7f58802e9d00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "# change: experiment name\n",
    "\n",
    "# Restore Interrupted run\n",
    "tuner = tune.Tuner.restore(\n",
    "    f\"{wandb_init['config']['run_local_dir']}/{run_name}\",\n",
    "    resume_errored=True\n",
    ")\n",
    "tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "160c2790-f9ac-41cb-8198-d571d2c51332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7f5880280b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = tuner.get_results()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ace959cb-3e05-4caa-8dd9-f00bbab33eb0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The requested checkpoint is not available on this node, most likely because you are using Ray client or disabled checkpoint synchronization. To avoid this, enable checkpoint synchronization to cloud storage by specifying a `SyncConfig`. The checkpoint may be available on a different node - please check this location on worker nodes: /workspace/darm-mujoco/darm_training/results/SF_rllib_es_vast_ai_rew4/ES_darm_DarmSFHand-v0_e4270_00000_0_2023-02-14_22-57-01/checkpoint_000710\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Result(metrics={'episode_reward_mean': 24.031534, 'episode_len_mean': 100.0, 'timesteps_this_iter': 115260, 'info': {'weights_norm': 594.49335, 'grad_norm': 4.660049, 'update_ratio': 0.024672424, 'episodes_this_iter': 1234, 'episodes_so_far': 745896}, 'done': False, 'trial_id': 'e4270_00000', 'perf': {'cpu_util_percent': 60.725, 'ram_util_percent': 19.5}, 'experiment_tag': '0'}, error=None, log_dir=PosixPath('/home/daniel/DARM/darm_mujoco/darm_training/results/SF_rllib_es_vast_ai_rew4/ES_darm_DarmSFHand-v0_e4270_00000_0_2023-02-14_22-57-01'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best result based on a particular metric.\n",
    "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beca7170-c89a-402c-afb7-ce88cf5524b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the best checkpoint corresponding to the best result.\n",
    "best_checkpoint = best_result.checkpoint\n",
    "best_checkpoint\n",
    "# best_checkpoint = \"/home/daniel/DARM/darm_mujoco/darm_training/results/SF_rllib_es_vast_ai/ES_darm_DarmSFHand-v0_ba596_00000_0_2023-02-14_00-30-05/checkpoint_000100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c13525d9-27ad-4603-a317-f85efec9487c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/daniel/DARM/darm_mujoco/darm_training/results/SF_rllib_es_vast_ai_rew3/ES_darm_DarmSFHand-v0_37337_00000_0_2023-02-14_15-35-32/checkpoint_000200'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint._local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9e8a43-146c-4a5b-99b7-12384ff38b84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n",
      "2023-02-15 02:08:05,175\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:08:14,135 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145473536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "2023-02-15 02:08:18,054\tINFO es.py:401 -- Creating actors.\n",
      "2023-02-15 02:08:18,082\tINFO trainable.py:172 -- Trainable.setup took 16.976 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-02-15 02:08:18,097\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n",
      "2023-02-15 02:08:18,103\tINFO filter_manager.py:34 -- Synchronizing filters ...\n",
      "\u001b[2m\u001b[36m(Worker pid=27624)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(Worker pid=27624)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(Worker pid=27624)\u001b[0m 2023-02-15 02:08:23,178\tINFO policy.py:1147 -- Policy (worker=local) running on CPU.\n",
      "\u001b[2m\u001b[36m(Worker pid=27624)\u001b[0m 2023-02-15 02:08:23,178\tINFO torch_policy.py:184 -- Found 0 visible cuda devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Worker pid=27624)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Worker pid=27623)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(Worker pid=27623)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(Worker pid=27623)\u001b[0m 2023-02-15 02:08:23,736\tINFO policy.py:1147 -- Policy (worker=local) running on CPU.\n",
      "\u001b[2m\u001b[36m(Worker pid=27623)\u001b[0m 2023-02-15 02:08:23,736\tINFO torch_policy.py:184 -- Found 0 visible cuda devices.\n",
      "2023-02-15 02:08:23,959\tINFO filter_manager.py:55 -- Updating remote filters ...\n",
      "2023-02-15 02:08:23,969\tINFO trainable.py:790 -- Restored on 127.0.1.1 from checkpoint: /home/daniel/DARM/darm_mujoco/darm_training/results/SF_rllib_es_vast_ai_rew4/ES_darm_DarmSFHand-v0_e4270_00000_0_2023-02-14_22-57-01/checkpoint_000270\n",
      "2023-02-15 02:08:23,970\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 270, '_timesteps_total': 24334332, '_time_total': 916.8663566112518, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Worker pid=27623)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Worker pid=27625)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(Worker pid=27625)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(Worker pid=27625)\u001b[0m 2023-02-15 02:08:23,946\tINFO policy.py:1147 -- Policy (worker=local) running on CPU.\n",
      "\u001b[2m\u001b[36m(Worker pid=27625)\u001b[0m 2023-02-15 02:08:23,947\tINFO torch_policy.py:184 -- Found 0 visible cuda devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Worker pid=27625)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:08:24,140 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145403904; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:08:34,157 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145403904; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "# Get Algorithm from saved checkpoint\n",
    "# from ray.rllib.algorithms.algorithm import Algorithm\n",
    "# algo = Algorithm.from_checkpoint(best_checkpoint._local_path)\n",
    "# algo\n",
    "\n",
    "algo = config.build()\n",
    "algo.restore(best_checkpoint._local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cff7c5-f517-4287-9447-668320c35452",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 17:26:26,421\tINFO trial_runner.py:688 -- A local experiment checkpoint was found and will be used to restore the previous experiment state.\n",
      "2023-02-11 17:26:26,422\tINFO trial_runner.py:825 -- Using following checkpoint to resume: /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/experiment_state-2023-02-11_17-23-28.json\n",
      "2023-02-11 17:26:26,426\tWARNING trial_runner.py:830 -- Attempting to resume experiment from /home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET. This will ignore any new changes to the specification.\n",
      "2023-02-11 17:26:26,440\tINFO tune.py:653 -- TrialRunner resumed, ignoring new add_experiment but updating trial resources.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-11 17:29:20</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:54.01        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.3/7.5 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 4.0/4 CPUs, 0/0 GPUs, 0.0/1.72 GiB heap, 0.0/0.86 GiB objects\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td>RUNNING </td><td>192.168.152.36:15703</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         227.817</td><td style=\"text-align: right;\">13026</td><td style=\"text-align: right;\">-179.588</td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">               100</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:26,618 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061683200; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:30,934\tWARNING algorithm_config.py:488 -- Cannot create SACConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:31,413\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/wandb/run-20230211_172629-6a944_00000</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">Test_DARMSF_DELTA_TARGET</a></strong> to <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/DARM' target=\"_blank\">https://wandb.ai/danieladejumo/DARM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/DARM/runs/6a944_00000' target=\"_blank\">https://wandb.ai/danieladejumo/DARM/runs/6a944_00000</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:36,627 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061359616; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m Loaded XML file successfully\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15846)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15844)\u001b[0m 2023-02-11 17:26:38,825\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=15845)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m /home/daniel/miniconda3/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m   logger.warn(\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,232\tWARNING env.py:147 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,261\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:790 -- Restored on 192.168.152.36 from checkpoint: /tmp/checkpoint_tmp_7f50b6e15e2c473dba807bf1d398566d\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,442\tINFO trainable.py:799 -- Current state after restoring: {'_iteration': 11, '_timesteps_total': None, '_time_total': 113.04964661598206, '_episodes_total': 114}\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n",
      "\u001b[2m\u001b[36m(SAC pid=15703)\u001b[0m 2023-02-11 17:26:40,721\tWARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:46,634 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061335040; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:26:56,640 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:06,648 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061339136; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:16,654 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061343232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:26,659 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1061314560; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                        </th><th style=\"text-align: right;\">  agent_timesteps_total</th><th>counters                                                                                                                                                                                          </th><th>custom_metrics  </th><th>date               </th><th>done  </th><th style=\"text-align: right;\">  episode_len_mean</th><th>episode_media  </th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_mean</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episodes_this_iter</th><th style=\"text-align: right;\">  episodes_total</th><th>experiment_id                   </th><th>hostname  </th><th>info  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip       </th><th style=\"text-align: right;\">  num_agent_steps_sampled</th><th style=\"text-align: right;\">  num_agent_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_sampled</th><th style=\"text-align: right;\">  num_env_steps_sampled_this_iter</th><th style=\"text-align: right;\">  num_env_steps_trained</th><th style=\"text-align: right;\">  num_env_steps_trained_this_iter</th><th style=\"text-align: right;\">  num_faulty_episodes</th><th style=\"text-align: right;\">  num_healthy_workers</th><th style=\"text-align: right;\">  num_in_flight_async_reqs</th><th style=\"text-align: right;\">  num_remote_worker_restarts</th><th style=\"text-align: right;\">  num_steps_trained_this_iter</th><th>perf                                                                          </th><th style=\"text-align: right;\">  pid</th><th>policy_reward_max  </th><th>policy_reward_mean  </th><th>policy_reward_min  </th><th>sampler_perf                                                                                                                                                                                                   </th><th>sampler_results                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th>timers                                                                                                                                                                               </th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th style=\"text-align: right;\">  timesteps_total</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SAC_darm_DarmSFHand-v0_6a944_00000</td><td style=\"text-align: right;\">                  13026</td><td>{&#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}</td><td>{}              </td><td>2023-02-11_17-28-35</td><td>False </td><td style=\"text-align: right;\">               100</td><td>{}             </td><td style=\"text-align: right;\">            -166.097</td><td style=\"text-align: right;\">             -179.588</td><td style=\"text-align: right;\">            -189.684</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             132</td><td>2674246d3b814ef583cb37ca785123d2</td><td>Daniel    </td><td>{&#x27;learner&#x27;: {&#x27;default_policy&#x27;: {&#x27;learner_stats&#x27;: {&#x27;allreduce_latency&#x27;: 0.0, &#x27;grad_gnorm&#x27;: 8.40356159210205, &#x27;actor_loss&#x27;: -4.885239601135254, &#x27;critic_loss&#x27;: 0.3069121241569519, &#x27;alpha_loss&#x27;: -2.5390048027038574, &#x27;alpha_value&#x27;: 0.7392387, &#x27;log_alpha_value&#x27;: -0.30213442, &#x27;target_entropy&#x27;: -5.0, &#x27;policy_t&#x27;: -0.029988128691911697, &#x27;mean_q&#x27;: 2.379087448120117, &#x27;max_q&#x27;: 3.1470589637756348, &#x27;min_q&#x27;: 1.5433847904205322}, &#x27;td_error&#x27;: array([7.4213958e-01, 1.5848637e-01, 6.0251343e-01, 9.3348145e-01,\n",
       "       7.2470105e-01, 6.5075898e-01, 7.4386942e-01, 4.2802992e+00,\n",
       "       4.9475217e-01, 2.1274698e-01, 1.5443254e-01, 2.0181298e-01,\n",
       "       4.8542452e-01, 4.9696553e-01, 3.7915547e+00, 8.3584547e-02,\n",
       "       8.3843565e-01, 7.5096285e-01, 6.2452388e-01, 2.4125576e-01,\n",
       "       7.7261329e-01, 2.6608777e-01, 3.3530772e-01, 2.6860654e-01,\n",
       "       1.5399015e-01, 7.0978558e-01, 7.8079522e-01, 1.0731530e-01,\n",
       "       8.8066232e-01, 1.1126903e+00, 3.6070585e-02, 6.7874563e-01,\n",
       "       7.5406009e-01, 4.2981052e-01, 1.1391871e+00, 3.9740098e-01,\n",
       "       1.0762990e+00, 8.4136343e-01, 5.8252001e-01, 4.0861154e-01,\n",
       "       5.6281984e-01, 2.7024639e-01, 6.9000638e-01, 8.6244369e-01,\n",
       "       5.7595563e-01, 7.2603118e-01, 5.9470689e-01, 2.7473211e-01,\n",
       "       5.6826186e-01, 2.4650784e+02, 9.8598832e-01, 7.3479068e-01,\n",
       "       6.1449623e-01, 1.2699622e+00, 7.5296319e-01, 2.8090358e-02,\n",
       "       9.4109213e-01, 8.2771111e-01, 4.2838442e-01, 3.8090675e+00,\n",
       "       4.7546709e-01, 2.4742079e-01, 4.1203547e-01, 7.3801911e-01,\n",
       "       1.0025257e+00, 6.7763782e-01, 6.7099619e-01, 8.6762822e-01,\n",
       "       5.6190348e-01, 8.8954902e-01, 8.1222010e-01, 8.6386180e-01,\n",
       "       7.6953566e-01, 1.0633967e+00, 5.9996891e-01, 5.3750610e-01,\n",
       "       7.0670819e-01, 4.9724150e-01, 3.3370614e-02, 6.8903613e-01,\n",
       "       9.4764221e-01, 5.0915122e-02, 5.0027347e-01, 9.6055913e-01,\n",
       "       5.5192137e-01, 7.9515433e-01, 7.2671640e-01, 3.9931262e-01,\n",
       "       1.8239129e-01, 9.9649012e-01, 8.4206927e-01, 4.1600978e-01,\n",
       "       4.0527940e-01, 7.6102638e-01, 2.3393106e-01, 4.7766042e-01,\n",
       "       2.2459340e-01, 8.5827851e-01, 1.4306033e-01, 2.4650784e+02,\n",
       "       7.1198571e-01, 3.9922416e+00, 1.2246186e+00, 7.4194229e-01,\n",
       "       2.7496171e-01, 4.5212805e-02, 7.4664807e-01, 1.3847947e-02,\n",
       "       8.7445688e-01, 6.6402781e-01, 1.0255686e+00, 4.5125723e-01,\n",
       "       4.8755097e-01, 2.4650784e+02, 4.4124365e-01, 1.0487792e+00,\n",
       "       5.8346188e-01, 2.6959336e-01, 3.5287654e-01, 5.9907603e-01,\n",
       "       4.8603582e-01, 6.1551094e-01, 6.9831514e-01, 5.1433253e-01,\n",
       "       1.8200487e-01, 9.6122825e-01, 7.8497732e-01, 2.2768998e-01,\n",
       "       9.6964097e-01, 1.4972503e+00, 8.0229974e-01, 1.0484257e+00,\n",
       "       5.5421102e-01, 8.3084774e-01, 4.7661805e-01, 3.9173824e-01,\n",
       "       3.1396019e-01, 4.2802992e+00, 2.7052438e-01, 2.6957560e-01,\n",
       "       7.5368738e-01, 4.4456518e-01, 3.1527257e-01, 8.5121763e-01,\n",
       "       9.0664178e-01, 9.4629610e-01, 5.6297445e-01, 5.9285718e-01,\n",
       "       6.3104606e-01, 5.2718985e-01, 6.5370166e-01, 7.0399725e-01,\n",
       "       4.5417070e-02, 2.4650784e+02, 7.2803473e-01, 1.1245636e+00,\n",
       "       3.7708211e-01, 3.7433398e-01, 4.3422055e-01, 3.2808065e-01,\n",
       "       6.2305951e-01, 1.7103601e-01, 7.9449832e-01, 1.3040452e+00,\n",
       "       7.1471536e-01, 4.5487504e+00, 4.1272748e-01, 6.5745860e-01,\n",
       "       6.6768157e-01, 8.8028562e-01, 7.0535421e-01, 5.2402341e-01,\n",
       "       5.6226981e-01, 5.4202604e-01, 2.7826047e-01, 2.6031137e-01,\n",
       "       6.0549617e-02, 3.6561573e-01, 2.4650784e+02, 8.0606019e-01,\n",
       "       8.4074116e-01, 4.9388194e-01, 7.1800745e-01, 2.9282093e-02,\n",
       "       1.9090211e-01, 3.8544512e-01, 1.4638956e+00, 1.4547678e+00,\n",
       "       1.0922147e+00, 2.6176953e-01, 1.3020796e-01, 5.6222248e-01,\n",
       "       5.6339896e-01, 7.6045167e-01, 7.8438163e-01, 7.5755298e-01,\n",
       "       8.2661462e-01, 3.5743856e-01, 1.3571662e-01, 5.3244066e-01,\n",
       "       8.8719201e-01, 8.2828355e-01, 3.8229942e-01, 6.0678411e-01,\n",
       "       4.7898412e-01, 8.2518208e-01, 5.2971601e-01, 6.7987609e-01,\n",
       "       7.6182199e-01, 1.0264168e+00, 6.2066817e-01, 9.0486789e-01,\n",
       "       4.7908902e-01, 1.1681950e-01, 7.6850456e-01, 3.1422675e-01,\n",
       "       9.3148047e-01, 9.5507002e-01, 8.3421135e-01, 5.6414163e-01,\n",
       "       4.1598296e-01, 5.0719857e-02, 9.6793044e-01, 1.4145180e+00,\n",
       "       1.4200950e-01, 8.1434751e-01, 7.0387411e-01, 8.6176515e-01,\n",
       "       6.2346458e-01, 1.4636874e-01, 3.2455921e-01, 1.5807381e+00,\n",
       "       5.9650755e-01, 7.9351628e-01, 1.6089365e+00, 7.5115800e-01,\n",
       "       5.8976293e-01, 4.7450304e-02, 6.6682827e-01, 7.1542680e-01,\n",
       "       4.6520185e-01, 3.4638846e-01, 7.5957966e-01, 4.9341345e-01,\n",
       "       4.8143768e-01, 1.2025452e-01, 6.0646594e-01, 1.1619196e+00,\n",
       "       2.7393532e-01, 8.4904301e-01, 2.5427663e-01, 7.0259297e-01,\n",
       "       5.2577734e-01, 2.9342413e-01, 6.1365223e-01, 9.0736806e-01],\n",
       "      dtype=float32), &#x27;mean_td_error&#x27;: 5.492199897766113, &#x27;model&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;num_agent_steps_trained&#x27;: 256.0, &#x27;num_grad_updates_lifetime&#x27;: 668.0, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: 667.0}}, &#x27;num_env_steps_sampled&#x27;: 13026, &#x27;num_env_steps_trained&#x27;: 258304, &#x27;num_agent_steps_sampled&#x27;: 13026, &#x27;num_agent_steps_trained&#x27;: 258304, &#x27;last_target_update_ts&#x27;: 13026, &#x27;num_target_updates&#x27;: 1009}       </td><td style=\"text-align: right;\">                         2</td><td>192.168.152.36</td><td style=\"text-align: right;\">                    13026</td><td style=\"text-align: right;\">                   258304</td><td style=\"text-align: right;\">                  13026</td><td style=\"text-align: right;\">                             1002</td><td style=\"text-align: right;\">                 258304</td><td style=\"text-align: right;\">                            85504</td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">                         0</td><td style=\"text-align: right;\">                           0</td><td style=\"text-align: right;\">                        85504</td><td>{&#x27;cpu_util_percent&#x27;: 54.76744186046512, &#x27;ram_util_percent&#x27;: 85.32209302325585}</td><td style=\"text-align: right;\">15703</td><td>{}                 </td><td>{}                  </td><td>{}                 </td><td>{&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}</td><td>{&#x27;episode_reward_max&#x27;: -166.09740307927132, &#x27;episode_reward_min&#x27;: -189.6840973868966, &#x27;episode_reward_mean&#x27;: -179.5880893824829, &#x27;episode_len_mean&#x27;: 100.0, &#x27;episode_media&#x27;: {}, &#x27;episodes_this_iter&#x27;: 9, &#x27;policy_reward_min&#x27;: {}, &#x27;policy_reward_max&#x27;: {}, &#x27;policy_reward_mean&#x27;: {}, &#x27;custom_metrics&#x27;: {}, &#x27;hist_stats&#x27;: {&#x27;episode_reward&#x27;: [-187.3498569726944, -166.09740307927132, -172.9712873697281, -187.82146245241165, -176.65354753285646, -183.53197374939919, -176.7706963941455, -189.6840973868966, -175.4124795049429], &#x27;episode_lengths&#x27;: [100, 100, 100, 100, 100, 100, 100, 100, 100]}, &#x27;sampler_perf&#x27;: {&#x27;mean_raw_obs_processing_ms&#x27;: 1.3155451329359085, &#x27;mean_inference_ms&#x27;: 2.6820931912181267, &#x27;mean_action_processing_ms&#x27;: 0.25946855188663404, &#x27;mean_env_wait_ms&#x27;: 3.287473482817159, &#x27;mean_env_render_ms&#x27;: 0.0}, &#x27;num_faulty_episodes&#x27;: 0}</td><td style=\"text-align: right;\">             114.767</td><td style=\"text-align: right;\">            62.318</td><td style=\"text-align: right;\">       227.817</td><td>{&#x27;training_iteration_time_ms&#x27;: 151.985, &#x27;load_time_ms&#x27;: 0.246, &#x27;load_throughput&#x27;: 1042265.409, &#x27;learn_time_ms&#x27;: 25.824, &#x27;learn_throughput&#x27;: 9913.287, &#x27;synch_weights_time_ms&#x27;: 6.049}</td><td style=\"text-align: right;\"> 1676132915</td><td style=\"text-align: right;\">                        0</td><td style=\"text-align: right;\">            13026</td><td style=\"text-align: right;\">                  13</td><td>6a944_00000</td><td style=\"text-align: right;\">      9.03385</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000012)... Done. 0.0s\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:36,665 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055997952; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:46,672 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055973376; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:27:56,678 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1055977472; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:06,689 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056280576; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:16,700 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056186368; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:26,706 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1056030720; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/daniel/DARM/darm_mujoco/darm_training/results/Test_DARMSF_DELTA_TARGET/SAC_darm_DarmSFHand-v0_6a944_00000_0_2023-02-11_17-23-28/checkpoint_000013)... Done. 0.0s\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:36,714 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053261824; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:46,719 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053159424; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:28:56,725 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053106176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:06,732 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053073408; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "2023-02-11 17:29:16,846\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-11 17:29:16,738 E 14732 14777] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-11_17-23-24_266872_14581 is over 95% full, available space: 1053069312; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "2023-02-11 17:29:17,441\tWARNING tune.py:690 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2023-02-11 17:29:20,661\tERROR tune.py:758 -- Trials did not complete: [SAC_darm_DarmSFHand-v0_6a944_00000]\n",
      "2023-02-11 17:29:20,663\tINFO tune.py:762 -- Total run time: 174.25 seconds (174.00 seconds for the tuning loop).\n",
      "2023-02-11 17:29:20,664\tWARNING tune.py:768 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.result_grid.ResultGrid at 0x7fedc40a1d90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resume the interrupted run\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9358c3e3-de5f-4c5e-b284-0884e276e62a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded XML file successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:17:05,090 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144625664; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Reward: -0.044669644004530815, \n",
      " Action: [-0.3416028  -0.35292995  0.07321934 -0.8370828  -0.79603755] \n",
      " Info: {'sim_time': 8.149999999999391, 'action': array([0.        , 0.        , 0.07321934, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.02050434]), 'bonus': array([0.]), 'act_reg': -0.03660966828465462, 'penalty': array([-0.]), 'sparse': array([-0.02050434]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.04466964])}, 'TimeLimit.truncated': True} \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.821191225618935"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use similar environment to what we trained on\n",
    "env = gym.wrappers.TimeLimit(env=DARMSFEnv(render_mode=\"human\", reaction_time=0.08, hand_name=\"hand1\"), max_episode_steps=200)\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "\n",
    "episode_reward = 0\n",
    "done = False\n",
    "\n",
    "res = []\n",
    "\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = algo.compute_single_action(obs)\n",
    "    obs,rew, done, info = env.step(action)\n",
    "    episode_reward += rew\n",
    "    # if info[\"reward\"][\"reach_reward\"] == 100:\n",
    "    #     print(\"Done\")\n",
    "    #     obs = env.reset()\n",
    "    \n",
    "    res.append(f\"Step Reward: {rew}, \\n Action: {action} \\n Info: {info} \\n\\n\\n\")\n",
    "print(f\"Step Reward: {rew}, \\n Action: {action} \\n Info: {info} \\n\\n\\n\")\n",
    "episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e72ce2d-6251-4194-98df-34e22b63751c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.821191225618935"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:17:15,111 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144592896; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:17:25,135 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144580608; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:17:35,157 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144560128; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:17:45,177 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144523264; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "env.close()\n",
    "episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a61e93-8dd5-430d-8f5d-75c5c76677f1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step Reward: 3.984342810409328, \n",
      " Action: [-0.8860119  -0.30007792  0.01995797 -0.8822051  -0.63987327] \n",
      " Info: {'sim_time': 0.08000000000000006, 'action': array([0.        , 0.        , 0.01995797, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00732965]), 'bonus': array([1.]), 'act_reg': -0.00997898355126381, 'penalty': array([-0.]), 'sparse': array([-0.00732965]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98434281])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9829649989700893, \n",
      " Action: [-0.8721748  -0.2886872   0.03908411 -0.87554014 -0.64917165] \n",
      " Info: {'sim_time': 0.16000000000000011, 'action': array([0.        , 0.        , 0.03908411, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.0075404]), 'bonus': array([1.]), 'act_reg': -0.019542057067155838, 'penalty': array([-0.]), 'sparse': array([-0.0075404]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.982965])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9830823392285124, \n",
      " Action: [-0.87441087 -0.29067117  0.03685523 -0.87638426 -0.6478751 ] \n",
      " Info: {'sim_time': 0.24000000000000019, 'action': array([0.        , 0.        , 0.03685523, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00753745]), 'bonus': array([1.]), 'act_reg': -0.018427614122629166, 'penalty': array([-0.]), 'sparse': array([-0.00753745]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98308234])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9830968034470047, \n",
      " Action: [-0.874758   -0.29092026  0.03662098 -0.8768544  -0.6483755 ] \n",
      " Info: {'sim_time': 0.32000000000000023, 'action': array([0.        , 0.        , 0.03662098, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00753607]), 'bonus': array([1.]), 'act_reg': -0.018310490995645523, 'penalty': array([-0.]), 'sparse': array([-0.00753607]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9830968])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9831067965383413, \n",
      " Action: [-0.8751052  -0.29116514  0.03637338 -0.8773379  -0.64888984] \n",
      " Info: {'sim_time': 0.4000000000000003, 'action': array([0.        , 0.        , 0.03637338, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00753727]), 'bonus': array([1.]), 'act_reg': -0.018186692148447037, 'penalty': array([-0.]), 'sparse': array([-0.00753727]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9831068])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983107198280863, \n",
      " Action: [-0.8754612  -0.2914157   0.03610776 -0.87782747 -0.64939696] \n",
      " Info: {'sim_time': 0.48000000000000037, 'action': array([0.        , 0.        , 0.03610776, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00754371]), 'bonus': array([1.]), 'act_reg': -0.018053878098726273, 'penalty': array([-0.]), 'sparse': array([-0.00754371]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9831072])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983116857360427, \n",
      " Action: [-0.8758436  -0.29168445  0.03579292 -0.8783398  -0.6498947 ] \n",
      " Info: {'sim_time': 0.5600000000000004, 'action': array([0.        , 0.        , 0.03579292, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00754675]), 'bonus': array([1.]), 'act_reg': -0.017896462231874466, 'penalty': array([-0.]), 'sparse': array([-0.00754675]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98311686])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983134681421187, \n",
      " Action: [-0.87620085 -0.29193562  0.03552423 -0.8788297  -0.65039897] \n",
      " Info: {'sim_time': 0.6400000000000005, 'action': array([0.        , 0.        , 0.03552423, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00754455]), 'bonus': array([1.]), 'act_reg': -0.017762113362550735, 'penalty': array([-0.]), 'sparse': array([-0.00754455]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98313468])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9831426022406897, \n",
      " Action: [-0.8765203  -0.29215991  0.03532247 -0.87928575 -0.6509104 ] \n",
      " Info: {'sim_time': 0.7200000000000005, 'action': array([0.        , 0.        , 0.03532247, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00754564]), 'bonus': array([1.]), 'act_reg': -0.017661232501268387, 'penalty': array([-0.]), 'sparse': array([-0.00754564]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9831426])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9831512257519073, \n",
      " Action: [-0.8768503  -0.29239172  0.035096   -0.8797482  -0.6514095 ] \n",
      " Info: {'sim_time': 0.8000000000000006, 'action': array([0.      , 0.      , 0.035096, 0.      , 0.      ], dtype=float32), 'reward': {'reach': array([-0.00754699]), 'bonus': array([1.]), 'act_reg': -0.01754799857735634, 'penalty': array([-0.]), 'sparse': array([-0.00754699]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98315123])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983168812028481, \n",
      " Action: [-0.87717223 -0.29261792  0.03487764 -0.880201   -0.65190065] \n",
      " Info: {'sim_time': 0.8800000000000007, 'action': array([0.        , 0.        , 0.03487764, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00754365]), 'bonus': array([1.]), 'act_reg': -0.017438817769289017, 'penalty': array([-0.]), 'sparse': array([-0.00754365]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98316881])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983244551484781, \n",
      " Action: [-0.87746936 -0.2928263   0.03471435 -0.880635   -0.6524123 ] \n",
      " Info: {'sim_time': 0.9600000000000007, 'action': array([0.        , 0.        , 0.03471435, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00750987]), 'bonus': array([1.]), 'act_reg': -0.017357174307107925, 'penalty': array([-0.]), 'sparse': array([-0.00750987]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98324455])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9832428727199916, \n",
      " Action: [-0.8777448  -0.2930208   0.03479481 -0.8811439  -0.653252  ] \n",
      " Info: {'sim_time': 1.0420000000000007, 'action': array([0.        , 0.        , 0.03479481, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00750869]), 'bonus': array([1.]), 'act_reg': -0.017397407442331314, 'penalty': array([-0.]), 'sparse': array([-0.00750869]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98324287])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983257601934726, \n",
      " Action: [-0.87851435 -0.29355896  0.03436337 -0.8822659  -0.6545623 ] \n",
      " Info: {'sim_time': 1.1220000000000008, 'action': array([0.        , 0.        , 0.03436337, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00751211]), 'bonus': array([1.]), 'act_reg': -0.01718168333172798, 'penalty': array([-0.]), 'sparse': array([-0.00751211]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9832576])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9832579226395897, \n",
      " Action: [-0.87926227 -0.29408062  0.03394533 -0.88335586 -0.6558346 ] \n",
      " Info: {'sim_time': 1.2020000000000008, 'action': array([0.        , 0.        , 0.03394533, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00752241]), 'bonus': array([1.]), 'act_reg': -0.01697266474366188, 'penalty': array([-0.]), 'sparse': array([-0.00752241]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98325792])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9832513789363024, \n",
      " Action: [-0.88004607 -0.29462603  0.03349281 -0.8844906  -0.65714085] \n",
      " Info: {'sim_time': 1.282000000000001, 'action': array([0.        , 0.        , 0.03349281, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00753699]), 'bonus': array([1.]), 'act_reg': -0.016746405512094498, 'penalty': array([-0.]), 'sparse': array([-0.00753699]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98325138])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983195743641231, \n",
      " Action: [-0.8808767  -0.29520175  0.03302834 -0.88569874 -0.65854377] \n",
      " Info: {'sim_time': 1.362000000000001, 'action': array([0.        , 0.        , 0.03302834, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00757642]), 'bonus': array([1.]), 'act_reg': -0.016514170914888382, 'penalty': array([-0.]), 'sparse': array([-0.00757642]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98319574])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9832082750038325, \n",
      " Action: [-0.8819807  -0.29596505  0.03230233 -0.88725495 -0.6602354 ] \n",
      " Info: {'sim_time': 1.442000000000001, 'action': array([0.        , 0.        , 0.03230233, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.0075883]), 'bonus': array([1.]), 'act_reg': -0.01615116372704506, 'penalty': array([-0.]), 'sparse': array([-0.0075883]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98320828])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9831749812824224, \n",
      " Action: [-0.8828858  -0.29658896  0.03197799 -0.8886495  -0.66203296] \n",
      " Info: {'sim_time': 1.5220000000000011, 'action': array([0.        , 0.        , 0.03197799, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00761306]), 'bonus': array([1.]), 'act_reg': -0.015988994389772415, 'penalty': array([-0.]), 'sparse': array([-0.00761306]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98317498])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.983107420347184, \n",
      " Action: [-0.88380045 -0.2972171   0.03161142 -0.8900399  -0.6637829 ] \n",
      " Info: {'sim_time': 1.6020000000000012, 'action': array([0.        , 0.        , 0.03161142, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.007656]), 'bonus': array([1.]), 'act_reg': -0.01580571010708809, 'penalty': array([-0.]), 'sparse': array([-0.007656]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98310742])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9830115182937864, \n",
      " Action: [-0.8847633  -0.29787558  0.03113262 -0.89146096 -0.66547614] \n",
      " Info: {'sim_time': 1.6820000000000013, 'action': array([0.        , 0.        , 0.03113262, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00771593]), 'bonus': array([1.]), 'act_reg': -0.015566308051347733, 'penalty': array([-0.]), 'sparse': array([-0.00771593]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98301152])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9828891394052652, \n",
      " Action: [-0.8857704  -0.29856244  0.03054468 -0.8929075  -0.6671078 ] \n",
      " Info: {'sim_time': 1.7620000000000013, 'action': array([0.        , 0.        , 0.03054468, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00779181]), 'bonus': array([1.]), 'act_reg': -0.015272337943315506, 'penalty': array([-0.]), 'sparse': array([-0.00779181]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98288914])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9827425805117267, \n",
      " Action: [-0.886821   -0.29927674  0.02984742 -0.89437765 -0.6686755 ] \n",
      " Info: {'sim_time': 1.8420000000000014, 'action': array([0.        , 0.        , 0.02984742, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00788252]), 'bonus': array([1.]), 'act_reg': -0.014923710376024246, 'penalty': array([-0.]), 'sparse': array([-0.00788252]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.98274258])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: 3.9825743993779956, \n",
      " Action: [-0.88791186 -0.30001706  0.02904148 -0.8958683  -0.6701756 ] \n",
      " Info: {'sim_time': 1.9220000000000015, 'action': array([0.        , 0.        , 0.02904148, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00798676]), 'bonus': array([1.]), 'act_reg': -0.014520738273859024, 'penalty': array([-0.]), 'sparse': array([-0.00798676]), 'solved': array([False]), 'done': array([False]), 'dense': array([3.9825744])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.017618563709704972, \n",
      " Action: [-0.88904065 -0.30078113  0.0281289  -0.89737564 -0.67160416] \n",
      " Info: {'sim_time': 2.004000000000001, 'action': array([0.       , 0.       , 0.0281289, 0.       , 0.       ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00810606]), 'bonus': array([0.]), 'act_reg': -0.014064449816942215, 'penalty': array([-0.]), 'sparse': array([-0.00810606]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01761856])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.017828246908831176, \n",
      " Action: [-0.8902318  -0.30158582  0.02708808 -0.8989314  -0.67298985] \n",
      " Info: {'sim_time': 2.085999999999992, 'action': array([0.        , 0.        , 0.02708808, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00823692]), 'bonus': array([0.]), 'act_reg': -0.01354404166340828, 'penalty': array([-0.]), 'sparse': array([-0.00823692]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01782825])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.018078887408795388, \n",
      " Action: [-0.8914556  -0.3024107   0.02593762 -0.9004947  -0.6742884 ] \n",
      " Info: {'sim_time': 2.167999999999983, 'action': array([0.        , 0.        , 0.02593762, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.008391]), 'bonus': array([0.]), 'act_reg': -0.012968812137842178, 'penalty': array([-0.]), 'sparse': array([-0.008391]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01807889])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.01834973262836799, \n",
      " Action: [-0.89280623 -0.3033201   0.02453733 -0.90216374 -0.6755256 ] \n",
      " Info: {'sim_time': 2.249999999999974, 'action': array([0.        , 0.        , 0.02453733, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00856143]), 'bonus': array([0.]), 'act_reg': -0.012268666177988052, 'penalty': array([-0.]), 'sparse': array([-0.00856143]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01834973])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.018643153039466825, \n",
      " Action: [-0.89424044 -0.30428335  0.0229596  -0.90389764 -0.6767024 ] \n",
      " Info: {'sim_time': 2.3319999999999648, 'action': array([0.       , 0.       , 0.0229596, 0.       , 0.       ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00874759]), 'bonus': array([0.]), 'act_reg': -0.011479798704385757, 'penalty': array([-0.]), 'sparse': array([-0.00874759]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01864315])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.01895874331112797, \n",
      " Action: [-0.89575595 -0.3052994   0.02119935 -0.90569097 -0.6778088 ] \n",
      " Info: {'sim_time': 2.4139999999999557, 'action': array([0.        , 0.        , 0.02119935, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00894939]), 'bonus': array([0.]), 'act_reg': -0.01059967651963234, 'penalty': array([-0.]), 'sparse': array([-0.00894939]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01895874])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.01929558041413386, \n",
      " Action: [-0.89735436 -0.3063689   0.01924551 -0.9075408  -0.6788311 ] \n",
      " Info: {'sim_time': 2.4959999999999467, 'action': array([0.        , 0.        , 0.01924551, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00916665]), 'bonus': array([0.]), 'act_reg': -0.009622756391763687, 'penalty': array([-0.]), 'sparse': array([-0.00916665]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01929558])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.019653021013395725, \n",
      " Action: [-0.89903516 -0.307491    0.01708622 -0.9094414  -0.6797528 ] \n",
      " Info: {'sim_time': 2.5779999999999377, 'action': array([0.        , 0.        , 0.01708622, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00939936]), 'bonus': array([0.]), 'act_reg': -0.008543107658624649, 'penalty': array([-0.]), 'sparse': array([-0.00939936]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.01965302])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.020030105014170765, \n",
      " Action: [-0.90079767 -0.30866557  0.01470748 -0.91138667 -0.6805543 ] \n",
      " Info: {'sim_time': 2.6599999999999286, 'action': array([0.        , 0.        , 0.01470748, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00964737]), 'bonus': array([0.]), 'act_reg': -0.007353741675615311, 'penalty': array([-0.]), 'sparse': array([-0.00964737]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02003011])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02042603366701419, \n",
      " Action: [-0.9026389  -0.3098901   0.01209692 -0.9133661  -0.68121123] \n",
      " Info: {'sim_time': 2.7419999999999196, 'action': array([0.        , 0.        , 0.01209692, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.00991059]), 'bonus': array([0.]), 'act_reg': -0.006048459559679031, 'penalty': array([-0.]), 'sparse': array([-0.00991059]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02042603])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.020839888080414256, \n",
      " Action: [-0.90455455 -0.31116134  0.00924195 -0.91536593 -0.68169665] \n",
      " Info: {'sim_time': 2.8239999999999106, 'action': array([0.        , 0.        , 0.00924195, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.0101889]), 'bonus': array([0.]), 'act_reg': -0.0046209730207920074, 'penalty': array([-0.]), 'sparse': array([-0.0101889]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02083989])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.021270308061052096, \n",
      " Action: [-0.90653586 -0.31247312  0.0061313  -0.9173674  -0.68197584] \n",
      " Info: {'sim_time': 2.9059999999999016, 'action': array([0.       , 0.       , 0.0061313, 0.       , 0.       ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.01048187]), 'bonus': array([0.]), 'act_reg': -0.0030656494200229645, 'penalty': array([-0.]), 'sparse': array([-0.01048187]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02127031])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02171645062493223, \n",
      " Action: [-0.9085683  -0.31381586  0.00275917 -0.9193427  -0.6820076 ] \n",
      " Info: {'sim_time': 2.9879999999998925, 'action': array([0.        , 0.        , 0.00275917, 0.        , 0.        ],\n",
      "      dtype=float32), 'reward': {'reach': array([-0.01078925]), 'bonus': array([0.]), 'act_reg': -0.0013795830309391022, 'penalty': array([-0.]), 'sparse': array([-0.01078925]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02171645])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02222189806514314, \n",
      " Action: [-9.1063315e-01 -3.1517625e-01 -8.7829679e-04 -9.2125583e-01\n",
      " -6.8174028e-01] \n",
      " Info: {'sim_time': 3.0699999999998835, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01111095]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01111095]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.0222219])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.022904084086849658, \n",
      " Action: [-0.912705   -0.3165388  -0.00478172 -0.9230602  -0.68110925] \n",
      " Info: {'sim_time': 3.1519999999998745, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01145204]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01145204]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02290408])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02364526134564756, \n",
      " Action: [-0.9147731  -0.31789404 -0.00900941 -0.92471355 -0.680012  ] \n",
      " Info: {'sim_time': 3.2339999999998654, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01182263]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01182263]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02364526])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.024454795624756026, \n",
      " Action: [-0.91682094 -0.3192312  -0.01367622 -0.92613167 -0.6782411 ] \n",
      " Info: {'sim_time': 3.3159999999998564, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.0122274]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.0122274]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.0244548])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025281750179647778, \n",
      " Action: [-0.9187278  -0.32047078 -0.01879635 -0.9270889  -0.675467  ] \n",
      " Info: {'sim_time': 3.3979999999998474, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01264088]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01264088]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02528175])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02514358972091047, \n",
      " Action: [-0.9201583  -0.32139117 -0.02392163 -0.9272006  -0.6715035 ] \n",
      " Info: {'sim_time': 3.4799999999998383, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01257179]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01257179]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02514359])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025103900420455707, \n",
      " Action: [-0.9198691  -0.3212078  -0.02311944 -0.92706615 -0.6719534 ] \n",
      " Info: {'sim_time': 3.5619999999998293, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255195]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255195]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.0251039])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108098677168025, \n",
      " Action: [-0.91980225 -0.32116553 -0.02288132 -0.92705935 -0.67213416] \n",
      " Info: {'sim_time': 3.6439999999998203, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255405]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255405]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.0251081])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108860418660867, \n",
      " Action: [-0.9198146  -0.3211735  -0.02290448 -0.92707044 -0.6721311 ] \n",
      " Info: {'sim_time': 3.7259999999998112, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255443]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255443]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510886])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02510896918014062, \n",
      " Action: [-0.91981643 -0.3211745  -0.02290877 -0.92707205 -0.6721298 ] \n",
      " Info: {'sim_time': 3.807999999999802, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255448]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255448]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510897])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108983353842533, \n",
      " Action: [-0.9198168  -0.3211748  -0.02290946 -0.92707217 -0.6721296 ] \n",
      " Info: {'sim_time': 3.889999999999793, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510898])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985263657846, \n",
      " Action: [-0.9198168  -0.32117486 -0.02290948 -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 3.971999999999784, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02510898552417645, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.053999999999776, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985558380016, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.1359999999997665, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.02510898556307869, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.2179999999997575, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563700306, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.2999999999997485, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563784315, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.381999999999739, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563795698, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.46399999999973, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.0251089855637973, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.545999999999721, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.627999999999712, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.709999999999703, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.791999999999694, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.873999999999685, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 4.955999999999676, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.037999999999667, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.119999999999658, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.201999999999649, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.28399999999964, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.365999999999631, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.447999999999622, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.529999999999613, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.611999999999604, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.693999999999595, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.775999999999586, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.857999999999577, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 5.939999999999568, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.021999999999559, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.10399999999955, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.185999999999541, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.267999999999532, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.349999999999523, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.431999999999514, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.513999999999505, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.595999999999496, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.677999999999487, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.7599999999994775, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.8419999999994685, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 6.9239999999994595, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.0059999999994504, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.087999999999441, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.169999999999432, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.251999999999423, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.333999999999414, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.415999999999405, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.497999999999396, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.579999999999387, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.661999999999378, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.743999999999369, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.82599999999936, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.907999999999351, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 7.989999999999342, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 8.069999999999364, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}} \n",
      "\n",
      "\n",
      "\n",
      "Step Reward: -0.025108985563797325, \n",
      " Action: [-0.9198169  -0.3211749  -0.0229094  -0.92707205 -0.67212963] \n",
      " Info: {'sim_time': 8.149999999999391, 'action': array([0., 0., 0., 0., 0.], dtype=float32), 'reward': {'reach': array([-0.01255449]), 'bonus': array([0.]), 'act_reg': -0.0, 'penalty': array([-0.]), 'sparse': array([-0.01255449]), 'solved': array([False]), 'done': array([False]), 'dense': array([-0.02510899])}, 'TimeLimit.truncated': True} \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:11:34,464 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145035264; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:11:44,483 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145035264; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:11:54,501 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145027072; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:04,519 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145022976; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:14,538 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 145002496; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:24,558 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144986112; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:34,579 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144986112; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:44,596 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144982016; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:12:54,616 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144977920; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:13:04,635 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144842752; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:13:14,653 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144818176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:13:24,671 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144814080; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-15 02:13:34,689 E 27340 27387] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-15_02-08-02_051251_27228 is over 95% full, available space: 144814080; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "[print(i) for i in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e583cf79-0485-4366-990e-c8147bcac849",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/tune/trainable/trainable.py:1019\u001b[0m, in \u001b[0;36mTrainable.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_monitor\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_logfiles()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/algorithms/es/es.py:562\u001b[0m, in \u001b[0;36mES.cleanup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;129m@override\u001b[39m(Algorithm)\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcleanup\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:631\u001b[0m, in \u001b[0;36mWorkerSet.stop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;124;03m\"\"\"Calls `stop` on all rollout workers (including the local one).\"\"\"\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# Make sure we stop all workers, include the ones that were just\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;66;03m# restarted / recovered.\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    635\u001b[0m     logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to stop workers!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py:688\u001b[0m, in \u001b[0;36mWorkerSet.foreach_worker\u001b[0;34m(self, func, local_worker, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m local_worker \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m     local_result \u001b[38;5;241m=\u001b[39m [func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_worker())]\n\u001b[0;32m--> 688\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__worker_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    696\u001b[0m handle_remote_call_result_errors(remote_results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_worker_failures)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py:574\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.foreach_actor\u001b[0;34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    565\u001b[0m     func, remote_actor_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_func_and_remote_actor_id_by_state(\n\u001b[1;32m    566\u001b[0m         func, remote_actor_ids\n\u001b[1;32m    567\u001b[0m     )\n\u001b[1;32m    569\u001b[0m remote_calls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_actors(\n\u001b[1;32m    570\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    571\u001b[0m     remote_actor_ids\u001b[38;5;241m=\u001b[39mremote_actor_ids,\n\u001b[1;32m    572\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m _, remote_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/utils/actor_manager.py:453\u001b[0m, in \u001b[0;36mFaultTolerantActorManager.__fetch_result\u001b[0;34m(self, remote_actor_ids, remote_calls, timeout_seconds, return_obj_refs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;66;03m# Notice that we do not return the refs to any unfinished calls to the\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;66;03m# user, since it is not safe to handle such remote actor calls outside the\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;66;03m# context of this actor manager. These requests are simply dropped.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(timeout_seconds) \u001b[38;5;28;01mif\u001b[39;00m timeout_seconds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m ready, _ \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m remote_results \u001b[38;5;241m=\u001b[39m RemoteCallResults()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/_private/worker.py:2496\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[1;32m   2494\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m\n\u001b[1;32m   2495\u001b[0m timeout_milliseconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m-> 2496\u001b[0m ready_ids, remaining_ids \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1759\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:195\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "algo.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f42fe0e-96f4-403d-8018-af9f40ff5ade",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanieladejumo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:12:20,557 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72884224; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/daniel/DARM/darm_mujoco/darm_training/wandb/run-20230214_031215-gtql76dz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/danieladejumo/darm_mujoco-darm_training/runs/gtql76dz' target=\"_blank\">passionate-balloon-3</a></strong> to <a href='https://wandb.ai/danieladejumo/darm_mujoco-darm_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/danieladejumo/darm_mujoco-darm_training' target=\"_blank\">https://wandb.ai/danieladejumo/darm_mujoco-darm_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/danieladejumo/darm_mujoco-darm_training/runs/gtql76dz' target=\"_blank\">https://wandb.ai/danieladejumo/darm_mujoco-darm_training/runs/gtql76dz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "479975aa-8999-4078-a7f6-366e7a6741b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = run.use_artifact('danieladejumo/DARM/checkpoint_SF_rllib_es_vast_ai:v3', type='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c454ebe0-1ce6-46e5-a746-f755e30b3249",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4 of 4 files downloaded.  \n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:12:30,571 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72368128; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "artifact_dir = artifact.download(root=\"/home/daniel/DARM/darm_mujoco/darm_training/results/vast_ai_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "565687a2-2ed9-45d7-bb57-1076532240bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/home/daniel/DARM/darm_mujoco/darm_training/results/vast_ai_checkpoints': No such file or directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:12:40,589 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72364032; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:12:50,607 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72351744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:00,615 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72355840; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:10,626 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72351744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:20,637 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72351744; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:30,649 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72294400; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:40,657 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72265728; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:13:50,668 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72257536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:00,677 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72241152; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:10,691 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72196096; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:20,704 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72114176; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:30,723 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72056832; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:40,740 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72024064; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:14:50,758 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72024064; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:00,775 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 72019968; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:10,791 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71999488; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:20,807 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71995392; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:30,824 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71970816; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:40,840 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71958528; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:15:50,856 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71950336; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:00,874 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71950336; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:10,892 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 71921664; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:20,904 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 70557696; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:30,919 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 70623232; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:40,933 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 56385536; capacity: 31845081088. Object creation will fail if spilling is required.\n",
      "\u001b[2m\u001b[33m(raylet)\u001b[0m [2023-02-14 03:16:50,948 E 13144 13195] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2023-02-14_02-59-27_105877_12500 is over 95% full, available space: 56381440; capacity: 31845081088. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "!ls /home/daniel/DARM/darm_mujoco/darm_training/results/vast_ai_checkpoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
